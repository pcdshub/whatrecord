{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"whatrecord What is this? whatrecord provides a variety of independent tools that work together as part of a larger web-facing application for gathering information about EPICS IOCs and related files. Lark grammar-based parsers Lark-based grammars allow for parsing any of the following into easy-to-use Python dataclasses: EPICS access security files (.acf) EPICS autosave save files (.sav) EPICS V3 database files EPICS V4 database files EPICS msi-style template/substitutions files (.template/.substitutions) EPICS gateway configuration (.pvlist) EPICS sequencer state notation language programs (.st) EPICS StreamDevice protocols (.proto) All of the above can be easily serialized to JSON for interoperability. Pseudo-IOC shell interpreter Reads st.cmd files as if whatrecord were the IOC process Loads and lints record files (and other supported formats above) Builds inter- and intra- IOC PV relationship graphs Stores context information about where each record/field/etc came from API server IOC finder (LCLS IOC manager, list of files, or external script) Provides access to all parsed information above Preliminary asyncio-based client to talk with the server Frontend This is a user-friendly vue.js v3 frontend that communicates with API server. It contains interfaces for: Searching for records Record relationships (processing and links, cross-IOC links) IOC information Gateway configuration overview Duplicate records Optional plugins API server logs Plugins happi devices Simple LDAP search (LCLS hosts, \"netconfig\") LCLS-specific epicsArch / logbook DAQ PVs TwinCAT PLC source code (pytmc) Makefile / build system information Determine build dependencies from a Makefile Recursively inspect sub-dependencies Graph IOC dependency information or output it as JSON Command-line tools whatrecord lint - lint a database whatrecord parse - parse supported formats to JSON whatrecord server - start the API server whatrecord graph - graph PV relationships, SNL diagrams, IOC dependencies Plugins can similarly be executed to provide parsed information in JSON Installing $ pip install whatrecord Starting the server See Server / client for more information. Fair warning whatrecord isn\u2019t error or bug-free whatrecord aims to be as compliant as possible when parsing the formats it supports, but there may be discrepancies. If you find a case where it parses something incorrectly (or doesn't parse it at all) please create an issue. whatrecord isn\u2019t a good example of how to store relational data. The initial goals were breadth-first feature support: Parse and interpret everything: in-memory dataclasses storing all information Get it to be displayed in a friendly way Efficient storage can be tackled later! Database-backed information along with and corresponding backend/frontend changes will need to be pursued Background This started out as a project where I thought I'd reuse as much of epics-base as possible to generate information about IOCs for easy indexing, and all the while learn about some modern web development practices. In no particular order, the project has gone through some transformations: I ended up writing a bunch of Lark grammars which effectively replaced the need for epics-pypdb and other miscellaneous core stuff in epics-base. the possibilities for such a tool became more clear to me, specifically targetting EPICS IOC record debugging. I was curious if we were using pva2pva at all. So now the grammars will load up pvAccess Q:group tags. But it's likely not 100% correct, and certainly not complete. I had other thoughts about what could be integrated (gateway, happi, pytmc, IOC dependencies, versions, ...) It's likely this hasn't finished morphing just yet. I definitely need to circle back and clean up the initial prototype mess.","title":"whatrecord"},{"location":"#whatrecord","text":"","title":"whatrecord"},{"location":"#what-is-this","text":"whatrecord provides a variety of independent tools that work together as part of a larger web-facing application for gathering information about EPICS IOCs and related files.","title":"What is this?"},{"location":"#lark-grammar-based-parsers","text":"Lark-based grammars allow for parsing any of the following into easy-to-use Python dataclasses: EPICS access security files (.acf) EPICS autosave save files (.sav) EPICS V3 database files EPICS V4 database files EPICS msi-style template/substitutions files (.template/.substitutions) EPICS gateway configuration (.pvlist) EPICS sequencer state notation language programs (.st) EPICS StreamDevice protocols (.proto) All of the above can be easily serialized to JSON for interoperability.","title":"Lark grammar-based parsers"},{"location":"#pseudo-ioc-shell-interpreter","text":"Reads st.cmd files as if whatrecord were the IOC process Loads and lints record files (and other supported formats above) Builds inter- and intra- IOC PV relationship graphs Stores context information about where each record/field/etc came from","title":"Pseudo-IOC shell interpreter"},{"location":"#api-server","text":"IOC finder (LCLS IOC manager, list of files, or external script) Provides access to all parsed information above Preliminary asyncio-based client to talk with the server","title":"API server"},{"location":"#frontend","text":"This is a user-friendly vue.js v3 frontend that communicates with API server. It contains interfaces for: Searching for records Record relationships (processing and links, cross-IOC links) IOC information Gateway configuration overview Duplicate records Optional plugins API server logs","title":"Frontend"},{"location":"#plugins","text":"happi devices Simple LDAP search (LCLS hosts, \"netconfig\") LCLS-specific epicsArch / logbook DAQ PVs TwinCAT PLC source code (pytmc)","title":"Plugins"},{"location":"#makefile-build-system-information","text":"Determine build dependencies from a Makefile Recursively inspect sub-dependencies Graph IOC dependency information or output it as JSON","title":"Makefile / build system information"},{"location":"#command-line-tools","text":"whatrecord lint - lint a database whatrecord parse - parse supported formats to JSON whatrecord server - start the API server whatrecord graph - graph PV relationships, SNL diagrams, IOC dependencies Plugins can similarly be executed to provide parsed information in JSON","title":"Command-line tools"},{"location":"#installing","text":"$ pip install whatrecord","title":"Installing"},{"location":"#starting-the-server","text":"See Server / client for more information.","title":"Starting the server"},{"location":"#fair-warning","text":"whatrecord isn\u2019t error or bug-free whatrecord aims to be as compliant as possible when parsing the formats it supports, but there may be discrepancies. If you find a case where it parses something incorrectly (or doesn't parse it at all) please create an issue. whatrecord isn\u2019t a good example of how to store relational data. The initial goals were breadth-first feature support: Parse and interpret everything: in-memory dataclasses storing all information Get it to be displayed in a friendly way Efficient storage can be tackled later! Database-backed information along with and corresponding backend/frontend changes will need to be pursued","title":"Fair warning"},{"location":"#background","text":"This started out as a project where I thought I'd reuse as much of epics-base as possible to generate information about IOCs for easy indexing, and all the while learn about some modern web development practices. In no particular order, the project has gone through some transformations: I ended up writing a bunch of Lark grammars which effectively replaced the need for epics-pypdb and other miscellaneous core stuff in epics-base. the possibilities for such a tool became more clear to me, specifically targetting EPICS IOC record debugging. I was curious if we were using pva2pva at all. So now the grammars will load up pvAccess Q:group tags. But it's likely not 100% correct, and certainly not complete. I had other thoughts about what could be integrated (gateway, happi, pytmc, IOC dependencies, versions, ...) It's likely this hasn't finished morphing just yet. I definitely need to circle back and clean up the initial prototype mess.","title":"Background"},{"location":"cli/","text":"CLI Top-level options: usage: whatrecord [-h] [--version] [--log LOG_LEVEL] {info,iocmanager-loader,lint,parse,server} ... `whatrecord` is the top-level command for accessing various subcommands. Try:: $ whatrecord info --help $ whatrecord iocmanager-loader --help $ whatrecord lint --help $ whatrecord parse --help $ whatrecord server --help positional arguments: {info,iocmanager-loader,lint,parse,server} Possible subcommands optional arguments: -h, --help show this help message and exit --version, -V Show the whatrec version number and exit. --log LOG_LEVEL, -l LOG_LEVEL Python logging level (e.g. DEBUG, INFO, WARNING) lint whatrecord lint is used to lint a startup script or database file. See if there are errors in your database file, startup script contents, etc. usage: whatrecord lint [-h] [--dbd DBD] [--standin-directory [STANDIN_DIRECTORY ...]] [--json] [-v] [--use-gdb] filename \"whatrecord lint\" is used to lint a startup script or database file. positional arguments: filename Startup script filename optional arguments: -h, --help show this help message and exit --dbd DBD The dbd file, if parsing a database --standin-directory [STANDIN_DIRECTORY ...] Map a \"stand-in\" directory to another on disk --json -v, --verbose Increase verbosity --use-gdb Use metadata derived from the script binary parse \"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default. usage: whatrecord parse [-h] [--format FORMAT] [--dbd DBD] [--standin-directory [STANDIN_DIRECTORY ...]] [--macros MACROS] [--friendly] [--friendly-format FRIENDLY_FORMAT] [--use-gdb] [--expand] filename \"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default. positional arguments: filename Startup script filename optional arguments: -h, --help show this help message and exit --format FORMAT The file format. For files that lack a recognized extension or are otherwise misidentified by whatrecord. --dbd DBD The dbd file, if parsing a database --standin-directory [STANDIN_DIRECTORY ...] Map a \"stand-in\" directory to another on disk --macros MACROS Macro to add, in the usual form ``macro=value,...`` --friendly Output Python object representation instead of JSON --friendly-format FRIENDLY_FORMAT Output Python object representation instead of JSON --use-gdb Use metadata derived from the script binary --expand Expand a substitutions file, as in the msi tool server This is how to start the API server. usage: whatrecord server [-h] [--scripts [SCRIPTS ...]] [--script-loader [SCRIPT_LOADER ...]] [--archive-management-url ARCHIVE_MANAGEMENT_URL] [--gateway-config GATEWAY_CONFIG] [--standin-directory [STANDIN_DIRECTORY ...]] [--port PORT] [--tracemalloc] \"whatrecord server\" is used to start an aiohttp-backed web server which hosts startup script and record information. optional arguments: -h, --help show this help message and exit --scripts [SCRIPTS ...] Startup script filename(s) --script-loader [SCRIPT_LOADER ...] Run an external script to get IOC configuration information --archive-management-url ARCHIVE_MANAGEMENT_URL Archiver management URL for finding archived PVs. --gateway-config GATEWAY_CONFIG Gateway configuration file or directory --standin-directory [STANDIN_DIRECTORY ...] Map a \"stand-in\" directory to another on disk --port PORT Web server TCP port --tracemalloc [Debug] Use tracemalloc to debug server memory usage info whatrecord info talks to the API server to get information about a record. usage: whatrecord info [-h] [--json] records [records ...] \"whatrecord info\" is used to get PV information from the whatrecord server. positional arguments: records Record name(s) optional arguments: -h, --help show this help message and exit --json Output raw JSON API whatrecord.bin special Modules whatrecord.bin.deps \"whatrecord deps\" is used to get dependency information from EPICS IOC or module Makefiles. Under the hood, this uses GNU make, which is an external dependency required for correct functionality. whatrecord.bin.graph \"whatrecord graph\" is used to parse and generate a relationship graph of whatrecord-supported file types. Functions whatrecord . bin . graph . get_database_graph ( * loaded_items : DatabaseItem , * , highlight : Optional [ List [ str ]] = None ) -> RecordLinkGraph Get a database graph from a number of database items. Source code in whatrecord/bin/graph.py def get_database_graph ( * loaded_items : DatabaseItem , highlight : Optional [ List [ str ]] = None , ) -> RecordLinkGraph : \"\"\" Get a database graph from a number of database items. \"\"\" database = Database . from_multiple ( * loaded_items ) starting_records = _records_by_patterns ( database , highlight ) if highlight else [] relations = build_database_relations ( database = database . records , record_types = database . record_types or {}, aliases = database . aliases or {}, ) return graph_links ( database = database . records , starting_records = starting_records , relations = relations , ) whatrecord.bin.info \"whatrecord info\" is used to get PV information from the whatrecord server. whatrecord.bin.iocmanager_loader \"whatrecord iocmanager-loader\" is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files. whatrecord.bin.lint \"whatrecord lint\" is used to lint a startup script or database file. Functions whatrecord . bin . lint . lint ( obj : Union [ whatrecord . db . Database , whatrecord . shell . LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = < _io . StringIO object at 0x105330af0 > , fmt : FormatContext = None ) -> Union [ whatrecord . db . Database , whatrecord . shell . LoadedIoc ] Lint a startup script or a database file. Parameters: Name Type Description Default obj Union[whatrecord.db.Database, whatrecord.shell.LoadedIoc] The object to lint. required Source code in whatrecord/bin/lint.py def lint ( obj : Union [ Database , LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ) -> Union [ Database , LoadedIoc ]: \"\"\" Lint a startup script or a database file. Parameters ---------- obj : The object to lint. \"\"\" fmt = fmt or FormatContext () if isinstance ( obj , LoadedIoc ): commands = obj . metadata . commands # variables = obj.metadata.variables for line in obj . script . lines : if line . line or verbosity > 2 : if line . error or verbosity > 1 : print ( fmt . render_object ( line ) . rstrip (), file = file ) if commands and line . argv : command_info = commands . get ( line . argv [ 0 ], None ) lint_command ( command_info = command_info , argv = line . argv , file = file , fmt = fmt ) whatrecord . bin . lint . lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = < _io . StringIO object at 0x105330af0 > , fmt : FormatContext = None ) Lint a command given its argumenet information. Source code in whatrecord/bin/lint.py def lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ): \"\"\"Lint a command given its argumenet information.\"\"\" if not command_info : print ( f \" ! Warning: Unknown command: { argv [ 0 ] } \" ) return expected_args = command_info . args actual_args = argv [ 1 :] arg_names = [ arg . name for arg in expected_args ] if len ( actual_args ) == len ( expected_args ): return if len ( actual_args ) < len ( expected_args ): arg_names = [ arg . name for arg in expected_args ] arg_values = list ( actual_args ) + [ \"?\" ] * ( len ( expected_args ) - len ( actual_args )) print ( \" ! Warning: may be too few arguments\" , file = file ) else : print ( \" ! Warning: too many arguments\" , file = file ) arg_names = [ arg . name for arg in expected_args ] + [ \"?\" ] * ( len ( actual_args ) - len ( expected_args )) arg_values = actual_args for idx , ( arg_name , value ) in enumerate ( zip ( arg_names , arg_values ), 1 ): print ( f \" { idx } . { arg_name } = { value } \" , file = file ) print ( file = file ) whatrecord.bin.main whatrecord is the top-level command for accessing various subcommands. Try:: whatrecord.bin.parse \"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default. Functions whatrecord . bin . parse . parse_from_cli_args ( filename : Union [ str , pathlib . Path ], dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False ) -> Union [ whatrecord . access_security . AccessSecurityConfig , whatrecord . db . Database , whatrecord . gateway . PVList , whatrecord . db . LinterResults , whatrecord . shell . LoadedIoc , whatrecord . snl . SequencerProgram , whatrecord . streamdevice . StreamProtocol , whatrecord . dbtemplate . TemplateSubstitution , whatrecord . makefile . Makefile ] Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that parse expects. For programmatic usage, please use parse() directly. Parameters: Name Type Description Default filename Union[str, pathlib.Path] The filename to parse. required dbd Optional[str] The associated database definition file, if parsing a database file. None standin_directories list A list of substitute directories of the form DirectoryA=DirectoryB . required macros Optional[str] Macro string to use when parsing the file. None expand bool Expand a substitutions file. False v3 bool Use V3 database grammar where applicable. False Source code in whatrecord/bin/parse.py def parse_from_cli_args ( filename : AnyPath , dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False , ) -> ParseResult : \"\"\" Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that `parse` expects. For programmatic usage, please use ``parse()`` directly. Parameters ---------- filename : str or pathlib.Path The filename to parse. dbd : str or pathlib.Path, optional The associated database definition file, if parsing a database file. standin_directories : list, optional A list of substitute directories of the form ``DirectoryA=DirectoryB``. macros : str, optional Macro string to use when parsing the file. expand : bool, optional Expand a substitutions file. v3 : bool, optional Use V3 database grammar where applicable. \"\"\" standin_directories = dict ( path . split ( \"=\" , 1 ) for path in standin_directory or \"\" ) if isinstance ( filename , str ) and filename . startswith ( \"{\" ): # } # TODO - argparse fixup? ioc_metadata = IocMetadata . from_dict ( json . loads ( filename )) # TODO macros, use_gdb, ... # ioc_metadata.macros = macros return LoadedIoc . from_metadata ( ioc_metadata ) try : format = FileFormat ( format ) if format is not None else None except ValueError : options = [ fmt . name for fmt in list ( FileFormat )] raise ValueError ( f \" { format !r} is not a valid FileFormat. Options include: \" f \" { options } \" ) return parse ( filename , dbd = dbd , standin_directories = standin_directories , macros = macros , use_gdb = use_gdb , format = format , expand = expand , v3 = v3 , ) whatrecord.bin.server \"whatrecord server\" is used to start an aiohttp-backed web server which hosts startup script and record information. whatrecord.bin.main whatrecord is the top-level command for accessing various subcommands. Try:: whatrecord.bin.lint \"whatrecord lint\" is used to lint a startup script or database file. Functions whatrecord . bin . lint . lint ( obj : Union [ whatrecord . db . Database , whatrecord . shell . LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = < _io . StringIO object at 0x105330af0 > , fmt : FormatContext = None ) -> Union [ whatrecord . db . Database , whatrecord . shell . LoadedIoc ] Lint a startup script or a database file. Parameters: Name Type Description Default obj Union[whatrecord.db.Database, whatrecord.shell.LoadedIoc] The object to lint. required Source code in whatrecord/bin/lint.py def lint ( obj : Union [ Database , LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ) -> Union [ Database , LoadedIoc ]: \"\"\" Lint a startup script or a database file. Parameters ---------- obj : The object to lint. \"\"\" fmt = fmt or FormatContext () if isinstance ( obj , LoadedIoc ): commands = obj . metadata . commands # variables = obj.metadata.variables for line in obj . script . lines : if line . line or verbosity > 2 : if line . error or verbosity > 1 : print ( fmt . render_object ( line ) . rstrip (), file = file ) if commands and line . argv : command_info = commands . get ( line . argv [ 0 ], None ) lint_command ( command_info = command_info , argv = line . argv , file = file , fmt = fmt ) whatrecord . bin . lint . lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = < _io . StringIO object at 0x105330af0 > , fmt : FormatContext = None ) Lint a command given its argumenet information. Source code in whatrecord/bin/lint.py def lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ): \"\"\"Lint a command given its argumenet information.\"\"\" if not command_info : print ( f \" ! Warning: Unknown command: { argv [ 0 ] } \" ) return expected_args = command_info . args actual_args = argv [ 1 :] arg_names = [ arg . name for arg in expected_args ] if len ( actual_args ) == len ( expected_args ): return if len ( actual_args ) < len ( expected_args ): arg_names = [ arg . name for arg in expected_args ] arg_values = list ( actual_args ) + [ \"?\" ] * ( len ( expected_args ) - len ( actual_args )) print ( \" ! Warning: may be too few arguments\" , file = file ) else : print ( \" ! Warning: too many arguments\" , file = file ) arg_names = [ arg . name for arg in expected_args ] + [ \"?\" ] * ( len ( actual_args ) - len ( expected_args )) arg_values = actual_args for idx , ( arg_name , value ) in enumerate ( zip ( arg_names , arg_values ), 1 ): print ( f \" { idx } . { arg_name } = { value } \" , file = file ) print ( file = file ) whatrecord.bin.parse \"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default. Functions whatrecord . bin . parse . parse_from_cli_args ( filename : Union [ str , pathlib . Path ], dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False ) -> Union [ whatrecord . access_security . AccessSecurityConfig , whatrecord . db . Database , whatrecord . gateway . PVList , whatrecord . db . LinterResults , whatrecord . shell . LoadedIoc , whatrecord . snl . SequencerProgram , whatrecord . streamdevice . StreamProtocol , whatrecord . dbtemplate . TemplateSubstitution , whatrecord . makefile . Makefile ] Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that parse expects. For programmatic usage, please use parse() directly. Parameters: Name Type Description Default filename Union[str, pathlib.Path] The filename to parse. required dbd Optional[str] The associated database definition file, if parsing a database file. None standin_directories list A list of substitute directories of the form DirectoryA=DirectoryB . required macros Optional[str] Macro string to use when parsing the file. None expand bool Expand a substitutions file. False v3 bool Use V3 database grammar where applicable. False Source code in whatrecord/bin/parse.py def parse_from_cli_args ( filename : AnyPath , dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False , ) -> ParseResult : \"\"\" Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that `parse` expects. For programmatic usage, please use ``parse()`` directly. Parameters ---------- filename : str or pathlib.Path The filename to parse. dbd : str or pathlib.Path, optional The associated database definition file, if parsing a database file. standin_directories : list, optional A list of substitute directories of the form ``DirectoryA=DirectoryB``. macros : str, optional Macro string to use when parsing the file. expand : bool, optional Expand a substitutions file. v3 : bool, optional Use V3 database grammar where applicable. \"\"\" standin_directories = dict ( path . split ( \"=\" , 1 ) for path in standin_directory or \"\" ) if isinstance ( filename , str ) and filename . startswith ( \"{\" ): # } # TODO - argparse fixup? ioc_metadata = IocMetadata . from_dict ( json . loads ( filename )) # TODO macros, use_gdb, ... # ioc_metadata.macros = macros return LoadedIoc . from_metadata ( ioc_metadata ) try : format = FileFormat ( format ) if format is not None else None except ValueError : options = [ fmt . name for fmt in list ( FileFormat )] raise ValueError ( f \" { format !r} is not a valid FileFormat. Options include: \" f \" { options } \" ) return parse ( filename , dbd = dbd , standin_directories = standin_directories , macros = macros , use_gdb = use_gdb , format = format , expand = expand , v3 = v3 , ) whatrecord.bin.server \"whatrecord server\" is used to start an aiohttp-backed web server which hosts startup script and record information.","title":"CLI"},{"location":"cli/#cli","text":"Top-level options: usage: whatrecord [-h] [--version] [--log LOG_LEVEL] {info,iocmanager-loader,lint,parse,server} ... `whatrecord` is the top-level command for accessing various subcommands. Try:: $ whatrecord info --help $ whatrecord iocmanager-loader --help $ whatrecord lint --help $ whatrecord parse --help $ whatrecord server --help positional arguments: {info,iocmanager-loader,lint,parse,server} Possible subcommands optional arguments: -h, --help show this help message and exit --version, -V Show the whatrec version number and exit. --log LOG_LEVEL, -l LOG_LEVEL Python logging level (e.g. DEBUG, INFO, WARNING)","title":"CLI"},{"location":"cli/#lint","text":"whatrecord lint is used to lint a startup script or database file. See if there are errors in your database file, startup script contents, etc. usage: whatrecord lint [-h] [--dbd DBD] [--standin-directory [STANDIN_DIRECTORY ...]] [--json] [-v] [--use-gdb] filename \"whatrecord lint\" is used to lint a startup script or database file. positional arguments: filename Startup script filename optional arguments: -h, --help show this help message and exit --dbd DBD The dbd file, if parsing a database --standin-directory [STANDIN_DIRECTORY ...] Map a \"stand-in\" directory to another on disk --json -v, --verbose Increase verbosity --use-gdb Use metadata derived from the script binary","title":"lint"},{"location":"cli/#parse","text":"\"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default. usage: whatrecord parse [-h] [--format FORMAT] [--dbd DBD] [--standin-directory [STANDIN_DIRECTORY ...]] [--macros MACROS] [--friendly] [--friendly-format FRIENDLY_FORMAT] [--use-gdb] [--expand] filename \"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default. positional arguments: filename Startup script filename optional arguments: -h, --help show this help message and exit --format FORMAT The file format. For files that lack a recognized extension or are otherwise misidentified by whatrecord. --dbd DBD The dbd file, if parsing a database --standin-directory [STANDIN_DIRECTORY ...] Map a \"stand-in\" directory to another on disk --macros MACROS Macro to add, in the usual form ``macro=value,...`` --friendly Output Python object representation instead of JSON --friendly-format FRIENDLY_FORMAT Output Python object representation instead of JSON --use-gdb Use metadata derived from the script binary --expand Expand a substitutions file, as in the msi tool","title":"parse"},{"location":"cli/#server","text":"This is how to start the API server. usage: whatrecord server [-h] [--scripts [SCRIPTS ...]] [--script-loader [SCRIPT_LOADER ...]] [--archive-management-url ARCHIVE_MANAGEMENT_URL] [--gateway-config GATEWAY_CONFIG] [--standin-directory [STANDIN_DIRECTORY ...]] [--port PORT] [--tracemalloc] \"whatrecord server\" is used to start an aiohttp-backed web server which hosts startup script and record information. optional arguments: -h, --help show this help message and exit --scripts [SCRIPTS ...] Startup script filename(s) --script-loader [SCRIPT_LOADER ...] Run an external script to get IOC configuration information --archive-management-url ARCHIVE_MANAGEMENT_URL Archiver management URL for finding archived PVs. --gateway-config GATEWAY_CONFIG Gateway configuration file or directory --standin-directory [STANDIN_DIRECTORY ...] Map a \"stand-in\" directory to another on disk --port PORT Web server TCP port --tracemalloc [Debug] Use tracemalloc to debug server memory usage","title":"server"},{"location":"cli/#info","text":"whatrecord info talks to the API server to get information about a record. usage: whatrecord info [-h] [--json] records [records ...] \"whatrecord info\" is used to get PV information from the whatrecord server. positional arguments: records Record name(s) optional arguments: -h, --help show this help message and exit --json Output raw JSON","title":"info"},{"location":"cli/#api","text":"","title":"API"},{"location":"cli/#whatrecord.bin","text":"","title":"bin"},{"location":"cli/#whatrecord.bin-modules","text":"","title":"Modules"},{"location":"cli/#whatrecord.bin.deps","text":"\"whatrecord deps\" is used to get dependency information from EPICS IOC or module Makefiles. Under the hood, this uses GNU make, which is an external dependency required for correct functionality.","title":"deps"},{"location":"cli/#whatrecord.bin.graph","text":"\"whatrecord graph\" is used to parse and generate a relationship graph of whatrecord-supported file types.","title":"graph"},{"location":"cli/#whatrecord.bin.graph-functions","text":"whatrecord . bin . graph . get_database_graph ( * loaded_items : DatabaseItem , * , highlight : Optional [ List [ str ]] = None ) -> RecordLinkGraph Get a database graph from a number of database items. Source code in whatrecord/bin/graph.py def get_database_graph ( * loaded_items : DatabaseItem , highlight : Optional [ List [ str ]] = None , ) -> RecordLinkGraph : \"\"\" Get a database graph from a number of database items. \"\"\" database = Database . from_multiple ( * loaded_items ) starting_records = _records_by_patterns ( database , highlight ) if highlight else [] relations = build_database_relations ( database = database . records , record_types = database . record_types or {}, aliases = database . aliases or {}, ) return graph_links ( database = database . records , starting_records = starting_records , relations = relations , )","title":"Functions"},{"location":"cli/#whatrecord.bin.info","text":"\"whatrecord info\" is used to get PV information from the whatrecord server.","title":"info"},{"location":"cli/#whatrecord.bin.iocmanager_loader","text":"\"whatrecord iocmanager-loader\" is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files.","title":"iocmanager_loader"},{"location":"cli/#whatrecord.bin.lint","text":"\"whatrecord lint\" is used to lint a startup script or database file.","title":"lint"},{"location":"cli/#whatrecord.bin.lint-functions","text":"whatrecord . bin . lint . lint ( obj : Union [ whatrecord . db . Database , whatrecord . shell . LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = < _io . StringIO object at 0x105330af0 > , fmt : FormatContext = None ) -> Union [ whatrecord . db . Database , whatrecord . shell . LoadedIoc ] Lint a startup script or a database file. Parameters: Name Type Description Default obj Union[whatrecord.db.Database, whatrecord.shell.LoadedIoc] The object to lint. required Source code in whatrecord/bin/lint.py def lint ( obj : Union [ Database , LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ) -> Union [ Database , LoadedIoc ]: \"\"\" Lint a startup script or a database file. Parameters ---------- obj : The object to lint. \"\"\" fmt = fmt or FormatContext () if isinstance ( obj , LoadedIoc ): commands = obj . metadata . commands # variables = obj.metadata.variables for line in obj . script . lines : if line . line or verbosity > 2 : if line . error or verbosity > 1 : print ( fmt . render_object ( line ) . rstrip (), file = file ) if commands and line . argv : command_info = commands . get ( line . argv [ 0 ], None ) lint_command ( command_info = command_info , argv = line . argv , file = file , fmt = fmt ) whatrecord . bin . lint . lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = < _io . StringIO object at 0x105330af0 > , fmt : FormatContext = None ) Lint a command given its argumenet information. Source code in whatrecord/bin/lint.py def lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ): \"\"\"Lint a command given its argumenet information.\"\"\" if not command_info : print ( f \" ! Warning: Unknown command: { argv [ 0 ] } \" ) return expected_args = command_info . args actual_args = argv [ 1 :] arg_names = [ arg . name for arg in expected_args ] if len ( actual_args ) == len ( expected_args ): return if len ( actual_args ) < len ( expected_args ): arg_names = [ arg . name for arg in expected_args ] arg_values = list ( actual_args ) + [ \"?\" ] * ( len ( expected_args ) - len ( actual_args )) print ( \" ! Warning: may be too few arguments\" , file = file ) else : print ( \" ! Warning: too many arguments\" , file = file ) arg_names = [ arg . name for arg in expected_args ] + [ \"?\" ] * ( len ( actual_args ) - len ( expected_args )) arg_values = actual_args for idx , ( arg_name , value ) in enumerate ( zip ( arg_names , arg_values ), 1 ): print ( f \" { idx } . { arg_name } = { value } \" , file = file ) print ( file = file )","title":"Functions"},{"location":"cli/#whatrecord.bin.main","text":"whatrecord is the top-level command for accessing various subcommands. Try::","title":"main"},{"location":"cli/#whatrecord.bin.parse","text":"\"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default.","title":"parse"},{"location":"cli/#whatrecord.bin.parse-functions","text":"whatrecord . bin . parse . parse_from_cli_args ( filename : Union [ str , pathlib . Path ], dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False ) -> Union [ whatrecord . access_security . AccessSecurityConfig , whatrecord . db . Database , whatrecord . gateway . PVList , whatrecord . db . LinterResults , whatrecord . shell . LoadedIoc , whatrecord . snl . SequencerProgram , whatrecord . streamdevice . StreamProtocol , whatrecord . dbtemplate . TemplateSubstitution , whatrecord . makefile . Makefile ] Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that parse expects. For programmatic usage, please use parse() directly. Parameters: Name Type Description Default filename Union[str, pathlib.Path] The filename to parse. required dbd Optional[str] The associated database definition file, if parsing a database file. None standin_directories list A list of substitute directories of the form DirectoryA=DirectoryB . required macros Optional[str] Macro string to use when parsing the file. None expand bool Expand a substitutions file. False v3 bool Use V3 database grammar where applicable. False Source code in whatrecord/bin/parse.py def parse_from_cli_args ( filename : AnyPath , dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False , ) -> ParseResult : \"\"\" Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that `parse` expects. For programmatic usage, please use ``parse()`` directly. Parameters ---------- filename : str or pathlib.Path The filename to parse. dbd : str or pathlib.Path, optional The associated database definition file, if parsing a database file. standin_directories : list, optional A list of substitute directories of the form ``DirectoryA=DirectoryB``. macros : str, optional Macro string to use when parsing the file. expand : bool, optional Expand a substitutions file. v3 : bool, optional Use V3 database grammar where applicable. \"\"\" standin_directories = dict ( path . split ( \"=\" , 1 ) for path in standin_directory or \"\" ) if isinstance ( filename , str ) and filename . startswith ( \"{\" ): # } # TODO - argparse fixup? ioc_metadata = IocMetadata . from_dict ( json . loads ( filename )) # TODO macros, use_gdb, ... # ioc_metadata.macros = macros return LoadedIoc . from_metadata ( ioc_metadata ) try : format = FileFormat ( format ) if format is not None else None except ValueError : options = [ fmt . name for fmt in list ( FileFormat )] raise ValueError ( f \" { format !r} is not a valid FileFormat. Options include: \" f \" { options } \" ) return parse ( filename , dbd = dbd , standin_directories = standin_directories , macros = macros , use_gdb = use_gdb , format = format , expand = expand , v3 = v3 , )","title":"Functions"},{"location":"cli/#whatrecord.bin.server","text":"\"whatrecord server\" is used to start an aiohttp-backed web server which hosts startup script and record information.","title":"server"},{"location":"cli/#whatrecord.bin.main","text":"whatrecord is the top-level command for accessing various subcommands. Try::","title":"main"},{"location":"cli/#whatrecord.bin.lint","text":"\"whatrecord lint\" is used to lint a startup script or database file.","title":"lint"},{"location":"cli/#whatrecord.bin.lint-functions","text":"","title":"Functions"},{"location":"cli/#whatrecord.bin.lint.lint","text":"Lint a startup script or a database file. Parameters: Name Type Description Default obj Union[whatrecord.db.Database, whatrecord.shell.LoadedIoc] The object to lint. required Source code in whatrecord/bin/lint.py def lint ( obj : Union [ Database , LoadedIoc ], * , verbosity : int = 0 , file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ) -> Union [ Database , LoadedIoc ]: \"\"\" Lint a startup script or a database file. Parameters ---------- obj : The object to lint. \"\"\" fmt = fmt or FormatContext () if isinstance ( obj , LoadedIoc ): commands = obj . metadata . commands # variables = obj.metadata.variables for line in obj . script . lines : if line . line or verbosity > 2 : if line . error or verbosity > 1 : print ( fmt . render_object ( line ) . rstrip (), file = file ) if commands and line . argv : command_info = commands . get ( line . argv [ 0 ], None ) lint_command ( command_info = command_info , argv = line . argv , file = file , fmt = fmt )","title":"lint()"},{"location":"cli/#whatrecord.bin.lint.lint_command","text":"Lint a command given its argumenet information. Source code in whatrecord/bin/lint.py def lint_command ( command_info : IocshCommand , argv : List [ str ], file : IO [ str ] = sys . stdout , fmt : FormatContext = None , ): \"\"\"Lint a command given its argumenet information.\"\"\" if not command_info : print ( f \" ! Warning: Unknown command: { argv [ 0 ] } \" ) return expected_args = command_info . args actual_args = argv [ 1 :] arg_names = [ arg . name for arg in expected_args ] if len ( actual_args ) == len ( expected_args ): return if len ( actual_args ) < len ( expected_args ): arg_names = [ arg . name for arg in expected_args ] arg_values = list ( actual_args ) + [ \"?\" ] * ( len ( expected_args ) - len ( actual_args )) print ( \" ! Warning: may be too few arguments\" , file = file ) else : print ( \" ! Warning: too many arguments\" , file = file ) arg_names = [ arg . name for arg in expected_args ] + [ \"?\" ] * ( len ( actual_args ) - len ( expected_args )) arg_values = actual_args for idx , ( arg_name , value ) in enumerate ( zip ( arg_names , arg_values ), 1 ): print ( f \" { idx } . { arg_name } = { value } \" , file = file ) print ( file = file )","title":"lint_command()"},{"location":"cli/#whatrecord.bin.parse","text":"\"whatrecord parse\" is used to parse and interpret any of whatrecord's supported file formats, dumping the results to the console (standard output) in JSON format, by default.","title":"parse"},{"location":"cli/#whatrecord.bin.parse-functions","text":"","title":"Functions"},{"location":"cli/#whatrecord.bin.parse.parse_from_cli_args","text":"Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that parse expects. For programmatic usage, please use parse() directly. Parameters: Name Type Description Default filename Union[str, pathlib.Path] The filename to parse. required dbd Optional[str] The associated database definition file, if parsing a database file. None standin_directories list A list of substitute directories of the form DirectoryA=DirectoryB . required macros Optional[str] Macro string to use when parsing the file. None expand bool Expand a substitutions file. False v3 bool Use V3 database grammar where applicable. False Source code in whatrecord/bin/parse.py def parse_from_cli_args ( filename : AnyPath , dbd : Optional [ str ] = None , standin_directory : Optional [ List [ str ]] = None , macros : Optional [ str ] = None , use_gdb : bool = False , format : Optional [ str ] = None , expand : bool = False , v3 : bool = False , ) -> ParseResult : \"\"\" Generically parse either a startup script or a database file. This variant uses the raw CLI arguments, mapping them on to those that `parse` expects. For programmatic usage, please use ``parse()`` directly. Parameters ---------- filename : str or pathlib.Path The filename to parse. dbd : str or pathlib.Path, optional The associated database definition file, if parsing a database file. standin_directories : list, optional A list of substitute directories of the form ``DirectoryA=DirectoryB``. macros : str, optional Macro string to use when parsing the file. expand : bool, optional Expand a substitutions file. v3 : bool, optional Use V3 database grammar where applicable. \"\"\" standin_directories = dict ( path . split ( \"=\" , 1 ) for path in standin_directory or \"\" ) if isinstance ( filename , str ) and filename . startswith ( \"{\" ): # } # TODO - argparse fixup? ioc_metadata = IocMetadata . from_dict ( json . loads ( filename )) # TODO macros, use_gdb, ... # ioc_metadata.macros = macros return LoadedIoc . from_metadata ( ioc_metadata ) try : format = FileFormat ( format ) if format is not None else None except ValueError : options = [ fmt . name for fmt in list ( FileFormat )] raise ValueError ( f \" { format !r} is not a valid FileFormat. Options include: \" f \" { options } \" ) return parse ( filename , dbd = dbd , standin_directories = standin_directories , macros = macros , use_gdb = use_gdb , format = format , expand = expand , v3 = v3 , )","title":"parse_from_cli_args()"},{"location":"cli/#whatrecord.bin.server","text":"\"whatrecord server\" is used to start an aiohttp-backed web server which hosts startup script and record information.","title":"server"},{"location":"iocsh/","text":"IOC Shell-Related API whatrecord.asyn Classes whatrecord.asyn.AdsAsynPort ( AsynPort ) dataclass AdsAsynPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = , ipaddr: 'str' = '', amsaddr: 'str' = '', amsport: 'int' = 0, asynParamTableSize: 'int' = 0, priority: 'int' = 0, noAutoConnect: 'int' = 0, defaultSampleTimeMS: 'int' = 0, maxDelayTimeMS: 'int' = 0, adsTimeoutMS: 'int' = 0, defaultTimeSource: 'str' = '') Source code in whatrecord/asyn.py @dataclass class AdsAsynPort ( AsynPort ): ipaddr : str = \"\" amsaddr : str = \"\" amsport : int = 0 asynParamTableSize : int = 0 priority : int = 0 noAutoConnect : int = 0 defaultSampleTimeMS : int = 0 maxDelayTimeMS : int = 0 adsTimeoutMS : int = 0 defaultTimeSource : str = \"\" _jinja_format_ : ClassVar [ dict ] = { \"console\" : AsynPort . _jinja_format_ [ \"console\" ] + \"\"\" ipaddr: {{ipaddr}} amsaddr: {{amsaddr}} amsport: {{amsport}} asynParamTableSize: {{asynParamTableSize}} priority: {{priority}} noAutoConnect: {{noAutoConnect}} defaultSampleTimeMS: {{defaultSampleTimeMS}} maxDelayTimeMS: {{maxDelayTimeMS}} adsTimeoutMS: {{adsTimeoutMS}} defaultTimeSource: {{defaultTimeSource}} \"\"\" } whatrecord.asyn.AsynIPPort ( AsynPort ) dataclass AsynIPPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = , hostInfo: 'str' = '', priority: 'str' = '', noAutoConnect: 'str' = '', noProcessEos: 'str' = '') Source code in whatrecord/asyn.py @dataclass class AsynIPPort ( AsynPort ): hostInfo : str = \"\" priority : str = \"\" noAutoConnect : str = \"\" noProcessEos : str = \"\" whatrecord.asyn.AsynMotor ( AsynPortBase ) dataclass AsynMotor(context: 'FullLoadContext', name: 'str', metadata: 'Dict[str, Union[str, int, float]]' = , parent: 'Optional[str]' = None) Source code in whatrecord/asyn.py @dataclass class AsynMotor ( AsynPortBase ): context : FullLoadContext name : str metadata : Dict [ str , Union [ str , int , float ]] = field ( default_factory = dict ) parent : Optional [ str ] = None whatrecord.asyn.AsynPort ( AsynPortBase ) dataclass AsynPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = ) Source code in whatrecord/asyn.py @dataclass class AsynPort ( AsynPortBase ): context : FullLoadContext name : str options : Dict [ str , AsynPortOption ] = field ( default_factory = dict ) metadata : Dict [ str , str ] = field ( default_factory = dict ) motors : Dict [ str , AsynMotor ] = field ( default_factory = dict ) _jinja_format_ : ClassVar [ dict ] = { \"console\" : \"\"\" \\ {{obj|classname}}: name: {{name}} options: {{options}} metadata: {{metadata}} Defined: { % f or ctx in context %} * {{ctx}} { % e ndfor %} { % f or motor in motors %} { % s et motor_text = render_object(motor, \"console\") %} {{ motor_text | indent(8)}} { % e ndfor %} \"\"\" , } whatrecord.asyn.AsynPortDevice ( AsynPortBase ) dataclass AsynPortDevice(context: 'FullLoadContext', name: 'str' = '', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = ) Source code in whatrecord/asyn.py @dataclass class AsynPortDevice ( AsynPortBase ): context : FullLoadContext name : str = \"\" options : Dict [ str , AsynPortOption ] = field ( default_factory = dict ) metadata : Dict [ str , str ] = field ( default_factory = dict ) motors : Dict [ str , AsynMotor ] = field ( default_factory = dict ) whatrecord.asyn.AsynPortMultiDevice ( AsynPortBase ) dataclass AsynPortMultiDevice(context: 'FullLoadContext', name: 'str', metadata: 'dict' = , motors: 'Dict[str, AsynMotor]' = , devices: 'Dict[str, AsynPortDevice]' = ) Source code in whatrecord/asyn.py @dataclass class AsynPortMultiDevice ( AsynPortBase ): context : FullLoadContext name : str metadata : dict = field ( default_factory = dict ) motors : Dict [ str , AsynMotor ] = field ( default_factory = dict ) devices : Dict [ str , AsynPortDevice ] = field ( default_factory = dict ) whatrecord.asyn.AsynPortOption dataclass AsynPortOption(context: 'FullLoadContext', key: 'str', value: 'str') Source code in whatrecord/asyn.py @dataclass class AsynPortOption : context : FullLoadContext key : str value : str whatrecord.asyn.AsynSerialPort ( AsynPort ) dataclass AsynSerialPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = , ttyName: 'str' = '', priority: 'str' = '', noAutoConnect: 'str' = '', noProcessEos: 'str' = '') Source code in whatrecord/asyn.py @dataclass class AsynSerialPort ( AsynPort ): ttyName : str = \"\" priority : str = \"\" noAutoConnect : str = \"\" noProcessEos : str = \"\" whatrecord.asyn.AsynState ( ShellStateHandler ) dataclass Asyn IOC shell state handler / container. Contains hooks for asyn-related commands and state information. Attributes: Name Type Description ports Dict[str, asyn.AsynPortBase] Asyn ports defined by name. Source code in whatrecord/asyn.py @dataclass class AsynState ( ShellStateHandler ): \"\"\" Asyn IOC shell state handler / container. Contains hooks for asyn-related commands and state information. Attributes ---------- ports : Dict[str, asyn.AsynPortBase] Asyn ports defined by name. \"\"\" metadata_key : ClassVar [ str ] = \"asyn\" ports : Dict [ str , AsynPortBase ] = field ( default_factory = dict ) @_handler def handle_drvAsynSerialPortConfigure ( self , portName : str , ttyName : str , priority : int = 0 , noAutoConnect : int = 0 , noProcessEos : int = 0 , ): # SLAC-specific, but doesn't hurt anyone self . ports [ portName ] = AsynSerialPort ( context = self . get_load_context (), name = portName , ttyName = ttyName , priority = priority , noAutoConnect = noAutoConnect , noProcessEos = noProcessEos , ) @_handler def handle_drvAsynIPPortConfigure ( self , portName : str , hostInfo : str , priority : int = 0 , noAutoConnect : int = 0 , noProcessEos : int = 0 , ): # SLAC-specific, but doesn't hurt anyone self . ports [ portName ] = AsynIPPort ( context = self . get_load_context (), name = portName , hostInfo = hostInfo , priority = priority , noAutoConnect = noAutoConnect , noProcessEos = noProcessEos , ) @_handler def handle_asynSetOption ( self , name : str , addr : str , key : str , value : str ): port = self . ports [ name ] opt = AsynPortOption ( context = self . get_load_context (), key = key , value = value , ) if isinstance ( port , AsynPortMultiDevice ): port . devices [ addr ] . options [ key ] = opt else : port . options [ key ] = opt def get_port_from_record ( self , inst : RecordInstance ) -> Optional [ AsynPort ]: \"\"\"Given a record, return its related asyn port.\"\"\" if inst . is_pva : return rec_field : Optional [ RecordField ] rec_field = inst . fields . get ( \"INP\" , inst . fields . get ( \"OUT\" , None )) if rec_field is None : return if not isinstance ( rec_field . value , str ): # No PVAccess links just yet return value = rec_field . value . strip () if value . startswith ( \"@asyn\" ): try : asyn_args = value . split ( \"@asyn\" )[ 1 ] . strip ( \" ()\" ) asyn_port , * _ = asyn_args . split ( \",\" ) return self . ports . get ( asyn_port . strip (), None ) except Exception : logger . debug ( \"Failed to parse asyn string\" , exc_info = True ) def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: port = self . get_port_from_record ( record ) if port is not None : parent_port = getattr ( port , \"parent\" , None ) ports = [ port_ for port_ in [ parent_port , port ] if port_ is not None ] return { \"ports\" : ports } Methods whatrecord . asyn . AsynState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate the given record's metadata with state-related information. Source code in whatrecord/asyn.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: port = self . get_port_from_record ( record ) if port is not None : parent_port = getattr ( port , \"parent\" , None ) ports = [ port_ for port_ in [ parent_port , port ] if port_ is not None ] return { \"ports\" : ports } whatrecord . asyn . AsynState . get_port_from_record ( self , inst : RecordInstance ) -> Optional [ AsynPort ] Given a record, return its related asyn port. Source code in whatrecord/asyn.py def get_port_from_record ( self , inst : RecordInstance ) -> Optional [ AsynPort ]: \"\"\"Given a record, return its related asyn port.\"\"\" if inst . is_pva : return rec_field : Optional [ RecordField ] rec_field = inst . fields . get ( \"INP\" , inst . fields . get ( \"OUT\" , None )) if rec_field is None : return if not isinstance ( rec_field . value , str ): # No PVAccess links just yet return value = rec_field . value . strip () if value . startswith ( \"@asyn\" ): try : asyn_args = value . split ( \"@asyn\" )[ 1 ] . strip ( \" ()\" ) asyn_port , * _ = asyn_args . split ( \",\" ) return self . ports . get ( asyn_port . strip (), None ) except Exception : logger . debug ( \"Failed to parse asyn string\" , exc_info = True ) whatrecord.iocsh Functions whatrecord . iocsh . parse_iocsh_line ( line : str , * , context : Optional [ whatrecord . common . LoadContext ] = None , prompt : str = 'epics>' , macro_context : Optional [ _whatrecord . macro . MacroContext ] = None , string_encoding : str = 'latin-1' ) -> IocshResult Parse an IOC shell line into an IocshResult. Parameters: Name Type Description Default line str The line to parse. required context Optional[whatrecord.common.LoadContext] The load context to populate the result with. None prompt str Replicating the EPICS source code, specify the state of the prompt here. Defaults to \"epics>\". If unset as in prior to IOC init, lines that do not start with \"#-\" will be eched. 'epics>' Returns: Type Description IocshResult A partially filled IocshResult, ready for interpreting by a higher-level function. Source code in whatrecord/iocsh.py def parse_iocsh_line ( line : str , * , context : Optional [ LoadContext ] = None , prompt : str = \"epics>\" , macro_context : Optional [ MacroContext ] = None , string_encoding : str = \"latin-1\" , ) -> IocshResult : \"\"\" Parse an IOC shell line into an IocshResult. Parameters ---------- line : str The line to parse. context : LoadContext, optional The load context to populate the result with. prompt : str, optional Replicating the EPICS source code, specify the state of the prompt here. Defaults to \"epics>\". If unset as in prior to IOC init, lines that do not start with \"#-\" will be eched. Returns ------- IocshResult A partially filled IocshResult, ready for interpreting by a higher-level function. \"\"\" result = IocshResult ( context = context , line = line , ) # Skip leading whitespace line = line . lstrip () if not line . startswith ( \"#-\" ): result . outputs . append ( line ) if line . startswith ( '#' ): # Echo non-empty lines read from a script. # Comments delineated with '#-' aren't echoed. return result if macro_context is not None : line = macro_context . expand ( line ) # * Skip leading white-space coming from a macro line = line . lstrip () # * Echo non-empty lines read from a script. # * Comments delineated with '#-' aren't echoed. if not prompt : if not line . startswith ( '#-' ): result . outputs . append ( line ) # * Ignore lines that became a comment or empty after macro expansion if not line or line . startswith ( '#' ): return result split = split_words ( line , string_encoding = string_encoding ) result . argv = split . argv # Only set the following if necessary; apischema can skip serialization # otherwise. if split . redirects : result . redirects = list ( split . redirects . values ()) if split . error : result . error = split . error return result whatrecord.motor Classes whatrecord.motor.MotorState ( ShellStateHandler ) dataclass Motor record support IOC shell state handler / container. Source code in whatrecord/motor.py @dataclass class MotorState ( ShellStateHandler ): \"\"\"Motor record support IOC shell state handler / container.\"\"\" metadata_key : ClassVar [ str ] = \"motor\" @property def asyn ( self ) -> asyn . AsynState : \"\"\"Asyn instance.\"\"\" if self . primary_handler is None : raise RuntimeError ( \"Requires a primary handler\" ) return self . primary_handler . asyn @property def ports ( self ) -> Dict [ str , AsynPortBase ]: \"\"\"Asyn ports.\"\"\" return self . asyn . ports @_handler ( stub = True ) def handle_A3200AsynConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , task_number : int , linear_move_commands : int , ): ... @_handler ( stub = True ) def handle_A3200AsynSetup ( self , max_controller_count : int ): ... @_handler ( stub = True ) def handle_ACRCreateController ( self , port_name : str , acr_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_AG_CONEXCreateController ( self , port_name : str , serial_port_name : str , controller_id : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_AG_UCCreateAxis ( self , controller_port_name : str , axis_number : int , has_limits : int , forward_amplitude : int , reverse_amplitude : int , ): ... @_handler ( stub = True ) def handle_AG_UCCreateController ( self , port_name : str , serial_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_ANC150AsynConfig ( self , card_being_configured : int , asyn_port_name : str , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_ANC150AsynSetup ( self , maximum_of_controllers : int ): ... @_handler ( stub = True ) def handle_ANF2CreateAxis ( self , port_name : str , axis_number : int , hex_config : str , base_speed : int , homing_timeout : int , ): ... @_handler ( stub = True ) def handle_ANF2CreateController ( self , port_name : str , anf2_in_port_name : str , anf2_out_port_name : str , number_of_axes : int , ): ... @_handler ( stub = True ) def handle_ANF2StartPoller ( self , port_name : str , moving_poll_period_ms : int , idle_poll_period_ms : int ): ... @_handler ( stub = True ) def handle_ANG1CreateController ( self , port_name : str , ang1_in_port_name : str , ang1_out_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_AcsMotionConfig ( self , acs_port_name : str , asyn_port_name : str , num_axes : int , moving_polling_rate : float , idle_polling_rate : float , ): ... @_handler ( stub = True ) def handle_C300CreateController ( self , port_name : str , c300_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_EMC18011Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_EMC18011Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_ESP300Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_ESP300Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_EnsembleAsynConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_EnsembleAsynSetup ( self , max_controller_count : int ): ... @_handler ( stub = True ) def handle_HXPCreateController ( self , port_name : str , ip_address : str , port : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_Hytec8601Configure ( self , port_name : str , num_axes : int , moving_poll_period : int , idle_poll_period : int , cardnum : int , carrier : int , ipslot : int , vector : int , useencoder : int , encoder_ratio0 : float , encoder_ratio1 : float , encoder_ratio2 : float , encoder_ratio3 : float , ): ... @_handler ( stub = True ) def handle_IM483PLConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_IM483PLSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_IM483SMConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_IM483SMSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_ImsMDrivePlusCreateController ( self , motor_port_name : str , io_port_name : str , device_name : str , moving_poll_period_ms : float , idle_poll_period_ms : float , ): ... @_handler ( stub = True ) def handle_LinmotCreateController ( self , port_name : str , linmot_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MAXvConfig ( self , card_being_configured : int , configuration_string : str , absolute_encoder_flags : int , grey_code_flags : int , ): ... @_handler ( stub = True ) def handle_MAXvSetup ( self , max_controller_count : int , vme_address_type : int , base_address_on_4_k_0x1000_boundary : int , valid_vectors : int , interrupt_level_1_6 : int , polling_rate_hz : int , ): ... @_handler ( stub = True ) def handle_MCB4BConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MCB4BCreateController ( self , port_name : str , mcb_4_b_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MCB4BSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MCDC2805Config ( self , card_being_configured : int , modules_on_this_serial_port : int , asyn_port_name : str , ): ... @_handler ( stub = True ) def handle_MCDC2805Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MCS2CreateController ( self , port_name : str , mcs2_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MDT695Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MDT695Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MDriveConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MDriveSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MM3000Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_MM300Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MM4000AsynConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_MM4000AsynSetup ( self , max_controller_count : int ): ... @_handler ( stub = True ) def handle_MM4000Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_MM4000Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MMC200CreateController ( self , port_name : str , mmc_200_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ignore_limit_flag : int , ): ... @_handler ( stub = True ) def handle_MVP2001CreateAxis ( self , controller_port_name : str , axis_number : int , encoder_lines_per_rev : int , max_current_ma : int , limit_polarity : int , ): ... @_handler ( stub = True ) def handle_MVP2001CreateController ( self , port_name : str , mvp_2001_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MXmotorSetup ( self , max_motor : int , mx_data_file : str , polling_rate : int ): ... @_handler ( stub = True ) def handle_MicosConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MicosSetup ( self , max_controller_count : int , max_motor_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MicroMoConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MicroMoSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_OmsPC68Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_OmsPC68Setup ( self , maximum_of_cards : int , polling_rate_hz : int ): ... @_handler ( stub = True ) def handle_PC6KConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_PC6KSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PC6KUpLoad ( self , controller_card : int , upload_file_path : str , program_name_null_immediate : str , ): ... @_handler ( stub = True ) def handle_PIC630Config ( self , card_being_configured : int , asyn_port_name : str , ch_1_current_setting : int , ch_2_current_setting : int , ch_3_current_setting : int , ch_4_current_setting : int , ch_5_current_setting : int , ch_6_current_setting : int , ch_7_current_setting : int , ch_8_current_setting : int , ch_9_current_setting : int , ): ... @_handler ( stub = True ) def handle_PIC630Setup ( self , max_controller_groups : int , max_axes_per_group : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC662Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_PIC662Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC663Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC663Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC844Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC844Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC848Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC848Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC862Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC862Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE516Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE516Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE517Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE517Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE710Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE710Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE816Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE816Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIJEDSConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIJEDSSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PI_GCS2_CreateController ( self , port_name : str , asyn_port_name : str , number_of_axes : int , priority : int , stack_size : int , moving_polling_time_msec : int , idle_polling_time_msec : int , ): ... @_handler ( stub = True ) def handle_PM304Config ( self , card_being_configured : int , asyn_port_name : str , number_of_axes : int ): ... @_handler ( stub = True ) def handle_PM304Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PM500Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PM500Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PMNC87xxConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PMNC87xxSetup ( self , max_controller_count : int , max_drivers_per_controller_count : int , polling_rate : int , ): ... @_handler ( stub = True ) def handle_SC800Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_SC800Setup ( self , maximum_of_cards : int , polling_rate_hz : int ): ... @_handler ( stub = True ) def handle_SMC100Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_SMC100CreateController ( self , port_name : str , smc100_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , eg_us_per_step : str , ): ... @_handler ( stub = True ) def handle_SMC100Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_SMCcorvusChangeResolution ( self , smc_corvus_port_name : str , axis_number : int , axis_resolution : float ): ... @_handler ( stub = True ) def handle_SMCcorvusCreateController ( self , port_name : str , smc_corvus_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_SMChydraChangeResolution ( self , smc_hydra_port_name : str , axis_number : int , axis_resolution : float ): ... @_handler ( stub = True ) def handle_SMChydraCreateController ( self , port_name : str , smc_hydra_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_SPiiPlusConfig ( self , card_being_configured : int , asyn_port_name : str , command_mode_bu_ffer_co_nnect_di_rect : str , ): ... @_handler ( stub = True ) def handle_SPiiPlusSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_ScriptAxisConfig ( self , controller_port_name : str , axis_number : int , parameters : str ): ... @_handler ( stub = True ) def handle_ScriptControllerConfig ( self , motor_port_name : str , number_of_axes : int , control_script : str , parameters : str , ): ... @_handler ( stub = True ) def handle_ScriptMotorReload ( self , motor_port_name : str ): ... @_handler ( stub = True ) def handle_SmartMotorConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_SmartMotorSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_SoloistConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address : int ): ... @_handler ( stub = True ) def handle_SoloistSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_XPSAuxConfig ( self , port_name : str , ip_address : str , ip_port : int , polling_period : int ): ... @_handler ( stub = True ) def handle_XPSConfig ( self , card_being_configured : int , ip : str , port : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_XPSConfigAxis ( self , card_number : int , axis_number : int , axis_name : str , steps_per_unit : str , no_disabled_error : int , ): ... @_handler ( stub = True ) def handle_XPSCreateAxis ( self , controller_port_name : str , axis_number : int , axis_name : str , steps_per_unit : str , ): ... @_handler ( stub = True ) def handle_XPSCreateController ( self , controller_port_name : str , ip_address : str , ip_port : int , number_of_axes : int , moving_poll_rate_ms : int , idle_poll_rate_ms : int , enable_set_position : int , set_position_settling_time_ms : int , ): ... @_handler ( stub = True ) def handle_XPSCreateProfile ( self , controller_port_name : str , max_points : int , ftp_username : str , ftp_password : str , ): ... @_handler ( stub = True ) def handle_XPSDisableAutoEnable ( self , controller_port_name : str ): ... @_handler ( stub = True ) def handle_XPSDisablePoll ( self , set_disable_poll_value : int ): ... @_handler ( stub = True ) def handle_XPSEnableMoveToHome ( self , card_number : int , axis_name : str , distance : int ): ... @_handler ( stub = True ) def handle_XPSEnableMovingMode ( self , controller_port_name : str ): ... @_handler ( stub = True ) def handle_XPSEnableSetPosition ( self , set_position_flag : int ): ... @_handler ( stub = True ) def handle_XPSGathering ( self , interelement_period : int ): ... @_handler ( stub = True ) def handle_XPSInterpose ( self , port_name : str ): ... @_handler ( stub = True ) def handle_XPSNoDisableError ( self , controller_port_name : str ): ... @_handler ( stub = True ) def handle_XPSSetPosSleepTime ( self , set_position_sleep_time : int ): ... @_handler ( stub = True ) def handle_XPSSetup ( self , number_of_xps_controllers : int ): ... @_handler ( stub = True ) def handle_asynMotorEnableMoveToHome ( self , controller_port_name : str , axis_number : int , distance : int ): ... @_handler ( stub = True ) def handle_listMovingMotors ( self , list_moving_motors : str ): ... @_handler ( stub = True ) def handle_motorSimConfigAxis ( self , post_name : str , axis : int , high_limit : int , low_limit : int , home_position : int , start_posn : int , ): ... @_handler ( stub = True ) def handle_motorSimCreate ( self , card : int , signal : int , high_limit : int , low_limit : int , home_position : int , num_cards : int , num_signals : int , start_posn : int , ): ... @_handler ( stub = True ) def handle_motorSimCreateController ( self , port_name : str , number_of_axes : int , priority : int , stack_size : int ): ... @_handler ( stub = True ) def handle_motorUtilInit ( self , ioc_name : str ): ... @_handler ( stub = True ) def handle_nf874xCreateController ( self , port_name : str , nf874x_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_oms58Setup ( self , num_card : int , addrs : int , vector : int , int_level : int , scan_rate : int ): ... @_handler ( stub = True ) def handle_omsMAXnetConfig ( self , asyn_motor_port_name : str , number_of_axes : int , asyn_serial_tcp_port_name : str , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvConfig ( self , number_of_card : int , asyn_motor_port_name : str , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvConfig2 ( self , slot_number : int , address_type_a16_a24_a32 : str , board_address_on_4_k_0x1000_boundary : int , interrupt_vector_noninterrupting_0_64_255 : int , interrupt_level_1_6 : int , asyn_motor_port_name : str , number_of_axes : int , task_priority_0_medium : int , stack_size_0_medium : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvEncFuncConfig ( self , number_of_card : int , asyn_motor_port_name : str , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvEncFuncConfig2 ( self , slot_number : int , address_type_a16_a24_a32 : str , board_address_on_4_k_0x1000_boundary : int , interrupt_vector_noninterrupting_0_64_255 : int , interrupt_level_1_6 : int , asyn_motor_port_name : str , number_of_axes : int , task_priority_0_medium : int , stack_size_0_medium : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvSetup ( self , max_controller_count : int , vme_address_type : int , base_address_on_4_k_0x1000_boundary : int , noninterrupting_0_valid_vectors_64_255 : int , interrupt_level_1_6 : int , ): ... @_handler ( stub = True ) def handle_phytronCreateAxis ( self , controller_name : str , module_index : int , axis_index : int ): ... @_handler ( stub = True ) def handle_phytronCreateController ( self , port_name : str , phytron_axis_port_name : str , moving_poll_period_ms : int , idle_poll_period_ms : int , timeout_ms : float , ): ... @_handler ( stub = True ) def handle_printChIDlist ( self , print_motor_util_chid_list : str ): ... @_handler ( stub = True ) def handle_setIdlePollPeriod ( self , controller_port_name : str , axis_number : float ): ... @_handler ( stub = True ) def handle_setMovingPollPeriod ( self , controller_port_name : str , axis_number : float ): ... @_handler ( stub = True ) def handle_smarActMCSCreateAxis ( self , controller_port_name_string : str , axis_number_int : int , channel_int : int ): ... @_handler ( stub = True ) def handle_smarActMCSCreateController ( self , port_name_string : str , i_o_port_name_string : str , number_of_axes_int : int , moving_poll_period_s_double : float , idle_poll_period_s_double : float , ): ... @_handler ( stub = True ) def handle_smarActSCUCreateAxis ( self , controller_port_name_string : str , axis_number_int : int , channel_int : int ): ... @_handler ( stub = True ) def handle_smarActSCUCreateController ( self , port_name_string : str , i_o_port_name_string : str , number_of_axes_int : int , moving_poll_period_s_double : float , idle_poll_period_s_double : float , ): ... @_handler ( stub = True ) def handle_tclcall ( self , tcl_name : str , task_name : str , function_args : str ): ... @_handler ( stub = True ) def handle_xps_gathering ( self , element_period_10_4 : int ): ... @_handler ( stub = True ) def handle_EthercatMCCreateAxis ( self , motor_port : str , axis_num : int , amplifier_flags : str , axis_config : str ): ... @_handler def handle_adsAsynPortDriverConfigure ( self , portName : str , ipaddr : str = \"\" , amsaddr : str = \"\" , amsport : int = 0 , asynParamTableSize : int = 0 , priority : int = 0 , noAutoConnect : int = 0 , defaultSampleTimeMS : int = 0 , maxDelayTimeMS : int = 0 , adsTimeoutMS : int = 0 , defaultTimeSource : str = \"\" , ): # SLAC-specific, but doesn't hurt anyone self . ports [ portName ] = asyn . AdsAsynPort ( context = self . get_load_context (), name = portName , ipaddr = ipaddr , amsaddr = amsaddr , amsport = amsport , asynParamTableSize = asynParamTableSize , priority = priority , noAutoConnect = noAutoConnect , defaultSampleTimeMS = defaultSampleTimeMS , maxDelayTimeMS = maxDelayTimeMS , adsTimeoutMS = adsTimeoutMS , defaultTimeSource = defaultTimeSource , ) @_handler def handle_drvAsynMotorConfigure ( self , port_name : str = \"\" , driver_name : str = \"\" , card_num : int = 0 , num_axes : int = 0 , ): self . ports [ port_name ] = asyn . AsynMotor ( context = self . get_load_context (), name = port_name , parent = None , metadata = dict ( num_axes = num_axes , card_num = card_num , driver_name = driver_name , ), ) @_handler def handle_EthercatMCCreateController ( self , motor_port : str , asyn_port : str , num_axes : int = 0 , move_poll_rate : float = 0.0 , idle_poll_rate : float = 0.0 , ): # SLAC-specific port = self . ports [ asyn_port ] motor = asyn . AsynMotor ( context = self . get_load_context (), name = motor_port , parent = asyn_port , metadata = dict ( num_axes = num_axes , move_poll_rate = move_poll_rate , idle_poll_rate = idle_poll_rate , ), ) # Tie it to both the original asyn port (as a motor) and also the # top-level asyn ports. port . motors [ motor_port ] = motor self . ports [ motor_port ] = motor Attributes whatrecord . motor . MotorState . asyn : AsynState property readonly Asyn instance. whatrecord . motor . MotorState . ports : Dict [ str , whatrecord . common . AsynPortBase ] property readonly Asyn ports. whatrecord.shell Classes whatrecord.shell.IocLoadFailure dataclass IocLoadFailure(ex_class: 'str', ex_message: 'str', traceback: 'str') Source code in whatrecord/shell.py @dataclass class IocLoadFailure : ex_class : str ex_message : str traceback : str whatrecord.shell.IocLoadResult dataclass IocLoadResult(identifier: 'Union[int, str]', load_time: 'float', cache_hit: 'bool', result: 'Union[IocLoadFailure, str]') Source code in whatrecord/shell.py @dataclass class IocLoadResult : identifier : Union [ int , str ] load_time : float cache_hit : bool result : Union [ IocLoadFailure , str ] whatrecord.shell.LoadedIoc dataclass LoadedIoc(name: 'str', path: 'pathlib.Path', metadata: 'IocMetadata', shell_state: 'ShellState', script: 'IocshScript', load_failure: 'bool' = False, pv_relations: 'PVRelations' = ) Source code in whatrecord/shell.py @dataclass class LoadedIoc : name : str path : pathlib . Path metadata : IocMetadata shell_state : ShellState script : IocshScript load_failure : bool = False pv_relations : PVRelations = field ( default_factory = dict ) _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: path: {{ path }} metadata: {% set metadata = render_object(metadata, \"console\") %} {{ metadata | indent(4) }} shell_state: {% set shell_state = render_object(shell_state, \"console\") %} {{ shell_state | indent(4) }} script: {% set script = render_object(script, \"console\") %} {{ script | indent(4) }} load_failure: {{ load_failure }} \"\"\" . rstrip (), ), \"console-verbose\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: path: {{ path }} metadata: {% set metadata = render_object(metadata, \"console-verbose\") %} {{ metadata | indent(4) }} shell_state: {% set shell_state = render_object(shell_state, \"console-verbose\") %} {{ shell_state | indent(4) }} script: {% set script = render_object(script, \"console-verbose\") %} {{ script | indent(4) }} load_failure: {{ load_failure }} pv_relations: {{ pv_relations }} \"\"\" . rstrip (), ) } @classmethod def _json_from_cache ( cls , md : IocMetadata ) -> Optional [ dict ]: try : with open ( md . ioc_cache_filename , \"rb\" ) as fp : return json . load ( fp ) except FileNotFoundError : ... except json . decoder . JSONDecodeError : # Truncated output file, perhaps ... @classmethod def from_cache ( cls , md : IocMetadata ) -> Optional [ LoadedIoc ]: json_dict = cls . _json_from_cache ( md ) if json_dict is not None : return apischema . deserialize ( cls , json_dict ) def save_to_cache ( self ) -> bool : if not settings . CACHE_PATH : return False with open ( self . metadata . ioc_cache_filename , \"wt\" ) as fp : json . dump ( apischema . serialize ( self ), fp = fp ) return True @classmethod def from_errored_load ( cls , md : IocMetadata , load_failure : IocLoadFailure ) -> LoadedIoc : exception_line = f \" { load_failure . ex_class } : { load_failure . ex_message } \" error_lines = [ exception_line ] + load_failure . traceback . splitlines () script = IocshScript ( path = str ( md . script ), lines = tuple ( IocshResult ( line = line , context = ( LoadContext ( \"error\" , lineno ),)) for lineno , line in enumerate ( error_lines , 1 ) ), ) md . metadata [ \"exception_class\" ] = load_failure . ex_class md . metadata [ \"exception_message\" ] = load_failure . ex_message md . metadata [ \"traceback\" ] = load_failure . traceback md . metadata [ \"load_failure\" ] = True return cls ( name = md . name , path = md . script , metadata = md , shell_state = ShellState (), script = script , load_failure = True , ) @classmethod def from_metadata ( cls , md : IocMetadata ) -> LoadedIoc : sh = ShellState ( ioc_info = md ) sh . working_directory = md . startup_directory sh . macro_context . define ( ** md . macros ) sh . standin_directories = md . standin_directories or {} # It's not enough to chdir, as we can rely on the environment variable # in shell scripts: os . environ [ \"PWD\" ] = str ( md . startup_directory ) script = IocshScript . from_metadata ( md , sh = sh ) return cls ( name = md . name , path = md . script , metadata = md , shell_state = sh , script = script , pv_relations = graph . build_database_relations ( sh . database ), ) def whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True ) -> Optional [ WhatRecord ]: \"\"\"Get record information, optionally including PVAccess results.\"\"\" state = self . shell_state v3_inst = state . database . get ( state . aliases . get ( rec , rec ), None ) pva_inst = state . pva_database . get ( rec , None ) if include_pva else None if not v3_inst and not pva_inst : return what = WhatRecord ( name = rec , ioc = self . metadata , record = None , pva_group = None , ) if v3_inst is not None : if not state . database_definition : defn = None else : defn = state . database_definition . record_types . get ( v3_inst . record_type , None ) what . menus = state . database_definition . menus # but what about device types and such? state . annotate_record ( v3_inst ) what . record = RecordDefinitionAndInstance ( defn , v3_inst ) if pva_inst is not None : what . pva_group = pva_inst return what Methods whatrecord . shell . LoadedIoc . whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True ) -> Optional [ WhatRecord ] Get record information, optionally including PVAccess results. Source code in whatrecord/shell.py def whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True ) -> Optional [ WhatRecord ]: \"\"\"Get record information, optionally including PVAccess results.\"\"\" state = self . shell_state v3_inst = state . database . get ( state . aliases . get ( rec , rec ), None ) pva_inst = state . pva_database . get ( rec , None ) if include_pva else None if not v3_inst and not pva_inst : return what = WhatRecord ( name = rec , ioc = self . metadata , record = None , pva_group = None , ) if v3_inst is not None : if not state . database_definition : defn = None else : defn = state . database_definition . record_types . get ( v3_inst . record_type , None ) what . menus = state . database_definition . menus # but what about device types and such? state . annotate_record ( v3_inst ) what . record = RecordDefinitionAndInstance ( defn , v3_inst ) if pva_inst is not None : what . pva_group = pva_inst return what whatrecord.shell.ScriptContainer dataclass Aggregate container for any number of LoadedIoc instances. Combines databases, sets of loaded files ease of querying. Source code in whatrecord/shell.py @dataclass class ScriptContainer : \"\"\" Aggregate container for any number of LoadedIoc instances. Combines databases, sets of loaded files ease of querying. \"\"\" database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) aliases : Dict [ str , str ] = field ( default_factory = dict ) pva_database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) scripts : Dict [ str , LoadedIoc ] = field ( default_factory = dict ) startup_script_to_ioc : Dict [ str , str ] = field ( default_factory = dict ) #: absolute filename path to sha loaded_files : Dict [ str , str ] = field ( default_factory = dict ) record_types : Dict [ str , RecordType ] = field ( default_factory = dict ) pv_relations : PVRelations = field ( default_factory = dict ) def add_loaded_ioc ( self , loaded : LoadedIoc ): ioc_name = loaded . metadata . name self . scripts [ ioc_name ] = loaded self . startup_script_to_ioc [ str ( loaded . metadata . script )] = ioc_name # TODO: IOCs will have conflicting definitions of records self . aliases . update ( loaded . shell_state . aliases ) if loaded . shell_state . database_definition : self . record_types . update ( loaded . shell_state . database_definition . record_types ) graph . combine_relations ( self . pv_relations , self . database , loaded . pv_relations , loaded . shell_state . database , record_types = self . record_types , aliases = self . aliases , ) self . database . update ( loaded . shell_state . database ) self . pva_database . update ( loaded . shell_state . pva_database ) self . loaded_files . update ( loaded . shell_state . loaded_files ) def whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True , format_option : str = \"console\" , file = sys . stdout , ) -> List [ WhatRecord ]: fmt = FormatContext () result = [] for name , loaded in self . scripts . items (): info : WhatRecord = loaded . whatrec ( rec , field , include_pva = include_pva ) if info is not None : info . ioc = loaded . metadata for match in [ info . record , info . pva_group ]: if file is not None and match is not None : print ( fmt . render_object ( match , format_option ), file = file ) result . append ( info ) return result whatrecord.shell.ShellState ( ShellStateHandler ) dataclass IOC shell state container. Contains hooks for commands and state information. This base state handler should only handle epics base-defined IOC shell commands, including: paths, variables, database loading, and IOC initialization. It is the top-level state container, which sub handlers should rely on for things like loading files and other core state information. Attributes: Name Type Description prompt str The prompt - PS1 - as in \"epics>\". variables dict Shell variables (not environment variables). string_encoding str String encoding for byte strings and files. macro_context MacroContext Macro context for commands that are evaluated. standin_directories dict Rewrite hard-coded directory prefixes by setting:: standin_directories = {\"/replace_this/\": \"/with/this\"} loaded_files Dict[str, str] Files loaded, mapped to a hash of their contents. working_directory pathlib.Path Current working directory. database_definition Database Loaded database definition (dbd). database Dict[str, RecordInstance] The IOC database of records. pva_database Dict[str, RecordInstance] The IOC database of PVAccess groups. aliases Dict[str, str] Alias name to record name. load_context List[MutableLoadContext] Current loading context stack (e.g., st.cmd then common_startup.cmd ). Modified in place as scripts are evaluated. Source code in whatrecord/shell.py @dataclass class ShellState ( ShellStateHandler ): \"\"\" IOC shell state container. Contains hooks for commands and state information. This base state handler should only handle epics base-defined IOC shell commands, including: paths, variables, database loading, and IOC initialization. It is the top-level state container, which sub handlers should rely on for things like loading files and other core state information. Attributes ---------- prompt : str The prompt - PS1 - as in \"epics>\". variables : dict Shell variables (not environment variables). string_encoding : str String encoding for byte strings and files. macro_context : MacroContext Macro context for commands that are evaluated. standin_directories : dict Rewrite hard-coded directory prefixes by setting:: standin_directories = {\"/replace_this/\": \"/with/this\"} loaded_files : Dict[str, str] Files loaded, mapped to a hash of their contents. working_directory : pathlib.Path Current working directory. database_definition : Database Loaded database definition (dbd). database : Dict[str, RecordInstance] The IOC database of records. pva_database : Dict[str, RecordInstance] The IOC database of PVAccess groups. aliases : Dict[str, str] Alias name to record name. load_context : List[MutableLoadContext] Current loading context stack (e.g., ``st.cmd`` then ``common_startup.cmd``). Modified in place as scripts are evaluated. \"\"\" prompt : str = \"epics>\" variables : Dict [ str , str ] = field ( default_factory = dict ) string_encoding : str = \"latin-1\" ioc_initialized : bool = False standin_directories : Dict [ str , str ] = field ( default_factory = dict ) working_directory : pathlib . Path = field ( default_factory = lambda : pathlib . Path . cwd (), ) aliases : Dict [ str , str ] = field ( default_factory = dict ) database_definition : Optional [ Database ] = None database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) pva_database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) load_context : List [ MutableLoadContext ] = field ( default_factory = list ) loaded_files : Dict [ str , str ] = field ( default_factory = dict ) macro_context : MacroContext = field ( default_factory = MacroContext , metadata = apischema . metadata . skip ) ioc_info : IocMetadata = field ( default_factory = IocMetadata ) db_add_paths : List [ pathlib . Path ] = field ( default_factory = list ) # Sub-state handlers: access_security : AccessSecurityState = field ( default_factory = AccessSecurityState ) asyn : AsynState = field ( default_factory = AsynState ) autosave : AutosaveState = field ( default_factory = AutosaveState ) motor : MotorState = field ( default_factory = MotorState ) streamdevice : StreamDeviceState = field ( default_factory = StreamDeviceState ) _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: \"\"\" . rstrip (), ), \"console-verbose\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: \"\"\" . rstrip (), ) } def __post_init__ ( self ): super () . __post_init__ () self . macro_context . string_encoding = self . string_encoding @property def sub_handlers ( self ) -> List [ ShellStateHandler ]: \"\"\"Handlers which contain their own state.\"\"\" return [ self . access_security , self . asyn , self . autosave , self . motor , self . streamdevice , ] def load_file ( self , filename : AnyPath ) -> Tuple [ pathlib . Path , str ]: \"\"\"Load a file, record its hash, and return its contents.\"\"\" filename = self . _fix_path ( filename ) filename = filename . resolve () shasum , contents = util . read_text_file_with_hash ( filename , encoding = self . string_encoding ) self . loaded_files [ str ( filename )] = shasum self . ioc_info . loaded_files [ str ( filename )] = shasum return filename , contents def _handle_input_redirect ( self , redir : IocshRedirect , shresult : IocshResult , recurse : bool = True , raise_on_error : bool = False , ): try : filename , contents = self . load_file ( redir . name ) except Exception as ex : shresult . error = f \" { type ( ex ) . __name__ } : { redir . name } \" yield shresult return yield shresult yield from self . interpret_shell_script_text ( contents . splitlines (), recurse = recurse , name = filename ) def interpret_shell_line ( self , line , recurse = True , raise_on_error = False ): \"\"\"Interpret a single shell script line.\"\"\" shresult = parse_iocsh_line ( line , context = self . get_load_context (), prompt = self . prompt , macro_context = self . macro_context , string_encoding = self . string_encoding , ) input_redirects = [ redir for redir in shresult . redirects if redir . mode == \"r\" ] if shresult . error : yield shresult elif input_redirects : if recurse : yield from self . _handle_input_redirect ( input_redirects [ 0 ], shresult , recurse = recurse , raise_on_error = raise_on_error , ) elif shresult . argv : try : result = self . _handle_command ( * shresult . argv ) if result : # Only set if not-None to speed up serialization shresult . result = result except Exception as ex : if raise_on_error : raise ex_details = traceback . format_exc () shresult . error = f \"Failed to execute: { ex } : \\n { ex_details } \" yield shresult if isinstance ( shresult . result , IocshCmdArgs ): yield from self . interpret_shell_line ( shresult . result . command , recurse = recurse ) else : # Otherwise, nothing to do yield shresult def interpret_shell_script ( self , filename : Union [ pathlib . Path , str ], recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Load and interpret a shell script named ``filename``.\"\"\" filename , contents = self . load_file ( filename ) yield from self . interpret_shell_script_text ( contents . splitlines (), name = str ( filename ), recurse = recurse , raise_on_error = raise_on_error , ) def interpret_shell_script_text ( self , lines : Iterable [ str ], name : str = \"unknown\" , recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Interpret a shell script named ``name`` with ``lines`` of text.\"\"\" load_ctx = MutableLoadContext ( str ( name ), 0 ) try : self . load_context . append ( load_ctx ) for lineno , line in enumerate ( lines , 1 ): load_ctx . line = lineno yield from self . interpret_shell_line ( line , recurse = recurse , raise_on_error = raise_on_error , ) finally : self . load_context . remove ( load_ctx ) # for rec in list(self.database.values()) + list(self.pva_database.values()): # try: # self.annotate_record(rec) # except Exception: # logger.exception(\"Failed to annotate record: %s\", rec.name) def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if not self . load_context : return tuple () return tuple ( ctx . to_load_context () for ctx in self . load_context ) def _handle_command ( self , command , * args ): \"\"\"Handle IOC shell 'command' with provided arguments.\"\"\" handler = self . _handlers . get ( command , None ) if handler is not None : return handler ( * args ) return self . unhandled ( command , args ) def _fix_path ( self , filename : AnyPath ) -> pathlib . Path : \"\"\" Makes filename an absolute path with respect to the working directory. Also replaces standin directories, if provided an absolute path. \"\"\" filename = str ( filename ) if os . path . isabs ( filename ): for from_ , to in self . standin_directories . items (): if filename . startswith ( from_ ): _ , suffix = filename . split ( from_ , 1 ) return pathlib . Path ( to + suffix ) return self . working_directory / filename @property def db_include_paths ( self ) -> List [ pathlib . Path ]: \"\"\"Database include paths (EPICS_DB_INCLUDE_PATH).\"\"\" env_paths = self . paths_from_env_var ( \"EPICS_DB_INCLUDE_PATH\" ) if not env_paths : return [ self . working_directory ] + self . db_add_paths return env_paths + self . db_add_paths def paths_from_env_var ( self , env_var : str , * , default : Optional [ str ] = None ) -> List [ pathlib . Path ]: \"\"\"Paths from an environment variable (or macro).\"\"\" env_var = self . macro_context . get ( env_var , default ) or \"\" return [ ( self . working_directory / pathlib . Path ( path )) . resolve () # TODO: this is actually OS-dependent (: on linux, ; on Windows) for path in env_var . split ( \":\" ) ] def _fix_path_with_search_list ( self , filename : Union [ str , pathlib . Path ], include_paths : List [ pathlib . Path ], ) -> pathlib . Path : \"\"\"Given a list of paths, find ``filename``.\"\"\" filename = str ( filename ) if not include_paths or \"/\" in filename or \" \\\\ \" in filename : # Include path unset or even something resembling a nested path # automatically is used as-is return self . working_directory / filename for path in include_paths : option = path / filename if option . exists () and option . is_file (): return option paths = list ( str ( path ) for path in include_paths ) raise FileNotFoundError ( f \"File { filename !r} not found in search path: { paths } \" ) def unhandled ( self , command , args ): ... # return f\"No handler for handle_{command}\" @_handler def handle_iocshRegisterVariable ( self , variable : str , value : str = \"\" ): self . variables [ variable ] = value return f \"Registered variable: { variable !r} = { value !r} \" def env_set_EPICS_BASE ( self , path ): # TODO: slac-specific path = str ( pathlib . Path ( path ) . resolve ()) version_prefixes = [ \"/reg/g/pcds/epics/base/\" , \"/cds/group/pcds/epics/base/\" , ] for prefix in version_prefixes : if path . startswith ( prefix ): path = path [ len ( prefix ):] if \"/\" in path : path = path . split ( \"/\" )[ 0 ] version = path . lstrip ( \"R\" ) if self . ioc_info . base_version == settings . DEFAULT_BASE_VERSION : self . ioc_info . base_version = version return f \"Set base version: { version } \" return ( f \"Found version ( { version } ) but version already specified:\" f \" { self . ioc_info . base_version } \" ) @_handler def handle_epicsEnvSet ( self , variable : str , value : str = \"\" ): self . macro_context . define ( ** { variable : value }) hook = getattr ( self , f \"env_set_ { variable } \" , None ) if hook and callable ( hook ): hook_result = hook ( value ) if hook_result : return { \"hook\" : hook_result , } @_handler def handle_epicsEnvShow ( self ): return self . macro_context . get_macros () def handle_iocshCmd ( self , command : str = \"\" , * _ ): # TODO: odd return type, used below return IocshCmdArgs ( context = self . get_load_context (), command = command ) @_handler def handle_cd ( self , path : str = \"\" ): if not path : raise RuntimeError ( \"Invalid directory path, ignored\" ) path = self . _fix_path ( path ) if path . is_absolute (): new_dir = path else : new_dir = self . working_directory / path if not new_dir . exists (): raise RuntimeError ( f \"Path does not exist: { new_dir } \" ) self . working_directory = new_dir . resolve () os . environ [ \"PWD\" ] = str ( self . working_directory ) return { \"result\" : f \"New working directory: { self . working_directory } \" } handle_chdir = handle_cd @_handler def handle_iocInit ( self ): if self . ioc_initialized : return { \"success\" : False , \"error\" : \"Already initialized\" , } result = { \"success\" : True , } for handler in self . sub_handlers : handler_result = handler . pre_ioc_init () result . update ( handler_result or {}) self . ioc_initialized = True for handler in self . sub_handlers : handler_result = handler . post_ioc_init () result . update ( handler_result or {}) return result @_handler def handle_dbLoadDatabase ( self , dbd : str , path : str = \"\" , substitutions : str = \"\" ): if self . ioc_initialized : raise RuntimeError ( \"Database cannot be loaded after iocInit\" ) if self . database_definition : # TODO: technically this is allowed; we'll need to update # raise RuntimeError(\"dbd already loaded\") return \"whatrecord: TODO multiple dbLoadDatabase\" dbd_path = self . _fix_path_with_search_list ( dbd , self . db_include_paths ) fn , contents = self . load_file ( dbd_path ) macro_context = MacroContext ( use_environment = False ) macro_context . define_from_string ( substitutions or \"\" ) self . database_definition = Database . from_string ( contents , version = self . ioc_info . database_version_spec , filename = fn , macro_context = macro_context , ) for addpath in self . database_definition . addpaths : for path in addpath . path . split ( os . pathsep ): # TODO: OS-dependent self . db_add_paths . append (( dbd_path . parent / path ) . resolve ()) self . aliases . update ( self . database_definition . aliases ) return { \"result\" : f \"Loaded database: { fn } \" } @_handler def handle_dbLoadTemplate ( self , filename : str , macros : str = \"\" ): filename = self . _fix_path_with_search_list ( filename , self . db_include_paths ) filename , contents = self . load_file ( filename ) # TODO this should be multiple load calls for the purposes of context result = { \"total_records\" : 0 , \"total_groups\" : 0 , \"loaded_files\" : [], } template = dbtemplate . TemplateSubstitution . from_string ( contents , filename = filename ) for sub in template . substitutions : database_contents = sub . expand_file ( search_paths = self . db_include_paths ) # TODO loading file twice (ensure it gets added to the loaded_files list) self . load_file ( sub . filename ) lint = self . _load_database ( filename = str ( sub . filename ), contents = database_contents , macros = macros , context = self . get_load_context () + sub . context , ) info = { \"filename\" : sub . filename , \"macros\" : sub . macros , \"records\" : len ( lint . records ), \"groups\" : len ( lint . pva_groups ), \"lint\" : lint , } result [ \"total_records\" ] += len ( lint . records ) result [ \"total_groups\" ] += len ( lint . pva_groups ) result [ \"loaded_files\" ] . append ( info ) return result def _load_database ( self , filename : str , contents : str , macros : str , context : FullLoadContext ) -> LinterResults : macro_context = MacroContext ( use_environment = False ) macros = macro_context . define_from_string ( macros or \"\" ) try : lint = LinterResults . from_database_string ( db = contents , dbd = self . database_definition , db_filename = filename , macro_context = macro_context , version = self . ioc_info . database_version_spec , ) except Exception as ex : # TODO move this around raise DatabaseLoadFailure ( f \"Failed to load { filename } : { type ( ex ) . __name__ } { ex } \" ) from ex db : Database = lint . db for name , rec in db . records . items (): if name not in self . database : self . database [ name ] = rec rec . context = context + rec . context rec . owner = self . ioc_info . name else : entry = self . database [ name ] entry . context = entry . context + rec . context entry . fields . update ( rec . fields ) # entry.owner = self.ioc_info.name ? for name , rec in db . pva_groups . items (): if name not in self . pva_database : self . pva_database [ name ] = rec rec . context = context + rec . context rec . owner = self . ioc_info . name else : entry = self . database [ name ] entry . context = entry . context + rec . context entry . fields . update ( rec . fields ) # entry.owner = self.ioc_info.name ? self . aliases . update ( db . aliases ) for addpath in db . addpaths : for path in addpath . path . split ( os . pathsep ): # TODO: OS-dependent self . db_add_paths . append (( db . parent / path ) . resolve ()) return lint @_handler def handle_dbLoadRecords ( self , filename : str , macros : str = \"\" ): if not self . database_definition : raise RuntimeError ( \"dbd not yet loaded\" ) if self . ioc_initialized : raise RuntimeError ( \"Records cannot be loaded after iocInit\" ) filename = self . _fix_path_with_search_list ( filename , self . db_include_paths ) filename , contents = self . load_file ( filename ) lint = self . _load_database ( filename = filename , contents = contents , macros = macros or \"\" , context = self . get_load_context () ) return { \"loaded_records\" : len ( lint . records ), \"loaded_groups\" : len ( lint . pva_groups ), \"lint\" : lint , } def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" for handler in self . sub_handlers : try : annotation = handler . annotate_record ( record ) except Exception : logger . exception ( \"Record annotation failed for %s with handler %s \" , record . name , type ( handler ) . __name__ ) else : if annotation is not None : record . metadata [ handler . metadata_key ] = annotation @_handler def handle_dbl ( self , rtyp : str = \"\" , fields : str = \"\" ): ... @_handler def handle_NDPvaConfigure ( self , portName : str , queueSize : int = 0 , blockingCallbacks : str = \"\" , NDArrayPort : str = \"\" , NDArrayAddr : str = \"\" , pvName : str = \"\" , maxBuffers : int = 0 , maxMemory : int = 0 , priority : int = 0 , stackSize : int = 0 , ): \"\"\"Implicitly creates a PVA group named ``pvName``.\"\"\" metadata = { \"portName\" : portName or \"\" , \"queueSize\" : queueSize or \"\" , \"blockingCallbacks\" : blockingCallbacks or \"\" , \"NDArrayPort\" : NDArrayPort or \"\" , \"NDArrayAddr\" : NDArrayAddr or \"\" , \"pvName\" : pvName or \"\" , \"maxBuffers\" : maxBuffers or \"\" , \"maxMemory\" : maxMemory or \"\" , \"priority\" : priority or \"\" , \"stackSize\" : stackSize or \"\" , } self . pva_database [ pvName ] = RecordInstance ( context = self . get_load_context (), name = pvName , record_type = \"PVA\" , fields = {}, is_pva = True , metadata = { \"areaDetector\" : metadata }, ) return metadata Attributes whatrecord . shell . ShellState . db_include_paths : List [ pathlib . Path ] property readonly Database include paths (EPICS_DB_INCLUDE_PATH). whatrecord . shell . ShellState . sub_handlers : List [ ShellStateHandler ] property readonly Handlers which contain their own state. Methods whatrecord . shell . ShellState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Hook to annotate a record after being loaded. Source code in whatrecord/shell.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" for handler in self . sub_handlers : try : annotation = handler . annotate_record ( record ) except Exception : logger . exception ( \"Record annotation failed for %s with handler %s \" , record . name , type ( handler ) . __name__ ) else : if annotation is not None : record . metadata [ handler . metadata_key ] = annotation whatrecord . shell . ShellState . get_load_context ( self ) -> FullLoadContext Get a FullLoadContext tuple representing where we are now. Source code in whatrecord/shell.py def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if not self . load_context : return tuple () return tuple ( ctx . to_load_context () for ctx in self . load_context ) whatrecord . shell . ShellState . handle_NDPvaConfigure ( self , portName : str , queueSize : int = 0 , blockingCallbacks : str = '' , NDArrayPort : str = '' , NDArrayAddr : str = '' , pvName : str = '' , maxBuffers : int = 0 , maxMemory : int = 0 , priority : int = 0 , stackSize : int = 0 ) Implicitly creates a PVA group named pvName . Source code in whatrecord/shell.py @_handler def handle_NDPvaConfigure ( self , portName : str , queueSize : int = 0 , blockingCallbacks : str = \"\" , NDArrayPort : str = \"\" , NDArrayAddr : str = \"\" , pvName : str = \"\" , maxBuffers : int = 0 , maxMemory : int = 0 , priority : int = 0 , stackSize : int = 0 , ): \"\"\"Implicitly creates a PVA group named ``pvName``.\"\"\" metadata = { \"portName\" : portName or \"\" , \"queueSize\" : queueSize or \"\" , \"blockingCallbacks\" : blockingCallbacks or \"\" , \"NDArrayPort\" : NDArrayPort or \"\" , \"NDArrayAddr\" : NDArrayAddr or \"\" , \"pvName\" : pvName or \"\" , \"maxBuffers\" : maxBuffers or \"\" , \"maxMemory\" : maxMemory or \"\" , \"priority\" : priority or \"\" , \"stackSize\" : stackSize or \"\" , } self . pva_database [ pvName ] = RecordInstance ( context = self . get_load_context (), name = pvName , record_type = \"PVA\" , fields = {}, is_pva = True , metadata = { \"areaDetector\" : metadata }, ) return metadata whatrecord . shell . ShellState . interpret_shell_line ( self , line , recurse = True , raise_on_error = False ) Interpret a single shell script line. Source code in whatrecord/shell.py def interpret_shell_line ( self , line , recurse = True , raise_on_error = False ): \"\"\"Interpret a single shell script line.\"\"\" shresult = parse_iocsh_line ( line , context = self . get_load_context (), prompt = self . prompt , macro_context = self . macro_context , string_encoding = self . string_encoding , ) input_redirects = [ redir for redir in shresult . redirects if redir . mode == \"r\" ] if shresult . error : yield shresult elif input_redirects : if recurse : yield from self . _handle_input_redirect ( input_redirects [ 0 ], shresult , recurse = recurse , raise_on_error = raise_on_error , ) elif shresult . argv : try : result = self . _handle_command ( * shresult . argv ) if result : # Only set if not-None to speed up serialization shresult . result = result except Exception as ex : if raise_on_error : raise ex_details = traceback . format_exc () shresult . error = f \"Failed to execute: { ex } : \\n { ex_details } \" yield shresult if isinstance ( shresult . result , IocshCmdArgs ): yield from self . interpret_shell_line ( shresult . result . command , recurse = recurse ) else : # Otherwise, nothing to do yield shresult whatrecord . shell . ShellState . interpret_shell_script ( self , filename : Union [ pathlib . Path , str ], recurse : bool = True , raise_on_error : bool = False ) -> Generator [ IocshResult , None , None ] Load and interpret a shell script named filename . Source code in whatrecord/shell.py def interpret_shell_script ( self , filename : Union [ pathlib . Path , str ], recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Load and interpret a shell script named ``filename``.\"\"\" filename , contents = self . load_file ( filename ) yield from self . interpret_shell_script_text ( contents . splitlines (), name = str ( filename ), recurse = recurse , raise_on_error = raise_on_error , ) whatrecord . shell . ShellState . interpret_shell_script_text ( self , lines : Iterable [ str ], name : str = 'unknown' , recurse : bool = True , raise_on_error : bool = False ) -> Generator [ IocshResult , None , None ] Interpret a shell script named name with lines of text. Source code in whatrecord/shell.py def interpret_shell_script_text ( self , lines : Iterable [ str ], name : str = \"unknown\" , recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Interpret a shell script named ``name`` with ``lines`` of text.\"\"\" load_ctx = MutableLoadContext ( str ( name ), 0 ) try : self . load_context . append ( load_ctx ) for lineno , line in enumerate ( lines , 1 ): load_ctx . line = lineno yield from self . interpret_shell_line ( line , recurse = recurse , raise_on_error = raise_on_error , ) finally : self . load_context . remove ( load_ctx ) # for rec in list(self.database.values()) + list(self.pva_database.values()): # try: # self.annotate_record(rec) # except Exception: # logger.exception(\"Failed to annotate record: %s\", rec.name) whatrecord . shell . ShellState . load_file ( self , filename : AnyPath ) -> Tuple [ pathlib . Path , str ] Load a file, record its hash, and return its contents. Source code in whatrecord/shell.py def load_file ( self , filename : AnyPath ) -> Tuple [ pathlib . Path , str ]: \"\"\"Load a file, record its hash, and return its contents.\"\"\" filename = self . _fix_path ( filename ) filename = filename . resolve () shasum , contents = util . read_text_file_with_hash ( filename , encoding = self . string_encoding ) self . loaded_files [ str ( filename )] = shasum self . ioc_info . loaded_files [ str ( filename )] = shasum return filename , contents whatrecord . shell . ShellState . paths_from_env_var ( self , env_var : str , * , default : Optional [ str ] = None ) -> List [ pathlib . Path ] Paths from an environment variable (or macro). Source code in whatrecord/shell.py def paths_from_env_var ( self , env_var : str , * , default : Optional [ str ] = None ) -> List [ pathlib . Path ]: \"\"\"Paths from an environment variable (or macro).\"\"\" env_var = self . macro_context . get ( env_var , default ) or \"\" return [ ( self . working_directory / pathlib . Path ( path )) . resolve () # TODO: this is actually OS-dependent (: on linux, ; on Windows) for path in env_var . split ( \":\" ) ] Functions whatrecord . shell . async_load_ioc ( identifier : Union [ int , str ], md : IocMetadata , standin_directories , use_gdb : bool = True , use_cache : bool = True ) -> IocLoadResult async Helper function for loading an IOC in a subprocess and relying on the cache. Source code in whatrecord/shell.py async def async_load_ioc ( identifier : Union [ int , str ], md : IocMetadata , standin_directories , use_gdb : bool = True , use_cache : bool = True , ) -> IocLoadResult : \"\"\" Helper function for loading an IOC in a subprocess and relying on the cache. \"\"\" if not settings . CACHE_PATH : use_cache = False with time_context () as ctx : try : md . standin_directories . update ( standin_directories ) if use_cache : cached_ioc = load_cached_ioc ( md ) if cached_ioc : return IocLoadResult ( identifier = identifier , load_time = ctx (), cache_hit = True , result = \"use_cache\" ) loaded = LoadedIoc . from_metadata ( md ) if use_gdb : await md . get_binary_information () if use_cache : loaded . metadata . save_to_cache () loaded . save_to_cache () # Avoid pickling massive JSON blob; instruct server to load # from cache with token 'use_cache' serialized = \"use_cache\" else : serialized = apischema . serialize ( loaded ) except Exception as ex : return IocLoadResult ( identifier = identifier , load_time = ctx (), cache_hit = False , result = IocLoadFailure ( ex_class = type ( ex ) . __name__ , ex_message = str ( ex ), traceback = traceback . format_exc (), ), ) return IocLoadResult ( identifier = identifier , load_time = ctx (), cache_hit = False , result = serialized , ) whatrecord . shell . load_startup_scripts_with_metadata ( * md_items , * , standin_directories = None , processes : int = 8 , use_gdb : bool = True ) -> ScriptContainer Load all given startup scripts into a shared ScriptContainer. Parameters: Name Type Description Default *md_items list of IocMetadata List of IOC metadata. () standin_directories dict Stand-in/substitute directory mapping. None processes int The number of processes to use when loading. 8 Source code in whatrecord/shell.py async def load_startup_scripts_with_metadata ( * md_items , standin_directories = None , processes : int = 8 , use_gdb : bool = True , ) -> ScriptContainer : \"\"\" Load all given startup scripts into a shared ScriptContainer. Parameters ---------- *md_items : list of IocMetadata List of IOC metadata. standin_directories : dict Stand-in/substitute directory mapping. processes : int The number of processes to use when loading. \"\"\" total_files = len ( md_items ) total_child_load_time = 0.0 with time_context () as total_time , ProcessPoolExecutor ( max_workers = processes , initializer = _process_init ) as executor : coros = [ asyncio . wrap_future ( executor . submit ( _load_ioc , identifier = idx , md = md , standin_directories = standin_directories , use_gdb = use_gdb ) ) for idx , md in enumerate ( md_items ) ] for coro in asyncio . as_completed ( coros ): try : load_result = await coro md = md_items [ load_result . identifier ] except Exception as ex : logger . exception ( \"Internal error while loading: %s : %s [server %.1f s]\" , type ( ex ) . __name__ , ex , total_time (), ) continue use_cache = load_result . result == \"use_cache\" if not use_cache : loaded = load_result . result else : try : loaded = load_cached_ioc ( md , allow_failed_load = True ) if loaded is None : raise ValueError ( \"Cache entry is empty?\" ) except Exception as ex : logger . exception ( \"Internal error while loading cached IOC from disk: \" \" %s : %s [server %.1f s]\" , type ( ex ) . __name__ , ex , total_time (), ) continue total_child_load_time += load_result . load_time if isinstance ( loaded , IocLoadFailure ): failure_result : IocLoadFailure = loaded logger . error ( \"Failed to load %s in subprocess: %s \" \"[ %.1f s; server %.1f ]: %s \\n %s \" , md . name or md . script , failure_result . ex_class , load_result . load_time , total_time (), failure_result . ex_message , ( failure_result . traceback if failure_result . ex_class != \"FileNotFoundError\" else \"\" ), ) if md . base_version == settings . DEFAULT_BASE_VERSION : md . base_version = \"unknown\" yield md , LoadedIoc . from_errored_load ( md , loaded ) continue with time_context () as ctx : loaded_ioc = apischema . deserialize ( LoadedIoc , loaded ) logger . info ( \"Child loaded %s%s in %.1f s, server deserialized in %.1f s\" , md . name or md . script , \" from cache\" if load_result . cache_hit else \"\" , load_result . load_time , ctx (), ) yield md , loaded_ioc logger . info ( \"Loaded %d startup scripts in %.1f s (wall time) with %d process(es)\" , total_files , total_time (), processes , ) logger . info ( \"Child processes reported taking a total of %.1f \" \"sec, the total time on %d process(es)\" , total_child_load_time , processes , )","title":"IOC Shell-Related"},{"location":"iocsh/#ioc-shell-related","text":"","title":"IOC Shell-Related"},{"location":"iocsh/#api","text":"","title":"API"},{"location":"iocsh/#whatrecord.asyn","text":"","title":"asyn"},{"location":"iocsh/#whatrecord.asyn-classes","text":"","title":"Classes"},{"location":"iocsh/#whatrecord.asyn.AdsAsynPort","text":"AdsAsynPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = , ipaddr: 'str' = '', amsaddr: 'str' = '', amsport: 'int' = 0, asynParamTableSize: 'int' = 0, priority: 'int' = 0, noAutoConnect: 'int' = 0, defaultSampleTimeMS: 'int' = 0, maxDelayTimeMS: 'int' = 0, adsTimeoutMS: 'int' = 0, defaultTimeSource: 'str' = '') Source code in whatrecord/asyn.py @dataclass class AdsAsynPort ( AsynPort ): ipaddr : str = \"\" amsaddr : str = \"\" amsport : int = 0 asynParamTableSize : int = 0 priority : int = 0 noAutoConnect : int = 0 defaultSampleTimeMS : int = 0 maxDelayTimeMS : int = 0 adsTimeoutMS : int = 0 defaultTimeSource : str = \"\" _jinja_format_ : ClassVar [ dict ] = { \"console\" : AsynPort . _jinja_format_ [ \"console\" ] + \"\"\" ipaddr: {{ipaddr}} amsaddr: {{amsaddr}} amsport: {{amsport}} asynParamTableSize: {{asynParamTableSize}} priority: {{priority}} noAutoConnect: {{noAutoConnect}} defaultSampleTimeMS: {{defaultSampleTimeMS}} maxDelayTimeMS: {{maxDelayTimeMS}} adsTimeoutMS: {{adsTimeoutMS}} defaultTimeSource: {{defaultTimeSource}} \"\"\" }","title":"AdsAsynPort"},{"location":"iocsh/#whatrecord.asyn.AsynIPPort","text":"AsynIPPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = , hostInfo: 'str' = '', priority: 'str' = '', noAutoConnect: 'str' = '', noProcessEos: 'str' = '') Source code in whatrecord/asyn.py @dataclass class AsynIPPort ( AsynPort ): hostInfo : str = \"\" priority : str = \"\" noAutoConnect : str = \"\" noProcessEos : str = \"\"","title":"AsynIPPort"},{"location":"iocsh/#whatrecord.asyn.AsynMotor","text":"AsynMotor(context: 'FullLoadContext', name: 'str', metadata: 'Dict[str, Union[str, int, float]]' = , parent: 'Optional[str]' = None) Source code in whatrecord/asyn.py @dataclass class AsynMotor ( AsynPortBase ): context : FullLoadContext name : str metadata : Dict [ str , Union [ str , int , float ]] = field ( default_factory = dict ) parent : Optional [ str ] = None","title":"AsynMotor"},{"location":"iocsh/#whatrecord.asyn.AsynPort","text":"AsynPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = ) Source code in whatrecord/asyn.py @dataclass class AsynPort ( AsynPortBase ): context : FullLoadContext name : str options : Dict [ str , AsynPortOption ] = field ( default_factory = dict ) metadata : Dict [ str , str ] = field ( default_factory = dict ) motors : Dict [ str , AsynMotor ] = field ( default_factory = dict ) _jinja_format_ : ClassVar [ dict ] = { \"console\" : \"\"\" \\ {{obj|classname}}: name: {{name}} options: {{options}} metadata: {{metadata}} Defined: { % f or ctx in context %} * {{ctx}} { % e ndfor %} { % f or motor in motors %} { % s et motor_text = render_object(motor, \"console\") %} {{ motor_text | indent(8)}} { % e ndfor %} \"\"\" , }","title":"AsynPort"},{"location":"iocsh/#whatrecord.asyn.AsynPortDevice","text":"AsynPortDevice(context: 'FullLoadContext', name: 'str' = '', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = ) Source code in whatrecord/asyn.py @dataclass class AsynPortDevice ( AsynPortBase ): context : FullLoadContext name : str = \"\" options : Dict [ str , AsynPortOption ] = field ( default_factory = dict ) metadata : Dict [ str , str ] = field ( default_factory = dict ) motors : Dict [ str , AsynMotor ] = field ( default_factory = dict )","title":"AsynPortDevice"},{"location":"iocsh/#whatrecord.asyn.AsynPortMultiDevice","text":"AsynPortMultiDevice(context: 'FullLoadContext', name: 'str', metadata: 'dict' = , motors: 'Dict[str, AsynMotor]' = , devices: 'Dict[str, AsynPortDevice]' = ) Source code in whatrecord/asyn.py @dataclass class AsynPortMultiDevice ( AsynPortBase ): context : FullLoadContext name : str metadata : dict = field ( default_factory = dict ) motors : Dict [ str , AsynMotor ] = field ( default_factory = dict ) devices : Dict [ str , AsynPortDevice ] = field ( default_factory = dict )","title":"AsynPortMultiDevice"},{"location":"iocsh/#whatrecord.asyn.AsynPortOption","text":"AsynPortOption(context: 'FullLoadContext', key: 'str', value: 'str') Source code in whatrecord/asyn.py @dataclass class AsynPortOption : context : FullLoadContext key : str value : str","title":"AsynPortOption"},{"location":"iocsh/#whatrecord.asyn.AsynSerialPort","text":"AsynSerialPort(context: 'FullLoadContext', name: 'str', options: 'Dict[str, AsynPortOption]' = , metadata: 'Dict[str, str]' = , motors: 'Dict[str, AsynMotor]' = , ttyName: 'str' = '', priority: 'str' = '', noAutoConnect: 'str' = '', noProcessEos: 'str' = '') Source code in whatrecord/asyn.py @dataclass class AsynSerialPort ( AsynPort ): ttyName : str = \"\" priority : str = \"\" noAutoConnect : str = \"\" noProcessEos : str = \"\"","title":"AsynSerialPort"},{"location":"iocsh/#whatrecord.asyn.AsynState","text":"Asyn IOC shell state handler / container. Contains hooks for asyn-related commands and state information. Attributes: Name Type Description ports Dict[str, asyn.AsynPortBase] Asyn ports defined by name. Source code in whatrecord/asyn.py @dataclass class AsynState ( ShellStateHandler ): \"\"\" Asyn IOC shell state handler / container. Contains hooks for asyn-related commands and state information. Attributes ---------- ports : Dict[str, asyn.AsynPortBase] Asyn ports defined by name. \"\"\" metadata_key : ClassVar [ str ] = \"asyn\" ports : Dict [ str , AsynPortBase ] = field ( default_factory = dict ) @_handler def handle_drvAsynSerialPortConfigure ( self , portName : str , ttyName : str , priority : int = 0 , noAutoConnect : int = 0 , noProcessEos : int = 0 , ): # SLAC-specific, but doesn't hurt anyone self . ports [ portName ] = AsynSerialPort ( context = self . get_load_context (), name = portName , ttyName = ttyName , priority = priority , noAutoConnect = noAutoConnect , noProcessEos = noProcessEos , ) @_handler def handle_drvAsynIPPortConfigure ( self , portName : str , hostInfo : str , priority : int = 0 , noAutoConnect : int = 0 , noProcessEos : int = 0 , ): # SLAC-specific, but doesn't hurt anyone self . ports [ portName ] = AsynIPPort ( context = self . get_load_context (), name = portName , hostInfo = hostInfo , priority = priority , noAutoConnect = noAutoConnect , noProcessEos = noProcessEos , ) @_handler def handle_asynSetOption ( self , name : str , addr : str , key : str , value : str ): port = self . ports [ name ] opt = AsynPortOption ( context = self . get_load_context (), key = key , value = value , ) if isinstance ( port , AsynPortMultiDevice ): port . devices [ addr ] . options [ key ] = opt else : port . options [ key ] = opt def get_port_from_record ( self , inst : RecordInstance ) -> Optional [ AsynPort ]: \"\"\"Given a record, return its related asyn port.\"\"\" if inst . is_pva : return rec_field : Optional [ RecordField ] rec_field = inst . fields . get ( \"INP\" , inst . fields . get ( \"OUT\" , None )) if rec_field is None : return if not isinstance ( rec_field . value , str ): # No PVAccess links just yet return value = rec_field . value . strip () if value . startswith ( \"@asyn\" ): try : asyn_args = value . split ( \"@asyn\" )[ 1 ] . strip ( \" ()\" ) asyn_port , * _ = asyn_args . split ( \",\" ) return self . ports . get ( asyn_port . strip (), None ) except Exception : logger . debug ( \"Failed to parse asyn string\" , exc_info = True ) def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: port = self . get_port_from_record ( record ) if port is not None : parent_port = getattr ( port , \"parent\" , None ) ports = [ port_ for port_ in [ parent_port , port ] if port_ is not None ] return { \"ports\" : ports }","title":"AsynState"},{"location":"iocsh/#whatrecord.asyn.AsynState-methods","text":"whatrecord . asyn . AsynState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate the given record's metadata with state-related information. Source code in whatrecord/asyn.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: port = self . get_port_from_record ( record ) if port is not None : parent_port = getattr ( port , \"parent\" , None ) ports = [ port_ for port_ in [ parent_port , port ] if port_ is not None ] return { \"ports\" : ports } whatrecord . asyn . AsynState . get_port_from_record ( self , inst : RecordInstance ) -> Optional [ AsynPort ] Given a record, return its related asyn port. Source code in whatrecord/asyn.py def get_port_from_record ( self , inst : RecordInstance ) -> Optional [ AsynPort ]: \"\"\"Given a record, return its related asyn port.\"\"\" if inst . is_pva : return rec_field : Optional [ RecordField ] rec_field = inst . fields . get ( \"INP\" , inst . fields . get ( \"OUT\" , None )) if rec_field is None : return if not isinstance ( rec_field . value , str ): # No PVAccess links just yet return value = rec_field . value . strip () if value . startswith ( \"@asyn\" ): try : asyn_args = value . split ( \"@asyn\" )[ 1 ] . strip ( \" ()\" ) asyn_port , * _ = asyn_args . split ( \",\" ) return self . ports . get ( asyn_port . strip (), None ) except Exception : logger . debug ( \"Failed to parse asyn string\" , exc_info = True )","title":"Methods"},{"location":"iocsh/#whatrecord.iocsh","text":"","title":"iocsh"},{"location":"iocsh/#whatrecord.iocsh-functions","text":"","title":"Functions"},{"location":"iocsh/#whatrecord.iocsh.parse_iocsh_line","text":"Parse an IOC shell line into an IocshResult. Parameters: Name Type Description Default line str The line to parse. required context Optional[whatrecord.common.LoadContext] The load context to populate the result with. None prompt str Replicating the EPICS source code, specify the state of the prompt here. Defaults to \"epics>\". If unset as in prior to IOC init, lines that do not start with \"#-\" will be eched. 'epics>' Returns: Type Description IocshResult A partially filled IocshResult, ready for interpreting by a higher-level function. Source code in whatrecord/iocsh.py def parse_iocsh_line ( line : str , * , context : Optional [ LoadContext ] = None , prompt : str = \"epics>\" , macro_context : Optional [ MacroContext ] = None , string_encoding : str = \"latin-1\" , ) -> IocshResult : \"\"\" Parse an IOC shell line into an IocshResult. Parameters ---------- line : str The line to parse. context : LoadContext, optional The load context to populate the result with. prompt : str, optional Replicating the EPICS source code, specify the state of the prompt here. Defaults to \"epics>\". If unset as in prior to IOC init, lines that do not start with \"#-\" will be eched. Returns ------- IocshResult A partially filled IocshResult, ready for interpreting by a higher-level function. \"\"\" result = IocshResult ( context = context , line = line , ) # Skip leading whitespace line = line . lstrip () if not line . startswith ( \"#-\" ): result . outputs . append ( line ) if line . startswith ( '#' ): # Echo non-empty lines read from a script. # Comments delineated with '#-' aren't echoed. return result if macro_context is not None : line = macro_context . expand ( line ) # * Skip leading white-space coming from a macro line = line . lstrip () # * Echo non-empty lines read from a script. # * Comments delineated with '#-' aren't echoed. if not prompt : if not line . startswith ( '#-' ): result . outputs . append ( line ) # * Ignore lines that became a comment or empty after macro expansion if not line or line . startswith ( '#' ): return result split = split_words ( line , string_encoding = string_encoding ) result . argv = split . argv # Only set the following if necessary; apischema can skip serialization # otherwise. if split . redirects : result . redirects = list ( split . redirects . values ()) if split . error : result . error = split . error return result","title":"parse_iocsh_line()"},{"location":"iocsh/#whatrecord.motor","text":"","title":"motor"},{"location":"iocsh/#whatrecord.motor-classes","text":"","title":"Classes"},{"location":"iocsh/#whatrecord.motor.MotorState","text":"Motor record support IOC shell state handler / container. Source code in whatrecord/motor.py @dataclass class MotorState ( ShellStateHandler ): \"\"\"Motor record support IOC shell state handler / container.\"\"\" metadata_key : ClassVar [ str ] = \"motor\" @property def asyn ( self ) -> asyn . AsynState : \"\"\"Asyn instance.\"\"\" if self . primary_handler is None : raise RuntimeError ( \"Requires a primary handler\" ) return self . primary_handler . asyn @property def ports ( self ) -> Dict [ str , AsynPortBase ]: \"\"\"Asyn ports.\"\"\" return self . asyn . ports @_handler ( stub = True ) def handle_A3200AsynConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , task_number : int , linear_move_commands : int , ): ... @_handler ( stub = True ) def handle_A3200AsynSetup ( self , max_controller_count : int ): ... @_handler ( stub = True ) def handle_ACRCreateController ( self , port_name : str , acr_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_AG_CONEXCreateController ( self , port_name : str , serial_port_name : str , controller_id : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_AG_UCCreateAxis ( self , controller_port_name : str , axis_number : int , has_limits : int , forward_amplitude : int , reverse_amplitude : int , ): ... @_handler ( stub = True ) def handle_AG_UCCreateController ( self , port_name : str , serial_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_ANC150AsynConfig ( self , card_being_configured : int , asyn_port_name : str , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_ANC150AsynSetup ( self , maximum_of_controllers : int ): ... @_handler ( stub = True ) def handle_ANF2CreateAxis ( self , port_name : str , axis_number : int , hex_config : str , base_speed : int , homing_timeout : int , ): ... @_handler ( stub = True ) def handle_ANF2CreateController ( self , port_name : str , anf2_in_port_name : str , anf2_out_port_name : str , number_of_axes : int , ): ... @_handler ( stub = True ) def handle_ANF2StartPoller ( self , port_name : str , moving_poll_period_ms : int , idle_poll_period_ms : int ): ... @_handler ( stub = True ) def handle_ANG1CreateController ( self , port_name : str , ang1_in_port_name : str , ang1_out_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_AcsMotionConfig ( self , acs_port_name : str , asyn_port_name : str , num_axes : int , moving_polling_rate : float , idle_polling_rate : float , ): ... @_handler ( stub = True ) def handle_C300CreateController ( self , port_name : str , c300_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_EMC18011Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_EMC18011Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_ESP300Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_ESP300Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_EnsembleAsynConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_EnsembleAsynSetup ( self , max_controller_count : int ): ... @_handler ( stub = True ) def handle_HXPCreateController ( self , port_name : str , ip_address : str , port : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_Hytec8601Configure ( self , port_name : str , num_axes : int , moving_poll_period : int , idle_poll_period : int , cardnum : int , carrier : int , ipslot : int , vector : int , useencoder : int , encoder_ratio0 : float , encoder_ratio1 : float , encoder_ratio2 : float , encoder_ratio3 : float , ): ... @_handler ( stub = True ) def handle_IM483PLConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_IM483PLSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_IM483SMConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_IM483SMSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_ImsMDrivePlusCreateController ( self , motor_port_name : str , io_port_name : str , device_name : str , moving_poll_period_ms : float , idle_poll_period_ms : float , ): ... @_handler ( stub = True ) def handle_LinmotCreateController ( self , port_name : str , linmot_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MAXvConfig ( self , card_being_configured : int , configuration_string : str , absolute_encoder_flags : int , grey_code_flags : int , ): ... @_handler ( stub = True ) def handle_MAXvSetup ( self , max_controller_count : int , vme_address_type : int , base_address_on_4_k_0x1000_boundary : int , valid_vectors : int , interrupt_level_1_6 : int , polling_rate_hz : int , ): ... @_handler ( stub = True ) def handle_MCB4BConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MCB4BCreateController ( self , port_name : str , mcb_4_b_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MCB4BSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MCDC2805Config ( self , card_being_configured : int , modules_on_this_serial_port : int , asyn_port_name : str , ): ... @_handler ( stub = True ) def handle_MCDC2805Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MCS2CreateController ( self , port_name : str , mcs2_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MDT695Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MDT695Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MDriveConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MDriveSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MM3000Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_MM300Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MM4000AsynConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_MM4000AsynSetup ( self , max_controller_count : int ): ... @_handler ( stub = True ) def handle_MM4000Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_MM4000Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MMC200CreateController ( self , port_name : str , mmc_200_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ignore_limit_flag : int , ): ... @_handler ( stub = True ) def handle_MVP2001CreateAxis ( self , controller_port_name : str , axis_number : int , encoder_lines_per_rev : int , max_current_ma : int , limit_polarity : int , ): ... @_handler ( stub = True ) def handle_MVP2001CreateController ( self , port_name : str , mvp_2001_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_MXmotorSetup ( self , max_motor : int , mx_data_file : str , polling_rate : int ): ... @_handler ( stub = True ) def handle_MicosConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MicosSetup ( self , max_controller_count : int , max_motor_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_MicroMoConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_MicroMoSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_OmsPC68Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_OmsPC68Setup ( self , maximum_of_cards : int , polling_rate_hz : int ): ... @_handler ( stub = True ) def handle_PC6KConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_PC6KSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PC6KUpLoad ( self , controller_card : int , upload_file_path : str , program_name_null_immediate : str , ): ... @_handler ( stub = True ) def handle_PIC630Config ( self , card_being_configured : int , asyn_port_name : str , ch_1_current_setting : int , ch_2_current_setting : int , ch_3_current_setting : int , ch_4_current_setting : int , ch_5_current_setting : int , ch_6_current_setting : int , ch_7_current_setting : int , ch_8_current_setting : int , ch_9_current_setting : int , ): ... @_handler ( stub = True ) def handle_PIC630Setup ( self , max_controller_groups : int , max_axes_per_group : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC662Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_PIC662Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC663Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC663Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC844Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC844Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC848Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC848Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIC862Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIC862Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE516Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE516Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE517Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE517Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE710Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE710Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIE816Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIE816Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PIJEDSConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PIJEDSSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PI_GCS2_CreateController ( self , port_name : str , asyn_port_name : str , number_of_axes : int , priority : int , stack_size : int , moving_polling_time_msec : int , idle_polling_time_msec : int , ): ... @_handler ( stub = True ) def handle_PM304Config ( self , card_being_configured : int , asyn_port_name : str , number_of_axes : int ): ... @_handler ( stub = True ) def handle_PM304Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PM500Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PM500Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_PMNC87xxConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_PMNC87xxSetup ( self , max_controller_count : int , max_drivers_per_controller_count : int , polling_rate : int , ): ... @_handler ( stub = True ) def handle_SC800Config ( self , card_being_configured : int , asyn_port_name : str , asyn_address_gpib : int ): ... @_handler ( stub = True ) def handle_SC800Setup ( self , maximum_of_cards : int , polling_rate_hz : int ): ... @_handler ( stub = True ) def handle_SMC100Config ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_SMC100CreateController ( self , port_name : str , smc100_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , eg_us_per_step : str , ): ... @_handler ( stub = True ) def handle_SMC100Setup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_SMCcorvusChangeResolution ( self , smc_corvus_port_name : str , axis_number : int , axis_resolution : float ): ... @_handler ( stub = True ) def handle_SMCcorvusCreateController ( self , port_name : str , smc_corvus_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_SMChydraChangeResolution ( self , smc_hydra_port_name : str , axis_number : int , axis_resolution : float ): ... @_handler ( stub = True ) def handle_SMChydraCreateController ( self , port_name : str , smc_hydra_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_SPiiPlusConfig ( self , card_being_configured : int , asyn_port_name : str , command_mode_bu_ffer_co_nnect_di_rect : str , ): ... @_handler ( stub = True ) def handle_SPiiPlusSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_ScriptAxisConfig ( self , controller_port_name : str , axis_number : int , parameters : str ): ... @_handler ( stub = True ) def handle_ScriptControllerConfig ( self , motor_port_name : str , number_of_axes : int , control_script : str , parameters : str , ): ... @_handler ( stub = True ) def handle_ScriptMotorReload ( self , motor_port_name : str ): ... @_handler ( stub = True ) def handle_SmartMotorConfig ( self , card_being_configured : int , asyn_port_name : str ): ... @_handler ( stub = True ) def handle_SmartMotorSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_SoloistConfig ( self , card_being_configured : int , asyn_port_name : str , asyn_address : int ): ... @_handler ( stub = True ) def handle_SoloistSetup ( self , max_controller_count : int , polling_rate : int ): ... @_handler ( stub = True ) def handle_XPSAuxConfig ( self , port_name : str , ip_address : str , ip_port : int , polling_period : int ): ... @_handler ( stub = True ) def handle_XPSConfig ( self , card_being_configured : int , ip : str , port : int , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , ): ... @_handler ( stub = True ) def handle_XPSConfigAxis ( self , card_number : int , axis_number : int , axis_name : str , steps_per_unit : str , no_disabled_error : int , ): ... @_handler ( stub = True ) def handle_XPSCreateAxis ( self , controller_port_name : str , axis_number : int , axis_name : str , steps_per_unit : str , ): ... @_handler ( stub = True ) def handle_XPSCreateController ( self , controller_port_name : str , ip_address : str , ip_port : int , number_of_axes : int , moving_poll_rate_ms : int , idle_poll_rate_ms : int , enable_set_position : int , set_position_settling_time_ms : int , ): ... @_handler ( stub = True ) def handle_XPSCreateProfile ( self , controller_port_name : str , max_points : int , ftp_username : str , ftp_password : str , ): ... @_handler ( stub = True ) def handle_XPSDisableAutoEnable ( self , controller_port_name : str ): ... @_handler ( stub = True ) def handle_XPSDisablePoll ( self , set_disable_poll_value : int ): ... @_handler ( stub = True ) def handle_XPSEnableMoveToHome ( self , card_number : int , axis_name : str , distance : int ): ... @_handler ( stub = True ) def handle_XPSEnableMovingMode ( self , controller_port_name : str ): ... @_handler ( stub = True ) def handle_XPSEnableSetPosition ( self , set_position_flag : int ): ... @_handler ( stub = True ) def handle_XPSGathering ( self , interelement_period : int ): ... @_handler ( stub = True ) def handle_XPSInterpose ( self , port_name : str ): ... @_handler ( stub = True ) def handle_XPSNoDisableError ( self , controller_port_name : str ): ... @_handler ( stub = True ) def handle_XPSSetPosSleepTime ( self , set_position_sleep_time : int ): ... @_handler ( stub = True ) def handle_XPSSetup ( self , number_of_xps_controllers : int ): ... @_handler ( stub = True ) def handle_asynMotorEnableMoveToHome ( self , controller_port_name : str , axis_number : int , distance : int ): ... @_handler ( stub = True ) def handle_listMovingMotors ( self , list_moving_motors : str ): ... @_handler ( stub = True ) def handle_motorSimConfigAxis ( self , post_name : str , axis : int , high_limit : int , low_limit : int , home_position : int , start_posn : int , ): ... @_handler ( stub = True ) def handle_motorSimCreate ( self , card : int , signal : int , high_limit : int , low_limit : int , home_position : int , num_cards : int , num_signals : int , start_posn : int , ): ... @_handler ( stub = True ) def handle_motorSimCreateController ( self , port_name : str , number_of_axes : int , priority : int , stack_size : int ): ... @_handler ( stub = True ) def handle_motorUtilInit ( self , ioc_name : str ): ... @_handler ( stub = True ) def handle_nf874xCreateController ( self , port_name : str , nf874x_port_name : str , number_of_axes : int , moving_poll_period_ms : int , idle_poll_period_ms : int , ): ... @_handler ( stub = True ) def handle_oms58Setup ( self , num_card : int , addrs : int , vector : int , int_level : int , scan_rate : int ): ... @_handler ( stub = True ) def handle_omsMAXnetConfig ( self , asyn_motor_port_name : str , number_of_axes : int , asyn_serial_tcp_port_name : str , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvConfig ( self , number_of_card : int , asyn_motor_port_name : str , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvConfig2 ( self , slot_number : int , address_type_a16_a24_a32 : str , board_address_on_4_k_0x1000_boundary : int , interrupt_vector_noninterrupting_0_64_255 : int , interrupt_level_1_6 : int , asyn_motor_port_name : str , number_of_axes : int , task_priority_0_medium : int , stack_size_0_medium : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvEncFuncConfig ( self , number_of_card : int , asyn_motor_port_name : str , number_of_axes : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvEncFuncConfig2 ( self , slot_number : int , address_type_a16_a24_a32 : str , board_address_on_4_k_0x1000_boundary : int , interrupt_vector_noninterrupting_0_64_255 : int , interrupt_level_1_6 : int , asyn_motor_port_name : str , number_of_axes : int , task_priority_0_medium : int , stack_size_0_medium : int , moving_poll_rate : int , idle_poll_rate : int , initstring : str , ): ... @_handler ( stub = True ) def handle_omsMAXvSetup ( self , max_controller_count : int , vme_address_type : int , base_address_on_4_k_0x1000_boundary : int , noninterrupting_0_valid_vectors_64_255 : int , interrupt_level_1_6 : int , ): ... @_handler ( stub = True ) def handle_phytronCreateAxis ( self , controller_name : str , module_index : int , axis_index : int ): ... @_handler ( stub = True ) def handle_phytronCreateController ( self , port_name : str , phytron_axis_port_name : str , moving_poll_period_ms : int , idle_poll_period_ms : int , timeout_ms : float , ): ... @_handler ( stub = True ) def handle_printChIDlist ( self , print_motor_util_chid_list : str ): ... @_handler ( stub = True ) def handle_setIdlePollPeriod ( self , controller_port_name : str , axis_number : float ): ... @_handler ( stub = True ) def handle_setMovingPollPeriod ( self , controller_port_name : str , axis_number : float ): ... @_handler ( stub = True ) def handle_smarActMCSCreateAxis ( self , controller_port_name_string : str , axis_number_int : int , channel_int : int ): ... @_handler ( stub = True ) def handle_smarActMCSCreateController ( self , port_name_string : str , i_o_port_name_string : str , number_of_axes_int : int , moving_poll_period_s_double : float , idle_poll_period_s_double : float , ): ... @_handler ( stub = True ) def handle_smarActSCUCreateAxis ( self , controller_port_name_string : str , axis_number_int : int , channel_int : int ): ... @_handler ( stub = True ) def handle_smarActSCUCreateController ( self , port_name_string : str , i_o_port_name_string : str , number_of_axes_int : int , moving_poll_period_s_double : float , idle_poll_period_s_double : float , ): ... @_handler ( stub = True ) def handle_tclcall ( self , tcl_name : str , task_name : str , function_args : str ): ... @_handler ( stub = True ) def handle_xps_gathering ( self , element_period_10_4 : int ): ... @_handler ( stub = True ) def handle_EthercatMCCreateAxis ( self , motor_port : str , axis_num : int , amplifier_flags : str , axis_config : str ): ... @_handler def handle_adsAsynPortDriverConfigure ( self , portName : str , ipaddr : str = \"\" , amsaddr : str = \"\" , amsport : int = 0 , asynParamTableSize : int = 0 , priority : int = 0 , noAutoConnect : int = 0 , defaultSampleTimeMS : int = 0 , maxDelayTimeMS : int = 0 , adsTimeoutMS : int = 0 , defaultTimeSource : str = \"\" , ): # SLAC-specific, but doesn't hurt anyone self . ports [ portName ] = asyn . AdsAsynPort ( context = self . get_load_context (), name = portName , ipaddr = ipaddr , amsaddr = amsaddr , amsport = amsport , asynParamTableSize = asynParamTableSize , priority = priority , noAutoConnect = noAutoConnect , defaultSampleTimeMS = defaultSampleTimeMS , maxDelayTimeMS = maxDelayTimeMS , adsTimeoutMS = adsTimeoutMS , defaultTimeSource = defaultTimeSource , ) @_handler def handle_drvAsynMotorConfigure ( self , port_name : str = \"\" , driver_name : str = \"\" , card_num : int = 0 , num_axes : int = 0 , ): self . ports [ port_name ] = asyn . AsynMotor ( context = self . get_load_context (), name = port_name , parent = None , metadata = dict ( num_axes = num_axes , card_num = card_num , driver_name = driver_name , ), ) @_handler def handle_EthercatMCCreateController ( self , motor_port : str , asyn_port : str , num_axes : int = 0 , move_poll_rate : float = 0.0 , idle_poll_rate : float = 0.0 , ): # SLAC-specific port = self . ports [ asyn_port ] motor = asyn . AsynMotor ( context = self . get_load_context (), name = motor_port , parent = asyn_port , metadata = dict ( num_axes = num_axes , move_poll_rate = move_poll_rate , idle_poll_rate = idle_poll_rate , ), ) # Tie it to both the original asyn port (as a motor) and also the # top-level asyn ports. port . motors [ motor_port ] = motor self . ports [ motor_port ] = motor","title":"MotorState"},{"location":"iocsh/#whatrecord.motor.MotorState-attributes","text":"whatrecord . motor . MotorState . asyn : AsynState property readonly Asyn instance. whatrecord . motor . MotorState . ports : Dict [ str , whatrecord . common . AsynPortBase ] property readonly Asyn ports.","title":"Attributes"},{"location":"iocsh/#whatrecord.shell","text":"","title":"shell"},{"location":"iocsh/#whatrecord.shell-classes","text":"","title":"Classes"},{"location":"iocsh/#whatrecord.shell.IocLoadFailure","text":"IocLoadFailure(ex_class: 'str', ex_message: 'str', traceback: 'str') Source code in whatrecord/shell.py @dataclass class IocLoadFailure : ex_class : str ex_message : str traceback : str","title":"IocLoadFailure"},{"location":"iocsh/#whatrecord.shell.IocLoadResult","text":"IocLoadResult(identifier: 'Union[int, str]', load_time: 'float', cache_hit: 'bool', result: 'Union[IocLoadFailure, str]') Source code in whatrecord/shell.py @dataclass class IocLoadResult : identifier : Union [ int , str ] load_time : float cache_hit : bool result : Union [ IocLoadFailure , str ]","title":"IocLoadResult"},{"location":"iocsh/#whatrecord.shell.LoadedIoc","text":"LoadedIoc(name: 'str', path: 'pathlib.Path', metadata: 'IocMetadata', shell_state: 'ShellState', script: 'IocshScript', load_failure: 'bool' = False, pv_relations: 'PVRelations' = ) Source code in whatrecord/shell.py @dataclass class LoadedIoc : name : str path : pathlib . Path metadata : IocMetadata shell_state : ShellState script : IocshScript load_failure : bool = False pv_relations : PVRelations = field ( default_factory = dict ) _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: path: {{ path }} metadata: {% set metadata = render_object(metadata, \"console\") %} {{ metadata | indent(4) }} shell_state: {% set shell_state = render_object(shell_state, \"console\") %} {{ shell_state | indent(4) }} script: {% set script = render_object(script, \"console\") %} {{ script | indent(4) }} load_failure: {{ load_failure }} \"\"\" . rstrip (), ), \"console-verbose\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: path: {{ path }} metadata: {% set metadata = render_object(metadata, \"console-verbose\") %} {{ metadata | indent(4) }} shell_state: {% set shell_state = render_object(shell_state, \"console-verbose\") %} {{ shell_state | indent(4) }} script: {% set script = render_object(script, \"console-verbose\") %} {{ script | indent(4) }} load_failure: {{ load_failure }} pv_relations: {{ pv_relations }} \"\"\" . rstrip (), ) } @classmethod def _json_from_cache ( cls , md : IocMetadata ) -> Optional [ dict ]: try : with open ( md . ioc_cache_filename , \"rb\" ) as fp : return json . load ( fp ) except FileNotFoundError : ... except json . decoder . JSONDecodeError : # Truncated output file, perhaps ... @classmethod def from_cache ( cls , md : IocMetadata ) -> Optional [ LoadedIoc ]: json_dict = cls . _json_from_cache ( md ) if json_dict is not None : return apischema . deserialize ( cls , json_dict ) def save_to_cache ( self ) -> bool : if not settings . CACHE_PATH : return False with open ( self . metadata . ioc_cache_filename , \"wt\" ) as fp : json . dump ( apischema . serialize ( self ), fp = fp ) return True @classmethod def from_errored_load ( cls , md : IocMetadata , load_failure : IocLoadFailure ) -> LoadedIoc : exception_line = f \" { load_failure . ex_class } : { load_failure . ex_message } \" error_lines = [ exception_line ] + load_failure . traceback . splitlines () script = IocshScript ( path = str ( md . script ), lines = tuple ( IocshResult ( line = line , context = ( LoadContext ( \"error\" , lineno ),)) for lineno , line in enumerate ( error_lines , 1 ) ), ) md . metadata [ \"exception_class\" ] = load_failure . ex_class md . metadata [ \"exception_message\" ] = load_failure . ex_message md . metadata [ \"traceback\" ] = load_failure . traceback md . metadata [ \"load_failure\" ] = True return cls ( name = md . name , path = md . script , metadata = md , shell_state = ShellState (), script = script , load_failure = True , ) @classmethod def from_metadata ( cls , md : IocMetadata ) -> LoadedIoc : sh = ShellState ( ioc_info = md ) sh . working_directory = md . startup_directory sh . macro_context . define ( ** md . macros ) sh . standin_directories = md . standin_directories or {} # It's not enough to chdir, as we can rely on the environment variable # in shell scripts: os . environ [ \"PWD\" ] = str ( md . startup_directory ) script = IocshScript . from_metadata ( md , sh = sh ) return cls ( name = md . name , path = md . script , metadata = md , shell_state = sh , script = script , pv_relations = graph . build_database_relations ( sh . database ), ) def whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True ) -> Optional [ WhatRecord ]: \"\"\"Get record information, optionally including PVAccess results.\"\"\" state = self . shell_state v3_inst = state . database . get ( state . aliases . get ( rec , rec ), None ) pva_inst = state . pva_database . get ( rec , None ) if include_pva else None if not v3_inst and not pva_inst : return what = WhatRecord ( name = rec , ioc = self . metadata , record = None , pva_group = None , ) if v3_inst is not None : if not state . database_definition : defn = None else : defn = state . database_definition . record_types . get ( v3_inst . record_type , None ) what . menus = state . database_definition . menus # but what about device types and such? state . annotate_record ( v3_inst ) what . record = RecordDefinitionAndInstance ( defn , v3_inst ) if pva_inst is not None : what . pva_group = pva_inst return what","title":"LoadedIoc"},{"location":"iocsh/#whatrecord.shell.LoadedIoc-methods","text":"whatrecord . shell . LoadedIoc . whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True ) -> Optional [ WhatRecord ] Get record information, optionally including PVAccess results. Source code in whatrecord/shell.py def whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True ) -> Optional [ WhatRecord ]: \"\"\"Get record information, optionally including PVAccess results.\"\"\" state = self . shell_state v3_inst = state . database . get ( state . aliases . get ( rec , rec ), None ) pva_inst = state . pva_database . get ( rec , None ) if include_pva else None if not v3_inst and not pva_inst : return what = WhatRecord ( name = rec , ioc = self . metadata , record = None , pva_group = None , ) if v3_inst is not None : if not state . database_definition : defn = None else : defn = state . database_definition . record_types . get ( v3_inst . record_type , None ) what . menus = state . database_definition . menus # but what about device types and such? state . annotate_record ( v3_inst ) what . record = RecordDefinitionAndInstance ( defn , v3_inst ) if pva_inst is not None : what . pva_group = pva_inst return what","title":"Methods"},{"location":"iocsh/#whatrecord.shell.ScriptContainer","text":"Aggregate container for any number of LoadedIoc instances. Combines databases, sets of loaded files ease of querying. Source code in whatrecord/shell.py @dataclass class ScriptContainer : \"\"\" Aggregate container for any number of LoadedIoc instances. Combines databases, sets of loaded files ease of querying. \"\"\" database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) aliases : Dict [ str , str ] = field ( default_factory = dict ) pva_database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) scripts : Dict [ str , LoadedIoc ] = field ( default_factory = dict ) startup_script_to_ioc : Dict [ str , str ] = field ( default_factory = dict ) #: absolute filename path to sha loaded_files : Dict [ str , str ] = field ( default_factory = dict ) record_types : Dict [ str , RecordType ] = field ( default_factory = dict ) pv_relations : PVRelations = field ( default_factory = dict ) def add_loaded_ioc ( self , loaded : LoadedIoc ): ioc_name = loaded . metadata . name self . scripts [ ioc_name ] = loaded self . startup_script_to_ioc [ str ( loaded . metadata . script )] = ioc_name # TODO: IOCs will have conflicting definitions of records self . aliases . update ( loaded . shell_state . aliases ) if loaded . shell_state . database_definition : self . record_types . update ( loaded . shell_state . database_definition . record_types ) graph . combine_relations ( self . pv_relations , self . database , loaded . pv_relations , loaded . shell_state . database , record_types = self . record_types , aliases = self . aliases , ) self . database . update ( loaded . shell_state . database ) self . pva_database . update ( loaded . shell_state . pva_database ) self . loaded_files . update ( loaded . shell_state . loaded_files ) def whatrec ( self , rec : str , field : Optional [ str ] = None , include_pva : bool = True , format_option : str = \"console\" , file = sys . stdout , ) -> List [ WhatRecord ]: fmt = FormatContext () result = [] for name , loaded in self . scripts . items (): info : WhatRecord = loaded . whatrec ( rec , field , include_pva = include_pva ) if info is not None : info . ioc = loaded . metadata for match in [ info . record , info . pva_group ]: if file is not None and match is not None : print ( fmt . render_object ( match , format_option ), file = file ) result . append ( info ) return result","title":"ScriptContainer"},{"location":"iocsh/#whatrecord.shell.ShellState","text":"IOC shell state container. Contains hooks for commands and state information. This base state handler should only handle epics base-defined IOC shell commands, including: paths, variables, database loading, and IOC initialization. It is the top-level state container, which sub handlers should rely on for things like loading files and other core state information. Attributes: Name Type Description prompt str The prompt - PS1 - as in \"epics>\". variables dict Shell variables (not environment variables). string_encoding str String encoding for byte strings and files. macro_context MacroContext Macro context for commands that are evaluated. standin_directories dict Rewrite hard-coded directory prefixes by setting:: standin_directories = {\"/replace_this/\": \"/with/this\"} loaded_files Dict[str, str] Files loaded, mapped to a hash of their contents. working_directory pathlib.Path Current working directory. database_definition Database Loaded database definition (dbd). database Dict[str, RecordInstance] The IOC database of records. pva_database Dict[str, RecordInstance] The IOC database of PVAccess groups. aliases Dict[str, str] Alias name to record name. load_context List[MutableLoadContext] Current loading context stack (e.g., st.cmd then common_startup.cmd ). Modified in place as scripts are evaluated. Source code in whatrecord/shell.py @dataclass class ShellState ( ShellStateHandler ): \"\"\" IOC shell state container. Contains hooks for commands and state information. This base state handler should only handle epics base-defined IOC shell commands, including: paths, variables, database loading, and IOC initialization. It is the top-level state container, which sub handlers should rely on for things like loading files and other core state information. Attributes ---------- prompt : str The prompt - PS1 - as in \"epics>\". variables : dict Shell variables (not environment variables). string_encoding : str String encoding for byte strings and files. macro_context : MacroContext Macro context for commands that are evaluated. standin_directories : dict Rewrite hard-coded directory prefixes by setting:: standin_directories = {\"/replace_this/\": \"/with/this\"} loaded_files : Dict[str, str] Files loaded, mapped to a hash of their contents. working_directory : pathlib.Path Current working directory. database_definition : Database Loaded database definition (dbd). database : Dict[str, RecordInstance] The IOC database of records. pva_database : Dict[str, RecordInstance] The IOC database of PVAccess groups. aliases : Dict[str, str] Alias name to record name. load_context : List[MutableLoadContext] Current loading context stack (e.g., ``st.cmd`` then ``common_startup.cmd``). Modified in place as scripts are evaluated. \"\"\" prompt : str = \"epics>\" variables : Dict [ str , str ] = field ( default_factory = dict ) string_encoding : str = \"latin-1\" ioc_initialized : bool = False standin_directories : Dict [ str , str ] = field ( default_factory = dict ) working_directory : pathlib . Path = field ( default_factory = lambda : pathlib . Path . cwd (), ) aliases : Dict [ str , str ] = field ( default_factory = dict ) database_definition : Optional [ Database ] = None database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) pva_database : Dict [ str , RecordInstance ] = field ( default_factory = dict ) load_context : List [ MutableLoadContext ] = field ( default_factory = list ) loaded_files : Dict [ str , str ] = field ( default_factory = dict ) macro_context : MacroContext = field ( default_factory = MacroContext , metadata = apischema . metadata . skip ) ioc_info : IocMetadata = field ( default_factory = IocMetadata ) db_add_paths : List [ pathlib . Path ] = field ( default_factory = list ) # Sub-state handlers: access_security : AccessSecurityState = field ( default_factory = AccessSecurityState ) asyn : AsynState = field ( default_factory = AsynState ) autosave : AutosaveState = field ( default_factory = AutosaveState ) motor : MotorState = field ( default_factory = MotorState ) streamdevice : StreamDeviceState = field ( default_factory = StreamDeviceState ) _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: \"\"\" . rstrip (), ), \"console-verbose\" : textwrap . dedent ( \"\"\"\\ {{ obj | classname }}: \"\"\" . rstrip (), ) } def __post_init__ ( self ): super () . __post_init__ () self . macro_context . string_encoding = self . string_encoding @property def sub_handlers ( self ) -> List [ ShellStateHandler ]: \"\"\"Handlers which contain their own state.\"\"\" return [ self . access_security , self . asyn , self . autosave , self . motor , self . streamdevice , ] def load_file ( self , filename : AnyPath ) -> Tuple [ pathlib . Path , str ]: \"\"\"Load a file, record its hash, and return its contents.\"\"\" filename = self . _fix_path ( filename ) filename = filename . resolve () shasum , contents = util . read_text_file_with_hash ( filename , encoding = self . string_encoding ) self . loaded_files [ str ( filename )] = shasum self . ioc_info . loaded_files [ str ( filename )] = shasum return filename , contents def _handle_input_redirect ( self , redir : IocshRedirect , shresult : IocshResult , recurse : bool = True , raise_on_error : bool = False , ): try : filename , contents = self . load_file ( redir . name ) except Exception as ex : shresult . error = f \" { type ( ex ) . __name__ } : { redir . name } \" yield shresult return yield shresult yield from self . interpret_shell_script_text ( contents . splitlines (), recurse = recurse , name = filename ) def interpret_shell_line ( self , line , recurse = True , raise_on_error = False ): \"\"\"Interpret a single shell script line.\"\"\" shresult = parse_iocsh_line ( line , context = self . get_load_context (), prompt = self . prompt , macro_context = self . macro_context , string_encoding = self . string_encoding , ) input_redirects = [ redir for redir in shresult . redirects if redir . mode == \"r\" ] if shresult . error : yield shresult elif input_redirects : if recurse : yield from self . _handle_input_redirect ( input_redirects [ 0 ], shresult , recurse = recurse , raise_on_error = raise_on_error , ) elif shresult . argv : try : result = self . _handle_command ( * shresult . argv ) if result : # Only set if not-None to speed up serialization shresult . result = result except Exception as ex : if raise_on_error : raise ex_details = traceback . format_exc () shresult . error = f \"Failed to execute: { ex } : \\n { ex_details } \" yield shresult if isinstance ( shresult . result , IocshCmdArgs ): yield from self . interpret_shell_line ( shresult . result . command , recurse = recurse ) else : # Otherwise, nothing to do yield shresult def interpret_shell_script ( self , filename : Union [ pathlib . Path , str ], recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Load and interpret a shell script named ``filename``.\"\"\" filename , contents = self . load_file ( filename ) yield from self . interpret_shell_script_text ( contents . splitlines (), name = str ( filename ), recurse = recurse , raise_on_error = raise_on_error , ) def interpret_shell_script_text ( self , lines : Iterable [ str ], name : str = \"unknown\" , recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Interpret a shell script named ``name`` with ``lines`` of text.\"\"\" load_ctx = MutableLoadContext ( str ( name ), 0 ) try : self . load_context . append ( load_ctx ) for lineno , line in enumerate ( lines , 1 ): load_ctx . line = lineno yield from self . interpret_shell_line ( line , recurse = recurse , raise_on_error = raise_on_error , ) finally : self . load_context . remove ( load_ctx ) # for rec in list(self.database.values()) + list(self.pva_database.values()): # try: # self.annotate_record(rec) # except Exception: # logger.exception(\"Failed to annotate record: %s\", rec.name) def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if not self . load_context : return tuple () return tuple ( ctx . to_load_context () for ctx in self . load_context ) def _handle_command ( self , command , * args ): \"\"\"Handle IOC shell 'command' with provided arguments.\"\"\" handler = self . _handlers . get ( command , None ) if handler is not None : return handler ( * args ) return self . unhandled ( command , args ) def _fix_path ( self , filename : AnyPath ) -> pathlib . Path : \"\"\" Makes filename an absolute path with respect to the working directory. Also replaces standin directories, if provided an absolute path. \"\"\" filename = str ( filename ) if os . path . isabs ( filename ): for from_ , to in self . standin_directories . items (): if filename . startswith ( from_ ): _ , suffix = filename . split ( from_ , 1 ) return pathlib . Path ( to + suffix ) return self . working_directory / filename @property def db_include_paths ( self ) -> List [ pathlib . Path ]: \"\"\"Database include paths (EPICS_DB_INCLUDE_PATH).\"\"\" env_paths = self . paths_from_env_var ( \"EPICS_DB_INCLUDE_PATH\" ) if not env_paths : return [ self . working_directory ] + self . db_add_paths return env_paths + self . db_add_paths def paths_from_env_var ( self , env_var : str , * , default : Optional [ str ] = None ) -> List [ pathlib . Path ]: \"\"\"Paths from an environment variable (or macro).\"\"\" env_var = self . macro_context . get ( env_var , default ) or \"\" return [ ( self . working_directory / pathlib . Path ( path )) . resolve () # TODO: this is actually OS-dependent (: on linux, ; on Windows) for path in env_var . split ( \":\" ) ] def _fix_path_with_search_list ( self , filename : Union [ str , pathlib . Path ], include_paths : List [ pathlib . Path ], ) -> pathlib . Path : \"\"\"Given a list of paths, find ``filename``.\"\"\" filename = str ( filename ) if not include_paths or \"/\" in filename or \" \\\\ \" in filename : # Include path unset or even something resembling a nested path # automatically is used as-is return self . working_directory / filename for path in include_paths : option = path / filename if option . exists () and option . is_file (): return option paths = list ( str ( path ) for path in include_paths ) raise FileNotFoundError ( f \"File { filename !r} not found in search path: { paths } \" ) def unhandled ( self , command , args ): ... # return f\"No handler for handle_{command}\" @_handler def handle_iocshRegisterVariable ( self , variable : str , value : str = \"\" ): self . variables [ variable ] = value return f \"Registered variable: { variable !r} = { value !r} \" def env_set_EPICS_BASE ( self , path ): # TODO: slac-specific path = str ( pathlib . Path ( path ) . resolve ()) version_prefixes = [ \"/reg/g/pcds/epics/base/\" , \"/cds/group/pcds/epics/base/\" , ] for prefix in version_prefixes : if path . startswith ( prefix ): path = path [ len ( prefix ):] if \"/\" in path : path = path . split ( \"/\" )[ 0 ] version = path . lstrip ( \"R\" ) if self . ioc_info . base_version == settings . DEFAULT_BASE_VERSION : self . ioc_info . base_version = version return f \"Set base version: { version } \" return ( f \"Found version ( { version } ) but version already specified:\" f \" { self . ioc_info . base_version } \" ) @_handler def handle_epicsEnvSet ( self , variable : str , value : str = \"\" ): self . macro_context . define ( ** { variable : value }) hook = getattr ( self , f \"env_set_ { variable } \" , None ) if hook and callable ( hook ): hook_result = hook ( value ) if hook_result : return { \"hook\" : hook_result , } @_handler def handle_epicsEnvShow ( self ): return self . macro_context . get_macros () def handle_iocshCmd ( self , command : str = \"\" , * _ ): # TODO: odd return type, used below return IocshCmdArgs ( context = self . get_load_context (), command = command ) @_handler def handle_cd ( self , path : str = \"\" ): if not path : raise RuntimeError ( \"Invalid directory path, ignored\" ) path = self . _fix_path ( path ) if path . is_absolute (): new_dir = path else : new_dir = self . working_directory / path if not new_dir . exists (): raise RuntimeError ( f \"Path does not exist: { new_dir } \" ) self . working_directory = new_dir . resolve () os . environ [ \"PWD\" ] = str ( self . working_directory ) return { \"result\" : f \"New working directory: { self . working_directory } \" } handle_chdir = handle_cd @_handler def handle_iocInit ( self ): if self . ioc_initialized : return { \"success\" : False , \"error\" : \"Already initialized\" , } result = { \"success\" : True , } for handler in self . sub_handlers : handler_result = handler . pre_ioc_init () result . update ( handler_result or {}) self . ioc_initialized = True for handler in self . sub_handlers : handler_result = handler . post_ioc_init () result . update ( handler_result or {}) return result @_handler def handle_dbLoadDatabase ( self , dbd : str , path : str = \"\" , substitutions : str = \"\" ): if self . ioc_initialized : raise RuntimeError ( \"Database cannot be loaded after iocInit\" ) if self . database_definition : # TODO: technically this is allowed; we'll need to update # raise RuntimeError(\"dbd already loaded\") return \"whatrecord: TODO multiple dbLoadDatabase\" dbd_path = self . _fix_path_with_search_list ( dbd , self . db_include_paths ) fn , contents = self . load_file ( dbd_path ) macro_context = MacroContext ( use_environment = False ) macro_context . define_from_string ( substitutions or \"\" ) self . database_definition = Database . from_string ( contents , version = self . ioc_info . database_version_spec , filename = fn , macro_context = macro_context , ) for addpath in self . database_definition . addpaths : for path in addpath . path . split ( os . pathsep ): # TODO: OS-dependent self . db_add_paths . append (( dbd_path . parent / path ) . resolve ()) self . aliases . update ( self . database_definition . aliases ) return { \"result\" : f \"Loaded database: { fn } \" } @_handler def handle_dbLoadTemplate ( self , filename : str , macros : str = \"\" ): filename = self . _fix_path_with_search_list ( filename , self . db_include_paths ) filename , contents = self . load_file ( filename ) # TODO this should be multiple load calls for the purposes of context result = { \"total_records\" : 0 , \"total_groups\" : 0 , \"loaded_files\" : [], } template = dbtemplate . TemplateSubstitution . from_string ( contents , filename = filename ) for sub in template . substitutions : database_contents = sub . expand_file ( search_paths = self . db_include_paths ) # TODO loading file twice (ensure it gets added to the loaded_files list) self . load_file ( sub . filename ) lint = self . _load_database ( filename = str ( sub . filename ), contents = database_contents , macros = macros , context = self . get_load_context () + sub . context , ) info = { \"filename\" : sub . filename , \"macros\" : sub . macros , \"records\" : len ( lint . records ), \"groups\" : len ( lint . pva_groups ), \"lint\" : lint , } result [ \"total_records\" ] += len ( lint . records ) result [ \"total_groups\" ] += len ( lint . pva_groups ) result [ \"loaded_files\" ] . append ( info ) return result def _load_database ( self , filename : str , contents : str , macros : str , context : FullLoadContext ) -> LinterResults : macro_context = MacroContext ( use_environment = False ) macros = macro_context . define_from_string ( macros or \"\" ) try : lint = LinterResults . from_database_string ( db = contents , dbd = self . database_definition , db_filename = filename , macro_context = macro_context , version = self . ioc_info . database_version_spec , ) except Exception as ex : # TODO move this around raise DatabaseLoadFailure ( f \"Failed to load { filename } : { type ( ex ) . __name__ } { ex } \" ) from ex db : Database = lint . db for name , rec in db . records . items (): if name not in self . database : self . database [ name ] = rec rec . context = context + rec . context rec . owner = self . ioc_info . name else : entry = self . database [ name ] entry . context = entry . context + rec . context entry . fields . update ( rec . fields ) # entry.owner = self.ioc_info.name ? for name , rec in db . pva_groups . items (): if name not in self . pva_database : self . pva_database [ name ] = rec rec . context = context + rec . context rec . owner = self . ioc_info . name else : entry = self . database [ name ] entry . context = entry . context + rec . context entry . fields . update ( rec . fields ) # entry.owner = self.ioc_info.name ? self . aliases . update ( db . aliases ) for addpath in db . addpaths : for path in addpath . path . split ( os . pathsep ): # TODO: OS-dependent self . db_add_paths . append (( db . parent / path ) . resolve ()) return lint @_handler def handle_dbLoadRecords ( self , filename : str , macros : str = \"\" ): if not self . database_definition : raise RuntimeError ( \"dbd not yet loaded\" ) if self . ioc_initialized : raise RuntimeError ( \"Records cannot be loaded after iocInit\" ) filename = self . _fix_path_with_search_list ( filename , self . db_include_paths ) filename , contents = self . load_file ( filename ) lint = self . _load_database ( filename = filename , contents = contents , macros = macros or \"\" , context = self . get_load_context () ) return { \"loaded_records\" : len ( lint . records ), \"loaded_groups\" : len ( lint . pva_groups ), \"lint\" : lint , } def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" for handler in self . sub_handlers : try : annotation = handler . annotate_record ( record ) except Exception : logger . exception ( \"Record annotation failed for %s with handler %s \" , record . name , type ( handler ) . __name__ ) else : if annotation is not None : record . metadata [ handler . metadata_key ] = annotation @_handler def handle_dbl ( self , rtyp : str = \"\" , fields : str = \"\" ): ... @_handler def handle_NDPvaConfigure ( self , portName : str , queueSize : int = 0 , blockingCallbacks : str = \"\" , NDArrayPort : str = \"\" , NDArrayAddr : str = \"\" , pvName : str = \"\" , maxBuffers : int = 0 , maxMemory : int = 0 , priority : int = 0 , stackSize : int = 0 , ): \"\"\"Implicitly creates a PVA group named ``pvName``.\"\"\" metadata = { \"portName\" : portName or \"\" , \"queueSize\" : queueSize or \"\" , \"blockingCallbacks\" : blockingCallbacks or \"\" , \"NDArrayPort\" : NDArrayPort or \"\" , \"NDArrayAddr\" : NDArrayAddr or \"\" , \"pvName\" : pvName or \"\" , \"maxBuffers\" : maxBuffers or \"\" , \"maxMemory\" : maxMemory or \"\" , \"priority\" : priority or \"\" , \"stackSize\" : stackSize or \"\" , } self . pva_database [ pvName ] = RecordInstance ( context = self . get_load_context (), name = pvName , record_type = \"PVA\" , fields = {}, is_pva = True , metadata = { \"areaDetector\" : metadata }, ) return metadata","title":"ShellState"},{"location":"iocsh/#whatrecord.shell.ShellState-attributes","text":"whatrecord . shell . ShellState . db_include_paths : List [ pathlib . Path ] property readonly Database include paths (EPICS_DB_INCLUDE_PATH). whatrecord . shell . ShellState . sub_handlers : List [ ShellStateHandler ] property readonly Handlers which contain their own state.","title":"Attributes"},{"location":"iocsh/#whatrecord.shell.ShellState-methods","text":"whatrecord . shell . ShellState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Hook to annotate a record after being loaded. Source code in whatrecord/shell.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" for handler in self . sub_handlers : try : annotation = handler . annotate_record ( record ) except Exception : logger . exception ( \"Record annotation failed for %s with handler %s \" , record . name , type ( handler ) . __name__ ) else : if annotation is not None : record . metadata [ handler . metadata_key ] = annotation whatrecord . shell . ShellState . get_load_context ( self ) -> FullLoadContext Get a FullLoadContext tuple representing where we are now. Source code in whatrecord/shell.py def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if not self . load_context : return tuple () return tuple ( ctx . to_load_context () for ctx in self . load_context ) whatrecord . shell . ShellState . handle_NDPvaConfigure ( self , portName : str , queueSize : int = 0 , blockingCallbacks : str = '' , NDArrayPort : str = '' , NDArrayAddr : str = '' , pvName : str = '' , maxBuffers : int = 0 , maxMemory : int = 0 , priority : int = 0 , stackSize : int = 0 ) Implicitly creates a PVA group named pvName . Source code in whatrecord/shell.py @_handler def handle_NDPvaConfigure ( self , portName : str , queueSize : int = 0 , blockingCallbacks : str = \"\" , NDArrayPort : str = \"\" , NDArrayAddr : str = \"\" , pvName : str = \"\" , maxBuffers : int = 0 , maxMemory : int = 0 , priority : int = 0 , stackSize : int = 0 , ): \"\"\"Implicitly creates a PVA group named ``pvName``.\"\"\" metadata = { \"portName\" : portName or \"\" , \"queueSize\" : queueSize or \"\" , \"blockingCallbacks\" : blockingCallbacks or \"\" , \"NDArrayPort\" : NDArrayPort or \"\" , \"NDArrayAddr\" : NDArrayAddr or \"\" , \"pvName\" : pvName or \"\" , \"maxBuffers\" : maxBuffers or \"\" , \"maxMemory\" : maxMemory or \"\" , \"priority\" : priority or \"\" , \"stackSize\" : stackSize or \"\" , } self . pva_database [ pvName ] = RecordInstance ( context = self . get_load_context (), name = pvName , record_type = \"PVA\" , fields = {}, is_pva = True , metadata = { \"areaDetector\" : metadata }, ) return metadata whatrecord . shell . ShellState . interpret_shell_line ( self , line , recurse = True , raise_on_error = False ) Interpret a single shell script line. Source code in whatrecord/shell.py def interpret_shell_line ( self , line , recurse = True , raise_on_error = False ): \"\"\"Interpret a single shell script line.\"\"\" shresult = parse_iocsh_line ( line , context = self . get_load_context (), prompt = self . prompt , macro_context = self . macro_context , string_encoding = self . string_encoding , ) input_redirects = [ redir for redir in shresult . redirects if redir . mode == \"r\" ] if shresult . error : yield shresult elif input_redirects : if recurse : yield from self . _handle_input_redirect ( input_redirects [ 0 ], shresult , recurse = recurse , raise_on_error = raise_on_error , ) elif shresult . argv : try : result = self . _handle_command ( * shresult . argv ) if result : # Only set if not-None to speed up serialization shresult . result = result except Exception as ex : if raise_on_error : raise ex_details = traceback . format_exc () shresult . error = f \"Failed to execute: { ex } : \\n { ex_details } \" yield shresult if isinstance ( shresult . result , IocshCmdArgs ): yield from self . interpret_shell_line ( shresult . result . command , recurse = recurse ) else : # Otherwise, nothing to do yield shresult whatrecord . shell . ShellState . interpret_shell_script ( self , filename : Union [ pathlib . Path , str ], recurse : bool = True , raise_on_error : bool = False ) -> Generator [ IocshResult , None , None ] Load and interpret a shell script named filename . Source code in whatrecord/shell.py def interpret_shell_script ( self , filename : Union [ pathlib . Path , str ], recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Load and interpret a shell script named ``filename``.\"\"\" filename , contents = self . load_file ( filename ) yield from self . interpret_shell_script_text ( contents . splitlines (), name = str ( filename ), recurse = recurse , raise_on_error = raise_on_error , ) whatrecord . shell . ShellState . interpret_shell_script_text ( self , lines : Iterable [ str ], name : str = 'unknown' , recurse : bool = True , raise_on_error : bool = False ) -> Generator [ IocshResult , None , None ] Interpret a shell script named name with lines of text. Source code in whatrecord/shell.py def interpret_shell_script_text ( self , lines : Iterable [ str ], name : str = \"unknown\" , recurse : bool = True , raise_on_error : bool = False , ) -> Generator [ IocshResult , None , None ]: \"\"\"Interpret a shell script named ``name`` with ``lines`` of text.\"\"\" load_ctx = MutableLoadContext ( str ( name ), 0 ) try : self . load_context . append ( load_ctx ) for lineno , line in enumerate ( lines , 1 ): load_ctx . line = lineno yield from self . interpret_shell_line ( line , recurse = recurse , raise_on_error = raise_on_error , ) finally : self . load_context . remove ( load_ctx ) # for rec in list(self.database.values()) + list(self.pva_database.values()): # try: # self.annotate_record(rec) # except Exception: # logger.exception(\"Failed to annotate record: %s\", rec.name) whatrecord . shell . ShellState . load_file ( self , filename : AnyPath ) -> Tuple [ pathlib . Path , str ] Load a file, record its hash, and return its contents. Source code in whatrecord/shell.py def load_file ( self , filename : AnyPath ) -> Tuple [ pathlib . Path , str ]: \"\"\"Load a file, record its hash, and return its contents.\"\"\" filename = self . _fix_path ( filename ) filename = filename . resolve () shasum , contents = util . read_text_file_with_hash ( filename , encoding = self . string_encoding ) self . loaded_files [ str ( filename )] = shasum self . ioc_info . loaded_files [ str ( filename )] = shasum return filename , contents whatrecord . shell . ShellState . paths_from_env_var ( self , env_var : str , * , default : Optional [ str ] = None ) -> List [ pathlib . Path ] Paths from an environment variable (or macro). Source code in whatrecord/shell.py def paths_from_env_var ( self , env_var : str , * , default : Optional [ str ] = None ) -> List [ pathlib . Path ]: \"\"\"Paths from an environment variable (or macro).\"\"\" env_var = self . macro_context . get ( env_var , default ) or \"\" return [ ( self . working_directory / pathlib . Path ( path )) . resolve () # TODO: this is actually OS-dependent (: on linux, ; on Windows) for path in env_var . split ( \":\" ) ]","title":"Methods"},{"location":"iocsh/#whatrecord.shell-functions","text":"","title":"Functions"},{"location":"iocsh/#whatrecord.shell.async_load_ioc","text":"Helper function for loading an IOC in a subprocess and relying on the cache. Source code in whatrecord/shell.py async def async_load_ioc ( identifier : Union [ int , str ], md : IocMetadata , standin_directories , use_gdb : bool = True , use_cache : bool = True , ) -> IocLoadResult : \"\"\" Helper function for loading an IOC in a subprocess and relying on the cache. \"\"\" if not settings . CACHE_PATH : use_cache = False with time_context () as ctx : try : md . standin_directories . update ( standin_directories ) if use_cache : cached_ioc = load_cached_ioc ( md ) if cached_ioc : return IocLoadResult ( identifier = identifier , load_time = ctx (), cache_hit = True , result = \"use_cache\" ) loaded = LoadedIoc . from_metadata ( md ) if use_gdb : await md . get_binary_information () if use_cache : loaded . metadata . save_to_cache () loaded . save_to_cache () # Avoid pickling massive JSON blob; instruct server to load # from cache with token 'use_cache' serialized = \"use_cache\" else : serialized = apischema . serialize ( loaded ) except Exception as ex : return IocLoadResult ( identifier = identifier , load_time = ctx (), cache_hit = False , result = IocLoadFailure ( ex_class = type ( ex ) . __name__ , ex_message = str ( ex ), traceback = traceback . format_exc (), ), ) return IocLoadResult ( identifier = identifier , load_time = ctx (), cache_hit = False , result = serialized , )","title":"async_load_ioc()"},{"location":"iocsh/#whatrecord.shell.load_startup_scripts_with_metadata","text":"Load all given startup scripts into a shared ScriptContainer. Parameters: Name Type Description Default *md_items list of IocMetadata List of IOC metadata. () standin_directories dict Stand-in/substitute directory mapping. None processes int The number of processes to use when loading. 8 Source code in whatrecord/shell.py async def load_startup_scripts_with_metadata ( * md_items , standin_directories = None , processes : int = 8 , use_gdb : bool = True , ) -> ScriptContainer : \"\"\" Load all given startup scripts into a shared ScriptContainer. Parameters ---------- *md_items : list of IocMetadata List of IOC metadata. standin_directories : dict Stand-in/substitute directory mapping. processes : int The number of processes to use when loading. \"\"\" total_files = len ( md_items ) total_child_load_time = 0.0 with time_context () as total_time , ProcessPoolExecutor ( max_workers = processes , initializer = _process_init ) as executor : coros = [ asyncio . wrap_future ( executor . submit ( _load_ioc , identifier = idx , md = md , standin_directories = standin_directories , use_gdb = use_gdb ) ) for idx , md in enumerate ( md_items ) ] for coro in asyncio . as_completed ( coros ): try : load_result = await coro md = md_items [ load_result . identifier ] except Exception as ex : logger . exception ( \"Internal error while loading: %s : %s [server %.1f s]\" , type ( ex ) . __name__ , ex , total_time (), ) continue use_cache = load_result . result == \"use_cache\" if not use_cache : loaded = load_result . result else : try : loaded = load_cached_ioc ( md , allow_failed_load = True ) if loaded is None : raise ValueError ( \"Cache entry is empty?\" ) except Exception as ex : logger . exception ( \"Internal error while loading cached IOC from disk: \" \" %s : %s [server %.1f s]\" , type ( ex ) . __name__ , ex , total_time (), ) continue total_child_load_time += load_result . load_time if isinstance ( loaded , IocLoadFailure ): failure_result : IocLoadFailure = loaded logger . error ( \"Failed to load %s in subprocess: %s \" \"[ %.1f s; server %.1f ]: %s \\n %s \" , md . name or md . script , failure_result . ex_class , load_result . load_time , total_time (), failure_result . ex_message , ( failure_result . traceback if failure_result . ex_class != \"FileNotFoundError\" else \"\" ), ) if md . base_version == settings . DEFAULT_BASE_VERSION : md . base_version = \"unknown\" yield md , LoadedIoc . from_errored_load ( md , loaded ) continue with time_context () as ctx : loaded_ioc = apischema . deserialize ( LoadedIoc , loaded ) logger . info ( \"Child loaded %s%s in %.1f s, server deserialized in %.1f s\" , md . name or md . script , \" from cache\" if load_result . cache_hit else \"\" , load_result . load_time , ctx (), ) yield md , loaded_ioc logger . info ( \"Loaded %d startup scripts in %.1f s (wall time) with %d process(es)\" , total_files , total_time (), processes , ) logger . info ( \"Child processes reported taking a total of %.1f \" \"sec, the total time on %d process(es)\" , total_child_load_time , processes , )","title":"load_startup_scripts_with_metadata()"},{"location":"lcls/","text":"LCLS LCLS-specific whatrecord plugins and helpers. whatrecord.iocmanager SLAC PCDS IocManager configuration file loading support. Functions whatrecord . iocmanager . find_stcmd ( directory : str , ioc_id : str ) -> str Find the startup script st.cmd for a given IOC. Source code in whatrecord/iocmanager.py def find_stcmd ( directory : str , ioc_id : str ) -> str : \"\"\"Find the startup script st.cmd for a given IOC.\"\"\" if directory . startswith ( \"ioc\" ): directory = os . path . join ( EPICS_SITE_TOP , directory ) suffix = ( \"iocBoot\" , ioc_id , \"st.cmd\" ) # Templated IOCs are... different: options = [ os . path . join ( directory , \"children\" , \"build\" , * suffix ), os . path . join ( directory , \"build\" , * suffix ), os . path . join ( directory , * suffix ), os . path . join ( directory , \"st.cmd\" ), ] for option in options : if os . path . exists ( option ): return option # Guess at what's correct: return options [ - 1 ] whatrecord . iocmanager . get_iocs_from_configs ( configs : List [ Union [ str , pathlib . Path ]], sorter : Optional [ Callable [[ Dict [ str , Union [ str , Dict [ str , str ], List [ str ]]]], Any ]] = None ) -> List [ Dict [ str , Union [ str , Dict [ str , str ], List [ str ]]]] Get IOC information in a list of dictionaries. Parameters: Name Type Description Default configs List[Union[str, pathlib.Path]] Configuration filenames to load. required sorter Optional[Callable[[Dict[str, Union[str, Dict[str, str], List[str]]]], Any]] Sort IOCs with this, defaults to sorting by host name and then IOC name. None Returns: Type Description List[Dict[str, Union[str, Dict[str, str], List[str]]]] List of IOC info Source code in whatrecord/iocmanager.py def get_iocs_from_configs ( configs : List [ Union [ str , pathlib . Path ]], sorter : Optional [ Callable [[ IocInfoDict ], Any ]] = None ) -> List [ IocInfoDict ]: \"\"\" Get IOC information in a list of dictionaries. Parameters ---------- configs : list[str or pathlib.Path] Configuration filenames to load. sorter : callable, optional Sort IOCs with this, defaults to sorting by host name and then IOC name. Returns ------- ioc_info : list of IOC info dictionaries List of IOC info \"\"\" configs = [ pathlib . Path ( config ) . resolve () for config in configs or [] ] def default_sorter ( ioc ): return ( ioc [ \"host\" ], ioc [ \"name\" ]) iocs = ( ioc for fn in set ( configs ) for ioc in load_config_file ( fn ) ) return list ( sorted ( iocs , key = sorter or default_sorter )) whatrecord . iocmanager . load_config_file ( fn : Union [ str , pathlib . Path ]) -> List [ Dict [ str , Union [ str , Dict [ str , str ], List [ str ]]]] Load a configuration file and return the IOCs it contains. Parameters: Name Type Description Default fn Union[str, pathlib.Path] The configuration filename required Returns: Type Description List[Dict[str, Union[str, Dict[str, str], List[str]]]] List of IOC info Source code in whatrecord/iocmanager.py def load_config_file ( fn : Union [ str , pathlib . Path ]) -> List [ IocInfoDict ]: \"\"\" Load a configuration file and return the IOCs it contains. Parameters ---------- fn : str or pathlib.Path The configuration filename Returns ------- ioc_info : list of IOC info dictionaries List of IOC info \"\"\" with open ( fn , \"rt\" ) as f : lines = f . read () . splitlines () iocs = parse_config ( lines ) for ioc in list ( iocs ): # For now, assume old database syntax by specifying 3.15: ioc [ \"base_version\" ] = \"3.15\" if not validate_config_keys ( ioc ): iocs . remove ( ioc ) else : # Add \"config_file\" and rename some keys: ioc [ \"config_file\" ] = str ( fn ) ioc [ \"name\" ] = ioc . pop ( \"id\" ) ioc [ \"script\" ] = find_stcmd ( ioc [ \"dir\" ], ioc [ \"name\" ]) ioc [ \"binary\" ] = find_binary_from_hashbang ( ioc [ \"script\" ]) return iocs whatrecord . iocmanager . parse_config ( lines : List [ str ]) -> List [ Dict [ str , Union [ str , Dict [ str , str ], List [ str ]]]] Parse an IOC manager config to get its IOCs. Parameters: Name Type Description Default lines List[str] List of raw configuration file lines. required Returns: Type Description List[Dict[str, Union[str, Dict[str, str], List[str]]]] List of IOC info Source code in whatrecord/iocmanager.py def parse_config ( lines : List [ str ]) -> List [ IocInfoDict ]: \"\"\" Parse an IOC manager config to get its IOCs. Parameters ---------- lines : list of str List of raw configuration file lines. Returns ------- ioc_info : list of IOC info dictionaries List of IOC info \"\"\" entries = [] loading = False entry = None for line in lines : if \"procmgr_config\" in line : loading = True continue if not loading : continue if \"id:\" in line : if \"}\" in line : entries . append ( line ) else : entry = line elif entry is not None : entry += line if \"}\" in entry : entries . append ( entry ) entry = None def fix_entry ( entry ): return ast . literal_eval ( KEY_RE . sub ( r '\"\\1\":' , entry . strip ( \", \\t \" ))) result = [] for entry in entries : try : result . append ( fix_entry ( entry )) except Exception : logger . exception ( \"Failed to fix up IOC manager entry: %s \" , entry ) return result whatrecord . iocmanager . validate_config_keys ( cfg : Dict [ str , Union [ str , Dict [ str , str ], List [ str ]]]) -> bool Validate that a configuration has all required keys. Source code in whatrecord/iocmanager.py def validate_config_keys ( cfg : IocInfoDict ) -> bool : \"\"\"Validate that a configuration has all required keys.\"\"\" return all ( key in cfg and cfg [ key ] for key in REQUIRED_KEYS ) whatrecord iocmanager-loader whatrecord iocmanager-loader is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files. usage: whatrecord iocmanager-loader [-h] configs [configs ...] \"whatrec iocmanager_loader\" is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files. positional arguments: configs Configuration file location(s) optional arguments: -h, --help show this help message and exit whatrecord.bin.iocmanager_loader \"whatrecord iocmanager-loader\" is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files. API whatrecord.plugins.epicsarch LCLS-specific epicsArch.txt plugin. Classes whatrecord.plugins.epicsarch.Comment dataclass Comment(context: 'FullLoadContext', text: 'str') Source code in whatrecord/plugins/epicsarch.py @dataclass class Comment : context : FullLoadContext text : str whatrecord.plugins.epicsarch.DaqPV dataclass A single PV configured for storage in the DAQ/logbook. Source code in whatrecord/plugins/epicsarch.py @dataclass class DaqPV : \"\"\"A single PV configured for storage in the DAQ/logbook.\"\"\" context : FullLoadContext name : str alias : str = \"\" provider : str = \"ca\" comments : List [ Comment ] = field ( default_factory = list ) whatrecord.plugins.epicsarch.LclsEpicsArchFile dataclass Representation of an LCLS-specific DAQ recording epicsArch.txt file. Source code in whatrecord/plugins/epicsarch.py @dataclass class LclsEpicsArchFile : \"\"\"Representation of an LCLS-specific DAQ recording epicsArch.txt file.\"\"\" pvs : Dict [ str , DaqPV ] aliases : Dict [ str , str ] warnings : List [ Warning ] filename : Optional [ pathlib . Path ] = None loaded_files : Dict [ str , str ] = field ( default_factory = dict ) @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file given its string contents.\"\"\" if filename : filename = pathlib . Path ( filename ) . resolve () grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"lcls_epicsarch.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , propagate_positions = True , debug = debug , ) transformer_ = _EpicsArchTransformer ( cls , filename , contents , grammar , context = context ) return transformer_ . transform ( grammar . parse ( contents + \" \\n \" )) @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file from a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), context = context , ) @classmethod def from_file ( cls , fn : AnyPath , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\" Load an epicsArch.txt file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : LclsEpicsArchFile The parsed file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , context = context ) Methods whatrecord . plugins . epicsarch . LclsEpicsArchFile . from_file ( fn : AnyPath , context : Optional [ FullLoadContext ] = None ) -> LclsEpicsArchFile classmethod Load an epicsArch.txt file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description LclsEpicsArchFile The parsed file. Source code in whatrecord/plugins/epicsarch.py @classmethod def from_file ( cls , fn : AnyPath , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\" Load an epicsArch.txt file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : LclsEpicsArchFile The parsed file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , context = context ) whatrecord . plugins . epicsarch . LclsEpicsArchFile . from_file_obj ( fp , filename : Optional [ AnyPath ] = None , context : Optional [ FullLoadContext ] = None ) -> LclsEpicsArchFile classmethod Load an epicsArch.txt file from a file object. Source code in whatrecord/plugins/epicsarch.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file from a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), context = context , ) whatrecord . plugins . epicsarch . LclsEpicsArchFile . from_string ( contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , context : Optional [ FullLoadContext ] = None ) -> LclsEpicsArchFile classmethod Load an epicsArch.txt file given its string contents. Source code in whatrecord/plugins/epicsarch.py @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file given its string contents.\"\"\" if filename : filename = pathlib . Path ( filename ) . resolve () grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"lcls_epicsarch.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , propagate_positions = True , debug = debug , ) transformer_ = _EpicsArchTransformer ( cls , filename , contents , grammar , context = context ) return transformer_ . transform ( grammar . parse ( contents + \" \\n \" )) whatrecord.plugins.epicsarch.LclsEpicsArchPluginResults ( PluginResults ) dataclass LclsEpicsArchPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/epicsarch.py @dataclass class LclsEpicsArchPluginResults ( PluginResults ): # Could potentially further specify metadata_by_key or metadata ... whatrecord.plugins.epicsarch.Warning dataclass epicsArch-format warning. Source code in whatrecord/plugins/epicsarch.py @dataclass class Warning : \"\"\"epicsArch-format warning.\"\"\" context : FullLoadContext type_ : str text : str whatrecord.plugins.twincat_pytmc TwinCAT / pytmc whatrecord plugin Match your TwinCAT project symbols to EPICS records. Set project to generate metadata for one particular PLC project. Alternatively, the plugin will query WHATRECORD_SERVER for all IOCs and attempt to find ads-ioc-based IOCs with associated TwinCAT projects. Classes whatrecord.plugins.twincat_pytmc.DataType dataclass DataType(name: 'str') Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class DataType : name : str whatrecord.plugins.twincat_pytmc.Declaration dataclass Declaration(context: 'FullLoadContext', name: 'str' = 'unknown', type: 'str' = 'unknown') Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class Declaration : context : FullLoadContext name : str = \"unknown\" type : str = \"unknown\" whatrecord.plugins.twincat_pytmc.NCAxes dataclass Top-level NC axis information. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class NCAxes : \"\"\"Top-level NC axis information.\"\"\" context : FullLoadContext filename : str hash : str axes : List [ NCAxis ] @classmethod def from_pytmc ( cls , plc : pytmc . parser . Plc , ) -> Optional [ NCAxes ]: \"\"\"Create an NCAxes instance from a pytmc-parsed Plc.\"\"\" try : nc = next ( plc . root . find ( pytmc . parser . NC )) except StopIteration : return filename = str ( nc . filename . resolve ()) return cls ( context = ( LoadContext ( filename , 0 ), ), filename = filename , hash = get_file_sha256 ( filename ), axes = [ NCAxis . from_pytmc ( axis ) for axis in nc . axes ], ) Methods whatrecord . plugins . twincat_pytmc . NCAxes . from_pytmc ( plc : pytmc . parser . Plc ) -> Optional [ NCAxes ] classmethod Create an NCAxes instance from a pytmc-parsed Plc. Source code in whatrecord/plugins/twincat_pytmc.py @classmethod def from_pytmc ( cls , plc : pytmc . parser . Plc , ) -> Optional [ NCAxes ]: \"\"\"Create an NCAxes instance from a pytmc-parsed Plc.\"\"\" try : nc = next ( plc . root . find ( pytmc . parser . NC )) except StopIteration : return filename = str ( nc . filename . resolve ()) return cls ( context = ( LoadContext ( filename , 0 ), ), filename = filename , hash = get_file_sha256 ( filename ), axes = [ NCAxis . from_pytmc ( axis ) for axis in nc . axes ], ) whatrecord.plugins.twincat_pytmc.NCAxis dataclass A single NC axis. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class NCAxis : \"\"\"A single NC axis.\"\"\" context : FullLoadContext filename : str hash : str axis_id : int name : str units : str params : Dict [ str , str ] @classmethod def from_pytmc ( cls , axis : pytmc . parser . Axis , ) -> NCAxis : filename = str ( axis . filename . resolve ()) return cls ( context = ( LoadContext ( filename , 0 ), ), filename = filename , hash = get_file_sha256 ( filename ), axis_id = axis . axis_number , name = axis . name , units = axis . units , params = dict ( axis . summarize ()), ) whatrecord.plugins.twincat_pytmc.PlcCode dataclass PlcCode() Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcCode : ... whatrecord.plugins.twincat_pytmc.PlcMetadata ( InlineCached , PlcMetadataCacheKey ) dataclass This metadata is keyed on PlcMetadataCacheKey. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcMetadata ( cache . InlineCached , PlcMetadataCacheKey ): \"\"\"This metadata is keyed on PlcMetadataCacheKey.\"\"\" context : FullLoadContext symbols : Dict [ str , PlcSymbolMetadata ] loaded_files : Dict [ pathlib . Path , str ] record_to_symbol : Dict [ str , str ] dependencies : Dict [ str , dependency_store . ResolvedDependency ] nc : Optional [ NCAxes ] = None @classmethod def from_ioc ( cls , md : IocMetadata , ) -> Generator [ PlcMetadata , None , None ]: try : makefile_hash , makefile_contents , makefile_path = get_ioc_makefile ( md ) except FileNotFoundError : return project_info = get_project_from_ioc ( md , makefile_contents ) if project_info is None : logger . debug ( \"No project found for %s \" , md . name ) return loaded_files = { str ( makefile_path ): makefile_hash or get_file_sha256 } project , plc_name = project_info logger . info ( \"Found a PLC for this project: %s %s ( %s )\" , md . name , plc_name , project ) yield from PlcMetadata . from_project_filename ( project , plc_whitelist = [ plc_name ], loaded_files = loaded_files , ) @classmethod def from_blark ( cls , blark_md : dependency_store . PlcProjectMetadata , include_dependencies : bool = True , use_cache : bool = True , ) -> PlcMetadata : \"\"\"Create a PlcMetadata instance from a pytmc-parsed one.\"\"\" loaded_files = dict ( blark_md . loaded_files ) nc = NCAxes . from_pytmc ( blark_md . plc ) if nc is not None : loaded_files [ nc . filename ] = nc . hash for axis in nc . axes : loaded_files [ axis . filename ] = axis . hash tmc = blark_md . plc . tmc if tmc is None : logger . debug ( \" %s : No TMC file for symbols; skipping...\" , blark_md . plc . name ) return PlcMetadata ( name = blark_md . name , code = {}, symbols = {}, record_to_symbol = {}, nc = None , loaded_files = loaded_files , ) filename = blark_md . plc . filename . resolve () if use_cache : key = PlcMetadataCacheKey ( name = blark_md . plc . name , filename = str ( filename ), include_dependencies = include_dependencies , ) cached = cls . from_cache ( key ) if cached is not None : if util . check_files_up_to_date ( cached . loaded_files ): return cached loaded_files [ filename ] = util . get_file_sha256 ( filename ) md = cls ( name = blark_md . plc . name , filename = filename , include_dependencies = include_dependencies , context = ( LoadContext ( filename , 0 ), ), symbols = {}, record_to_symbol = {}, dependencies = blark_md . dependencies , loaded_files = loaded_files , nc = nc , ) def by_name ( symbol ): return symbol . name for symbol in sorted ( pytmc . pragmas . find_pytmc_symbols ( tmc ), key = by_name ): for symbol_md in get_symbol_metadata ( blark_md , symbol ): md . symbols [ symbol_md . name ] = symbol_md for record in symbol_md . records : md . record_to_symbol [ record ] = symbol_md . name logger . debug ( \"PLC %s : Found %d symbols ( %d generated metadata; %d records)\" , blark_md . plc . name , len ( blark_md . tmc_symbols ), len ( md . symbols ), len ( md . record_to_symbol ), ) if use_cache : md . save_to_cache () return md @classmethod def from_project_filename ( cls , project : AnyPath , include_dependencies : bool = True , plc_whitelist : Optional [ List [ str ]] = None , ) -> Generator [ PlcMetadata , None , None ]: \"\"\"Given a project/solution filename, get all PlcMetadata.\"\"\" projects = dependency_store . load_projects ( project , include_dependencies = include_dependencies , plc_whitelist = plc_whitelist , ) for project in projects : logger . debug ( \"Found plc project %s from %s \" , project . name , project . filename ) plc_md = cls . from_blark ( project , include_dependencies = include_dependencies , ) if plc_md is not None : yield plc_md Classes whatrecord.plugins.twincat_pytmc.PlcMetadata.CacheKey ( CacheKey ) dataclass These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcMetadataCacheKey ( cache . CacheKey ): \"\"\" These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. \"\"\" name : str filename : str include_dependencies : bool Methods whatrecord . plugins . twincat_pytmc . PlcMetadata . from_blark ( blark_md : dependency_store . PlcProjectMetadata , include_dependencies : bool = True , use_cache : bool = True ) -> PlcMetadata classmethod Create a PlcMetadata instance from a pytmc-parsed one. Source code in whatrecord/plugins/twincat_pytmc.py @classmethod def from_blark ( cls , blark_md : dependency_store . PlcProjectMetadata , include_dependencies : bool = True , use_cache : bool = True , ) -> PlcMetadata : \"\"\"Create a PlcMetadata instance from a pytmc-parsed one.\"\"\" loaded_files = dict ( blark_md . loaded_files ) nc = NCAxes . from_pytmc ( blark_md . plc ) if nc is not None : loaded_files [ nc . filename ] = nc . hash for axis in nc . axes : loaded_files [ axis . filename ] = axis . hash tmc = blark_md . plc . tmc if tmc is None : logger . debug ( \" %s : No TMC file for symbols; skipping...\" , blark_md . plc . name ) return PlcMetadata ( name = blark_md . name , code = {}, symbols = {}, record_to_symbol = {}, nc = None , loaded_files = loaded_files , ) filename = blark_md . plc . filename . resolve () if use_cache : key = PlcMetadataCacheKey ( name = blark_md . plc . name , filename = str ( filename ), include_dependencies = include_dependencies , ) cached = cls . from_cache ( key ) if cached is not None : if util . check_files_up_to_date ( cached . loaded_files ): return cached loaded_files [ filename ] = util . get_file_sha256 ( filename ) md = cls ( name = blark_md . plc . name , filename = filename , include_dependencies = include_dependencies , context = ( LoadContext ( filename , 0 ), ), symbols = {}, record_to_symbol = {}, dependencies = blark_md . dependencies , loaded_files = loaded_files , nc = nc , ) def by_name ( symbol ): return symbol . name for symbol in sorted ( pytmc . pragmas . find_pytmc_symbols ( tmc ), key = by_name ): for symbol_md in get_symbol_metadata ( blark_md , symbol ): md . symbols [ symbol_md . name ] = symbol_md for record in symbol_md . records : md . record_to_symbol [ record ] = symbol_md . name logger . debug ( \"PLC %s : Found %d symbols ( %d generated metadata; %d records)\" , blark_md . plc . name , len ( blark_md . tmc_symbols ), len ( md . symbols ), len ( md . record_to_symbol ), ) if use_cache : md . save_to_cache () return md whatrecord . plugins . twincat_pytmc . PlcMetadata . from_project_filename ( project : AnyPath , include_dependencies : bool = True , plc_whitelist : Optional [ List [ str ]] = None ) -> Generator [ PlcMetadata , None , None ] classmethod Given a project/solution filename, get all PlcMetadata. Source code in whatrecord/plugins/twincat_pytmc.py @classmethod def from_project_filename ( cls , project : AnyPath , include_dependencies : bool = True , plc_whitelist : Optional [ List [ str ]] = None , ) -> Generator [ PlcMetadata , None , None ]: \"\"\"Given a project/solution filename, get all PlcMetadata.\"\"\" projects = dependency_store . load_projects ( project , include_dependencies = include_dependencies , plc_whitelist = plc_whitelist , ) for project in projects : logger . debug ( \"Found plc project %s from %s \" , project . name , project . filename ) plc_md = cls . from_blark ( project , include_dependencies = include_dependencies , ) if plc_md is not None : yield plc_md whatrecord.plugins.twincat_pytmc.PlcMetadataCacheKey ( CacheKey ) dataclass These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcMetadataCacheKey ( cache . CacheKey ): \"\"\" These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. \"\"\" name : str filename : str include_dependencies : bool whatrecord.plugins.twincat_pytmc.PlcSymbolMetadata dataclass PlcSymbolMetadata(context: 'FullLoadContext', name: 'str', type: 'str', records: 'List[str]') Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcSymbolMetadata : context : FullLoadContext name : str type : str records : List [ str ] whatrecord.plugins.twincat_pytmc.PytmcPluginResults ( PluginResults ) dataclass PytmcPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PytmcPluginResults ( PluginResults ): def merge ( self , results : PytmcPluginResults ) -> None : self . files_to_monitor . update ( results . files_to_monitor ) self . record_to_metadata_keys . update ( results . record_to_metadata_keys ) self . metadata_by_key . update ( results . metadata_by_key ) self . execution_info . update ( results . execution_info ) self . nested . update ( results . nested ) @classmethod def from_metadata ( cls , md : PlcMetadata ) -> PytmcPluginResults : def _stringify_path ( path ): if isinstance ( path , str ): return path return str ( path . resolve ()) plc_results = PytmcPluginResults ( files_to_monitor = { _stringify_path ( path ): shasum for path , shasum in md . loaded_files . items () }, record_to_metadata_keys = { rec : [ sym ] for rec , sym in md . record_to_symbol . items () }, metadata_by_key = md . symbols , metadata = { \"dependencies\" : md . dependencies , \"nc\" : md . nc , }, execution_info = {}, ) return PytmcPluginResults ( nested = { md . name : plc_results } ) @classmethod def from_metadata_items ( cls , mds : Iterable [ PlcMetadata ] ) -> Optional [ PytmcPluginResults ]: results = None for plc_md in mds : single = PytmcPluginResults . from_metadata ( plc_md ) if results is None : results = single else : results . merge ( single ) if results is not None : return results return PytmcPluginResults ( files_to_monitor = {}, record_to_metadata_keys = {}, metadata_by_key = {}, execution_info = { \"result\" : \"No PLCs found.\" }, ) Functions whatrecord . plugins . twincat_pytmc . get_ioc_makefile ( md : IocMetadata ) -> Tuple [ str , str , pathlib . Path ] Get the IOC Makefile contents, if available. Source code in whatrecord/plugins/twincat_pytmc.py def get_ioc_makefile ( md : IocMetadata ) -> Tuple [ str , str , pathlib . Path ]: \"\"\"Get the IOC Makefile contents, if available.\"\"\" makefile_path = ( md . script . parent / \"Makefile\" ) . resolve () sha , contents = read_text_file_with_hash ( makefile_path ) return sha , contents , makefile_path whatrecord . plugins . twincat_pytmc . get_project_from_ioc ( md : IocMetadata , makefile : str ) -> Optional [ Tuple [ pathlib . Path , str ]] Get the TwinCAT Project from a provided ads-ioc IocMetadata and Makefile contents. Source code in whatrecord/plugins/twincat_pytmc.py def get_project_from_ioc ( md : IocMetadata , makefile : str ) -> Optional [ Tuple [ pathlib . Path , str ]]: \"\"\"Get the TwinCAT Project from a provided ads-ioc IocMetadata and Makefile contents.\"\"\" variables = dict ( MAKEFILE_VAR_RE . findall ( makefile )) logger . debug ( \"IOC: %s Makefile variables: %s \" , md . name , variables ) try : plc_name = variables [ \"PLC\" ] project_path = variables [ \"PROJECT_PATH\" ] except KeyError : return None project_path = ( md . script . parent / project_path ) . resolve () if not project_path . exists (): logger . debug ( \"Project path doesn't exist: %s \" , project_path ) return return project_path , plc_name whatrecord . plugins . twincat_pytmc . get_symbol_metadata ( blark_md : dependency_store . PlcMetadata , symbol : pytmc . parser . Symbol , require_records : bool = True , add_project_prefix : bool = True ) -> Generator [ PlcSymbolMetadata , None , None ] Get symbol metadata given a pytmc Symbol. Source code in whatrecord/plugins/twincat_pytmc.py def get_symbol_metadata ( blark_md : dependency_store . PlcMetadata , symbol : pytmc . parser . Symbol , require_records : bool = True , add_project_prefix : bool = True , ) -> Generator [ PlcSymbolMetadata , None , None ]: \"\"\"Get symbol metadata given a pytmc Symbol.\"\"\" symbol_type_name = symbol . data_type . qualified_type_name for pkg in pytmc . pragmas . record_packages_from_symbol ( symbol , yield_exceptions = True , allow_no_pragma = False ): if isinstance ( pkg , Exception ): # Eat these up rather than raising continue # context = get_symbol_context(symbol.data_type.name, pkg.tcname) path = blark_md . summary . find_path ( pkg . tcname ) if not path : # Can't find the declaration in the code, somehow continue records = [ record . pvname for record in pkg . records ] if records or not require_records : annotated_name = pkg . tcname if add_project_prefix : annotated_name = f \" { blark_md . name } : { annotated_name } \" try : chain_type_name = pkg . chain . data_type . qualified_type_name except AttributeError : chain_type_name = \"unknown\" if symbol_type_name == chain_type_name : type_name = symbol_type_name else : type_name = f \" { chain_type_name } ( { symbol_type_name } )\" yield PlcSymbolMetadata ( context = load_context_from_path ( path ), name = annotated_name , records = records , type = type_name , ) whatrecord . plugins . twincat_pytmc . load_context_from_path ( path : List [ blark . summary . Summary ]) -> FullLoadContext Get a FullLoadContext from a blark variable path. Source code in whatrecord/plugins/twincat_pytmc.py def load_context_from_path ( path : List [ blark . summary . Summary ]) -> FullLoadContext : \"\"\"Get a FullLoadContext from a blark variable path.\"\"\" result = [] saw_files = set () for file , line in reversed ( blark . summary . path_to_file_and_line ( path )): file = str ( file ) if file not in saw_files : result . append ( LoadContext ( str ( file ), line )) saw_files . add ( file ) return tuple ( result [:: - 1 ])","title":"LCLS"},{"location":"lcls/#lcls","text":"LCLS-specific whatrecord plugins and helpers.","title":"LCLS"},{"location":"lcls/#whatrecord.iocmanager","text":"SLAC PCDS IocManager configuration file loading support.","title":"iocmanager"},{"location":"lcls/#whatrecord.iocmanager-functions","text":"","title":"Functions"},{"location":"lcls/#whatrecord.iocmanager.find_stcmd","text":"Find the startup script st.cmd for a given IOC. Source code in whatrecord/iocmanager.py def find_stcmd ( directory : str , ioc_id : str ) -> str : \"\"\"Find the startup script st.cmd for a given IOC.\"\"\" if directory . startswith ( \"ioc\" ): directory = os . path . join ( EPICS_SITE_TOP , directory ) suffix = ( \"iocBoot\" , ioc_id , \"st.cmd\" ) # Templated IOCs are... different: options = [ os . path . join ( directory , \"children\" , \"build\" , * suffix ), os . path . join ( directory , \"build\" , * suffix ), os . path . join ( directory , * suffix ), os . path . join ( directory , \"st.cmd\" ), ] for option in options : if os . path . exists ( option ): return option # Guess at what's correct: return options [ - 1 ]","title":"find_stcmd()"},{"location":"lcls/#whatrecord.iocmanager.get_iocs_from_configs","text":"Get IOC information in a list of dictionaries. Parameters: Name Type Description Default configs List[Union[str, pathlib.Path]] Configuration filenames to load. required sorter Optional[Callable[[Dict[str, Union[str, Dict[str, str], List[str]]]], Any]] Sort IOCs with this, defaults to sorting by host name and then IOC name. None Returns: Type Description List[Dict[str, Union[str, Dict[str, str], List[str]]]] List of IOC info Source code in whatrecord/iocmanager.py def get_iocs_from_configs ( configs : List [ Union [ str , pathlib . Path ]], sorter : Optional [ Callable [[ IocInfoDict ], Any ]] = None ) -> List [ IocInfoDict ]: \"\"\" Get IOC information in a list of dictionaries. Parameters ---------- configs : list[str or pathlib.Path] Configuration filenames to load. sorter : callable, optional Sort IOCs with this, defaults to sorting by host name and then IOC name. Returns ------- ioc_info : list of IOC info dictionaries List of IOC info \"\"\" configs = [ pathlib . Path ( config ) . resolve () for config in configs or [] ] def default_sorter ( ioc ): return ( ioc [ \"host\" ], ioc [ \"name\" ]) iocs = ( ioc for fn in set ( configs ) for ioc in load_config_file ( fn ) ) return list ( sorted ( iocs , key = sorter or default_sorter ))","title":"get_iocs_from_configs()"},{"location":"lcls/#whatrecord.iocmanager.load_config_file","text":"Load a configuration file and return the IOCs it contains. Parameters: Name Type Description Default fn Union[str, pathlib.Path] The configuration filename required Returns: Type Description List[Dict[str, Union[str, Dict[str, str], List[str]]]] List of IOC info Source code in whatrecord/iocmanager.py def load_config_file ( fn : Union [ str , pathlib . Path ]) -> List [ IocInfoDict ]: \"\"\" Load a configuration file and return the IOCs it contains. Parameters ---------- fn : str or pathlib.Path The configuration filename Returns ------- ioc_info : list of IOC info dictionaries List of IOC info \"\"\" with open ( fn , \"rt\" ) as f : lines = f . read () . splitlines () iocs = parse_config ( lines ) for ioc in list ( iocs ): # For now, assume old database syntax by specifying 3.15: ioc [ \"base_version\" ] = \"3.15\" if not validate_config_keys ( ioc ): iocs . remove ( ioc ) else : # Add \"config_file\" and rename some keys: ioc [ \"config_file\" ] = str ( fn ) ioc [ \"name\" ] = ioc . pop ( \"id\" ) ioc [ \"script\" ] = find_stcmd ( ioc [ \"dir\" ], ioc [ \"name\" ]) ioc [ \"binary\" ] = find_binary_from_hashbang ( ioc [ \"script\" ]) return iocs","title":"load_config_file()"},{"location":"lcls/#whatrecord.iocmanager.parse_config","text":"Parse an IOC manager config to get its IOCs. Parameters: Name Type Description Default lines List[str] List of raw configuration file lines. required Returns: Type Description List[Dict[str, Union[str, Dict[str, str], List[str]]]] List of IOC info Source code in whatrecord/iocmanager.py def parse_config ( lines : List [ str ]) -> List [ IocInfoDict ]: \"\"\" Parse an IOC manager config to get its IOCs. Parameters ---------- lines : list of str List of raw configuration file lines. Returns ------- ioc_info : list of IOC info dictionaries List of IOC info \"\"\" entries = [] loading = False entry = None for line in lines : if \"procmgr_config\" in line : loading = True continue if not loading : continue if \"id:\" in line : if \"}\" in line : entries . append ( line ) else : entry = line elif entry is not None : entry += line if \"}\" in entry : entries . append ( entry ) entry = None def fix_entry ( entry ): return ast . literal_eval ( KEY_RE . sub ( r '\"\\1\":' , entry . strip ( \", \\t \" ))) result = [] for entry in entries : try : result . append ( fix_entry ( entry )) except Exception : logger . exception ( \"Failed to fix up IOC manager entry: %s \" , entry ) return result","title":"parse_config()"},{"location":"lcls/#whatrecord.iocmanager.validate_config_keys","text":"Validate that a configuration has all required keys. Source code in whatrecord/iocmanager.py def validate_config_keys ( cfg : IocInfoDict ) -> bool : \"\"\"Validate that a configuration has all required keys.\"\"\" return all ( key in cfg and cfg [ key ] for key in REQUIRED_KEYS )","title":"validate_config_keys()"},{"location":"lcls/#whatrecord-iocmanager-loader","text":"whatrecord iocmanager-loader is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files. usage: whatrecord iocmanager-loader [-h] configs [configs ...] \"whatrec iocmanager_loader\" is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files. positional arguments: configs Configuration file location(s) optional arguments: -h, --help show this help message and exit","title":"whatrecord iocmanager-loader"},{"location":"lcls/#whatrecord.bin.iocmanager_loader","text":"\"whatrecord iocmanager-loader\" is used to import IOC configuration information from SLAC PCDS IocManager-format configuration files.","title":"iocmanager_loader"},{"location":"lcls/#api","text":"","title":"API"},{"location":"lcls/#whatrecord.plugins.epicsarch","text":"LCLS-specific epicsArch.txt plugin.","title":"epicsarch"},{"location":"lcls/#whatrecord.plugins.epicsarch-classes","text":"","title":"Classes"},{"location":"lcls/#whatrecord.plugins.epicsarch.Comment","text":"Comment(context: 'FullLoadContext', text: 'str') Source code in whatrecord/plugins/epicsarch.py @dataclass class Comment : context : FullLoadContext text : str","title":"Comment"},{"location":"lcls/#whatrecord.plugins.epicsarch.DaqPV","text":"A single PV configured for storage in the DAQ/logbook. Source code in whatrecord/plugins/epicsarch.py @dataclass class DaqPV : \"\"\"A single PV configured for storage in the DAQ/logbook.\"\"\" context : FullLoadContext name : str alias : str = \"\" provider : str = \"ca\" comments : List [ Comment ] = field ( default_factory = list )","title":"DaqPV"},{"location":"lcls/#whatrecord.plugins.epicsarch.LclsEpicsArchFile","text":"Representation of an LCLS-specific DAQ recording epicsArch.txt file. Source code in whatrecord/plugins/epicsarch.py @dataclass class LclsEpicsArchFile : \"\"\"Representation of an LCLS-specific DAQ recording epicsArch.txt file.\"\"\" pvs : Dict [ str , DaqPV ] aliases : Dict [ str , str ] warnings : List [ Warning ] filename : Optional [ pathlib . Path ] = None loaded_files : Dict [ str , str ] = field ( default_factory = dict ) @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file given its string contents.\"\"\" if filename : filename = pathlib . Path ( filename ) . resolve () grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"lcls_epicsarch.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , propagate_positions = True , debug = debug , ) transformer_ = _EpicsArchTransformer ( cls , filename , contents , grammar , context = context ) return transformer_ . transform ( grammar . parse ( contents + \" \\n \" )) @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file from a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), context = context , ) @classmethod def from_file ( cls , fn : AnyPath , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\" Load an epicsArch.txt file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : LclsEpicsArchFile The parsed file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , context = context )","title":"LclsEpicsArchFile"},{"location":"lcls/#whatrecord.plugins.epicsarch.LclsEpicsArchFile-methods","text":"whatrecord . plugins . epicsarch . LclsEpicsArchFile . from_file ( fn : AnyPath , context : Optional [ FullLoadContext ] = None ) -> LclsEpicsArchFile classmethod Load an epicsArch.txt file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description LclsEpicsArchFile The parsed file. Source code in whatrecord/plugins/epicsarch.py @classmethod def from_file ( cls , fn : AnyPath , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\" Load an epicsArch.txt file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : LclsEpicsArchFile The parsed file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , context = context ) whatrecord . plugins . epicsarch . LclsEpicsArchFile . from_file_obj ( fp , filename : Optional [ AnyPath ] = None , context : Optional [ FullLoadContext ] = None ) -> LclsEpicsArchFile classmethod Load an epicsArch.txt file from a file object. Source code in whatrecord/plugins/epicsarch.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file from a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), context = context , ) whatrecord . plugins . epicsarch . LclsEpicsArchFile . from_string ( contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , context : Optional [ FullLoadContext ] = None ) -> LclsEpicsArchFile classmethod Load an epicsArch.txt file given its string contents. Source code in whatrecord/plugins/epicsarch.py @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , context : Optional [ FullLoadContext ] = None , ) -> LclsEpicsArchFile : \"\"\"Load an epicsArch.txt file given its string contents.\"\"\" if filename : filename = pathlib . Path ( filename ) . resolve () grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"lcls_epicsarch.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , propagate_positions = True , debug = debug , ) transformer_ = _EpicsArchTransformer ( cls , filename , contents , grammar , context = context ) return transformer_ . transform ( grammar . parse ( contents + \" \\n \" ))","title":"Methods"},{"location":"lcls/#whatrecord.plugins.epicsarch.LclsEpicsArchPluginResults","text":"LclsEpicsArchPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/epicsarch.py @dataclass class LclsEpicsArchPluginResults ( PluginResults ): # Could potentially further specify metadata_by_key or metadata ...","title":"LclsEpicsArchPluginResults"},{"location":"lcls/#whatrecord.plugins.epicsarch.Warning","text":"epicsArch-format warning. Source code in whatrecord/plugins/epicsarch.py @dataclass class Warning : \"\"\"epicsArch-format warning.\"\"\" context : FullLoadContext type_ : str text : str","title":"Warning"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc","text":"TwinCAT / pytmc whatrecord plugin Match your TwinCAT project symbols to EPICS records. Set project to generate metadata for one particular PLC project. Alternatively, the plugin will query WHATRECORD_SERVER for all IOCs and attempt to find ads-ioc-based IOCs with associated TwinCAT projects.","title":"twincat_pytmc"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc-classes","text":"","title":"Classes"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.DataType","text":"DataType(name: 'str') Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class DataType : name : str","title":"DataType"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.Declaration","text":"Declaration(context: 'FullLoadContext', name: 'str' = 'unknown', type: 'str' = 'unknown') Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class Declaration : context : FullLoadContext name : str = \"unknown\" type : str = \"unknown\"","title":"Declaration"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.NCAxes","text":"Top-level NC axis information. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class NCAxes : \"\"\"Top-level NC axis information.\"\"\" context : FullLoadContext filename : str hash : str axes : List [ NCAxis ] @classmethod def from_pytmc ( cls , plc : pytmc . parser . Plc , ) -> Optional [ NCAxes ]: \"\"\"Create an NCAxes instance from a pytmc-parsed Plc.\"\"\" try : nc = next ( plc . root . find ( pytmc . parser . NC )) except StopIteration : return filename = str ( nc . filename . resolve ()) return cls ( context = ( LoadContext ( filename , 0 ), ), filename = filename , hash = get_file_sha256 ( filename ), axes = [ NCAxis . from_pytmc ( axis ) for axis in nc . axes ], )","title":"NCAxes"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.NCAxes-methods","text":"whatrecord . plugins . twincat_pytmc . NCAxes . from_pytmc ( plc : pytmc . parser . Plc ) -> Optional [ NCAxes ] classmethod Create an NCAxes instance from a pytmc-parsed Plc. Source code in whatrecord/plugins/twincat_pytmc.py @classmethod def from_pytmc ( cls , plc : pytmc . parser . Plc , ) -> Optional [ NCAxes ]: \"\"\"Create an NCAxes instance from a pytmc-parsed Plc.\"\"\" try : nc = next ( plc . root . find ( pytmc . parser . NC )) except StopIteration : return filename = str ( nc . filename . resolve ()) return cls ( context = ( LoadContext ( filename , 0 ), ), filename = filename , hash = get_file_sha256 ( filename ), axes = [ NCAxis . from_pytmc ( axis ) for axis in nc . axes ], )","title":"Methods"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.NCAxis","text":"A single NC axis. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class NCAxis : \"\"\"A single NC axis.\"\"\" context : FullLoadContext filename : str hash : str axis_id : int name : str units : str params : Dict [ str , str ] @classmethod def from_pytmc ( cls , axis : pytmc . parser . Axis , ) -> NCAxis : filename = str ( axis . filename . resolve ()) return cls ( context = ( LoadContext ( filename , 0 ), ), filename = filename , hash = get_file_sha256 ( filename ), axis_id = axis . axis_number , name = axis . name , units = axis . units , params = dict ( axis . summarize ()), )","title":"NCAxis"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PlcCode","text":"PlcCode() Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcCode : ...","title":"PlcCode"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PlcMetadata","text":"This metadata is keyed on PlcMetadataCacheKey. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcMetadata ( cache . InlineCached , PlcMetadataCacheKey ): \"\"\"This metadata is keyed on PlcMetadataCacheKey.\"\"\" context : FullLoadContext symbols : Dict [ str , PlcSymbolMetadata ] loaded_files : Dict [ pathlib . Path , str ] record_to_symbol : Dict [ str , str ] dependencies : Dict [ str , dependency_store . ResolvedDependency ] nc : Optional [ NCAxes ] = None @classmethod def from_ioc ( cls , md : IocMetadata , ) -> Generator [ PlcMetadata , None , None ]: try : makefile_hash , makefile_contents , makefile_path = get_ioc_makefile ( md ) except FileNotFoundError : return project_info = get_project_from_ioc ( md , makefile_contents ) if project_info is None : logger . debug ( \"No project found for %s \" , md . name ) return loaded_files = { str ( makefile_path ): makefile_hash or get_file_sha256 } project , plc_name = project_info logger . info ( \"Found a PLC for this project: %s %s ( %s )\" , md . name , plc_name , project ) yield from PlcMetadata . from_project_filename ( project , plc_whitelist = [ plc_name ], loaded_files = loaded_files , ) @classmethod def from_blark ( cls , blark_md : dependency_store . PlcProjectMetadata , include_dependencies : bool = True , use_cache : bool = True , ) -> PlcMetadata : \"\"\"Create a PlcMetadata instance from a pytmc-parsed one.\"\"\" loaded_files = dict ( blark_md . loaded_files ) nc = NCAxes . from_pytmc ( blark_md . plc ) if nc is not None : loaded_files [ nc . filename ] = nc . hash for axis in nc . axes : loaded_files [ axis . filename ] = axis . hash tmc = blark_md . plc . tmc if tmc is None : logger . debug ( \" %s : No TMC file for symbols; skipping...\" , blark_md . plc . name ) return PlcMetadata ( name = blark_md . name , code = {}, symbols = {}, record_to_symbol = {}, nc = None , loaded_files = loaded_files , ) filename = blark_md . plc . filename . resolve () if use_cache : key = PlcMetadataCacheKey ( name = blark_md . plc . name , filename = str ( filename ), include_dependencies = include_dependencies , ) cached = cls . from_cache ( key ) if cached is not None : if util . check_files_up_to_date ( cached . loaded_files ): return cached loaded_files [ filename ] = util . get_file_sha256 ( filename ) md = cls ( name = blark_md . plc . name , filename = filename , include_dependencies = include_dependencies , context = ( LoadContext ( filename , 0 ), ), symbols = {}, record_to_symbol = {}, dependencies = blark_md . dependencies , loaded_files = loaded_files , nc = nc , ) def by_name ( symbol ): return symbol . name for symbol in sorted ( pytmc . pragmas . find_pytmc_symbols ( tmc ), key = by_name ): for symbol_md in get_symbol_metadata ( blark_md , symbol ): md . symbols [ symbol_md . name ] = symbol_md for record in symbol_md . records : md . record_to_symbol [ record ] = symbol_md . name logger . debug ( \"PLC %s : Found %d symbols ( %d generated metadata; %d records)\" , blark_md . plc . name , len ( blark_md . tmc_symbols ), len ( md . symbols ), len ( md . record_to_symbol ), ) if use_cache : md . save_to_cache () return md @classmethod def from_project_filename ( cls , project : AnyPath , include_dependencies : bool = True , plc_whitelist : Optional [ List [ str ]] = None , ) -> Generator [ PlcMetadata , None , None ]: \"\"\"Given a project/solution filename, get all PlcMetadata.\"\"\" projects = dependency_store . load_projects ( project , include_dependencies = include_dependencies , plc_whitelist = plc_whitelist , ) for project in projects : logger . debug ( \"Found plc project %s from %s \" , project . name , project . filename ) plc_md = cls . from_blark ( project , include_dependencies = include_dependencies , ) if plc_md is not None : yield plc_md","title":"PlcMetadata"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PlcMetadata-classes","text":"whatrecord.plugins.twincat_pytmc.PlcMetadata.CacheKey ( CacheKey ) dataclass These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcMetadataCacheKey ( cache . CacheKey ): \"\"\" These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. \"\"\" name : str filename : str include_dependencies : bool","title":"Classes"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PlcMetadata-methods","text":"whatrecord . plugins . twincat_pytmc . PlcMetadata . from_blark ( blark_md : dependency_store . PlcProjectMetadata , include_dependencies : bool = True , use_cache : bool = True ) -> PlcMetadata classmethod Create a PlcMetadata instance from a pytmc-parsed one. Source code in whatrecord/plugins/twincat_pytmc.py @classmethod def from_blark ( cls , blark_md : dependency_store . PlcProjectMetadata , include_dependencies : bool = True , use_cache : bool = True , ) -> PlcMetadata : \"\"\"Create a PlcMetadata instance from a pytmc-parsed one.\"\"\" loaded_files = dict ( blark_md . loaded_files ) nc = NCAxes . from_pytmc ( blark_md . plc ) if nc is not None : loaded_files [ nc . filename ] = nc . hash for axis in nc . axes : loaded_files [ axis . filename ] = axis . hash tmc = blark_md . plc . tmc if tmc is None : logger . debug ( \" %s : No TMC file for symbols; skipping...\" , blark_md . plc . name ) return PlcMetadata ( name = blark_md . name , code = {}, symbols = {}, record_to_symbol = {}, nc = None , loaded_files = loaded_files , ) filename = blark_md . plc . filename . resolve () if use_cache : key = PlcMetadataCacheKey ( name = blark_md . plc . name , filename = str ( filename ), include_dependencies = include_dependencies , ) cached = cls . from_cache ( key ) if cached is not None : if util . check_files_up_to_date ( cached . loaded_files ): return cached loaded_files [ filename ] = util . get_file_sha256 ( filename ) md = cls ( name = blark_md . plc . name , filename = filename , include_dependencies = include_dependencies , context = ( LoadContext ( filename , 0 ), ), symbols = {}, record_to_symbol = {}, dependencies = blark_md . dependencies , loaded_files = loaded_files , nc = nc , ) def by_name ( symbol ): return symbol . name for symbol in sorted ( pytmc . pragmas . find_pytmc_symbols ( tmc ), key = by_name ): for symbol_md in get_symbol_metadata ( blark_md , symbol ): md . symbols [ symbol_md . name ] = symbol_md for record in symbol_md . records : md . record_to_symbol [ record ] = symbol_md . name logger . debug ( \"PLC %s : Found %d symbols ( %d generated metadata; %d records)\" , blark_md . plc . name , len ( blark_md . tmc_symbols ), len ( md . symbols ), len ( md . record_to_symbol ), ) if use_cache : md . save_to_cache () return md whatrecord . plugins . twincat_pytmc . PlcMetadata . from_project_filename ( project : AnyPath , include_dependencies : bool = True , plc_whitelist : Optional [ List [ str ]] = None ) -> Generator [ PlcMetadata , None , None ] classmethod Given a project/solution filename, get all PlcMetadata. Source code in whatrecord/plugins/twincat_pytmc.py @classmethod def from_project_filename ( cls , project : AnyPath , include_dependencies : bool = True , plc_whitelist : Optional [ List [ str ]] = None , ) -> Generator [ PlcMetadata , None , None ]: \"\"\"Given a project/solution filename, get all PlcMetadata.\"\"\" projects = dependency_store . load_projects ( project , include_dependencies = include_dependencies , plc_whitelist = plc_whitelist , ) for project in projects : logger . debug ( \"Found plc project %s from %s \" , project . name , project . filename ) plc_md = cls . from_blark ( project , include_dependencies = include_dependencies , ) if plc_md is not None : yield plc_md","title":"Methods"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PlcMetadataCacheKey","text":"These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcMetadataCacheKey ( cache . CacheKey ): \"\"\" These attributes define a PlcMetadata cache item. The PLC name and filename will be used as a cache key; however, additional checks will be made to see that the files have not changed on disk since the last save. \"\"\" name : str filename : str include_dependencies : bool","title":"PlcMetadataCacheKey"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PlcSymbolMetadata","text":"PlcSymbolMetadata(context: 'FullLoadContext', name: 'str', type: 'str', records: 'List[str]') Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PlcSymbolMetadata : context : FullLoadContext name : str type : str records : List [ str ]","title":"PlcSymbolMetadata"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.PytmcPluginResults","text":"PytmcPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/twincat_pytmc.py @dataclass class PytmcPluginResults ( PluginResults ): def merge ( self , results : PytmcPluginResults ) -> None : self . files_to_monitor . update ( results . files_to_monitor ) self . record_to_metadata_keys . update ( results . record_to_metadata_keys ) self . metadata_by_key . update ( results . metadata_by_key ) self . execution_info . update ( results . execution_info ) self . nested . update ( results . nested ) @classmethod def from_metadata ( cls , md : PlcMetadata ) -> PytmcPluginResults : def _stringify_path ( path ): if isinstance ( path , str ): return path return str ( path . resolve ()) plc_results = PytmcPluginResults ( files_to_monitor = { _stringify_path ( path ): shasum for path , shasum in md . loaded_files . items () }, record_to_metadata_keys = { rec : [ sym ] for rec , sym in md . record_to_symbol . items () }, metadata_by_key = md . symbols , metadata = { \"dependencies\" : md . dependencies , \"nc\" : md . nc , }, execution_info = {}, ) return PytmcPluginResults ( nested = { md . name : plc_results } ) @classmethod def from_metadata_items ( cls , mds : Iterable [ PlcMetadata ] ) -> Optional [ PytmcPluginResults ]: results = None for plc_md in mds : single = PytmcPluginResults . from_metadata ( plc_md ) if results is None : results = single else : results . merge ( single ) if results is not None : return results return PytmcPluginResults ( files_to_monitor = {}, record_to_metadata_keys = {}, metadata_by_key = {}, execution_info = { \"result\" : \"No PLCs found.\" }, )","title":"PytmcPluginResults"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc-functions","text":"","title":"Functions"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.get_ioc_makefile","text":"Get the IOC Makefile contents, if available. Source code in whatrecord/plugins/twincat_pytmc.py def get_ioc_makefile ( md : IocMetadata ) -> Tuple [ str , str , pathlib . Path ]: \"\"\"Get the IOC Makefile contents, if available.\"\"\" makefile_path = ( md . script . parent / \"Makefile\" ) . resolve () sha , contents = read_text_file_with_hash ( makefile_path ) return sha , contents , makefile_path","title":"get_ioc_makefile()"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.get_project_from_ioc","text":"Get the TwinCAT Project from a provided ads-ioc IocMetadata and Makefile contents. Source code in whatrecord/plugins/twincat_pytmc.py def get_project_from_ioc ( md : IocMetadata , makefile : str ) -> Optional [ Tuple [ pathlib . Path , str ]]: \"\"\"Get the TwinCAT Project from a provided ads-ioc IocMetadata and Makefile contents.\"\"\" variables = dict ( MAKEFILE_VAR_RE . findall ( makefile )) logger . debug ( \"IOC: %s Makefile variables: %s \" , md . name , variables ) try : plc_name = variables [ \"PLC\" ] project_path = variables [ \"PROJECT_PATH\" ] except KeyError : return None project_path = ( md . script . parent / project_path ) . resolve () if not project_path . exists (): logger . debug ( \"Project path doesn't exist: %s \" , project_path ) return return project_path , plc_name","title":"get_project_from_ioc()"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.get_symbol_metadata","text":"Get symbol metadata given a pytmc Symbol. Source code in whatrecord/plugins/twincat_pytmc.py def get_symbol_metadata ( blark_md : dependency_store . PlcMetadata , symbol : pytmc . parser . Symbol , require_records : bool = True , add_project_prefix : bool = True , ) -> Generator [ PlcSymbolMetadata , None , None ]: \"\"\"Get symbol metadata given a pytmc Symbol.\"\"\" symbol_type_name = symbol . data_type . qualified_type_name for pkg in pytmc . pragmas . record_packages_from_symbol ( symbol , yield_exceptions = True , allow_no_pragma = False ): if isinstance ( pkg , Exception ): # Eat these up rather than raising continue # context = get_symbol_context(symbol.data_type.name, pkg.tcname) path = blark_md . summary . find_path ( pkg . tcname ) if not path : # Can't find the declaration in the code, somehow continue records = [ record . pvname for record in pkg . records ] if records or not require_records : annotated_name = pkg . tcname if add_project_prefix : annotated_name = f \" { blark_md . name } : { annotated_name } \" try : chain_type_name = pkg . chain . data_type . qualified_type_name except AttributeError : chain_type_name = \"unknown\" if symbol_type_name == chain_type_name : type_name = symbol_type_name else : type_name = f \" { chain_type_name } ( { symbol_type_name } )\" yield PlcSymbolMetadata ( context = load_context_from_path ( path ), name = annotated_name , records = records , type = type_name , )","title":"get_symbol_metadata()"},{"location":"lcls/#whatrecord.plugins.twincat_pytmc.load_context_from_path","text":"Get a FullLoadContext from a blark variable path. Source code in whatrecord/plugins/twincat_pytmc.py def load_context_from_path ( path : List [ blark . summary . Summary ]) -> FullLoadContext : \"\"\"Get a FullLoadContext from a blark variable path.\"\"\" result = [] saw_files = set () for file , line in reversed ( blark . summary . path_to_file_and_line ( path )): file = str ( file ) if file not in saw_files : result . append ( LoadContext ( str ( file ), line )) saw_files . add ( file ) return tuple ( result [:: - 1 ])","title":"load_context_from_path()"},{"location":"parsers/","text":"Parsers Usage For each of the parser classes: AccessSecurityConfig Database GatewayPVList LclsEpicsArchFile SequencerProgram StreamProtocol TemplateSubstitution Data can be loaded from a file, file object, or string. Filename information will be automatically added to the load context information when available, but may be specified separately in the latter case. Taking AccessSecurityConfig for example: from whatrecord import AccessSecurityConfig # 1. Load from a file directly config = AccessSecurityConfig.from_file(\"filename.acf\") # 2. Load from a file object with open(\"filename.acf\", \"rt\") as fp: config = AccessSecurityConfig.from_file_obj(fp) # 3. Load from a string: with open(\"filename.acf\", \"rt\") as fp: contents = fp.read() config = AccessSecurityConfig.from_string(contents, filename=\"filename.acf\") API whatrecord.access_security V3 Access Security file parsing. Documentation from the application developer's guide are interspersed here and in the classes below. A brief summary of the Functional Requirements is: * Each field of each record type is assigned an access security level. * Each record instance is assigned to a unique access security group. * Each user is assigned to one or more user access groups. * Each node is assigned to a host access group. For each access security group a set of access rules can be defined. Each rule specifies: - Access security level - READ or READ/WRITE access. - An optional list of User Access Groups or * meaning anyone. - An optional list of Host Access Groups or * meaning anywhere. - Conditions based on values of process variables Classes whatrecord.access_security.AccessSecurityConfig dataclass An Access Security Configuration file (ACF) container. Source code in whatrecord/access_security.py @dataclass class AccessSecurityConfig : \"\"\"An Access Security Configuration file (ACF) container.\"\"\" filename : Optional [ str ] = None hash : Optional [ str ] = None users : Dict [ str , UserAccessGroup ] = field ( default_factory = dict ) groups : Dict [ str , AccessSecurityGroup ] = field ( default_factory = dict ) hosts : Dict [ str , HostAccessGroup ] = field ( default_factory = dict ) header : str = \"\" comments : List [ lark . Token ] = field ( default_factory = list , metadata = apischema . metadata . skip , ) def get_group_from_record ( self , record : RecordInstance ) -> Optional [ AccessSecurityGroup ]: \"\"\"Get the appropriate access security group for the given record.\"\"\" if record . is_pva : return return self . groups . get ( record . access_security_group , None ) @classmethod def from_string ( cls , contents : str , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\" Load access security configuration from a string. Parameters ---------- contents : str The access security file contents. filename : str, optional The access security filename to use for LoadContext. \"\"\" contents_hash = get_bytes_sha256 ( contents . encode ( \"utf-8\" )) comments = [] def add_comment ( comment : lark . Token ): comments . append ( StringWithContext ( str ( comment ) . lstrip ( \"# \" ), context = context_from_lark_token ( filename , comment ), ) ) grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"access_security.lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : add_comment }, transformer = _AcfTransformer ( filename , contents_hash , comments ), maybe_placeholders = False , ) return grammar . parse ( contents ) @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\"Load an ACF file from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]) -> AccessSecurityConfig : \"\"\"Load an ACF file from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn )) Methods whatrecord . access_security . AccessSecurityConfig . from_file ( fn : Union [ str , pathlib . Path ]) -> AccessSecurityConfig classmethod Load an ACF file from a filename. Source code in whatrecord/access_security.py @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]) -> AccessSecurityConfig : \"\"\"Load an ACF file from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn )) whatrecord . access_security . AccessSecurityConfig . from_file_obj ( fp , filename : Optional [ str ] = None ) -> AccessSecurityConfig classmethod Load an ACF file from a file object. Source code in whatrecord/access_security.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\"Load an ACF file from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) whatrecord . access_security . AccessSecurityConfig . from_string ( contents : str , filename : Optional [ str ] = None ) -> AccessSecurityConfig classmethod Load access security configuration from a string. Parameters: Name Type Description Default contents str The access security file contents. required filename Optional[str] The access security filename to use for LoadContext. None Source code in whatrecord/access_security.py @classmethod def from_string ( cls , contents : str , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\" Load access security configuration from a string. Parameters ---------- contents : str The access security file contents. filename : str, optional The access security filename to use for LoadContext. \"\"\" contents_hash = get_bytes_sha256 ( contents . encode ( \"utf-8\" )) comments = [] def add_comment ( comment : lark . Token ): comments . append ( StringWithContext ( str ( comment ) . lstrip ( \"# \" ), context = context_from_lark_token ( filename , comment ), ) ) grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"access_security.lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : add_comment }, transformer = _AcfTransformer ( filename , contents_hash , comments ), maybe_placeholders = False , ) return grammar . parse ( contents ) whatrecord . access_security . AccessSecurityConfig . get_group_from_record ( self , record : RecordInstance ) -> Optional [ AccessSecurityGroup ] Get the appropriate access security group for the given record. Source code in whatrecord/access_security.py def get_group_from_record ( self , record : RecordInstance ) -> Optional [ AccessSecurityGroup ]: \"\"\"Get the appropriate access security group for the given record.\"\"\" if record . is_pva : return return self . groups . get ( record . access_security_group , None ) whatrecord.access_security.AccessSecurityGroup dataclass An access security group. Source code in whatrecord/access_security.py @dataclass class AccessSecurityGroup : \"\"\"An access security group.\"\"\" context : FullLoadContext comments : str name : str inputs : Dict [ str , str ] = field ( default_factory = dict ) rules : List [ AccessSecurityRule ] = field ( default_factory = list ) whatrecord.access_security.AccessSecurityRule dataclass Access Security Configuration rule, which defines access permissions. must be 0 or 1. Permission for a level 1 field implies permission for level 0 fields. The permissions are NONE, READ, and WRITE. WRITE permission implies READ permission. The standard EPICS record types have all fields set to level 1 except for VAL, CMD (command), and RES (reset). An optional argument specifies if writes should be trapped. See the section below on trapping Channel Access writes for how this is used. If not given the default is NOTRAPWRITE. UAG specifies a list of user access groups that can have the access privilege. If UAG is not defined then all users are allowed. HAG specifies a list of host access groups that have the access privilege. If HAG is not defined then all hosts are allowed. CALC is just like the CALC field of a calculation record except that the result must evaluate to TRUE or FALSE. The rule only applies if the calculation result is TRUE, where the actual test for TRUE is (0.99 < result < 1.01). Anything else is regarded as FALSE and will cause the rule to be ignored. Assignment statements are not permitted in CALC expressions here. Source code in whatrecord/access_security.py @apischema . fields . with_fields_set @dataclass class AccessSecurityRule : \"\"\" Access Security Configuration rule, which defines access permissions. <level> must be 0 or 1. Permission for a level 1 field implies permission for level 0 fields. The permissions are NONE, READ, and WRITE. WRITE permission implies READ permission. The standard EPICS record types have all fields set to level 1 except for VAL, CMD (command), and RES (reset). An optional argument specifies if writes should be trapped. See the section below on trapping Channel Access writes for how this is used. If not given the default is NOTRAPWRITE. UAG specifies a list of user access groups that can have the access privilege. If UAG is not defined then all users are allowed. HAG specifies a list of host access groups that have the access privilege. If HAG is not defined then all hosts are allowed. CALC is just like the CALC field of a calculation record except that the result must evaluate to TRUE or FALSE. The rule only applies if the calculation result is TRUE, where the actual test for TRUE is (0.99 < result < 1.01). Anything else is regarded as FALSE and will cause the rule to be ignored. Assignment statements are not permitted in CALC expressions here. \"\"\" context : FullLoadContext comments : str level : int options : str log_options : Optional [ str ] = None users : Optional [ List [ str ]] = None hosts : Optional [ List [ str ]] = None calc : Optional [ str ] = None whatrecord.access_security.AccessSecurityState ( ShellStateHandler ) dataclass Access Security IOC shell state handler / container. Contains hooks for as-related commands and state information. Attributes: Name Type Description config AccessSecurityState The access security configuration. filename pathlib.Path The access security filename. macros Dict[str, str] Macros used when expanding the access security file. Source code in whatrecord/access_security.py @dataclass class AccessSecurityState ( ShellStateHandler ): \"\"\" Access Security IOC shell state handler / container. Contains hooks for as-related commands and state information. Attributes ---------- config : AccessSecurityState The access security configuration. filename : pathlib.Path The access security filename. macros : Dict[str, str] Macros used when expanding the access security file. \"\"\" metadata_key : ClassVar [ str ] = \"asg\" config : Optional [ AccessSecurityConfig ] = None filename : Optional [ pathlib . Path ] = None macros : Optional [ Dict [ str , str ]] = None def post_ioc_init ( self ): super () . post_ioc_init () if self . filename is None : return try : return { \"access_security\" : self . _load_access_security () } except Exception as ex : return { \"access_security\" : { \"exception_class\" : type ( ex ) . __name__ , \"error\" : str ( ex ), } } @_handler def handle_asSetSubstitutions ( self , macros : str ): if self . primary_handler is None : return macro_context = self . primary_handler . macro_context self . macros = macro_context . definitions_to_dict ( macros ) return { \"macros\" : self . macros , \"note\" : \"See iocInit results for details.\" , } @_handler def handle_asSetFilename ( self , filename : str ): if self . primary_handler is None : return self . filename = self . primary_handler . _fix_path ( filename ) . resolve () return { \"filename\" : str ( self . filename ), \"note\" : \"See iocInit results for details.\" , } def _load_access_security ( self ): \"\"\"Load access security settings at iocInit time.\"\"\" if self . primary_handler is None : return filename , contents = self . primary_handler . load_file ( self . filename ) if self . macros : macro_context = MacroContext ( use_environment = False ) macro_context . define ( ** self . macros ) contents = \" \\n \" . join ( macro_context . expand ( line ) for line in contents . splitlines () ) self . config = AccessSecurityConfig . from_string ( contents , filename = str ( filename ) ) return { \"filename\" : filename , \"macros\" : self . macros , } def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate record with access security information.\"\"\" if self . config is not None : asg = self . config . get_group_from_record ( record ) if asg is not None : return apischema . serialize ( asg ) Methods whatrecord . access_security . AccessSecurityState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate record with access security information. Source code in whatrecord/access_security.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate record with access security information.\"\"\" if self . config is not None : asg = self . config . get_group_from_record ( record ) if asg is not None : return apischema . serialize ( asg ) whatrecord . access_security . AccessSecurityState . post_ioc_init ( self ) Post-iocInit hook. Source code in whatrecord/access_security.py def post_ioc_init ( self ): super () . post_ioc_init () if self . filename is None : return try : return { \"access_security\" : self . _load_access_security () } except Exception as ex : return { \"access_security\" : { \"exception_class\" : type ( ex ) . __name__ , \"error\" : str ( ex ), } } whatrecord.access_security.HostAccessGroup dataclass Host Access Group. This is a list of host names. It may be empty. The same host name can appear in multiple HAGs. To match, a host name must match the host name read by the CA client library running on the client machine; both names are converted to lower case before comparison however. For vxWorks clients, the host name is usually taken from the target name of the boot parameters. Source code in whatrecord/access_security.py @dataclass class HostAccessGroup : \"\"\" Host Access Group. This is a list of host names. It may be empty. The same host name can appear in multiple HAGs. To match, a host name must match the host name read by the CA client library running on the client machine; both names are converted to lower case before comparison however. For vxWorks clients, the host name is usually taken from the target name of the boot parameters. \"\"\" context : FullLoadContext comments : str name : str hosts : List [ str ] whatrecord.access_security.UserAccessGroup dataclass User Access Group. This is a list of user names. The list may be empty. A user name may appear in more than one UAG. To match, a user name must be identical to the user name read by the CA client library running on the client machine. For vxWorks clients, the user name is usually taken from the user field of the boot parameters. Source code in whatrecord/access_security.py @dataclass class UserAccessGroup : \"\"\" User Access Group. This is a list of user names. The list may be empty. A user name may appear in more than one UAG. To match, a user name must be identical to the user name read by the CA client library running on the client machine. For vxWorks clients, the user name is usually taken from the user field of the boot parameters. \"\"\" context : FullLoadContext comments : str name : str users : List [ str ] whatrecord.autosave Classes whatrecord.autosave.AutosaveRestoreFile dataclass Representation of an autosave restore (.sav) file. Source code in whatrecord/autosave.py @dataclass class AutosaveRestoreFile : \"\"\"Representation of an autosave restore (.sav) file.\"\"\" filename : str values : Dict [ str , Dict [ str , RestoreValue ]] = field ( default_factory = dict ) disconnected : List [ str ] = field ( default_factory = list ) errors : List [ RestoreError ] = field ( default_factory = list ) comments : List [ str ] = field ( default_factory = list ) @classmethod def from_string ( cls , contents : str , filename : AnyPath = \"\" , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given its string contents.\"\"\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"autosave_save.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , propagate_positions = True , ) if macros : contents = MacroContext ( macros = macros ) . expand_by_line ( contents ) return _AutosaveRestoreTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) @classmethod def from_file_obj ( cls , fp , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), macros = macros , ) @classmethod def from_file ( cls , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\" Load an autosave restore (.sav) file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : AutosaveRestoreFile The resulting parsed file. \"\"\" with open ( filename , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = filename , macros = macros ) Methods whatrecord . autosave . AutosaveRestoreFile . from_file ( filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile classmethod Load an autosave restore (.sav) file. Parameters: Name Type Description Default filename AnyPath The filename. required Returns: Type Description AutosaveRestoreFile The resulting parsed file. Source code in whatrecord/autosave.py @classmethod def from_file ( cls , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\" Load an autosave restore (.sav) file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : AutosaveRestoreFile The resulting parsed file. \"\"\" with open ( filename , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = filename , macros = macros ) whatrecord . autosave . AutosaveRestoreFile . from_file_obj ( fp , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile classmethod Load an autosave file given a file object. Source code in whatrecord/autosave.py @classmethod def from_file_obj ( cls , fp , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), macros = macros , ) whatrecord . autosave . AutosaveRestoreFile . from_string ( contents : str , filename : AnyPath = '' , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile classmethod Load an autosave file given its string contents. Source code in whatrecord/autosave.py @classmethod def from_string ( cls , contents : str , filename : AnyPath = \"\" , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given its string contents.\"\"\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"autosave_save.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , propagate_positions = True , ) if macros : contents = MacroContext ( macros = macros ) . expand_by_line ( contents ) return _AutosaveRestoreTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) whatrecord.autosave.AutosaveRestorePassFile dataclass AutosaveRestorePassFile(context: 'FullLoadContext', save_filename: 'str', macros: 'Dict[str, str]' = , pass_number: 'int' = 0, load_timestamp: 'Optional[datetime.datetime]' = None, file_timestamp: 'Optional[datetime.datetime]' = None, data: 'Optional[AutosaveRestoreFile]' = None) Source code in whatrecord/autosave.py @dataclass class AutosaveRestorePassFile : context : FullLoadContext save_filename : str macros : Dict [ str , str ] = field ( default_factory = dict ) pass_number : int = 0 load_timestamp : Optional [ datetime . datetime ] = None file_timestamp : Optional [ datetime . datetime ] = None data : Optional [ AutosaveRestoreFile ] = None def update ( self , save_path : pathlib . Path ) -> AutosaveRestoreFile : \"\"\"Update the autosave .sav file from disk.\"\"\" fn = save_path / self . save_filename file_timestamp = datetime . datetime . fromtimestamp ( fn . stat () . st_mtime ) if self . file_timestamp is not None and file_timestamp == self . file_timestamp : if self . data is not None : return self . data if self . load_timestamp is not None and self . data is not None : dt = datetime . datetime . now () - self . load_timestamp if dt . total_seconds () < settings . AUTOSAVE_RELOAD_PERIOD : return self . data self . file_timestamp = file_timestamp self . load_timestamp = datetime . datetime . now () self . data = AutosaveRestoreFile . from_file ( fn , macros = self . macros , ) return self . data Methods whatrecord . autosave . AutosaveRestorePassFile . update ( self , save_path : pathlib . Path ) -> AutosaveRestoreFile Update the autosave .sav file from disk. Source code in whatrecord/autosave.py def update ( self , save_path : pathlib . Path ) -> AutosaveRestoreFile : \"\"\"Update the autosave .sav file from disk.\"\"\" fn = save_path / self . save_filename file_timestamp = datetime . datetime . fromtimestamp ( fn . stat () . st_mtime ) if self . file_timestamp is not None and file_timestamp == self . file_timestamp : if self . data is not None : return self . data if self . load_timestamp is not None and self . data is not None : dt = datetime . datetime . now () - self . load_timestamp if dt . total_seconds () < settings . AUTOSAVE_RELOAD_PERIOD : return self . data self . file_timestamp = file_timestamp self . load_timestamp = datetime . datetime . now () self . data = AutosaveRestoreFile . from_file ( fn , macros = self . macros , ) return self . data whatrecord.autosave.AutosaveSet dataclass AutosaveSet(context: 'FullLoadContext', request_filename: 'str', save_filename: 'str', period: 'Optional[int]' = None, trigger_channel: 'Optional[str]' = None, macros: 'Dict[str, str]' = , method: 'str' = 'manual') Source code in whatrecord/autosave.py @dataclass class AutosaveSet : context : FullLoadContext request_filename : str save_filename : str period : Optional [ int ] = None trigger_channel : Optional [ str ] = None macros : Dict [ str , str ] = field ( default_factory = dict ) method : str = \"manual\" whatrecord.autosave.AutosaveState ( ShellStateHandler ) dataclass The state of autosave in an IOC. Source code in whatrecord/autosave.py @dataclass class AutosaveState ( ShellStateHandler ): \"\"\"The state of autosave in an IOC.\"\"\" metadata_key : ClassVar [ str ] = \"autosave\" configured : bool = False request_paths : List [ pathlib . Path ] = field ( default_factory = list ) save_path : pathlib . Path = field ( default_factory = pathlib . Path ) sets : Dict [ str , AutosaveSet ] = field ( default_factory = dict ) restore_files : Dict [ str , AutosaveRestorePassFile ] = field ( default_factory = dict ) incomplete_sets_ok : Optional [ bool ] = None # default: True dated_backups : Optional [ bool ] = None # default: True date_period_minutes : Optional [ int ] = None # default: 0 num_seq_files : Optional [ int ] = None # default: 3 seq_period : Optional [ int ] = None # default: 0 retry_seconds : Optional [ int ] = None # default: 0 ca_reconnect : Optional [ bool ] = None # default: False callback_timeout : Optional [ int ] = None # default: 0 task_priority : Optional [ int ] = None # default: 0 nfs_host : Optional [ str ] = None use_status_pvs : Optional [ bool ] = None # default: False status_prefix : Optional [ str ] = None file_permissions : Optional [ int ] = None # default: 0o664 debug : Optional [ int ] = None # default: 0 @property def save_name_pv ( self ) -> Optional [ str ]: \"\"\"The save name PV, derived from the macro context.\"\"\" if self . primary_handler is not None : return self . primary_handler . macro_context . get ( \"SAVENAMEPV\" ) @property def save_path_pv ( self ) -> Optional [ str ]: \"\"\"The save path PV, derived from the macro context.\"\"\" if self . primary_handler is not None : return self . primary_handler . macro_context . get ( \"SAVEPATHPV\" ) # save_restore.c @_handler def handle_fdbrestore ( self , filename : str = \"\" ): \"\"\" If save_file refers to a save set that exists in memory, then PV's in the save set will be restored from values in memory. Otherwise, this functions restores the PV's in <saveRestorePath>/<save_file> and creates a new backup file \"<saveRestorePath>/<save_file>.bu\". The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPutX() calls. Record processing will result from caput()'s to inherently process- passive fields. \"\"\" @_handler def handle_fdbrestoreX ( self , filename = \"\" , macrostring = \"\" ): \"\"\" This function restores from the file <saveRestorePath>/<save_file>, which can look just like a save file, but which needn't end with <END>. No backup file will be written. The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPut*() calls. Record processing will result from caput()'s to inherently process-passive fields. \"\"\" @_handler def handle_manual_save ( self , request_file : str = \"\" ): \"\"\" Cause current PV values for the request file to be saved. Any request file named in a create_xxx_set() command can be saved manually. \"\"\" @_handler def handle_set_savefile_name ( self , request_file : str = \"\" , save_filename : str = \"\" ): \"\"\" If a save set has already been created for the request file, this function will change the save file name. \"\"\" try : set_ = self . sets [ request_file ] except KeyError : raise ValueError ( \"Request file not configured\" ) set_ . save_filename = save_filename @_handler def handle_create_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = period , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"periodic\" , ) @_handler def handle_create_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written whenever the PV specified by trigger_channel is posted. Normally this occurs when the PV's value changes. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = trigger_channel , macros = macros_from_string ( macro_string ), method = \"triggered\" , ) @_handler def handle_create_monitor_set ( self , filename : Optional [ str ] = None , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds, if any PV in the save set was posted (changed value) since the last write. \"\"\" if filename is None : # An indicator to \"start the save task\" return self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = int ( period ), trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"monitor\" , ) @_handler def handle_create_manual_set ( self , filename : str = \"\" , macro_string : str = \"\" ): \"\"\" Create a save set for the request file. The save file will be written when the function manual_save() is called with the same request-file name. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"manual\" , ) @_handler def handle_save_restoreShow ( self , verbose : int = 0 ): \"\"\"Show the save restore status.\"\"\" return self . sets @_handler def handle_set_requestfile_path ( self , path : str = \"\" , subpath : str = \"\" ): full_path = ( pathlib . Path ( path ) / subpath ) . resolve () if full_path not in self . request_paths : self . request_paths . append ( full_path ) @_handler def handle_set_savefile_path ( self , path : str = \"\" , subpath : str = \"\" ): \"\"\" Called before iocInit(), this function specifies the path to be prepended to save-file and restore-file names. pathsub, if present, will be appended to path, if present, with a separating '/', whether or not path ends or pathsub begins with '/'. If the result does not end in '/', one will be appended to it. If save_restore is managing its own NFS mount, this function specifies the mount point, and calling it will result in an NFS mount if all other requirements have already been met. If a valid NFS mount already exists, the file system will be dismounted and then mounted with the new path name. This function can be called at any time. \"\"\" path = pathlib . Path ( path ) / subpath if self . primary_handler is not None : path = self . primary_handler . _fix_path ( path ) self . save_path = path . resolve () @_handler def handle_set_saveTask_priority ( self , priority : int = 0 ): \"\"\"Set the priority of the save_restore task.\"\"\" self . task_priority = int ( priority ) @_handler def handle_save_restoreSet_NFSHost ( self , hostname : str = \"\" , address : str = \"\" , mntpoint : str = \"\" , * _ ): \"\"\" Specifies the name and IP address of the NFS host. If both have been specified, and set_savefile_path() has been called to specify the file path, save_restore will manage its own NFS mount. This allows save_restore to recover from a reboot of the NFS host (that is, a stale file handle) and from some kinds of tampering with the save_restore directory. \"\"\" self . nfs_host = f \"nfs:// { hostname } / { mntpoint } ( { address } )\" @_handler def handle_remove_data_set ( self , filename : str = \"\" ): \"\"\"If a save set has been created for request_file, this function will delete it.\"\"\" ... @_handler def handle_reload_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_periodic_set(). \"\"\" @_handler def handle_reload_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the trigger channel associated with a save set created by create_triggered_set(). \"\"\" @_handler def handle_reload_monitor_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_monitor_set(). \"\"\" @_handler def handle_reload_manual_set ( self , filename : str = \"\" , macrostring : str = \"\" ): \"\"\" This function allows you to change the PV's associated with a save set created by create_manual_set(). \"\"\" @_handler def handle_save_restoreSet_Debug ( self , level : int = 0 ): \"\"\" Sets the value (int) save_restoreDebug (initially 0). Increase to get more informational messages printed to the console. \"\"\" self . debug = int ( level ) @_handler def handle_save_restoreSet_NumSeqFiles ( self , numSeqFiles : int = 0 ): \"\"\" Sets the value of (int) save_restoreNumSeqFiles (initially 3). This is the number of sequenced backup files to be maintained. \"\"\" self . num_seq_files = int ( numSeqFiles ) if not ( 0 <= self . num_seq_files <= 10 ): raise ValueError ( \"numSeqFiles must be between 0 and 10 inclusive.\" ) @_handler def handle_save_restoreSet_SeqPeriodInSeconds ( self , period : int = 0 ): \"\"\" Sets the value of (int) save_restoreSeqPeriodInSeconds (initially 60). Sequenced backup files will be written with this period. \"\"\" self . seq_period = int ( period ) if self . seq_period < 10 : raise ValueError ( \"period must be 10 or greater.\" ) @_handler def handle_save_restoreSet_IncompleteSetsOk ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreIncompleteSetsOk (initially 1). If set to zero, save files will not be restored at boot time unless they are perfect, and they will not be overwritten at save time unless a valid CA connection and value exists for every PV in the list. \"\"\" self . incomplete_sets_ok = bool ( ok ) @_handler def handle_save_restoreSet_DatedBackupFiles ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = bool ( ok ) @_handler def handle_save_restoreSet_status_prefix ( self , prefix : str = \"\" ): \"\"\" Specifies the prefix to be used to construct the names of PV's with which save_restore reports its status. If you want autosave to update status PVs as it operates, you must call this function and load the database save_restoreStatus.db, specifying the same prefix in both commands. \"\"\" self . status_prefix = prefix @_handler def handle_save_restoreSet_FilePermissions ( self , permissions : int = 0 ): \"\"\" Specify the file permissions used to create new .sav files. This integer value will be supplied, exactly as given, to the system call, open(), and to the call fchmod(). Typically, file permissions are set with an octal number, such as 0640, and save_restoreSet_FilePermissions() will confirm any number given to it by echoing it to the console as an octal number. \"\"\" self . file_permissions = int ( permissions ) @_handler def handle_save_restoreSet_RetrySeconds ( self , seconds : int = 0 ): \"\"\" Specify the time delay between a failed .sav-file write and the retry of that write. The default delay is 60 seconds. If list-PV's change during the delay, the new values will be written. \"\"\" self . retry_seconds = int ( seconds ) @_handler def handle_save_restoreSet_UseStatusPVs ( self , ok : int = 0 ): \"\"\" Specifies whether save_restore should report its status to a preloaded set of EPICS PV's (contained in the database save_restoreStatus.db). If the argument is '0', then status PV's will not be used. \"\"\" self . use_status_pvs = bool ( ok ) @_handler def handle_save_restoreSet_CAReconnect ( self , ok : int = 0 ): \"\"\" Specify whether autosave should periodically retry connecting to PVs whose initial connection attempt failed. Currently, the connection-retry interval is hard-wired at 60 seconds. \"\"\" self . ca_reconnect = bool ( ok ) @_handler def handle_save_restoreSet_CallbackTimeout ( self , timeout : int = 0 ): \"\"\" Specify the time interval in seconds between forced save-file writes. (-1 means forever). This is intended to get save files written even if the normal trigger mechanism is broken. \"\"\" self . callback_timeout = int ( timeout ) @_handler def handle_asVerify ( self , filename : str = \"\" , verbose : int = 0 , restoreFileName : str = \"\" , * _ ): \"\"\" Compare PV values in the IOC with values written in filename (which should be an autosave restore file, or at least look like one). If restoreFileName is not empty, write a new restore file. \"\"\" ... @_handler def handle_save_restoreSet_periodicDatedBackups ( self , periodMinutes : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = True self . date_period_minutes = int ( periodMinutes ) # dbrestore.c @_handler def handle_set_pass0_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, before record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 0 , ) return { \"autosave\" : f \"Added pass 0 restore file { self . save_path } / { file } \" } @_handler def handle_set_pass1_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, after record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 1 , ) return { \"autosave\" : f \"Added pass 1 restore file { self . save_path } / { file } \" } @_handler def handle_dbrestoreShow ( self ): \"\"\" List all the save sets currently being managed by the save_restore task. If (verbose != 0), lists the PV's as well. \"\"\" ... @_handler def handle_makeAutosaveFileFromDbInfo ( self , filename : str = \"\" , info_name : str = \"\" , * _ ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for 'info' nodes named info_name; construct a list of PV names from the associated info_values found, and write the PV names to the file fileBaseName. If fileBaseName does not contain the string '.req', this string will be appended to it. See makeAutosaveFiles() for more information. \"\"\" @_handler def handle_makeAutosaveFiles ( self ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for info nodes named 'autosaveFields' and 'autosaveFields_pass0'; construct lists of PV names from the associated info values, and write the PV names to the files 'info_settings.req' and 'info_positions.req', respectively. \"\"\" @_handler def handle_eraseFile ( self , filename : str = \"\" ): \"\"\"Erase (empty) an autosave file.\"\"\" ... @_handler def handle_appendToFile ( self , filename : str = \"\" , line : str = \"\" ): \"\"\" Append line to a file. For example, to add a line to built_settings.req yourself: appendToFile(\"built_settings.req\", '$(P)userStringSeqEnable') \"\"\" ... @_handler def handle_autosaveBuild ( self , filename : str = \"\" , reqFileSuffix : str = \"\" , on : int = 0 , * _ ): \"\"\" It's tedious and error prone to have these entries separately maintained, so autosave can do the request-file part for you. To do this, you tell autosave to arrange to be called whenever dbLoadRecords() is called (note that dbLoadTemplate() calls dbLoadRecords()), you tell it how to make a request-file name from a database-file name, and you give it the name of the request file you want it to build. You can do this with the following command: autosaveBuild(\"built_settings.req\", \"_settings.req\", 1) This tells autosave to do the following: 1. Begin building the file built_settings.req. If this is the first call that mentions built_settings.req, erase the file. 2. Generate request-file names by stripping \".db\", or \".vdb\", or \".template\" from database-file names, and adding the suffix \"_settings.req\". 3. Enable (disable) automated building if the third argument is 1 (0). While automated building is enabled, autosave will generate request-file names and search for those files in its request-file path. If it finds a request file, it will add the appropriate line to built_settings.req. All this does is get the file built_settings.req built. If you want it to be used, you must add the following line to auto_settings.req: file built_settings.req P=$(P) \"\"\" def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: metadata = {} for restore_file in self . restore_files . values (): try : data = restore_file . update ( self . save_path ) except FileNotFoundError : fn = self . save_path / restore_file . save_filename metadata . setdefault ( \"error\" , []) . append ( f \"Restore file not found: { fn } \" ) continue record_data = data . values . get ( record . name , None ) if record_data is not None : metadata . setdefault ( \"restore\" , []) . append ( record_data ) for pvname in data . disconnected : if pvname . split ( \".\" )[ 0 ] == record . name : if \".\" in pvname : field = pvname . split ( \".\" , 1 )[ 1 ] else : field = \"VAL\" metadata . setdefault ( \"disconnected\" , []) . append ( field ) return metadata if metadata else None Attributes whatrecord . autosave . AutosaveState . save_name_pv : Optional [ str ] property readonly The save name PV, derived from the macro context. whatrecord . autosave . AutosaveState . save_path_pv : Optional [ str ] property readonly The save path PV, derived from the macro context. Methods whatrecord . autosave . AutosaveState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate the given record's metadata with state-related information. Source code in whatrecord/autosave.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: metadata = {} for restore_file in self . restore_files . values (): try : data = restore_file . update ( self . save_path ) except FileNotFoundError : fn = self . save_path / restore_file . save_filename metadata . setdefault ( \"error\" , []) . append ( f \"Restore file not found: { fn } \" ) continue record_data = data . values . get ( record . name , None ) if record_data is not None : metadata . setdefault ( \"restore\" , []) . append ( record_data ) for pvname in data . disconnected : if pvname . split ( \".\" )[ 0 ] == record . name : if \".\" in pvname : field = pvname . split ( \".\" , 1 )[ 1 ] else : field = \"VAL\" metadata . setdefault ( \"disconnected\" , []) . append ( field ) return metadata if metadata else None whatrecord . autosave . AutosaveState . handle_appendToFile ( self , filename : str = '' , line : str = '' ) Append line to a file. For example, to add a line to built_settings.req yourself: appendToFile(\"built_settings.req\", '$(P)userStringSeqEnable') Source code in whatrecord/autosave.py @_handler def handle_appendToFile ( self , filename : str = \"\" , line : str = \"\" ): \"\"\" Append line to a file. For example, to add a line to built_settings.req yourself: appendToFile(\"built_settings.req\", '$(P)userStringSeqEnable') \"\"\" ... whatrecord . autosave . AutosaveState . handle_asVerify ( self , filename : str = '' , verbose : int = 0 , restoreFileName : str = '' , * _ ) Compare PV values in the IOC with values written in filename (which should be an autosave restore file, or at least look like one). If restoreFileName is not empty, write a new restore file. Source code in whatrecord/autosave.py @_handler def handle_asVerify ( self , filename : str = \"\" , verbose : int = 0 , restoreFileName : str = \"\" , * _ ): \"\"\" Compare PV values in the IOC with values written in filename (which should be an autosave restore file, or at least look like one). If restoreFileName is not empty, write a new restore file. \"\"\" ... whatrecord . autosave . AutosaveState . handle_autosaveBuild ( self , filename : str = '' , reqFileSuffix : str = '' , on : int = 0 , * _ ) It's tedious and error prone to have these entries separately maintained, so autosave can do the request-file part for you. To do this, you tell autosave to arrange to be called whenever dbLoadRecords() is called (note that dbLoadTemplate() calls dbLoadRecords()), you tell it how to make a request-file name from a database-file name, and you give it the name of the request file you want it to build. You can do this with the following command: autosaveBuild(\"built_settings.req\", \"_settings.req\", 1) This tells autosave to do the following: 1. Begin building the file built_settings.req. If this is the first call that mentions built_settings.req, erase the file. 2. Generate request-file names by stripping \".db\", or \".vdb\", or \".template\" from database-file names, and adding the suffix \"_settings.req\". 3. Enable (disable) automated building if the third argument is 1 (0). While automated building is enabled, autosave will generate request-file names and search for those files in its request-file path. If it finds a request file, it will add the appropriate line to built_settings.req. All this does is get the file built_settings.req built. If you want it to be used, you must add the following line to auto_settings.req: file built_settings.req P=$(P) Source code in whatrecord/autosave.py @_handler def handle_autosaveBuild ( self , filename : str = \"\" , reqFileSuffix : str = \"\" , on : int = 0 , * _ ): \"\"\" It's tedious and error prone to have these entries separately maintained, so autosave can do the request-file part for you. To do this, you tell autosave to arrange to be called whenever dbLoadRecords() is called (note that dbLoadTemplate() calls dbLoadRecords()), you tell it how to make a request-file name from a database-file name, and you give it the name of the request file you want it to build. You can do this with the following command: autosaveBuild(\"built_settings.req\", \"_settings.req\", 1) This tells autosave to do the following: 1. Begin building the file built_settings.req. If this is the first call that mentions built_settings.req, erase the file. 2. Generate request-file names by stripping \".db\", or \".vdb\", or \".template\" from database-file names, and adding the suffix \"_settings.req\". 3. Enable (disable) automated building if the third argument is 1 (0). While automated building is enabled, autosave will generate request-file names and search for those files in its request-file path. If it finds a request file, it will add the appropriate line to built_settings.req. All this does is get the file built_settings.req built. If you want it to be used, you must add the following line to auto_settings.req: file built_settings.req P=$(P) \"\"\" whatrecord . autosave . AutosaveState . handle_create_manual_set ( self , filename : str = '' , macro_string : str = '' ) Create a save set for the request file. The save file will be written when the function manual_save() is called with the same request-file name. Source code in whatrecord/autosave.py @_handler def handle_create_manual_set ( self , filename : str = \"\" , macro_string : str = \"\" ): \"\"\" Create a save set for the request file. The save file will be written when the function manual_save() is called with the same request-file name. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"manual\" , ) whatrecord . autosave . AutosaveState . handle_create_monitor_set ( self , filename : Optional [ str ] = None , period : int = 0 , macro_string : str = '' , * _ ) Create a save set for the request file. The save file will be written every period seconds, if any PV in the save set was posted (changed value) since the last write. Source code in whatrecord/autosave.py @_handler def handle_create_monitor_set ( self , filename : Optional [ str ] = None , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds, if any PV in the save set was posted (changed value) since the last write. \"\"\" if filename is None : # An indicator to \"start the save task\" return self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = int ( period ), trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"monitor\" , ) whatrecord . autosave . AutosaveState . handle_create_periodic_set ( self , filename : str = '' , period : int = 0 , macro_string : str = '' , * _ ) Create a save set for the request file. The save file will be written every period seconds. Source code in whatrecord/autosave.py @_handler def handle_create_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = period , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"periodic\" , ) whatrecord . autosave . AutosaveState . handle_create_triggered_set ( self , filename : str = '' , trigger_channel : str = '' , macro_string : str = '' , * _ ) Create a save set for the request file. The save file will be written whenever the PV specified by trigger_channel is posted. Normally this occurs when the PV's value changes. Source code in whatrecord/autosave.py @_handler def handle_create_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written whenever the PV specified by trigger_channel is posted. Normally this occurs when the PV's value changes. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = trigger_channel , macros = macros_from_string ( macro_string ), method = \"triggered\" , ) whatrecord . autosave . AutosaveState . handle_dbrestoreShow ( self ) List all the save sets currently being managed by the save_restore task. If (verbose != 0), lists the PV's as well. Source code in whatrecord/autosave.py @_handler def handle_dbrestoreShow ( self ): \"\"\" List all the save sets currently being managed by the save_restore task. If (verbose != 0), lists the PV's as well. \"\"\" ... whatrecord . autosave . AutosaveState . handle_eraseFile ( self , filename : str = '' ) Erase (empty) an autosave file. Source code in whatrecord/autosave.py @_handler def handle_eraseFile ( self , filename : str = \"\" ): \"\"\"Erase (empty) an autosave file.\"\"\" ... whatrecord . autosave . AutosaveState . handle_fdbrestore ( self , filename : str = '' ) If save_file refers to a save set that exists in memory, then PV's in the save set will be restored from values in memory. Otherwise, this functions restores the PV's in / and creates a new backup file \" / .bu\". The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPutX() calls. Record processing will result from caput()'s to inherently process- passive fields. Source code in whatrecord/autosave.py @_handler def handle_fdbrestore ( self , filename : str = \"\" ): \"\"\" If save_file refers to a save set that exists in memory, then PV's in the save set will be restored from values in memory. Otherwise, this functions restores the PV's in <saveRestorePath>/<save_file> and creates a new backup file \"<saveRestorePath>/<save_file>.bu\". The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPutX() calls. Record processing will result from caput()'s to inherently process- passive fields. \"\"\" whatrecord . autosave . AutosaveState . handle_fdbrestoreX ( self , filename = '' , macrostring = '' ) This function restores from the file / , which can look just like a save file, but which needn't end with . No backup file will be written. The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPut*() calls. Record processing will result from caput()'s to inherently process-passive fields. Source code in whatrecord/autosave.py @_handler def handle_fdbrestoreX ( self , filename = \"\" , macrostring = \"\" ): \"\"\" This function restores from the file <saveRestorePath>/<save_file>, which can look just like a save file, but which needn't end with <END>. No backup file will be written. The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPut*() calls. Record processing will result from caput()'s to inherently process-passive fields. \"\"\" whatrecord . autosave . AutosaveState . handle_makeAutosaveFileFromDbInfo ( self , filename : str = '' , info_name : str = '' , * _ ) Search through the EPICS database (that is, all EPICS records loaded into an IOC) for 'info' nodes named info_name; construct a list of PV names from the associated info_values found, and write the PV names to the file fileBaseName. If fileBaseName does not contain the string '.req', this string will be appended to it. See makeAutosaveFiles() for more information. Source code in whatrecord/autosave.py @_handler def handle_makeAutosaveFileFromDbInfo ( self , filename : str = \"\" , info_name : str = \"\" , * _ ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for 'info' nodes named info_name; construct a list of PV names from the associated info_values found, and write the PV names to the file fileBaseName. If fileBaseName does not contain the string '.req', this string will be appended to it. See makeAutosaveFiles() for more information. \"\"\" whatrecord . autosave . AutosaveState . handle_makeAutosaveFiles ( self ) Search through the EPICS database (that is, all EPICS records loaded into an IOC) for info nodes named 'autosaveFields' and 'autosaveFields_pass0'; construct lists of PV names from the associated info values, and write the PV names to the files 'info_settings.req' and 'info_positions.req', respectively. Source code in whatrecord/autosave.py @_handler def handle_makeAutosaveFiles ( self ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for info nodes named 'autosaveFields' and 'autosaveFields_pass0'; construct lists of PV names from the associated info values, and write the PV names to the files 'info_settings.req' and 'info_positions.req', respectively. \"\"\" whatrecord . autosave . AutosaveState . handle_manual_save ( self , request_file : str = '' ) Cause current PV values for the request file to be saved. Any request file named in a create_xxx_set() command can be saved manually. Source code in whatrecord/autosave.py @_handler def handle_manual_save ( self , request_file : str = \"\" ): \"\"\" Cause current PV values for the request file to be saved. Any request file named in a create_xxx_set() command can be saved manually. \"\"\" whatrecord . autosave . AutosaveState . handle_reload_manual_set ( self , filename : str = '' , macrostring : str = '' ) This function allows you to change the PV's associated with a save set created by create_manual_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_manual_set ( self , filename : str = \"\" , macrostring : str = \"\" ): \"\"\" This function allows you to change the PV's associated with a save set created by create_manual_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_reload_monitor_set ( self , filename : str = '' , period : int = 0 , macro_string : str = '' , * _ ) This function allows you to change the PV's and the period associated with a save set created by create_monitor_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_monitor_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_monitor_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_reload_periodic_set ( self , filename : str = '' , period : int = 0 , macro_string : str = '' , * _ ) This function allows you to change the PV's and the period associated with a save set created by create_periodic_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_periodic_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_reload_triggered_set ( self , filename : str = '' , trigger_channel : str = '' , macro_string : str = '' , * _ ) This function allows you to change the PV's and the trigger channel associated with a save set created by create_triggered_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the trigger channel associated with a save set created by create_triggered_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_remove_data_set ( self , filename : str = '' ) If a save set has been created for request_file, this function will delete it. Source code in whatrecord/autosave.py @_handler def handle_remove_data_set ( self , filename : str = \"\" ): \"\"\"If a save set has been created for request_file, this function will delete it.\"\"\" ... whatrecord . autosave . AutosaveState . handle_save_restoreSet_CAReconnect ( self , ok : int = 0 ) Specify whether autosave should periodically retry connecting to PVs whose initial connection attempt failed. Currently, the connection-retry interval is hard-wired at 60 seconds. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_CAReconnect ( self , ok : int = 0 ): \"\"\" Specify whether autosave should periodically retry connecting to PVs whose initial connection attempt failed. Currently, the connection-retry interval is hard-wired at 60 seconds. \"\"\" self . ca_reconnect = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_CallbackTimeout ( self , timeout : int = 0 ) Specify the time interval in seconds between forced save-file writes. (-1 means forever). This is intended to get save files written even if the normal trigger mechanism is broken. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_CallbackTimeout ( self , timeout : int = 0 ): \"\"\" Specify the time interval in seconds between forced save-file writes. (-1 means forever). This is intended to get save files written even if the normal trigger mechanism is broken. \"\"\" self . callback_timeout = int ( timeout ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_DatedBackupFiles ( self , ok : int = 0 ) Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_DatedBackupFiles ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_Debug ( self , level : int = 0 ) Sets the value (int) save_restoreDebug (initially 0). Increase to get more informational messages printed to the console. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_Debug ( self , level : int = 0 ): \"\"\" Sets the value (int) save_restoreDebug (initially 0). Increase to get more informational messages printed to the console. \"\"\" self . debug = int ( level ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_FilePermissions ( self , permissions : int = 0 ) Specify the file permissions used to create new .sav files. This integer value will be supplied, exactly as given, to the system call, open(), and to the call fchmod(). Typically, file permissions are set with an octal number, such as 0640, and save_restoreSet_FilePermissions() will confirm any number given to it by echoing it to the console as an octal number. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_FilePermissions ( self , permissions : int = 0 ): \"\"\" Specify the file permissions used to create new .sav files. This integer value will be supplied, exactly as given, to the system call, open(), and to the call fchmod(). Typically, file permissions are set with an octal number, such as 0640, and save_restoreSet_FilePermissions() will confirm any number given to it by echoing it to the console as an octal number. \"\"\" self . file_permissions = int ( permissions ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_IncompleteSetsOk ( self , ok : int = 0 ) Sets the value of (int) save_restoreIncompleteSetsOk (initially 1). If set to zero, save files will not be restored at boot time unless they are perfect, and they will not be overwritten at save time unless a valid CA connection and value exists for every PV in the list. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_IncompleteSetsOk ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreIncompleteSetsOk (initially 1). If set to zero, save files will not be restored at boot time unless they are perfect, and they will not be overwritten at save time unless a valid CA connection and value exists for every PV in the list. \"\"\" self . incomplete_sets_ok = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_NFSHost ( self , hostname : str = '' , address : str = '' , mntpoint : str = '' , * _ ) Specifies the name and IP address of the NFS host. If both have been specified, and set_savefile_path() has been called to specify the file path, save_restore will manage its own NFS mount. This allows save_restore to recover from a reboot of the NFS host (that is, a stale file handle) and from some kinds of tampering with the save_restore directory. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_NFSHost ( self , hostname : str = \"\" , address : str = \"\" , mntpoint : str = \"\" , * _ ): \"\"\" Specifies the name and IP address of the NFS host. If both have been specified, and set_savefile_path() has been called to specify the file path, save_restore will manage its own NFS mount. This allows save_restore to recover from a reboot of the NFS host (that is, a stale file handle) and from some kinds of tampering with the save_restore directory. \"\"\" self . nfs_host = f \"nfs:// { hostname } / { mntpoint } ( { address } )\" whatrecord . autosave . AutosaveState . handle_save_restoreSet_NumSeqFiles ( self , numSeqFiles : int = 0 ) Sets the value of (int) save_restoreNumSeqFiles (initially 3). This is the number of sequenced backup files to be maintained. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_NumSeqFiles ( self , numSeqFiles : int = 0 ): \"\"\" Sets the value of (int) save_restoreNumSeqFiles (initially 3). This is the number of sequenced backup files to be maintained. \"\"\" self . num_seq_files = int ( numSeqFiles ) if not ( 0 <= self . num_seq_files <= 10 ): raise ValueError ( \"numSeqFiles must be between 0 and 10 inclusive.\" ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_RetrySeconds ( self , seconds : int = 0 ) Specify the time delay between a failed .sav-file write and the retry of that write. The default delay is 60 seconds. If list-PV's change during the delay, the new values will be written. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_RetrySeconds ( self , seconds : int = 0 ): \"\"\" Specify the time delay between a failed .sav-file write and the retry of that write. The default delay is 60 seconds. If list-PV's change during the delay, the new values will be written. \"\"\" self . retry_seconds = int ( seconds ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_SeqPeriodInSeconds ( self , period : int = 0 ) Sets the value of (int) save_restoreSeqPeriodInSeconds (initially 60). Sequenced backup files will be written with this period. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_SeqPeriodInSeconds ( self , period : int = 0 ): \"\"\" Sets the value of (int) save_restoreSeqPeriodInSeconds (initially 60). Sequenced backup files will be written with this period. \"\"\" self . seq_period = int ( period ) if self . seq_period < 10 : raise ValueError ( \"period must be 10 or greater.\" ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_UseStatusPVs ( self , ok : int = 0 ) Specifies whether save_restore should report its status to a preloaded set of EPICS PV's (contained in the database save_restoreStatus.db). If the argument is '0', then status PV's will not be used. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_UseStatusPVs ( self , ok : int = 0 ): \"\"\" Specifies whether save_restore should report its status to a preloaded set of EPICS PV's (contained in the database save_restoreStatus.db). If the argument is '0', then status PV's will not be used. \"\"\" self . use_status_pvs = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_periodicDatedBackups ( self , periodMinutes : int = 0 ) Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_periodicDatedBackups ( self , periodMinutes : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = True self . date_period_minutes = int ( periodMinutes ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_status_prefix ( self , prefix : str = '' ) Specifies the prefix to be used to construct the names of PV's with which save_restore reports its status. If you want autosave to update status PVs as it operates, you must call this function and load the database save_restoreStatus.db, specifying the same prefix in both commands. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_status_prefix ( self , prefix : str = \"\" ): \"\"\" Specifies the prefix to be used to construct the names of PV's with which save_restore reports its status. If you want autosave to update status PVs as it operates, you must call this function and load the database save_restoreStatus.db, specifying the same prefix in both commands. \"\"\" self . status_prefix = prefix whatrecord . autosave . AutosaveState . handle_save_restoreShow ( self , verbose : int = 0 ) Show the save restore status. Source code in whatrecord/autosave.py @_handler def handle_save_restoreShow ( self , verbose : int = 0 ): \"\"\"Show the save restore status.\"\"\" return self . sets whatrecord . autosave . AutosaveState . handle_set_pass0_restoreFile ( self , file : str = '' , macro_string : str = '' ) This function specifies a save file to be restored during iocInit, before record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. Source code in whatrecord/autosave.py @_handler def handle_set_pass0_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, before record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 0 , ) return { \"autosave\" : f \"Added pass 0 restore file { self . save_path } / { file } \" } whatrecord . autosave . AutosaveState . handle_set_pass1_restoreFile ( self , file : str = '' , macro_string : str = '' ) This function specifies a save file to be restored during iocInit, after record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. Source code in whatrecord/autosave.py @_handler def handle_set_pass1_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, after record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 1 , ) return { \"autosave\" : f \"Added pass 1 restore file { self . save_path } / { file } \" } whatrecord . autosave . AutosaveState . handle_set_saveTask_priority ( self , priority : int = 0 ) Set the priority of the save_restore task. Source code in whatrecord/autosave.py @_handler def handle_set_saveTask_priority ( self , priority : int = 0 ): \"\"\"Set the priority of the save_restore task.\"\"\" self . task_priority = int ( priority ) whatrecord . autosave . AutosaveState . handle_set_savefile_name ( self , request_file : str = '' , save_filename : str = '' ) If a save set has already been created for the request file, this function will change the save file name. Source code in whatrecord/autosave.py @_handler def handle_set_savefile_name ( self , request_file : str = \"\" , save_filename : str = \"\" ): \"\"\" If a save set has already been created for the request file, this function will change the save file name. \"\"\" try : set_ = self . sets [ request_file ] except KeyError : raise ValueError ( \"Request file not configured\" ) set_ . save_filename = save_filename whatrecord . autosave . AutosaveState . handle_set_savefile_path ( self , path : str = '' , subpath : str = '' ) Called before iocInit(), this function specifies the path to be prepended to save-file and restore-file names. pathsub, if present, will be appended to path, if present, with a separating '/', whether or not path ends or pathsub begins with '/'. If the result does not end in '/', one will be appended to it. If save_restore is managing its own NFS mount, this function specifies the mount point, and calling it will result in an NFS mount if all other requirements have already been met. If a valid NFS mount already exists, the file system will be dismounted and then mounted with the new path name. This function can be called at any time. Source code in whatrecord/autosave.py @_handler def handle_set_savefile_path ( self , path : str = \"\" , subpath : str = \"\" ): \"\"\" Called before iocInit(), this function specifies the path to be prepended to save-file and restore-file names. pathsub, if present, will be appended to path, if present, with a separating '/', whether or not path ends or pathsub begins with '/'. If the result does not end in '/', one will be appended to it. If save_restore is managing its own NFS mount, this function specifies the mount point, and calling it will result in an NFS mount if all other requirements have already been met. If a valid NFS mount already exists, the file system will be dismounted and then mounted with the new path name. This function can be called at any time. \"\"\" path = pathlib . Path ( path ) / subpath if self . primary_handler is not None : path = self . primary_handler . _fix_path ( path ) self . save_path = path . resolve () whatrecord.autosave.RestoreError dataclass RestoreError(context: 'FullLoadContext', number: 'int', description: 'str') Source code in whatrecord/autosave.py @dataclass class RestoreError : context : FullLoadContext number : int description : str whatrecord.autosave.RestoreValue dataclass RestoreValue(context: 'FullLoadContext', pvname: 'str', record: 'str', field: 'str', value: 'Union[str, List[str]]') Source code in whatrecord/autosave.py @dataclass class RestoreValue : context : FullLoadContext pvname : str record : str field : str value : Union [ str , List [ str ]] whatrecord.db Classes whatrecord.db.Database dataclass Representation of an EPICS database, database definition, or both. Attributes: Name Type Description standalone_aliases Standalone aliases are those defined outside of the record body; this may only be useful for faithfully reconstructing the Database according to its original source code. Keyed on alias to actual record name. aliases Alias name to record name. paths The path command specifies the current search path for use when loading database and database definition files. The addpath appends directory names to the current path. The path is used to locate the initial database file and included files. An empty dir at the beginning, middle, or end of a non-empty path string means the current directory. addpaths See 'paths' above. breaktables Breakpoint table (look-up table) of raw-to-engineering values. comments Comments encountered while parsing the database. devices Device support declarations (dset). drivers Driver declarations (drvet). functions Exported C function names. includes Inline inclusion. Not supported just yet. links Links. menus Named value enumerations (enums). records Record name to RecordInstance. record_types Record type name to RecordType. registrars Exported registrar function name. variables IOC shell variables. Source code in whatrecord/db.py @dataclass class Database : \"\"\" Representation of an EPICS database, database definition, or both. Attributes ---------- standalone_aliases : Standalone aliases are those defined outside of the record body; this may only be useful for faithfully reconstructing the Database according to its original source code. Keyed on alias to actual record name. aliases : Alias name to record name. paths : The path command specifies the current search path for use when loading database and database definition files. The addpath appends directory names to the current path. The path is used to locate the initial database file and included files. An empty dir at the beginning, middle, or end of a non-empty path string means the current directory. addpaths : See 'paths' above. breaktables : Breakpoint table (look-up table) of raw-to-engineering values. comments : Comments encountered while parsing the database. devices : Device support declarations (dset). drivers : Driver declarations (drvet). functions : Exported C function names. includes : Inline inclusion. Not supported just yet. links : Links. menus : Named value enumerations (enums). records : Record name to RecordInstance. record_types : Record type name to RecordType. registrars : Exported registrar function name. variables : IOC shell variables. \"\"\" standalone_aliases : Dict [ str , str ] = field ( default_factory = dict ) aliases : Dict [ str , str ] = field ( default_factory = dict ) paths : List [ str ] = field ( default_factory = list ) addpaths : List [ str ] = field ( default_factory = list ) breaktables : Dict [ str , List [ str ]] = field ( default_factory = dict ) comments : List [ str ] = field ( default_factory = list ) devices : List [ DatabaseDevice ] = field ( default_factory = list ) drivers : List [ str ] = field ( default_factory = list ) functions : List [ str ] = field ( default_factory = list ) includes : List [ str ] = field ( default_factory = list ) links : Dict [ str , str ] = field ( default_factory = dict ) menus : Dict [ str , DatabaseMenu ] = field ( default_factory = dict ) records : Dict [ str , RecordInstance ] = field ( default_factory = dict ) pva_groups : Dict [ str , RecordInstance ] = field ( default_factory = dict ) record_types : Dict [ str , RecordType ] = field ( default_factory = dict ) registrars : List [ str ] = field ( default_factory = list ) variables : Dict [ str , Optional [ str ]] = field ( default_factory = dict ) @classmethod def from_string ( cls , contents : str , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , include_aliases : bool = True , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a string.\"\"\" if dbd is not None and not isinstance ( dbd , Database ): dbd = Database . from_file ( dbd , version = version ) comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , f \"db.v { version } .lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : comments . append }, transformer = _DatabaseTransformer ( filename , dbd = dbd , lint = lint ), maybe_placeholders = False , # Per-user `gettempdir` caching of the LALR grammar analysis way of # passing ``True`` here: cache = True , ) if macro_context is not None : contents = macro_context . expand_by_line ( contents ) . rstrip () + \" \\n \" db , linter_results = grammar . parse ( contents ) db . comments = comments if include_aliases : for record_name , record in list ( db . records . items ()): for alias in record . aliases : db . records [ alias ] = record return db @classmethod def from_file_obj ( cls , fp , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a file object.\"\"\" return cls . from_string ( fp . read (), filename = filename or getattr ( fp , \"name\" , None ), dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ], dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) def field_names_by_type ( self , field_types : List [ str ] ) -> Dict [ str , FrozenSet [ str ]]: \"\"\" Generate dictionary of record type to frozenset of field names. This can be used in scenarios where database definition files are unavailable and link information is requested. Parameters ---------- field_types : list of str Field types to look for. \"\"\" by_rtype = {} for rtype , info in sorted ( self . record_types . items ()): by_rtype [ rtype ] = frozenset ( field . name for field in info . fields . values () if field . type in field_types ) return by_rtype def add_or_update_record ( self , record : RecordInstance ): \"\"\" Update (or add) records given a dictionary of records. \"\"\" if record . is_pva : existing_record = self . pva_groups . get ( record . name , None ) else : existing_record = self . records . get ( record . name , None ) if not existing_record : self . records [ record . name ] = record else : existing_record . update ( record ) def append ( self , other : Database ): \"\"\" Append the other database, best-effort updating existing entries. This is not likely to do everything correctly (TODO). \"\"\" for instance in other . records . values (): self . add_or_update_record ( instance ) for instance in other . pva_groups . values (): self . add_or_update_record ( instance ) def _update_list ( this , other ): this . extend ([ v for v in other if v not in this ]) _update_list ( self . addpaths , other . addpaths ) _update_list ( self . comments , other . comments ) _update_list ( self . devices , other . devices ) _update_list ( self . drivers , other . drivers ) _update_list ( self . functions , other . functions ) _update_list ( self . includes , other . includes ) _update_list ( self . paths , other . paths ) _update_list ( self . registrars , other . registrars ) self . aliases . update ( other . aliases ) self . breaktables . update ( other . breaktables ) self . links . update ( other . links ) self . menus . update ( other . menus ) self . record_types . update ( other . record_types or {}) self . standalone_aliases . update ( other . standalone_aliases ) self . variables . update ( other . variables ) @classmethod def from_multiple ( cls , * items : _DatabaseSource ) -> Database : \"\"\" Create a Database instance from multiple sources, including: * Other Database instances * LinterResults * LoadedIoc * ShellState \"\"\" from .shell import LoadedIoc , ShellState db = cls () for item in items : if isinstance ( item , Database ): db . append ( item ) elif isinstance ( item , LinterResults ): if item . db is not None : db . append ( item . db ) elif isinstance ( item , ( LoadedIoc , ShellState )): state = item . shell_state if isinstance ( item , LoadedIoc ) else item new_records = list ( state . database . values ()) + list ( state . pva_database . values ()) for record in new_records : db . add_or_update_record ( record ) db . aliases . update ( state . aliases ) else : raise ValueError ( f \"Expected { _DatabaseSource } , got { type ( item ) } \" ) return db Methods whatrecord . db . Database . add_or_update_record ( self , record : RecordInstance ) Update (or add) records given a dictionary of records. Source code in whatrecord/db.py def add_or_update_record ( self , record : RecordInstance ): \"\"\" Update (or add) records given a dictionary of records. \"\"\" if record . is_pva : existing_record = self . pva_groups . get ( record . name , None ) else : existing_record = self . records . get ( record . name , None ) if not existing_record : self . records [ record . name ] = record else : existing_record . update ( record ) whatrecord . db . Database . append ( self , other : Database ) Append the other database, best-effort updating existing entries. This is not likely to do everything correctly (TODO). Source code in whatrecord/db.py def append ( self , other : Database ): \"\"\" Append the other database, best-effort updating existing entries. This is not likely to do everything correctly (TODO). \"\"\" for instance in other . records . values (): self . add_or_update_record ( instance ) for instance in other . pva_groups . values (): self . add_or_update_record ( instance ) def _update_list ( this , other ): this . extend ([ v for v in other if v not in this ]) _update_list ( self . addpaths , other . addpaths ) _update_list ( self . comments , other . comments ) _update_list ( self . devices , other . devices ) _update_list ( self . drivers , other . drivers ) _update_list ( self . functions , other . functions ) _update_list ( self . includes , other . includes ) _update_list ( self . paths , other . paths ) _update_list ( self . registrars , other . registrars ) self . aliases . update ( other . aliases ) self . breaktables . update ( other . breaktables ) self . links . update ( other . links ) self . menus . update ( other . menus ) self . record_types . update ( other . record_types or {}) self . standalone_aliases . update ( other . standalone_aliases ) self . variables . update ( other . variables ) whatrecord . db . Database . field_names_by_type ( self , field_types : List [ str ]) -> Dict [ str , FrozenSet [ str ]] Generate dictionary of record type to frozenset of field names. This can be used in scenarios where database definition files are unavailable and link information is requested. Parameters: Name Type Description Default field_types List[str] Field types to look for. required Source code in whatrecord/db.py def field_names_by_type ( self , field_types : List [ str ] ) -> Dict [ str , FrozenSet [ str ]]: \"\"\" Generate dictionary of record type to frozenset of field names. This can be used in scenarios where database definition files are unavailable and link information is requested. Parameters ---------- field_types : list of str Field types to look for. \"\"\" by_rtype = {} for rtype , info in sorted ( self . record_types . items ()): by_rtype [ rtype ] = frozenset ( field . name for field in info . fields . values () if field . type in field_types ) return by_rtype whatrecord . db . Database . from_file ( fn : Union [ str , pathlib . Path ], dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None ) -> Database classmethod Load a database [definition] from a filename. Source code in whatrecord/db.py @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ], dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) whatrecord . db . Database . from_file_obj ( fp , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None ) -> Database classmethod Load a database [definition] from a file object. Source code in whatrecord/db.py @classmethod def from_file_obj ( cls , fp , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a file object.\"\"\" return cls . from_string ( fp . read (), filename = filename or getattr ( fp , \"name\" , None ), dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) whatrecord . db . Database . from_multiple ( * items : _DatabaseSource ) -> Database classmethod Create a Database instance from multiple sources, including: Other Database instances LinterResults LoadedIoc ShellState Source code in whatrecord/db.py @classmethod def from_multiple ( cls , * items : _DatabaseSource ) -> Database : \"\"\" Create a Database instance from multiple sources, including: * Other Database instances * LinterResults * LoadedIoc * ShellState \"\"\" from .shell import LoadedIoc , ShellState db = cls () for item in items : if isinstance ( item , Database ): db . append ( item ) elif isinstance ( item , LinterResults ): if item . db is not None : db . append ( item . db ) elif isinstance ( item , ( LoadedIoc , ShellState )): state = item . shell_state if isinstance ( item , LoadedIoc ) else item new_records = list ( state . database . values ()) + list ( state . pva_database . values ()) for record in new_records : db . add_or_update_record ( record ) db . aliases . update ( state . aliases ) else : raise ValueError ( f \"Expected { _DatabaseSource } , got { type ( item ) } \" ) return db whatrecord . db . Database . from_string ( contents : str , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , include_aliases : bool = True , lint : Optional [ LinterResults ] = None ) -> Database classmethod Load a database [definition] from a string. Source code in whatrecord/db.py @classmethod def from_string ( cls , contents : str , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , include_aliases : bool = True , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a string.\"\"\" if dbd is not None and not isinstance ( dbd , Database ): dbd = Database . from_file ( dbd , version = version ) comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , f \"db.v { version } .lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : comments . append }, transformer = _DatabaseTransformer ( filename , dbd = dbd , lint = lint ), maybe_placeholders = False , # Per-user `gettempdir` caching of the LALR grammar analysis way of # passing ``True`` here: cache = True , ) if macro_context is not None : contents = macro_context . expand_by_line ( contents ) . rstrip () + \" \\n \" db , linter_results = grammar . parse ( contents ) db . comments = comments if include_aliases : for record_name , record in list ( db . records . items ()): for alias in record . aliases : db . records [ alias ] = record return db whatrecord.db.DatabaseLoadFailure ( Exception ) Database load failure. Source code in whatrecord/db.py class DatabaseLoadFailure ( Exception ): \"\"\"Database load failure.\"\"\" ... whatrecord.db.LinterResults dataclass Container for dbdlint results, with easier-to-access attributes. Reimplementation of pyPDB.dbdlint.Results . Each error or warning has dictionary keys:: {name, message, file, line, raw_message, format_args} Attributes: Name Type Description errors list List of errors found warnings list List of warnings found Source code in whatrecord/db.py @dataclass ( repr = False ) class LinterResults : \"\"\" Container for dbdlint results, with easier-to-access attributes. Reimplementation of ``pyPDB.dbdlint.Results``. Each error or warning has dictionary keys:: {name, message, file, line, raw_message, format_args} Attributes ---------- errors : list List of errors found warnings : list List of warnings found \"\"\" macros : Dict [ str , str ] = field ( default_factory = dict ) errors : List [ LinterError ] = field ( default_factory = list ) warnings : List [ LinterWarning ] = field ( default_factory = list ) db : Optional [ Database ] = field ( default = None , metadata = apischema . metadata . skip ) dbd : Optional [ Database ] = field ( default = None , metadata = apischema . metadata . skip ) @classmethod def from_database_string ( cls , db : str , dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , db_filename : Optional [ Union [ str , pathlib . Path ]] = None , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database source. dbd : Database The pre-loaded database definition. Returns ------- results : LinterResults \"\"\" lint = cls () if dbd and not isinstance ( dbd , Database ): raise ValueError ( \"dbd should be a Database instance\" ) # The following fills `lint`, for better or worse database = Database . from_string ( db , dbd = dbd , macro_context = macro_context , version = version , lint = lint , filename = db_filename ) lint . db = database lint . dbd = dbd lint . macros = dict ( macro_context or {}) return lint @classmethod def from_database_file ( cls , db_filename : Union [ str , pathlib . Path ], dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database filename. dbd : Database The database definition. version : int, optional Use the old V3 style or new V3 style database grammar by specifying 3 or 4, respectively. Defaults to 3. Returns ------- results : LinterResults db : Database \"\"\" with open ( db_filename , \"rt\" ) as fp : db = fp . read () return cls . from_database_string ( db = db , dbd = dbd , db_filename = db_filename , macro_context = macro_context , version = version , ) @property def record_types ( self ) -> Optional [ Dict [ str , RecordType ]]: \"\"\"Defined record types.\"\"\" if self . dbd is not None : return self . dbd . record_types return self . db . record_types if self . db is not None else {} @property def records ( self ) -> Optional [ Dict [ str , RecordInstance ]]: \"\"\"Defined V3 records.\"\"\" return self . db . records if self . db is not None else {} @property def pva_groups ( self ) -> Optional [ Dict [ str , RecordInstance ]]: \"\"\"Defined PVAccess groups.\"\"\" return self . db . pva_groups if self . db is not None else {} def __repr__ ( self ): return ( f \"< { self . __class__ . __name__ } \" f \"records= { len ( self . records ) } \" f \"pva_groups= { len ( self . pva_groups ) } \" f \"errors= { len ( self . errors ) } \" f \"warnings= { len ( self . warnings ) } \" f \">\" ) Attributes whatrecord . db . LinterResults . pva_groups : Optional [ Dict [ str , RecordInstance ]] property readonly Defined PVAccess groups. whatrecord . db . LinterResults . record_types : Optional [ Dict [ str , RecordType ]] property readonly Defined record types. whatrecord . db . LinterResults . records : Optional [ Dict [ str , RecordInstance ]] property readonly Defined V3 records. Methods whatrecord . db . LinterResults . from_database_file ( db_filename : Union [ str , pathlib . Path ], dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , version : int = 3 ) -> LinterResults classmethod Lint a db (database) file using its database definition file (dbd). Parameters: Name Type Description Default db str The database filename. required dbd Optional[Database] The database definition. None version int Use the old V3 style or new V3 style database grammar by specifying 3 or 4, respectively. Defaults to 3. 3 Source code in whatrecord/db.py @classmethod def from_database_file ( cls , db_filename : Union [ str , pathlib . Path ], dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database filename. dbd : Database The database definition. version : int, optional Use the old V3 style or new V3 style database grammar by specifying 3 or 4, respectively. Defaults to 3. Returns ------- results : LinterResults db : Database \"\"\" with open ( db_filename , \"rt\" ) as fp : db = fp . read () return cls . from_database_string ( db = db , dbd = dbd , db_filename = db_filename , macro_context = macro_context , version = version , ) whatrecord . db . LinterResults . from_database_string ( db : str , dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , db_filename : Optional [ Union [ str , pathlib . Path ]] = None , version : int = 3 ) -> LinterResults classmethod Lint a db (database) file using its database definition file (dbd). Parameters: Name Type Description Default db str The database source. required dbd Optional[Database] The pre-loaded database definition. None Source code in whatrecord/db.py @classmethod def from_database_string ( cls , db : str , dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , db_filename : Optional [ Union [ str , pathlib . Path ]] = None , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database source. dbd : Database The pre-loaded database definition. Returns ------- results : LinterResults \"\"\" lint = cls () if dbd and not isinstance ( dbd , Database ): raise ValueError ( \"dbd should be a Database instance\" ) # The following fills `lint`, for better or worse database = Database . from_string ( db , dbd = dbd , macro_context = macro_context , version = version , lint = lint , filename = db_filename ) lint . db = database lint . dbd = dbd lint . macros = dict ( macro_context or {}) return lint whatrecord.db.UnquotedString ( str ) An unquoted string token found when loading a database file. May be a linter warning. Source code in whatrecord/db.py class UnquotedString ( str ): \"\"\" An unquoted string token found when loading a database file. May be a linter warning. \"\"\" ... Functions whatrecord . db . split_record_and_field ( pvname ) -> Tuple [ str , str ] Split REC.FLD into REC and FLD. Source code in whatrecord/db.py def split_record_and_field ( pvname ) -> Tuple [ str , str ]: \"\"\"Split REC.FLD into REC and FLD.\"\"\" record , * field = pvname . split ( \".\" , 1 ) return record , field [ 0 ] if field else \"\" whatrecord.dbtemplate dbLoadTemplate and msi -S substitution grammar helpers. Classes whatrecord.dbtemplate.GlobalDefinitions ( VariableDefinitions ) dataclass Global variable definitions. Source code in whatrecord/dbtemplate.py @dataclass class GlobalDefinitions ( VariableDefinitions ): \"\"\"Global variable definitions.\"\"\" whatrecord.dbtemplate.PatternHeader dataclass Pattern header. Source code in whatrecord/dbtemplate.py @dataclass class PatternHeader : \"\"\"Pattern header.\"\"\" context : FullLoadContext patterns : List [ str ] whatrecord.dbtemplate.PatternValues dataclass Pattern values. Source code in whatrecord/dbtemplate.py @dataclass class PatternValues : \"\"\"Pattern values.\"\"\" context : FullLoadContext values : List [ str ] whatrecord.dbtemplate.Substitution dataclass Single database template file from a full template. Represents approximately one line of a .substitutions file. For example, in this substitution file, file template.txt { pattern {a, b, c} {A, B, C} } The resulting Substitution would be Substitution(macros={\"a\": \"A\", \"b\": \"B\", \"c\": \"C\"}, filename=\"template.txt\") . Global macro values will be aggregated into this dictionary. Inside of the template file - template.txt above: * \"include\" is a supported command for the template file. * \"substitute\" is optionally supported (set allow_substitute ) Source code in whatrecord/dbtemplate.py @dataclass class Substitution : \"\"\" Single database template file from a full template. Represents approximately one line of a .substitutions file. For example, in this substitution file, ``` file template.txt { pattern {a, b, c} {A, B, C} } ``` The resulting Substitution would be ``Substitution(macros={\"a\": \"A\", \"b\": \"B\", \"c\": \"C\"}, filename=\"template.txt\")``. Global macro values will be aggregated into this dictionary. Inside of the template file - ``template.txt`` above: * \"include\" is a supported command for the template file. * \"substitute\" is optionally supported (set ``allow_substitute``) \"\"\" context : FullLoadContext filename : Optional [ str ] = None macros : Dict [ str , str ] = field ( default_factory = dict ) use_environment : bool = False allow_substitute : bool = True _items : Optional [ List [ Any ]] = field ( default_factory = list , metadata = apischema . metadata . skip , ) def expand_file ( self , * , filename : Optional [ str ] = None , search_paths : Optional [ List [ AnyPath ]] = None ) -> str : \"\"\" Expand the given file, looking in ``search_paths`` for template files. Parameters ---------- filename : str, optional Expand this file or fall back to the instance-defined filename. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" filename = filename or self . filename if filename is None : raise ValueError ( \"This substitution does not have a file defined\" ) filename = pathlib . Path ( filename ) search_paths = search_paths or [ filename . resolve () . parent ] with open ( self . filename , \"rt\" ) as fp : return self . expand ( fp . read (), search_paths = search_paths ) @property def macro_context ( self ) -> MacroContext : \"\"\"The macro context to be used when expanding the template.\"\"\" ctx = MacroContext ( use_environment = self . use_environment ) ctx . define ( ** self . macros ) return ctx @staticmethod def handle_include ( filename : str , search_paths : List [ AnyPath ]) -> str : \"\"\"Expand include files from the given search path.\"\"\" for path in search_paths : option = pathlib . Path ( path ) / filename if option . exists (): with open ( option , \"rt\" ) as fp : return fp . read () friendly_paths = \" or \" . join ( f '\" { path } \"' for path in search_paths ) raise FileNotFoundError ( f \" { filename } not found in { friendly_paths } \" ) def expand ( self , source : str , search_paths : Optional [ List [ AnyPath ]] = None ): \"\"\" Expand the provided substitution template, using the macro environment. Parameters ---------- source : str The source substitution template. May contain \"include\" or \"substitute\" lines. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" ctx = self . macro_context search_paths = search_paths or [ pathlib . Path ( \".\" )] results = [] source_stack = collections . deque ( source . splitlines ()) while source_stack : line = source_stack . popleft () logger . debug ( \"line %r \" , line ) line = ctx . expand ( line ) command , * command_args = line . strip () . split ( \" \" , 1 ) if command == \"include\" : # case sensitive args = shlex . split ( command_args [ 0 ]) if len ( args ) != 1 : raise ValueError ( f \"Include command takes one argument; got: { args } \" f \"where line= { line !r} \" ) include_file = args [ 0 ] logger . debug ( \"Including file from %s \" , include_file ) include_source = self . handle_include ( include_file , search_paths ) source_stack . extendleft ( reversed ( include_source . splitlines ())) logger . debug ( \"stack %r \" , source_stack ) elif command == \"substitute\" and self . allow_substitute : # Note that dbLoadTemplate does not support substitute, but msi # does. macro_string = command_args [ 0 ] . strip () # Strip only single beginning and end quotes macro_string = _strip_double_quote ( macro_string ) . strip () logger . debug ( \"Substituting additional macros %s \" , macro_string ) ctx . define_from_string ( macro_string ) else : results . append ( line ) return \" \\n \" . join ( results ) Attributes whatrecord . dbtemplate . Substitution . macro_context : MacroContext property readonly The macro context to be used when expanding the template. Methods whatrecord . dbtemplate . Substitution . expand ( self , source : str , search_paths : Optional [ List [ AnyPath ]] = None ) Expand the provided substitution template, using the macro environment. Parameters: Name Type Description Default source str The source substitution template. May contain \"include\" or \"substitute\" lines. required search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand ( self , source : str , search_paths : Optional [ List [ AnyPath ]] = None ): \"\"\" Expand the provided substitution template, using the macro environment. Parameters ---------- source : str The source substitution template. May contain \"include\" or \"substitute\" lines. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" ctx = self . macro_context search_paths = search_paths or [ pathlib . Path ( \".\" )] results = [] source_stack = collections . deque ( source . splitlines ()) while source_stack : line = source_stack . popleft () logger . debug ( \"line %r \" , line ) line = ctx . expand ( line ) command , * command_args = line . strip () . split ( \" \" , 1 ) if command == \"include\" : # case sensitive args = shlex . split ( command_args [ 0 ]) if len ( args ) != 1 : raise ValueError ( f \"Include command takes one argument; got: { args } \" f \"where line= { line !r} \" ) include_file = args [ 0 ] logger . debug ( \"Including file from %s \" , include_file ) include_source = self . handle_include ( include_file , search_paths ) source_stack . extendleft ( reversed ( include_source . splitlines ())) logger . debug ( \"stack %r \" , source_stack ) elif command == \"substitute\" and self . allow_substitute : # Note that dbLoadTemplate does not support substitute, but msi # does. macro_string = command_args [ 0 ] . strip () # Strip only single beginning and end quotes macro_string = _strip_double_quote ( macro_string ) . strip () logger . debug ( \"Substituting additional macros %s \" , macro_string ) ctx . define_from_string ( macro_string ) else : results . append ( line ) return \" \\n \" . join ( results ) whatrecord . dbtemplate . Substitution . expand_file ( self , * , filename : Optional [ str ] = None , search_paths : Optional [ List [ AnyPath ]] = None ) -> str Expand the given file, looking in search_paths for template files. Parameters: Name Type Description Default filename Optional[str] Expand this file or fall back to the instance-defined filename. None search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand_file ( self , * , filename : Optional [ str ] = None , search_paths : Optional [ List [ AnyPath ]] = None ) -> str : \"\"\" Expand the given file, looking in ``search_paths`` for template files. Parameters ---------- filename : str, optional Expand this file or fall back to the instance-defined filename. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" filename = filename or self . filename if filename is None : raise ValueError ( \"This substitution does not have a file defined\" ) filename = pathlib . Path ( filename ) search_paths = search_paths or [ filename . resolve () . parent ] with open ( self . filename , \"rt\" ) as fp : return self . expand ( fp . read (), search_paths = search_paths ) whatrecord . dbtemplate . Substitution . handle_include ( filename : str , search_paths : List [ AnyPath ]) -> str staticmethod Expand include files from the given search path. Source code in whatrecord/dbtemplate.py @staticmethod def handle_include ( filename : str , search_paths : List [ AnyPath ]) -> str : \"\"\"Expand include files from the given search path.\"\"\" for path in search_paths : option = pathlib . Path ( path ) / filename if option . exists (): with open ( option , \"rt\" ) as fp : return fp . read () friendly_paths = \" or \" . join ( f '\" { path } \"' for path in search_paths ) raise FileNotFoundError ( f \" { filename } not found in { friendly_paths } \" ) whatrecord.dbtemplate.TemplateSubstitution dataclass Database substitutions, containing zero or more template files. Source code in whatrecord/dbtemplate.py @dataclass class TemplateSubstitution : \"\"\"Database substitutions, containing zero or more template files.\"\"\" substitutions : List [ Substitution ] = field ( default_factory = list ) def expand_template ( self , template : str , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" , ) -> str : \"\"\" Expands all substitutions for the given string. Parameters ---------- template : str The template text. delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand ( template , search_paths = search_paths ) for sub in self . substitutions ) def expand_files ( self , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" ) -> str : \"\"\" Expands and combines all contained substitution files. Parameters ---------- delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand_file ( search_paths = search_paths ) for sub in self . substitutions ) @classmethod def from_string ( cls , contents , filename = None , msi_format = False , all_global_scope = False , ) -> TemplateSubstitution : \"\"\"Load a template substitutions file given its string contents.\"\"\" comments = [] grammar_filename = \"msi-sub.lark\" if msi_format else \"dbtemplate.lark\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , grammar_filename , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: This is unsupported in lark: # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = False , propagate_positions = True , ) if msi_format : tr = _TemplateMsiTransformer ( cls , filename , all_global_scope = all_global_scope ) else : tr = _TemplateTransformer ( cls , filename ) subs = tr . transform ( grammar . parse ( contents )) subs . comments = comments return subs @classmethod def from_file_obj ( cls , fp , filename = None ) -> TemplateSubstitution : \"\"\"Load a template file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) @classmethod def from_file ( cls , fn ) -> TemplateSubstitution : \"\"\" Load a template file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- template : TemplateSubstitution The template file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) Methods whatrecord . dbtemplate . TemplateSubstitution . expand_files ( self , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = ' \\n ' ) -> str Expands and combines all contained substitution files. Parameters: Name Type Description Default delimiter str Delimiter to join individual substitutions. '\\n' search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand_files ( self , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" ) -> str : \"\"\" Expands and combines all contained substitution files. Parameters ---------- delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand_file ( search_paths = search_paths ) for sub in self . substitutions ) whatrecord . dbtemplate . TemplateSubstitution . expand_template ( self , template : str , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = ' \\n ' ) -> str Expands all substitutions for the given string. Parameters: Name Type Description Default template str The template text. required delimiter str Delimiter to join individual substitutions. '\\n' search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand_template ( self , template : str , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" , ) -> str : \"\"\" Expands all substitutions for the given string. Parameters ---------- template : str The template text. delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand ( template , search_paths = search_paths ) for sub in self . substitutions ) whatrecord . dbtemplate . TemplateSubstitution . from_file ( fn ) -> TemplateSubstitution classmethod Load a template file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description TemplateSubstitution The template file. Source code in whatrecord/dbtemplate.py @classmethod def from_file ( cls , fn ) -> TemplateSubstitution : \"\"\" Load a template file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- template : TemplateSubstitution The template file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) whatrecord . dbtemplate . TemplateSubstitution . from_file_obj ( fp , filename = None ) -> TemplateSubstitution classmethod Load a template file given a file object. Source code in whatrecord/dbtemplate.py @classmethod def from_file_obj ( cls , fp , filename = None ) -> TemplateSubstitution : \"\"\"Load a template file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) whatrecord . dbtemplate . TemplateSubstitution . from_string ( contents , filename = None , msi_format = False , all_global_scope = False ) -> TemplateSubstitution classmethod Load a template substitutions file given its string contents. Source code in whatrecord/dbtemplate.py @classmethod def from_string ( cls , contents , filename = None , msi_format = False , all_global_scope = False , ) -> TemplateSubstitution : \"\"\"Load a template substitutions file given its string contents.\"\"\" comments = [] grammar_filename = \"msi-sub.lark\" if msi_format else \"dbtemplate.lark\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , grammar_filename , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: This is unsupported in lark: # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = False , propagate_positions = True , ) if msi_format : tr = _TemplateMsiTransformer ( cls , filename , all_global_scope = all_global_scope ) else : tr = _TemplateTransformer ( cls , filename ) subs = tr . transform ( grammar . parse ( contents )) subs . comments = comments return subs whatrecord.dbtemplate.VariableDefinitions dataclass Variable definitions. Source code in whatrecord/dbtemplate.py @dataclass class VariableDefinitions : \"\"\"Variable definitions.\"\"\" context : FullLoadContext definitions : Dict [ str , str ] = field ( default_factory = dict ) whatrecord.gateway Classes whatrecord.gateway.AccessSecurity dataclass A PVList rule access security settings. Source code in whatrecord/gateway.py @dataclass class AccessSecurity : \"\"\"A PVList rule access security settings.\"\"\" group : Optional [ str ] = None level : Optional [ str ] = None whatrecord.gateway.AliasRule ( Rule ) dataclass Rule to alias the pattern to a PV (or PVs). Source code in whatrecord/gateway.py @dataclass class AliasRule ( Rule ): \"\"\"Rule to alias the pattern to a PV (or PVs).\"\"\" pvname : str = \"\" access : Optional [ AccessSecurity ] = None whatrecord.gateway.AllowRule ( Rule ) dataclass Rule to allow access to a PV pattern. Source code in whatrecord/gateway.py @dataclass class AllowRule ( Rule ): \"\"\"Rule to allow access to a PV pattern.\"\"\" access : Optional [ AccessSecurity ] = None whatrecord.gateway.DenyRule ( Rule ) dataclass Rule to deny access to a PV pattern. Source code in whatrecord/gateway.py @dataclass class DenyRule ( Rule ): \"\"\"Rule to deny access to a PV pattern.\"\"\" hosts : List [ str ] = field ( default_factory = list ) whatrecord.gateway.GatewayConfig Source code in whatrecord/gateway.py class GatewayConfig : pvlists : Dict [ pathlib . Path , PVList ] def __init__ ( self , path : Union [ str , pathlib . Path ], glob_str : str = \"*.pvlist\" ): path = pathlib . Path ( path ) . resolve () if path . is_file (): filenames = [ path ] else : filenames = [ p . resolve () for p in path . glob ( glob_str )] self . pvlists = { filename : PVList . from_file ( filename ) for filename in filenames } def _update ( self , filename ): \"\"\"Update a gateway configuration file.\"\"\" self . pvlists [ filename ] = PVList . from_file ( filename ) def update_changed ( self ): \"\"\"Update any changed files.\"\"\" for filename , pvlist in self . pvlists . items (): if get_file_sha256 ( filename ) != pvlist . hash : logger . info ( \"Updating changed gateway file: %s \" , filename ) self . _update ( filename ) def get_matches ( self , name : str , remove_any : bool = True ) -> PVListMatches : \"\"\"Get matches from any PVList given a PV name.\"\"\" matches = [ PVListMatch ( filename = str ( fn ), rule = rule , groups = groups , ) for fn , pvlist in self . pvlists . items () for rule , groups in pvlist . match ( name ) if rule . pattern != \".*\" or not remove_any ] return PVListMatches ( name = name , matches = matches , ) Methods whatrecord . gateway . GatewayConfig . get_matches ( self , name : str , remove_any : bool = True ) -> PVListMatches Get matches from any PVList given a PV name. Source code in whatrecord/gateway.py def get_matches ( self , name : str , remove_any : bool = True ) -> PVListMatches : \"\"\"Get matches from any PVList given a PV name.\"\"\" matches = [ PVListMatch ( filename = str ( fn ), rule = rule , groups = groups , ) for fn , pvlist in self . pvlists . items () for rule , groups in pvlist . match ( name ) if rule . pattern != \".*\" or not remove_any ] return PVListMatches ( name = name , matches = matches , ) whatrecord . gateway . GatewayConfig . update_changed ( self ) Update any changed files. Source code in whatrecord/gateway.py def update_changed ( self ): \"\"\"Update any changed files.\"\"\" for filename , pvlist in self . pvlists . items (): if get_file_sha256 ( filename ) != pvlist . hash : logger . info ( \"Updating changed gateway file: %s \" , filename ) self . _update ( filename ) whatrecord.gateway.PVList dataclass A PVList container. Source code in whatrecord/gateway.py @dataclass class PVList : \"\"\"A PVList container.\"\"\" filename : Optional [ str ] = None evaluation_order : Optional [ str ] = None rules : List [ Rule ] = field ( default_factory = list ) hash : Optional [ str ] = None header : str = \"\" comments : List [ lark . Token ] = field ( default_factory = list , metadata = apischema . metadata . skip , ) def find ( self , cls : typing . Type ) -> Generator [ Rule , None , None ]: \"\"\"Yield matching rule types.\"\"\" for rule in self . rules : if isinstance ( rule , cls ): yield rule def match ( self , name : str ) -> Generator [ Tuple [ Rule , List [ str ]], None , None ]: \"\"\"Yield matching rules.\"\"\" for rule in self . rules : m = rule . match ( name ) if m : yield rule , list ( m . groups ()) @classmethod def from_string ( cls , contents : str , filename : Optional [ str ] = None ): contents_hash = get_bytes_sha256 ( contents . encode ( \"utf-8\" )) comments = [] def add_comment ( comment : lark . Token ): comments . append ( StringWithContext ( str ( comment ) . lstrip ( \"# \" ), context = context_from_lark_token ( filename , comment ), ) ) grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"gateway.lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , maybe_placeholders = False , lexer_callbacks = { \"COMMENT\" : add_comment }, transformer = _PVListTransformer ( filename , contents_hash , comments ), ) # Sorry, the grammar isn't perfect: require a newline for rules pvlist : PVList = grammar . parse ( f \" { contents . strip () } \\n \" ) pvlist . comments = comments return pvlist @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ): \"\"\"Load a PVList from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]): \"\"\"Load a PVList from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn )) Methods whatrecord . gateway . PVList . find ( self , cls : Type ) -> Generator [ whatrecord . gateway . Rule , NoneType , NoneType ] Yield matching rule types. Source code in whatrecord/gateway.py def find ( self , cls : typing . Type ) -> Generator [ Rule , None , None ]: \"\"\"Yield matching rule types.\"\"\" for rule in self . rules : if isinstance ( rule , cls ): yield rule whatrecord . gateway . PVList . from_file ( fn : Union [ str , pathlib . Path ]) classmethod Load a PVList from a filename. Source code in whatrecord/gateway.py @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]): \"\"\"Load a PVList from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn )) whatrecord . gateway . PVList . from_file_obj ( fp , filename : Optional [ str ] = None ) classmethod Load a PVList from a file object. Source code in whatrecord/gateway.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ): \"\"\"Load a PVList from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) whatrecord . gateway . PVList . match ( self , name : str ) -> Generator [ Tuple [ whatrecord . gateway . Rule , List [ str ]], NoneType , NoneType ] Yield matching rules. Source code in whatrecord/gateway.py def match ( self , name : str ) -> Generator [ Tuple [ Rule , List [ str ]], None , None ]: \"\"\"Yield matching rules.\"\"\" for rule in self . rules : m = rule . match ( name ) if m : yield rule , list ( m . groups ()) whatrecord.gateway.PVListMatch dataclass PVListMatch(filename: str, rule: whatrecord.gateway.Rule, groups: List[str]) Source code in whatrecord/gateway.py @dataclass class PVListMatch : filename : str rule : Rule groups : List [ str ] whatrecord.gateway.PVListMatches dataclass PVListMatches(name: str, matches: List[whatrecord.gateway.PVListMatch]) Source code in whatrecord/gateway.py @dataclass class PVListMatches : name : str matches : List [ PVListMatch ] whatrecord.gateway.Rule dataclass A PVList rule (base class). Source code in whatrecord/gateway.py @dataclass class Rule : \"\"\"A PVList rule (base class).\"\"\" context : FullLoadContext pattern : str command : str regex : typing . Pattern = field ( default = None , metadata = apischema . metadata . skip ) header : str = \"\" metadata : Dict [ str , str ] = field ( default_factory = dict ) def __post_init__ ( self ): if self . regex is None : try : self . regex = re . compile ( self . pattern ) except Exception as ex : self . metadata [ \"error\" ] = ( f \"Invalid regex. { ex . __class__ . __name__ } : { ex } \" ) def match ( self , name ): \"\"\"Match a pv name against this rule.\"\"\" if self . regex is not None : return self . regex . fullmatch ( name ) Methods whatrecord . gateway . Rule . match ( self , name ) Match a pv name against this rule. Source code in whatrecord/gateway.py def match ( self , name ): \"\"\"Match a pv name against this rule.\"\"\" if self . regex is not None : return self . regex . fullmatch ( name ) Functions whatrecord . gateway . create_arg_parser () Create the argument parser. Source code in whatrecord/gateway.py def create_arg_parser (): \"\"\"Create the argument parser.\"\"\" parser = argparse . ArgumentParser ( description = \"pvlist name matching and linting tool\" , ) parser . add_argument ( \"--lint\" , action = \"store_true\" , help = \"Lint regular expressions\" ) parser . add_argument ( \"--pvlists\" , type = str , nargs = \"*\" , help = \"Specific pvlists to check (empty for all)\" , ) parser . add_argument ( \"--hide-context\" , action = \"store_true\" , help = \"Hide comment context\" ) parser . add_argument ( \"--remove-any\" , action = \"store_true\" , help = \"Remove '.*' from results\" ) parser . add_argument ( \"names\" , nargs = \"*\" , type = str , help = \"PV names to match\" ) return parser whatrecord.snl Classes whatrecord.snl.AbstractDeclarator dataclass AbstractDeclarator(context: 'FullLoadContext', params: 'Optional[Sequence[ParameterDeclarator]]' = None, subscript: 'Optional[str]' = None, inner_decl: 'Optional[AbstractDeclarator]' = None) Source code in whatrecord/snl.py @dataclass class AbstractDeclarator : context : FullLoadContext params : Optional [ Sequence [ ParameterDeclarator ]] = None subscript : Optional [ str ] = None inner_decl : Optional [ AbstractDeclarator ] = None def __str__ ( self ) -> str : prefix = f \" { str ( self . inner_decl ) . strip () } \" if self . inner_decl is not None else \"\" if self . subscript is not None : return f \" { prefix }{ self . subscript } \" if self . params is not None : params = \", \" . join ( str ( param ) for param in self . params ) return f \" { prefix } ( { params } )\" return prefix . strip () whatrecord.snl.AbstractDeclaratorModifier dataclass AbstractDeclaratorModifier(context: 'FullLoadContext', modifier: 'str', decl: 'Optional[AbstractDeclarator]' = None) Source code in whatrecord/snl.py @dataclass class AbstractDeclaratorModifier : context : FullLoadContext modifier : str decl : Optional [ AbstractDeclarator ] = None def __str__ ( self ) -> str : if self . modifier == \"(\" : # ) return f \"( { self . decl } )\" if self . modifier == \"*\" : return f \"* { self . decl or '' } \" return f \" { self . modifier } { self . decl or '' } \" whatrecord.snl.Assignment ( Definition ) dataclass Assignment(context: 'FullLoadContext', variable: 'str', value: 'Optional[Union[str, Sequence[str]]]' = None, subscript: 'Optional[str]' = None) Source code in whatrecord/snl.py @dataclass class Assignment ( Definition ): variable : str value : Optional [ Union [ str , Sequence [ str ]]] = None subscript : Optional [ str ] = None def __str__ ( self ) -> str : if isinstance ( self . value , tuple ): value = \"{ \" + \", \" . join ( str ( s ) for s in self . value ) + \"}\" else : value = str ( self . value ) return f \" { self . variable }{ self . subscript or '' } = { value } ;\" whatrecord.snl.BinaryOperatorExpression ( Expression ) dataclass BinaryOperatorExpression(context: 'FullLoadContext', left: 'Expression', operator: 'str', right: 'Expression') Source code in whatrecord/snl.py @dataclass class BinaryOperatorExpression ( Expression ): left : Expression operator : str right : Expression def __str__ ( self ) -> str : return f \" { self . left } { self . operator } { self . right } \" whatrecord.snl.Block dataclass Block(context: 'FullLoadContext', definitions: 'Sequence[Definition]' = , statements: 'Sequence[Statement]' = ) Source code in whatrecord/snl.py @dataclass class Block : context : FullLoadContext definitions : Sequence [ Definition ] = field ( default_factory = list ) statements : Sequence [ Statement ] = field ( default_factory = list ) def __str__ ( self ) -> str : definitions = textwrap . indent ( \" \\n \" . join ( str ( defn ) for defn in self . definitions ), prefix = \" \" , ) statements = textwrap . indent ( \" \\n \" . join ( str ( statement ) for statement in self . statements ), prefix = \" \" , ) return \" \\n \" . join ( ( \"{\" , definitions , statements , \"}\" , ) ) whatrecord.snl.BracketedExpression ( Expression ) dataclass BracketedExpression(context: 'FullLoadContext', outer: 'Expression', inner: 'Expression') Source code in whatrecord/snl.py @dataclass class BracketedExpression ( Expression ): outer : Expression inner : Expression def __str__ ( self ) -> str : return f \" { self . outer } [ { self . inner } ]\" whatrecord.snl.BreakStatement ( Statement ) dataclass BreakStatement(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class BreakStatement ( Statement ): def __str__ ( self ) -> str : return \"break;\" whatrecord.snl.CCode ( Definition ) dataclass CCode(context: 'FullLoadContext', code: 'str') Source code in whatrecord/snl.py @dataclass class CCode ( Definition ): code : str def __str__ ( self ) -> str : return self . code whatrecord.snl.CommaSeparatedExpressions ( Expression ) dataclass CommaSeparatedExpressions(context: 'FullLoadContext', expressions: 'List[Expression]') Source code in whatrecord/snl.py @dataclass class CommaSeparatedExpressions ( Expression ): expressions : List [ Expression ] def __str__ ( self ) -> str : return \", \" . join ( str ( item ) for item in self . expressions ) whatrecord.snl.ContinueStatement ( Statement ) dataclass ContinueStatement(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class ContinueStatement ( Statement ): def __str__ ( self ) -> str : return \"continue;\" whatrecord.snl.Declaration ( Definition ) dataclass Declaration(context: 'FullLoadContext', type: 'Optional[Type]' = None, declarators: 'Optional[Sequence[Declarator]]' = ) Source code in whatrecord/snl.py @dataclass class Declaration ( Definition ): type : Optional [ Type ] = None declarators : Optional [ Sequence [ Declarator ]] = field ( default_factory = list ) def __str__ ( self ) -> str : declarators = \", \" . join ( str ( decl ) for decl in self . declarators or []) return f \" { self . type } { declarators } ;\" whatrecord.snl.Declarator dataclass Declarator(context: 'FullLoadContext', object: 'Union[Declarator, Variable]', params: 'Optional[List[ParameterDeclarator]]' = None, value: 'Optional[Expression]' = None, modifier: 'Optional[str]' = None, subscript: 'Optional[int]' = None) Source code in whatrecord/snl.py @dataclass class Declarator : context : FullLoadContext object : Union [ Declarator , Variable ] params : Optional [ List [ ParameterDeclarator ]] = None value : Optional [ Expression ] = None modifier : Optional [ str ] = None subscript : Optional [ int ] = None def __str__ ( self ) -> str : if self . modifier == \"()\" : decl = f \"( { self . object } )\" elif self . modifier : decl = f \" { self . modifier }{ self . object } \" elif self . subscript : decl = f \" { self . object }{ self . subscript } \" elif self . params : params = \", \" . join ( str ( param ) for param in self . params ) decl = f \" { self . object } ( { params } )\" else : decl = str ( self . object ) if self . value : return f \" { decl } = { self . value } \" return f \" { decl } \" whatrecord.snl.Definition dataclass Definition(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class Definition : context : FullLoadContext whatrecord.snl.ExitExpression ( Expression ) dataclass ExitExpression(context: 'FullLoadContext', args: 'OptionalExpression') Source code in whatrecord/snl.py @dataclass class ExitExpression ( Expression ): args : OptionalExpression def __str__ ( self ) -> str : return f \"exit( { self . args or '' } )\" whatrecord.snl.ExitTransition ( Transition ) dataclass ExitTransition(context: 'FullLoadContext', block: 'Block', target_state: 'Optional[str]' = None, condition: 'OptionalExpression' = None) Source code in whatrecord/snl.py @dataclass class ExitTransition ( Transition ): ... whatrecord.snl.Expression dataclass Expression(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class Expression : context : FullLoadContext whatrecord.snl.ExpressionStatement ( Statement ) dataclass ExpressionStatement(context: 'FullLoadContext', expression: 'CommaSeparatedExpressions') Source code in whatrecord/snl.py @dataclass class ExpressionStatement ( Statement ): expression : CommaSeparatedExpressions def __str__ ( self ) -> str : return f \" { self . expression } ;\" whatrecord.snl.ExpressionWithArguments ( Expression ) dataclass ExpressionWithArguments(context: 'FullLoadContext', expression: 'Expression', arguments: 'OptionalExpression' = None) Source code in whatrecord/snl.py @dataclass class ExpressionWithArguments ( Expression ): expression : Expression arguments : OptionalExpression = None def __str__ ( self ) -> str : return f \" { self . expression } ( { self . arguments or '' } )\" whatrecord.snl.ForStatement ( Statement ) dataclass ForStatement(context: 'FullLoadContext', init: 'OptionalExpression', condition: 'OptionalExpression', increment: 'OptionalExpression', statement: 'Statement') Source code in whatrecord/snl.py @dataclass class ForStatement ( Statement ): init : OptionalExpression condition : OptionalExpression increment : OptionalExpression statement : Statement def __str__ ( self ) -> str : return ( f \"for ( { self . init or '' } ; { self . condition or '' } ; { self . increment or '' } ) \" + str ( self . statement ) . lstrip () ) whatrecord.snl.ForeignDeclaration ( Declaration ) dataclass ForeignDeclaration(context: 'FullLoadContext', type: 'Optional[Type]' = None, declarators: 'Optional[Sequence[Declarator]]' = , names: 'Sequence[str]' = ) Source code in whatrecord/snl.py @dataclass class ForeignDeclaration ( Declaration ): names : Sequence [ str ] = field ( default_factory = list ) def __str__ ( self ) -> str : names = \", \" . join ( self . names ) return f \"foreign { names } ;\" whatrecord.snl.FuncDef ( Definition ) dataclass FuncDef(context: 'FullLoadContext', type: 'Type', declarator: 'Declarator', block: 'Block') Source code in whatrecord/snl.py @dataclass class FuncDef ( Definition ): type : Type declarator : Declarator block : Block def __str__ ( self ) -> str : return f \" { self . type } { self . declarator } ;\" whatrecord.snl.IfStatement ( Statement ) dataclass IfStatement(context: 'FullLoadContext', condition: 'CommaSeparatedExpressions', body: 'Statement', else_body: 'Optional[Statement]' = None) Source code in whatrecord/snl.py @dataclass class IfStatement ( Statement ): condition : CommaSeparatedExpressions body : Statement else_body : Optional [ Statement ] = None def __str__ ( self ) -> str : else_clause = \" \\n \" . join ( ( \" \\n else {\" , textwrap . indent ( str ( self . else_body ), \" \" * 4 ), \"}\" , ) if self . else_body else \"\" ) return \" \\n \" . join ( ( f \"if ( { self . condition } ) \" + \" {\" , textwrap . indent ( str ( self . body ), \" \" * 4 ), else_clause , \"}\" , ) ) whatrecord.snl.InitExpression ( Expression ) dataclass Of the form: ( type ) { init_exprs } { init_exprs } expr Source code in whatrecord/snl.py @dataclass class InitExpression ( Expression ): \"\"\" Of the form: ( type ) { init_exprs } { init_exprs } expr \"\"\" # TODO: may be improved? context : FullLoadContext expressions : Sequence [ Union [ InitExpression , Expression ]] = field ( default_factory = list ) type : Optional [ Type ] = None def __str__ ( self ) -> str : exprs = \", \" . join ( str ( expr or '' ) for expr in self . expressions ) type_prefix = f \"( { self . type } ) \" if self . type else \"\" return f \" { type_prefix } {{ { exprs } }} \" whatrecord.snl.Literal ( Expression ) dataclass Literal(context: 'FullLoadContext', type: 'str', value: 'str') Source code in whatrecord/snl.py @dataclass class Literal ( Expression ): type : str value : str def __str__ ( self ) -> str : return self . value whatrecord.snl.MemberExpression ( Expression ) dataclass MemberExpression(context: 'FullLoadContext', parent: 'Expression', member: 'str', dereference: 'bool') Source code in whatrecord/snl.py @dataclass class MemberExpression ( Expression ): parent : Expression member : str dereference : bool # True = ->, False = . def __str__ ( self ) -> str : if self . dereference : return f \" { self . parent } -> { self . member } \" return f \" { self . parent } . { self . member } \" whatrecord.snl.Monitor ( Definition ) dataclass Monitor(context: 'FullLoadContext', variable: 'str', subscript: 'Optional[int]') Source code in whatrecord/snl.py @dataclass class Monitor ( Definition ): variable : str subscript : Optional [ int ] def __str__ ( self ) -> str : return f \"monitor { self . variable }{ self . subscript or '' } ;\" whatrecord.snl.Option ( Definition ) dataclass Option(context: 'FullLoadContext', name: 'str', enable: 'bool') Source code in whatrecord/snl.py @dataclass class Option ( Definition ): name : str enable : bool def __str__ ( self ) -> str : plus = \"+\" if self . enable else \"-\" return f \"option { plus }{ self . name } ;\" whatrecord.snl.ParameterDeclarator dataclass ParameterDeclarator(context: 'FullLoadContext', type: 'Type', declarator: 'Optional[Declarator]' = None) Source code in whatrecord/snl.py @dataclass class ParameterDeclarator : context : FullLoadContext type : Type declarator : Optional [ Declarator ] = None def __str__ ( self ) -> str : if self . declarator : return f \" { self . type } { self . declarator } \" return str ( self . type ) whatrecord.snl.ParenthesisExpression ( Expression ) dataclass ParenthesisExpression(context: 'FullLoadContext', expression: 'Expression') Source code in whatrecord/snl.py @dataclass class ParenthesisExpression ( Expression ): expression : Expression def __str__ ( self ) -> str : return f \"( { self . expression } )\" whatrecord.snl.ReturnStatement ( Statement ) dataclass ReturnStatement(context: 'FullLoadContext', value: 'Optional[Expression]' = None) Source code in whatrecord/snl.py @dataclass class ReturnStatement ( Statement ): value : Optional [ Expression ] = None def __str__ ( self ) -> str : if self . value is not None : return f \"return { self . value } ;\" return \"return;\" whatrecord.snl.SequencerProgram dataclass Representation of a state notation language (snl seq) program. Source code in whatrecord/snl.py @dataclass class SequencerProgram : \"\"\"Representation of a state notation language (snl seq) program.\"\"\" context : FullLoadContext name : str params : Optional [ str ] initial_definitions : Sequence [ Definition ] = field ( default_factory = list ) entry : Optional [ Block ] = None state_sets : Sequence [ StateSet ] = field ( default_factory = list ) exit : Optional [ Block ] = None final_definitions : Sequence [ Definition ] = field ( default_factory = list ) def __str__ ( self ) -> str : initial_definitions = \" \\n \" . join ( str ( defn ) for defn in self . initial_definitions ) final_definitions = \" \\n \" . join ( str ( defn ) for defn in self . final_definitions ) state_sets = \" \\n\\n \" . join ( str ( state_set ) for state_set in self . state_sets ) param = f \"( { self . params } )\" if self . params else \"\" return \" \\n\\n \" . join ( line for line in ( f \"program { self . name }{ param } \" , initial_definitions , str ( self . entry or \"\" ), state_sets , str ( self . exit or \"\" ), final_definitions , ) if line ) @staticmethod def preprocess ( code : str , search_path : Optional [ AnyPath ] = None ) -> str : \"\"\"Preprocess the given sequencer code, expanding #include.\"\"\" # Line numbers will be off with this, sadly # The sequencer itself gets around this by using LINE_MARKER tokens # to indicate what file and line the code came from. This could # be something we support in the future, but it might not be easy # with lark... search_path = pathlib . Path ( \".\" if search_path is None else search_path ) result = [] stack = collections . deque ([( search_path , line ) for line in code . splitlines ()]) while stack : search_path , line = stack . popleft () if line . startswith ( \"#include\" ): _ , include_file , * _ = shlex . split ( line ) include_file = ( search_path / include_file ) . resolve () with open ( include_file , \"rt\" ) as fp : stack . extendleft ( [ ( include_file . parent , line ) for line in reversed ( fp . read () . splitlines ()) ] ) elif line . startswith ( \"#if\" ): ... # sorry; this may break things elif line . startswith ( \"#else\" ): ... # sorry; this may break things elif line . startswith ( \"#elif\" ): ... # sorry; this may break things elif line . startswith ( \"#endif\" ): ... # sorry; this may break things elif line . startswith ( \"#define\" ): while stack and line . endswith ( \" \\\\ \" ): search_path , line = stack . popleft () ... # sorry; I think we can do better else : result . append ( line ) return \" \\n \" . join ( result ) @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , ) -> SequencerProgram : \"\"\"Load a state notation language file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"snl.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: alternative comment finding method # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = True , propagate_positions = True , debug = debug , ) search_path = None if filename : search_path = pathlib . Path ( filename ) . resolve () . parent preprocessed = cls . preprocess ( contents , search_path = search_path ) proto = _ProgramTransformer ( cls , filename ) . transform ( grammar . parse ( preprocessed ) ) proto . comments = comments return proto @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None ) -> SequencerProgram : \"\"\"Load a state notation language program given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) @classmethod def from_file ( cls , fn : AnyPath ) -> SequencerProgram : \"\"\" Load a state notation language file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- program : SequencerProgram The parsed program. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) def as_graph ( self , ** kwargs ) -> SequencerProgramGraph : \"\"\" Create a graphviz digraph of the state notation diagram. Returns ------- graph : SequencerProgramGraph \"\"\" return SequencerProgramGraph ( self , ** kwargs ) Methods whatrecord . snl . SequencerProgram . as_graph ( self , ** kwargs ) -> SequencerProgramGraph Create a graphviz digraph of the state notation diagram. Source code in whatrecord/snl.py def as_graph ( self , ** kwargs ) -> SequencerProgramGraph : \"\"\" Create a graphviz digraph of the state notation diagram. Returns ------- graph : SequencerProgramGraph \"\"\" return SequencerProgramGraph ( self , ** kwargs ) whatrecord . snl . SequencerProgram . from_file ( fn : AnyPath ) -> SequencerProgram classmethod Load a state notation language file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description SequencerProgram The parsed program. Source code in whatrecord/snl.py @classmethod def from_file ( cls , fn : AnyPath ) -> SequencerProgram : \"\"\" Load a state notation language file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- program : SequencerProgram The parsed program. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) whatrecord . snl . SequencerProgram . from_file_obj ( fp , filename : Optional [ AnyPath ] = None ) -> SequencerProgram classmethod Load a state notation language program given a file object. Source code in whatrecord/snl.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None ) -> SequencerProgram : \"\"\"Load a state notation language program given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) whatrecord . snl . SequencerProgram . from_string ( contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False ) -> SequencerProgram classmethod Load a state notation language file given its string contents. Source code in whatrecord/snl.py @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , ) -> SequencerProgram : \"\"\"Load a state notation language file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"snl.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: alternative comment finding method # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = True , propagate_positions = True , debug = debug , ) search_path = None if filename : search_path = pathlib . Path ( filename ) . resolve () . parent preprocessed = cls . preprocess ( contents , search_path = search_path ) proto = _ProgramTransformer ( cls , filename ) . transform ( grammar . parse ( preprocessed ) ) proto . comments = comments return proto whatrecord . snl . SequencerProgram . preprocess ( code : str , search_path : Optional [ AnyPath ] = None ) -> str staticmethod Preprocess the given sequencer code, expanding #include. Source code in whatrecord/snl.py @staticmethod def preprocess ( code : str , search_path : Optional [ AnyPath ] = None ) -> str : \"\"\"Preprocess the given sequencer code, expanding #include.\"\"\" # Line numbers will be off with this, sadly # The sequencer itself gets around this by using LINE_MARKER tokens # to indicate what file and line the code came from. This could # be something we support in the future, but it might not be easy # with lark... search_path = pathlib . Path ( \".\" if search_path is None else search_path ) result = [] stack = collections . deque ([( search_path , line ) for line in code . splitlines ()]) while stack : search_path , line = stack . popleft () if line . startswith ( \"#include\" ): _ , include_file , * _ = shlex . split ( line ) include_file = ( search_path / include_file ) . resolve () with open ( include_file , \"rt\" ) as fp : stack . extendleft ( [ ( include_file . parent , line ) for line in reversed ( fp . read () . splitlines ()) ] ) elif line . startswith ( \"#if\" ): ... # sorry; this may break things elif line . startswith ( \"#else\" ): ... # sorry; this may break things elif line . startswith ( \"#elif\" ): ... # sorry; this may break things elif line . startswith ( \"#endif\" ): ... # sorry; this may break things elif line . startswith ( \"#define\" ): while stack and line . endswith ( \" \\\\ \" ): search_path , line = stack . popleft () ... # sorry; I think we can do better else : result . append ( line ) return \" \\n \" . join ( result ) whatrecord.snl.SequencerProgramGraph ( _GraphHelper ) A graph for a SequencerProgram. Parameters: Name Type Description Default program Optional[SequencerProgram] A program to add. None highlight_states Optional[List[str]] List of state names to highlight. None include_code bool Include code, where relevant, in nodes. False Source code in whatrecord/snl.py class SequencerProgramGraph ( _GraphHelper ): \"\"\" A graph for a SequencerProgram. Parameters ---------- program : SequencerProgram, optional A program to add. highlight_states : list of str, optional List of state names to highlight. include_code : bool, optional Include code, where relevant, in nodes. \"\"\" _entry_label : str = \"_Entry_\" _exit_label : str = \"_Exit_\" def __init__ ( self , program : Optional [ SequencerProgram ] = None , highlight_states : Optional [ List [ str ]] = None , include_code : bool = False , ): super () . __init__ () self . include_code = include_code self . highlight_states = highlight_states or [] if program is not None : self . add_program ( program ) def add_program ( self , program : SequencerProgram ): \"\"\"Add a program to the graph.\"\"\" for state_set in program . state_sets : for state in state_set . states : self . _add_state ( program , state_set , state ) # Only add entry/exit labels if there's an edge if self . _entry_label in self . nodes : self . get_node ( self . _entry_label , self . get_code ( program . entry , \"(Startup)\" ) ) if self . _exit_label in self . nodes : self . get_node ( self . _exit_label , self . get_code ( program . exit , \"(Exit)\" ) ) def _add_state ( self , program : SequencerProgram , state_set : StateSet , state : State ): \"\"\"Add a state set's state to the graph.\"\"\" qualified_name = f \" { state_set . name } . { state . name } \" self . get_node ( qualified_name , text = \" \\n \" . join ( self . _get_state_node_text ( state_set , state )), ) if state_set . states [ 0 ] is state : self . add_edge ( self . _entry_label , qualified_name , ) for transition in state . transitions : self . _add_transition ( program , state_set , state , transition ) for transition in state . code_transitions : self . add_edge ( qualified_name , f \" { state_set . name } . { transition . name } \" , label = f \"(Line { transition . context [ - 1 ] . line } )\" , ) def _ready_for_digraph ( self , graph : gv . Digraph ): \"\"\"Hook when the user calls ``to_digraph``.\"\"\" for node in self . nodes . values (): node . highlighted = node . label in self . highlight_states def _add_transition ( self , program : SequencerProgram , state_set : StateSet , state : State , transition : Transition , ): \"\"\"Add a state set's state transition to the graph.\"\"\" state_qualified_name = f \" { state_set . name } . { state . name } \" label = str ( transition . condition or \"\" ) transition_text = self . get_code ( transition . block ) target_state = ( f \" { state_set . name } . { transition . target_state } \" if transition . target_state else self . _exit_label ) if not self . include_code or not transition_text : self . add_edge ( state_qualified_name , target_state , label = label ) return transition_idx = state . transitions . index ( transition ) transition_node = f \" { state_qualified_name } . { transition_idx } \" self . get_node ( transition_node , text = transition_text ) self . add_edge ( state_qualified_name , transition_node , label = label ) self . add_edge ( transition_node , target_state ) def get_code ( self , obj , default : str = \"\" ): \"\"\"Get code for a node/edge.\"\"\" if self . include_code and obj is not None : return self . clean_code ( str ( obj )) or default return default def _get_state_node_text ( self , state_set : StateSet , state : State ): yield f \"<b> { state_set . name } . { state . name } </b>\" if self . include_code : if state . entry is not None : yield \"<u>Entry</u>\" yield self . clean_code ( state . entry ) if state . exit is not None : yield \"<u>Exit</u>\" yield self . clean_code ( state . exit ) Methods whatrecord . snl . SequencerProgramGraph . add_program ( self , program : SequencerProgram ) Add a program to the graph. Source code in whatrecord/snl.py def add_program ( self , program : SequencerProgram ): \"\"\"Add a program to the graph.\"\"\" for state_set in program . state_sets : for state in state_set . states : self . _add_state ( program , state_set , state ) # Only add entry/exit labels if there's an edge if self . _entry_label in self . nodes : self . get_node ( self . _entry_label , self . get_code ( program . entry , \"(Startup)\" ) ) if self . _exit_label in self . nodes : self . get_node ( self . _exit_label , self . get_code ( program . exit , \"(Exit)\" ) ) whatrecord . snl . SequencerProgramGraph . get_code ( self , obj , default : str = '' ) Get code for a node/edge. Source code in whatrecord/snl.py def get_code ( self , obj , default : str = \"\" ): \"\"\"Get code for a node/edge.\"\"\" if self . include_code and obj is not None : return self . clean_code ( str ( obj )) or default return default whatrecord.snl.SizeofExpression ( Expression ) dataclass SizeofExpression(context: 'FullLoadContext', type: 'Type') Source code in whatrecord/snl.py @dataclass class SizeofExpression ( Expression ): type : Type def __str__ ( self ) -> str : return f \"sizeof( { self . type } )\" whatrecord.snl.State dataclass State(context: 'FullLoadContext', name: 'str', definitions: 'Sequence[Definition]' = , transitions: 'Sequence[Transition]' = , entry: 'Optional[Block]' = None, exit: 'Optional[Block]' = None, code_transitions: 'List[StateStatement]' = ) Source code in whatrecord/snl.py @dataclass class State : context : FullLoadContext name : str definitions : Sequence [ Definition ] = field ( default_factory = list ) transitions : Sequence [ Transition ] = field ( default_factory = list ) entry : Optional [ Block ] = None exit : Optional [ Block ] = None code_transitions : List [ StateStatement ] = field ( default_factory = list ) def __str__ ( self ) -> str : definitions = \" \\n \" . join ( str ( defn ) for defn in self . definitions ) transitions = \" \\n \" . join ( str ( transition ) for transition in self . transitions ) return \" \\n \" . join ( line for line in ( f \"state { self . name } \" + \" {\" , str ( self . entry or \"\" ), textwrap . indent ( definitions , \" \" * 4 ), textwrap . indent ( transitions , \" \" * 4 ), str ( self . exit or \"\" ), \"}\" , ) if line ) whatrecord.snl.StateSet dataclass StateSet(context: 'FullLoadContext', name: 'str', definitions: 'Sequence[Definition]' = , states: 'Sequence[State]' = ) Source code in whatrecord/snl.py @dataclass class StateSet : context : FullLoadContext name : str definitions : Sequence [ Definition ] = field ( default_factory = list ) states : Sequence [ State ] = field ( default_factory = list ) def __str__ ( self ) -> str : definitions = \" \\n \" . join ( str ( defn ) for defn in self . definitions ) states = \" \\n \" . join ( str ( state ) for state in self . states ) return \" \\n \" . join ( ( f \"ss { self . name } \" + \" {\" , textwrap . indent ( definitions , \" \" * 4 ), textwrap . indent ( states , \" \" * 4 ), \"}\" , ) ) whatrecord.snl.StateStatement ( Statement ) dataclass StateStatement(context: 'FullLoadContext', name: 'str') Source code in whatrecord/snl.py @dataclass class StateStatement ( Statement ): name : str def __str__ ( self ) -> str : return f \"state { self . name } ;\" whatrecord.snl.Statement dataclass Statement(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class Statement : context : FullLoadContext whatrecord.snl.StructDef ( Definition ) dataclass StructDef(context: 'FullLoadContext', name: 'str', members: 'Sequence[Union[StructMemberDecl, CCode]]' = ) Source code in whatrecord/snl.py @dataclass class StructDef ( Definition ): name : str members : Sequence [ Union [ StructMemberDecl , CCode ]] = field ( default_factory = list ) def __str__ ( self ) -> str : members = \" \\n \" . join ( str ( member ) for member in self . members ) return \" \\n \" . join ( ( f \"struct { self . name } \" + \" {\" , textwrap . indent ( members , \" \" * 4 ), \"}\" , ) ) whatrecord.snl.StructMemberDecl dataclass StructMemberDecl(context: 'FullLoadContext', type: 'Type', declarator: 'Declarator') Source code in whatrecord/snl.py @dataclass class StructMemberDecl : context : FullLoadContext type : Type declarator : Declarator def __str__ ( self ) -> str : return f \" { self . type } { self . declarator } ;\" whatrecord.snl.Sync ( Definition ) dataclass Sync(context: 'FullLoadContext', variable: 'str', subscript: 'Optional[int]', queued: 'bool', event_flag: 'Optional[str]' = None, queue_size: 'Optional[int]' = None) Source code in whatrecord/snl.py @dataclass class Sync ( Definition ): variable : str subscript : Optional [ int ] queued : bool event_flag : Optional [ str ] = None queue_size : Optional [ int ] = None def __str__ ( self ) -> str : subscript = str ( self . subscript or \"\" ) variable = f \" { self . variable }{ subscript } \" event_flag = f \" to { self . event_flag } \" if self . event_flag else \"\" if self . queued : return f \"syncq { variable }{ event_flag } { self . queue_size or '' } ;\" return f \"sync { variable }{ event_flag } ;\" whatrecord.snl.TernaryExpression ( Expression ) dataclass TernaryExpression(context: 'FullLoadContext', condition: 'Expression', if_true: 'Expression', if_false: 'Expression') Source code in whatrecord/snl.py @dataclass class TernaryExpression ( Expression ): condition : Expression if_true : Expression if_false : Expression def __str__ ( self ) -> str : return f \" { self . condition } ? { self . if_true } : { self . if_false } \" whatrecord.snl.Transition dataclass Transition(context: 'FullLoadContext', block: 'Block', target_state: 'Optional[str]' = None, condition: 'OptionalExpression' = None) Source code in whatrecord/snl.py @dataclass class Transition : context : FullLoadContext block : Block target_state : Optional [ str ] = None condition : OptionalExpression = None def __str__ ( self ) -> str : state = ( f \"state { self . target_state } \" if self . target_state else \"exit\" ) return \" \\n \" . join ( line for line in ( f \"when ( { self . condition or '' } )\" + \" {\" , str ( self . block ), \"}\" + f \" { state } \" , ) if line ) whatrecord.snl.Type dataclass Type(context: 'FullLoadContext', name: 'str', abstract: 'Optional[AbstractDeclarator]' = None) Source code in whatrecord/snl.py @dataclass class Type : context : FullLoadContext name : str abstract : Optional [ AbstractDeclarator ] = None def __str__ ( self ) -> str : return f \" { self . abstract or '' }{ self . name } \" whatrecord.snl.TypeCastExpression ( Expression ) dataclass TypeCastExpression(context: 'FullLoadContext', type: 'Type', expression: 'Expression') Source code in whatrecord/snl.py @dataclass class TypeCastExpression ( Expression ): type : Type expression : Expression def __str__ ( self ) -> str : return f \" { self . type } ( { self . expression } )\" whatrecord.snl.UnaryPostfixExpression ( Expression ) dataclass UnaryPostfixExpression(context: 'FullLoadContext', expression: 'Expression', operator: 'str') Source code in whatrecord/snl.py @dataclass class UnaryPostfixExpression ( Expression ): expression : Expression operator : str def __str__ ( self ) -> str : return f \" { self . expression }{ self . operator } \" whatrecord.snl.UnaryPrefixExpression ( Expression ) dataclass UnaryPrefixExpression(context: 'FullLoadContext', operator: 'str', expression: 'Expression') Source code in whatrecord/snl.py @dataclass class UnaryPrefixExpression ( Expression ): operator : str expression : Expression def __str__ ( self ) -> str : return f \" { self . operator }{ self . expression } \" whatrecord.snl.Variable ( Expression ) dataclass Variable(context: 'FullLoadContext', name: 'str') Source code in whatrecord/snl.py @dataclass class Variable ( Expression ): name : str def __str__ ( self ) -> str : return self . name whatrecord.snl.WhileStatement ( Statement ) dataclass WhileStatement(context: 'FullLoadContext', condition: 'CommaSeparatedExpressions', body: 'Statement') Source code in whatrecord/snl.py @dataclass class WhileStatement ( Statement ): condition : CommaSeparatedExpressions body : Statement def __str__ ( self ) -> str : return f \"while ( { self . condition } ) \" + str ( self . body ) . lstrip () whatrecord.streamdevice Classes whatrecord.streamdevice.Command dataclass Command(name: 'str', arguments: 'List[str]') Source code in whatrecord/streamdevice.py @dataclass class Command : name : str arguments : List [ str ] whatrecord.streamdevice.ConfigurationSetting dataclass ConfigurationSetting(name: 'str', value: 'str') Source code in whatrecord/streamdevice.py @dataclass class ConfigurationSetting : name : str value : str whatrecord.streamdevice.HandlerDefinition dataclass HandlerDefinition(name: 'str', commands: 'List[Command]' = ) Source code in whatrecord/streamdevice.py @dataclass class HandlerDefinition : name : str commands : List [ Command ] = field ( default_factory = list ) whatrecord.streamdevice.ProtocolDefinition dataclass ProtocolDefinition(context: 'FullLoadContext', name: 'str', handlers: 'Dict[str, HandlerDefinition]' = , variables: 'Dict[str, str]' = , commands: 'List[Command]' = , config: 'Dict[str, str]' = ) Source code in whatrecord/streamdevice.py @dataclass class ProtocolDefinition : context : FullLoadContext name : str handlers : Dict [ str , HandlerDefinition ] = field ( default_factory = dict ) variables : Dict [ str , str ] = field ( default_factory = dict ) commands : List [ Command ] = field ( default_factory = list ) config : Dict [ str , str ] = field ( default_factory = dict ) whatrecord.streamdevice.StreamDeviceState ( ShellStateHandler ) dataclass StreamDevice IOC shell state handler / container. Contains hooks for StreamDevice-related commands and state information. Attributes: Name Type Description protocols Dict[str, StreamProtocol] Loaded StreamDevice protocols by name. Source code in whatrecord/streamdevice.py @dataclass class StreamDeviceState ( ShellStateHandler ): \"\"\" StreamDevice IOC shell state handler / container. Contains hooks for StreamDevice-related commands and state information. Attributes ---------- protocols : Dict[str, StreamProtocol] Loaded StreamDevice protocols by name. \"\"\" metadata_key : ClassVar [ str ] = \"streamdevice\" protocols : Dict [ str , StreamProtocol ] = field ( default_factory = dict ) def find_streamdevice_protocol ( self , filename : AnyPath ) -> pathlib . Path : shell_state = self . primary_handler return shell_state . _fix_path_with_search_list ( filename , shell_state . paths_from_env_var ( \"STREAM_PROTOCOL_PATH\" , default = \".\" ) ) def load_streamdevice_protocol ( self , filename : AnyPath , ) -> StreamProtocol : \"\"\"Load a StreamDevice protocol file.\"\"\" filename = self . find_streamdevice_protocol ( filename ) key = str ( filename ) if key not in self . protocols : shell_state = self . primary_handler fn , contents = shell_state . load_file ( filename ) self . protocols [ key ] = StreamProtocol . from_string ( contents , filename = fn ) return self . protocols [ key ] def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" dtype = record . fields . get ( \"DTYP\" , None ) if not dtype or getattr ( dtype , \"value\" , None ) != \"stream\" : return info_field = record . fields . get ( \"INP\" , record . fields . get ( \"OUT\" , None )) if not info_field or isinstance ( info_field , PVAFieldReference ): return { \"error\" : \"INP/OUT not defined correctly\" } if not isinstance ( info_field . value , str ): return { \"error\" : \"INP/OUT not defined correctly (JSON)\" } info_field = info_field . value . strip () results = {} try : proto_file , proto_name , * proto_args = split_words ( info_field ) . argv proto_file = proto_file . lstrip ( \"@ \" ) except Exception : results [ \"error\" ] = ( f \"Invalid StreamDevice input/output field: { info_field !r} \" ) proto_file = None proto_name = None proto_args = [] else : try : protocol = self . load_streamdevice_protocol ( proto_file ) except Exception as ex : results [ \"error\" ] = f \" { ex . __class__ . __name__ } : { ex } \" else : if proto_name in protocol . protocols : results [ \"protocol\" ] = protocol . protocols [ proto_name ] else : results [ \"error\" ] = ( f \"Unknown protocol { proto_name !r} in { proto_file } ; \" f \"options are: { list ( protocol . protocols ) } \" ) return { \"protocol_file\" : proto_file , \"protocol_name\" : proto_name , \"protocol_args\" : proto_args , ** results , } Methods whatrecord . streamdevice . StreamDeviceState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Hook to annotate a record after being loaded. Source code in whatrecord/streamdevice.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" dtype = record . fields . get ( \"DTYP\" , None ) if not dtype or getattr ( dtype , \"value\" , None ) != \"stream\" : return info_field = record . fields . get ( \"INP\" , record . fields . get ( \"OUT\" , None )) if not info_field or isinstance ( info_field , PVAFieldReference ): return { \"error\" : \"INP/OUT not defined correctly\" } if not isinstance ( info_field . value , str ): return { \"error\" : \"INP/OUT not defined correctly (JSON)\" } info_field = info_field . value . strip () results = {} try : proto_file , proto_name , * proto_args = split_words ( info_field ) . argv proto_file = proto_file . lstrip ( \"@ \" ) except Exception : results [ \"error\" ] = ( f \"Invalid StreamDevice input/output field: { info_field !r} \" ) proto_file = None proto_name = None proto_args = [] else : try : protocol = self . load_streamdevice_protocol ( proto_file ) except Exception as ex : results [ \"error\" ] = f \" { ex . __class__ . __name__ } : { ex } \" else : if proto_name in protocol . protocols : results [ \"protocol\" ] = protocol . protocols [ proto_name ] else : results [ \"error\" ] = ( f \"Unknown protocol { proto_name !r} in { proto_file } ; \" f \"options are: { list ( protocol . protocols ) } \" ) return { \"protocol_file\" : proto_file , \"protocol_name\" : proto_name , \"protocol_args\" : proto_args , ** results , } whatrecord . streamdevice . StreamDeviceState . load_streamdevice_protocol ( self , filename : AnyPath ) -> StreamProtocol Load a StreamDevice protocol file. Source code in whatrecord/streamdevice.py def load_streamdevice_protocol ( self , filename : AnyPath , ) -> StreamProtocol : \"\"\"Load a StreamDevice protocol file.\"\"\" filename = self . find_streamdevice_protocol ( filename ) key = str ( filename ) if key not in self . protocols : shell_state = self . primary_handler fn , contents = shell_state . load_file ( filename ) self . protocols [ key ] = StreamProtocol . from_string ( contents , filename = fn ) return self . protocols [ key ] whatrecord.streamdevice.StreamProtocol dataclass Representation of a StreamDevice protocol. Source code in whatrecord/streamdevice.py @dataclass class StreamProtocol : \"\"\"Representation of a StreamDevice protocol.\"\"\" variables : Dict [ str , str ] = field ( default_factory = dict ) protocols : Dict [ str , ProtocolDefinition ] = field ( default_factory = dict ) comments : List [ str ] = field ( default_factory = list ) config : Dict [ str , str ] = field ( default_factory = dict ) handlers : Dict [ str , HandlerDefinition ] = field ( default_factory = dict ) @classmethod def from_string ( cls , contents , filename = None , ) -> StreamProtocol : \"\"\"Load a protocol file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"streamdevice.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , # lexer_callbacks={\"COMMENT\": comments.append}, ) proto = _ProtocolTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) proto . comments = comments return proto @classmethod def from_file_obj ( cls , fp , filename = None ) -> StreamProtocol : \"\"\"Load a protocol file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) @classmethod def from_file ( cls , fn ) -> StreamProtocol : \"\"\" Load a StreamDevice protocol file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- protocol : StreamProtocol The StreamDevice protocol. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) Methods whatrecord . streamdevice . StreamProtocol . from_file ( fn ) -> StreamProtocol classmethod Load a StreamDevice protocol file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description StreamProtocol The StreamDevice protocol. Source code in whatrecord/streamdevice.py @classmethod def from_file ( cls , fn ) -> StreamProtocol : \"\"\" Load a StreamDevice protocol file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- protocol : StreamProtocol The StreamDevice protocol. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) whatrecord . streamdevice . StreamProtocol . from_file_obj ( fp , filename = None ) -> StreamProtocol classmethod Load a protocol file given a file object. Source code in whatrecord/streamdevice.py @classmethod def from_file_obj ( cls , fp , filename = None ) -> StreamProtocol : \"\"\"Load a protocol file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) whatrecord . streamdevice . StreamProtocol . from_string ( contents , filename = None ) -> StreamProtocol classmethod Load a protocol file given its string contents. Source code in whatrecord/streamdevice.py @classmethod def from_string ( cls , contents , filename = None , ) -> StreamProtocol : \"\"\"Load a protocol file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"streamdevice.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , # lexer_callbacks={\"COMMENT\": comments.append}, ) proto = _ProtocolTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) proto . comments = comments return proto whatrecord.streamdevice.VariableAssignment dataclass VariableAssignment(name: 'str', value: 'str') Source code in whatrecord/streamdevice.py @dataclass class VariableAssignment : name : str value : str whatrecord.transformer Helpers for writing lark transformers. Functions whatrecord . transformer . context_from_token ( fn : str , token : Token ) -> Sequence [ whatrecord . common . LoadContext ] Get a LoadContext from a lark Token. Source code in whatrecord/transformer.py def context_from_token ( fn : str , token : lark . Token ) -> FullLoadContext : \"\"\"Get a LoadContext from a lark Token.\"\"\" return ( LoadContext ( name = fn , line = token . line ), ) whatrecord . transformer . context_from_tree ( fn : str , tree : Tree ) -> Sequence [ whatrecord . common . LoadContext ] Get a LoadContext from a lark Tree. Source code in whatrecord/transformer.py def context_from_tree ( fn : str , tree : lark . Tree ) -> FullLoadContext : \"\"\"Get a LoadContext from a lark Tree.\"\"\" return ( LoadContext ( name = fn , line = tree . meta . line ), ) whatrecord . transformer . dictify ( * tuples : Tuple [ Any , Any ]) -> dict Transformer helper to stringify a single argument. Source code in whatrecord/transformer.py @staticmethod def dictify ( * tuples : Tuple [ Any , Any ]) -> dict : \"\"\"Transformer helper to stringify a single argument.\"\"\" return dict ( tuples ) whatrecord . transformer . ignore ( * args : Any ) -> None Transformer helper to drop the subtree. Source code in whatrecord/transformer.py @staticmethod def ignore ( * args : Any ) -> None : \"\"\"Transformer helper to drop the subtree.\"\"\" whatrecord . transformer . listify ( * objects : Any ) Transformer helper to listify *args. Source code in whatrecord/transformer.py @staticmethod def listify ( * objects : Any ): \"\"\"Transformer helper to listify *args.\"\"\" return list ( objects ) whatrecord . transformer . listify_strings ( * objects : Union [ str , lark . lexer . Token ]) Transformer helper to listify *args and stringify each arg. Source code in whatrecord/transformer.py @staticmethod def listify_strings ( * objects : Union [ str , lark . Token ]): \"\"\"Transformer helper to listify *args and stringify each arg.\"\"\" return list ( str ( obj ) for obj in objects ) whatrecord . transformer . pass_through ( obj : Optional [ ~ T ] = None ) -> Optional [ ~ T ] Transformer helper to pass through an optional single argument. Source code in whatrecord/transformer.py @staticmethod def pass_through ( obj : Optional [ T ] = None ) -> Optional [ T ]: \"\"\"Transformer helper to pass through an optional single argument.\"\"\" return obj whatrecord . transformer . stringify ( obj : Token ) -> str Transformer helper to stringify a single argument. Source code in whatrecord/transformer.py @staticmethod def stringify ( obj : lark . Token ) -> str : \"\"\"Transformer helper to stringify a single argument.\"\"\" return str ( obj ) whatrecord . transformer . tuple_args ( * objects : ~ T ) -> Tuple [ ~ T , ... ] Transformer helper to get back the *args tuple. Source code in whatrecord/transformer.py @staticmethod def tuple_args ( * objects : T ) -> Tuple [ T , ... ]: \"\"\"Transformer helper to get back the *args tuple.\"\"\" return objects","title":"Parsers"},{"location":"parsers/#parsers","text":"","title":"Parsers"},{"location":"parsers/#usage","text":"For each of the parser classes: AccessSecurityConfig Database GatewayPVList LclsEpicsArchFile SequencerProgram StreamProtocol TemplateSubstitution Data can be loaded from a file, file object, or string. Filename information will be automatically added to the load context information when available, but may be specified separately in the latter case. Taking AccessSecurityConfig for example: from whatrecord import AccessSecurityConfig # 1. Load from a file directly config = AccessSecurityConfig.from_file(\"filename.acf\") # 2. Load from a file object with open(\"filename.acf\", \"rt\") as fp: config = AccessSecurityConfig.from_file_obj(fp) # 3. Load from a string: with open(\"filename.acf\", \"rt\") as fp: contents = fp.read() config = AccessSecurityConfig.from_string(contents, filename=\"filename.acf\")","title":"Usage"},{"location":"parsers/#api","text":"","title":"API"},{"location":"parsers/#whatrecord.access_security","text":"V3 Access Security file parsing. Documentation from the application developer's guide are interspersed here and in the classes below. A brief summary of the Functional Requirements is: * Each field of each record type is assigned an access security level. * Each record instance is assigned to a unique access security group. * Each user is assigned to one or more user access groups. * Each node is assigned to a host access group. For each access security group a set of access rules can be defined. Each rule specifies: - Access security level - READ or READ/WRITE access. - An optional list of User Access Groups or * meaning anyone. - An optional list of Host Access Groups or * meaning anywhere. - Conditions based on values of process variables","title":"access_security"},{"location":"parsers/#whatrecord.access_security-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.access_security.AccessSecurityConfig","text":"An Access Security Configuration file (ACF) container. Source code in whatrecord/access_security.py @dataclass class AccessSecurityConfig : \"\"\"An Access Security Configuration file (ACF) container.\"\"\" filename : Optional [ str ] = None hash : Optional [ str ] = None users : Dict [ str , UserAccessGroup ] = field ( default_factory = dict ) groups : Dict [ str , AccessSecurityGroup ] = field ( default_factory = dict ) hosts : Dict [ str , HostAccessGroup ] = field ( default_factory = dict ) header : str = \"\" comments : List [ lark . Token ] = field ( default_factory = list , metadata = apischema . metadata . skip , ) def get_group_from_record ( self , record : RecordInstance ) -> Optional [ AccessSecurityGroup ]: \"\"\"Get the appropriate access security group for the given record.\"\"\" if record . is_pva : return return self . groups . get ( record . access_security_group , None ) @classmethod def from_string ( cls , contents : str , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\" Load access security configuration from a string. Parameters ---------- contents : str The access security file contents. filename : str, optional The access security filename to use for LoadContext. \"\"\" contents_hash = get_bytes_sha256 ( contents . encode ( \"utf-8\" )) comments = [] def add_comment ( comment : lark . Token ): comments . append ( StringWithContext ( str ( comment ) . lstrip ( \"# \" ), context = context_from_lark_token ( filename , comment ), ) ) grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"access_security.lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : add_comment }, transformer = _AcfTransformer ( filename , contents_hash , comments ), maybe_placeholders = False , ) return grammar . parse ( contents ) @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\"Load an ACF file from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]) -> AccessSecurityConfig : \"\"\"Load an ACF file from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn ))","title":"AccessSecurityConfig"},{"location":"parsers/#whatrecord.access_security.AccessSecurityConfig-methods","text":"whatrecord . access_security . AccessSecurityConfig . from_file ( fn : Union [ str , pathlib . Path ]) -> AccessSecurityConfig classmethod Load an ACF file from a filename. Source code in whatrecord/access_security.py @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]) -> AccessSecurityConfig : \"\"\"Load an ACF file from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn )) whatrecord . access_security . AccessSecurityConfig . from_file_obj ( fp , filename : Optional [ str ] = None ) -> AccessSecurityConfig classmethod Load an ACF file from a file object. Source code in whatrecord/access_security.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\"Load an ACF file from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) whatrecord . access_security . AccessSecurityConfig . from_string ( contents : str , filename : Optional [ str ] = None ) -> AccessSecurityConfig classmethod Load access security configuration from a string. Parameters: Name Type Description Default contents str The access security file contents. required filename Optional[str] The access security filename to use for LoadContext. None Source code in whatrecord/access_security.py @classmethod def from_string ( cls , contents : str , filename : Optional [ str ] = None ) -> AccessSecurityConfig : \"\"\" Load access security configuration from a string. Parameters ---------- contents : str The access security file contents. filename : str, optional The access security filename to use for LoadContext. \"\"\" contents_hash = get_bytes_sha256 ( contents . encode ( \"utf-8\" )) comments = [] def add_comment ( comment : lark . Token ): comments . append ( StringWithContext ( str ( comment ) . lstrip ( \"# \" ), context = context_from_lark_token ( filename , comment ), ) ) grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"access_security.lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : add_comment }, transformer = _AcfTransformer ( filename , contents_hash , comments ), maybe_placeholders = False , ) return grammar . parse ( contents ) whatrecord . access_security . AccessSecurityConfig . get_group_from_record ( self , record : RecordInstance ) -> Optional [ AccessSecurityGroup ] Get the appropriate access security group for the given record. Source code in whatrecord/access_security.py def get_group_from_record ( self , record : RecordInstance ) -> Optional [ AccessSecurityGroup ]: \"\"\"Get the appropriate access security group for the given record.\"\"\" if record . is_pva : return return self . groups . get ( record . access_security_group , None )","title":"Methods"},{"location":"parsers/#whatrecord.access_security.AccessSecurityGroup","text":"An access security group. Source code in whatrecord/access_security.py @dataclass class AccessSecurityGroup : \"\"\"An access security group.\"\"\" context : FullLoadContext comments : str name : str inputs : Dict [ str , str ] = field ( default_factory = dict ) rules : List [ AccessSecurityRule ] = field ( default_factory = list )","title":"AccessSecurityGroup"},{"location":"parsers/#whatrecord.access_security.AccessSecurityRule","text":"Access Security Configuration rule, which defines access permissions. must be 0 or 1. Permission for a level 1 field implies permission for level 0 fields. The permissions are NONE, READ, and WRITE. WRITE permission implies READ permission. The standard EPICS record types have all fields set to level 1 except for VAL, CMD (command), and RES (reset). An optional argument specifies if writes should be trapped. See the section below on trapping Channel Access writes for how this is used. If not given the default is NOTRAPWRITE. UAG specifies a list of user access groups that can have the access privilege. If UAG is not defined then all users are allowed. HAG specifies a list of host access groups that have the access privilege. If HAG is not defined then all hosts are allowed. CALC is just like the CALC field of a calculation record except that the result must evaluate to TRUE or FALSE. The rule only applies if the calculation result is TRUE, where the actual test for TRUE is (0.99 < result < 1.01). Anything else is regarded as FALSE and will cause the rule to be ignored. Assignment statements are not permitted in CALC expressions here. Source code in whatrecord/access_security.py @apischema . fields . with_fields_set @dataclass class AccessSecurityRule : \"\"\" Access Security Configuration rule, which defines access permissions. <level> must be 0 or 1. Permission for a level 1 field implies permission for level 0 fields. The permissions are NONE, READ, and WRITE. WRITE permission implies READ permission. The standard EPICS record types have all fields set to level 1 except for VAL, CMD (command), and RES (reset). An optional argument specifies if writes should be trapped. See the section below on trapping Channel Access writes for how this is used. If not given the default is NOTRAPWRITE. UAG specifies a list of user access groups that can have the access privilege. If UAG is not defined then all users are allowed. HAG specifies a list of host access groups that have the access privilege. If HAG is not defined then all hosts are allowed. CALC is just like the CALC field of a calculation record except that the result must evaluate to TRUE or FALSE. The rule only applies if the calculation result is TRUE, where the actual test for TRUE is (0.99 < result < 1.01). Anything else is regarded as FALSE and will cause the rule to be ignored. Assignment statements are not permitted in CALC expressions here. \"\"\" context : FullLoadContext comments : str level : int options : str log_options : Optional [ str ] = None users : Optional [ List [ str ]] = None hosts : Optional [ List [ str ]] = None calc : Optional [ str ] = None","title":"AccessSecurityRule"},{"location":"parsers/#whatrecord.access_security.AccessSecurityState","text":"Access Security IOC shell state handler / container. Contains hooks for as-related commands and state information. Attributes: Name Type Description config AccessSecurityState The access security configuration. filename pathlib.Path The access security filename. macros Dict[str, str] Macros used when expanding the access security file. Source code in whatrecord/access_security.py @dataclass class AccessSecurityState ( ShellStateHandler ): \"\"\" Access Security IOC shell state handler / container. Contains hooks for as-related commands and state information. Attributes ---------- config : AccessSecurityState The access security configuration. filename : pathlib.Path The access security filename. macros : Dict[str, str] Macros used when expanding the access security file. \"\"\" metadata_key : ClassVar [ str ] = \"asg\" config : Optional [ AccessSecurityConfig ] = None filename : Optional [ pathlib . Path ] = None macros : Optional [ Dict [ str , str ]] = None def post_ioc_init ( self ): super () . post_ioc_init () if self . filename is None : return try : return { \"access_security\" : self . _load_access_security () } except Exception as ex : return { \"access_security\" : { \"exception_class\" : type ( ex ) . __name__ , \"error\" : str ( ex ), } } @_handler def handle_asSetSubstitutions ( self , macros : str ): if self . primary_handler is None : return macro_context = self . primary_handler . macro_context self . macros = macro_context . definitions_to_dict ( macros ) return { \"macros\" : self . macros , \"note\" : \"See iocInit results for details.\" , } @_handler def handle_asSetFilename ( self , filename : str ): if self . primary_handler is None : return self . filename = self . primary_handler . _fix_path ( filename ) . resolve () return { \"filename\" : str ( self . filename ), \"note\" : \"See iocInit results for details.\" , } def _load_access_security ( self ): \"\"\"Load access security settings at iocInit time.\"\"\" if self . primary_handler is None : return filename , contents = self . primary_handler . load_file ( self . filename ) if self . macros : macro_context = MacroContext ( use_environment = False ) macro_context . define ( ** self . macros ) contents = \" \\n \" . join ( macro_context . expand ( line ) for line in contents . splitlines () ) self . config = AccessSecurityConfig . from_string ( contents , filename = str ( filename ) ) return { \"filename\" : filename , \"macros\" : self . macros , } def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate record with access security information.\"\"\" if self . config is not None : asg = self . config . get_group_from_record ( record ) if asg is not None : return apischema . serialize ( asg )","title":"AccessSecurityState"},{"location":"parsers/#whatrecord.access_security.AccessSecurityState-methods","text":"whatrecord . access_security . AccessSecurityState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate record with access security information. Source code in whatrecord/access_security.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate record with access security information.\"\"\" if self . config is not None : asg = self . config . get_group_from_record ( record ) if asg is not None : return apischema . serialize ( asg ) whatrecord . access_security . AccessSecurityState . post_ioc_init ( self ) Post-iocInit hook. Source code in whatrecord/access_security.py def post_ioc_init ( self ): super () . post_ioc_init () if self . filename is None : return try : return { \"access_security\" : self . _load_access_security () } except Exception as ex : return { \"access_security\" : { \"exception_class\" : type ( ex ) . __name__ , \"error\" : str ( ex ), } }","title":"Methods"},{"location":"parsers/#whatrecord.access_security.HostAccessGroup","text":"Host Access Group. This is a list of host names. It may be empty. The same host name can appear in multiple HAGs. To match, a host name must match the host name read by the CA client library running on the client machine; both names are converted to lower case before comparison however. For vxWorks clients, the host name is usually taken from the target name of the boot parameters. Source code in whatrecord/access_security.py @dataclass class HostAccessGroup : \"\"\" Host Access Group. This is a list of host names. It may be empty. The same host name can appear in multiple HAGs. To match, a host name must match the host name read by the CA client library running on the client machine; both names are converted to lower case before comparison however. For vxWorks clients, the host name is usually taken from the target name of the boot parameters. \"\"\" context : FullLoadContext comments : str name : str hosts : List [ str ]","title":"HostAccessGroup"},{"location":"parsers/#whatrecord.access_security.UserAccessGroup","text":"User Access Group. This is a list of user names. The list may be empty. A user name may appear in more than one UAG. To match, a user name must be identical to the user name read by the CA client library running on the client machine. For vxWorks clients, the user name is usually taken from the user field of the boot parameters. Source code in whatrecord/access_security.py @dataclass class UserAccessGroup : \"\"\" User Access Group. This is a list of user names. The list may be empty. A user name may appear in more than one UAG. To match, a user name must be identical to the user name read by the CA client library running on the client machine. For vxWorks clients, the user name is usually taken from the user field of the boot parameters. \"\"\" context : FullLoadContext comments : str name : str users : List [ str ]","title":"UserAccessGroup"},{"location":"parsers/#whatrecord.autosave","text":"","title":"autosave"},{"location":"parsers/#whatrecord.autosave-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.autosave.AutosaveRestoreFile","text":"Representation of an autosave restore (.sav) file. Source code in whatrecord/autosave.py @dataclass class AutosaveRestoreFile : \"\"\"Representation of an autosave restore (.sav) file.\"\"\" filename : str values : Dict [ str , Dict [ str , RestoreValue ]] = field ( default_factory = dict ) disconnected : List [ str ] = field ( default_factory = list ) errors : List [ RestoreError ] = field ( default_factory = list ) comments : List [ str ] = field ( default_factory = list ) @classmethod def from_string ( cls , contents : str , filename : AnyPath = \"\" , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given its string contents.\"\"\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"autosave_save.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , propagate_positions = True , ) if macros : contents = MacroContext ( macros = macros ) . expand_by_line ( contents ) return _AutosaveRestoreTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) @classmethod def from_file_obj ( cls , fp , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), macros = macros , ) @classmethod def from_file ( cls , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\" Load an autosave restore (.sav) file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : AutosaveRestoreFile The resulting parsed file. \"\"\" with open ( filename , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = filename , macros = macros )","title":"AutosaveRestoreFile"},{"location":"parsers/#whatrecord.autosave.AutosaveRestoreFile-methods","text":"whatrecord . autosave . AutosaveRestoreFile . from_file ( filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile classmethod Load an autosave restore (.sav) file. Parameters: Name Type Description Default filename AnyPath The filename. required Returns: Type Description AutosaveRestoreFile The resulting parsed file. Source code in whatrecord/autosave.py @classmethod def from_file ( cls , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\" Load an autosave restore (.sav) file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- file : AutosaveRestoreFile The resulting parsed file. \"\"\" with open ( filename , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = filename , macros = macros ) whatrecord . autosave . AutosaveRestoreFile . from_file_obj ( fp , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile classmethod Load an autosave file given a file object. Source code in whatrecord/autosave.py @classmethod def from_file_obj ( cls , fp , filename : AnyPath , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), macros = macros , ) whatrecord . autosave . AutosaveRestoreFile . from_string ( contents : str , filename : AnyPath = '' , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile classmethod Load an autosave file given its string contents. Source code in whatrecord/autosave.py @classmethod def from_string ( cls , contents : str , filename : AnyPath = \"\" , macros : Optional [ Dict [ str , str ]] = None ) -> AutosaveRestoreFile : \"\"\"Load an autosave file given its string contents.\"\"\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"autosave_save.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , propagate_positions = True , ) if macros : contents = MacroContext ( macros = macros ) . expand_by_line ( contents ) return _AutosaveRestoreTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) )","title":"Methods"},{"location":"parsers/#whatrecord.autosave.AutosaveRestorePassFile","text":"AutosaveRestorePassFile(context: 'FullLoadContext', save_filename: 'str', macros: 'Dict[str, str]' = , pass_number: 'int' = 0, load_timestamp: 'Optional[datetime.datetime]' = None, file_timestamp: 'Optional[datetime.datetime]' = None, data: 'Optional[AutosaveRestoreFile]' = None) Source code in whatrecord/autosave.py @dataclass class AutosaveRestorePassFile : context : FullLoadContext save_filename : str macros : Dict [ str , str ] = field ( default_factory = dict ) pass_number : int = 0 load_timestamp : Optional [ datetime . datetime ] = None file_timestamp : Optional [ datetime . datetime ] = None data : Optional [ AutosaveRestoreFile ] = None def update ( self , save_path : pathlib . Path ) -> AutosaveRestoreFile : \"\"\"Update the autosave .sav file from disk.\"\"\" fn = save_path / self . save_filename file_timestamp = datetime . datetime . fromtimestamp ( fn . stat () . st_mtime ) if self . file_timestamp is not None and file_timestamp == self . file_timestamp : if self . data is not None : return self . data if self . load_timestamp is not None and self . data is not None : dt = datetime . datetime . now () - self . load_timestamp if dt . total_seconds () < settings . AUTOSAVE_RELOAD_PERIOD : return self . data self . file_timestamp = file_timestamp self . load_timestamp = datetime . datetime . now () self . data = AutosaveRestoreFile . from_file ( fn , macros = self . macros , ) return self . data","title":"AutosaveRestorePassFile"},{"location":"parsers/#whatrecord.autosave.AutosaveRestorePassFile-methods","text":"whatrecord . autosave . AutosaveRestorePassFile . update ( self , save_path : pathlib . Path ) -> AutosaveRestoreFile Update the autosave .sav file from disk. Source code in whatrecord/autosave.py def update ( self , save_path : pathlib . Path ) -> AutosaveRestoreFile : \"\"\"Update the autosave .sav file from disk.\"\"\" fn = save_path / self . save_filename file_timestamp = datetime . datetime . fromtimestamp ( fn . stat () . st_mtime ) if self . file_timestamp is not None and file_timestamp == self . file_timestamp : if self . data is not None : return self . data if self . load_timestamp is not None and self . data is not None : dt = datetime . datetime . now () - self . load_timestamp if dt . total_seconds () < settings . AUTOSAVE_RELOAD_PERIOD : return self . data self . file_timestamp = file_timestamp self . load_timestamp = datetime . datetime . now () self . data = AutosaveRestoreFile . from_file ( fn , macros = self . macros , ) return self . data","title":"Methods"},{"location":"parsers/#whatrecord.autosave.AutosaveSet","text":"AutosaveSet(context: 'FullLoadContext', request_filename: 'str', save_filename: 'str', period: 'Optional[int]' = None, trigger_channel: 'Optional[str]' = None, macros: 'Dict[str, str]' = , method: 'str' = 'manual') Source code in whatrecord/autosave.py @dataclass class AutosaveSet : context : FullLoadContext request_filename : str save_filename : str period : Optional [ int ] = None trigger_channel : Optional [ str ] = None macros : Dict [ str , str ] = field ( default_factory = dict ) method : str = \"manual\"","title":"AutosaveSet"},{"location":"parsers/#whatrecord.autosave.AutosaveState","text":"The state of autosave in an IOC. Source code in whatrecord/autosave.py @dataclass class AutosaveState ( ShellStateHandler ): \"\"\"The state of autosave in an IOC.\"\"\" metadata_key : ClassVar [ str ] = \"autosave\" configured : bool = False request_paths : List [ pathlib . Path ] = field ( default_factory = list ) save_path : pathlib . Path = field ( default_factory = pathlib . Path ) sets : Dict [ str , AutosaveSet ] = field ( default_factory = dict ) restore_files : Dict [ str , AutosaveRestorePassFile ] = field ( default_factory = dict ) incomplete_sets_ok : Optional [ bool ] = None # default: True dated_backups : Optional [ bool ] = None # default: True date_period_minutes : Optional [ int ] = None # default: 0 num_seq_files : Optional [ int ] = None # default: 3 seq_period : Optional [ int ] = None # default: 0 retry_seconds : Optional [ int ] = None # default: 0 ca_reconnect : Optional [ bool ] = None # default: False callback_timeout : Optional [ int ] = None # default: 0 task_priority : Optional [ int ] = None # default: 0 nfs_host : Optional [ str ] = None use_status_pvs : Optional [ bool ] = None # default: False status_prefix : Optional [ str ] = None file_permissions : Optional [ int ] = None # default: 0o664 debug : Optional [ int ] = None # default: 0 @property def save_name_pv ( self ) -> Optional [ str ]: \"\"\"The save name PV, derived from the macro context.\"\"\" if self . primary_handler is not None : return self . primary_handler . macro_context . get ( \"SAVENAMEPV\" ) @property def save_path_pv ( self ) -> Optional [ str ]: \"\"\"The save path PV, derived from the macro context.\"\"\" if self . primary_handler is not None : return self . primary_handler . macro_context . get ( \"SAVEPATHPV\" ) # save_restore.c @_handler def handle_fdbrestore ( self , filename : str = \"\" ): \"\"\" If save_file refers to a save set that exists in memory, then PV's in the save set will be restored from values in memory. Otherwise, this functions restores the PV's in <saveRestorePath>/<save_file> and creates a new backup file \"<saveRestorePath>/<save_file>.bu\". The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPutX() calls. Record processing will result from caput()'s to inherently process- passive fields. \"\"\" @_handler def handle_fdbrestoreX ( self , filename = \"\" , macrostring = \"\" ): \"\"\" This function restores from the file <saveRestorePath>/<save_file>, which can look just like a save file, but which needn't end with <END>. No backup file will be written. The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPut*() calls. Record processing will result from caput()'s to inherently process-passive fields. \"\"\" @_handler def handle_manual_save ( self , request_file : str = \"\" ): \"\"\" Cause current PV values for the request file to be saved. Any request file named in a create_xxx_set() command can be saved manually. \"\"\" @_handler def handle_set_savefile_name ( self , request_file : str = \"\" , save_filename : str = \"\" ): \"\"\" If a save set has already been created for the request file, this function will change the save file name. \"\"\" try : set_ = self . sets [ request_file ] except KeyError : raise ValueError ( \"Request file not configured\" ) set_ . save_filename = save_filename @_handler def handle_create_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = period , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"periodic\" , ) @_handler def handle_create_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written whenever the PV specified by trigger_channel is posted. Normally this occurs when the PV's value changes. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = trigger_channel , macros = macros_from_string ( macro_string ), method = \"triggered\" , ) @_handler def handle_create_monitor_set ( self , filename : Optional [ str ] = None , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds, if any PV in the save set was posted (changed value) since the last write. \"\"\" if filename is None : # An indicator to \"start the save task\" return self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = int ( period ), trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"monitor\" , ) @_handler def handle_create_manual_set ( self , filename : str = \"\" , macro_string : str = \"\" ): \"\"\" Create a save set for the request file. The save file will be written when the function manual_save() is called with the same request-file name. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"manual\" , ) @_handler def handle_save_restoreShow ( self , verbose : int = 0 ): \"\"\"Show the save restore status.\"\"\" return self . sets @_handler def handle_set_requestfile_path ( self , path : str = \"\" , subpath : str = \"\" ): full_path = ( pathlib . Path ( path ) / subpath ) . resolve () if full_path not in self . request_paths : self . request_paths . append ( full_path ) @_handler def handle_set_savefile_path ( self , path : str = \"\" , subpath : str = \"\" ): \"\"\" Called before iocInit(), this function specifies the path to be prepended to save-file and restore-file names. pathsub, if present, will be appended to path, if present, with a separating '/', whether or not path ends or pathsub begins with '/'. If the result does not end in '/', one will be appended to it. If save_restore is managing its own NFS mount, this function specifies the mount point, and calling it will result in an NFS mount if all other requirements have already been met. If a valid NFS mount already exists, the file system will be dismounted and then mounted with the new path name. This function can be called at any time. \"\"\" path = pathlib . Path ( path ) / subpath if self . primary_handler is not None : path = self . primary_handler . _fix_path ( path ) self . save_path = path . resolve () @_handler def handle_set_saveTask_priority ( self , priority : int = 0 ): \"\"\"Set the priority of the save_restore task.\"\"\" self . task_priority = int ( priority ) @_handler def handle_save_restoreSet_NFSHost ( self , hostname : str = \"\" , address : str = \"\" , mntpoint : str = \"\" , * _ ): \"\"\" Specifies the name and IP address of the NFS host. If both have been specified, and set_savefile_path() has been called to specify the file path, save_restore will manage its own NFS mount. This allows save_restore to recover from a reboot of the NFS host (that is, a stale file handle) and from some kinds of tampering with the save_restore directory. \"\"\" self . nfs_host = f \"nfs:// { hostname } / { mntpoint } ( { address } )\" @_handler def handle_remove_data_set ( self , filename : str = \"\" ): \"\"\"If a save set has been created for request_file, this function will delete it.\"\"\" ... @_handler def handle_reload_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_periodic_set(). \"\"\" @_handler def handle_reload_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the trigger channel associated with a save set created by create_triggered_set(). \"\"\" @_handler def handle_reload_monitor_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_monitor_set(). \"\"\" @_handler def handle_reload_manual_set ( self , filename : str = \"\" , macrostring : str = \"\" ): \"\"\" This function allows you to change the PV's associated with a save set created by create_manual_set(). \"\"\" @_handler def handle_save_restoreSet_Debug ( self , level : int = 0 ): \"\"\" Sets the value (int) save_restoreDebug (initially 0). Increase to get more informational messages printed to the console. \"\"\" self . debug = int ( level ) @_handler def handle_save_restoreSet_NumSeqFiles ( self , numSeqFiles : int = 0 ): \"\"\" Sets the value of (int) save_restoreNumSeqFiles (initially 3). This is the number of sequenced backup files to be maintained. \"\"\" self . num_seq_files = int ( numSeqFiles ) if not ( 0 <= self . num_seq_files <= 10 ): raise ValueError ( \"numSeqFiles must be between 0 and 10 inclusive.\" ) @_handler def handle_save_restoreSet_SeqPeriodInSeconds ( self , period : int = 0 ): \"\"\" Sets the value of (int) save_restoreSeqPeriodInSeconds (initially 60). Sequenced backup files will be written with this period. \"\"\" self . seq_period = int ( period ) if self . seq_period < 10 : raise ValueError ( \"period must be 10 or greater.\" ) @_handler def handle_save_restoreSet_IncompleteSetsOk ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreIncompleteSetsOk (initially 1). If set to zero, save files will not be restored at boot time unless they are perfect, and they will not be overwritten at save time unless a valid CA connection and value exists for every PV in the list. \"\"\" self . incomplete_sets_ok = bool ( ok ) @_handler def handle_save_restoreSet_DatedBackupFiles ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = bool ( ok ) @_handler def handle_save_restoreSet_status_prefix ( self , prefix : str = \"\" ): \"\"\" Specifies the prefix to be used to construct the names of PV's with which save_restore reports its status. If you want autosave to update status PVs as it operates, you must call this function and load the database save_restoreStatus.db, specifying the same prefix in both commands. \"\"\" self . status_prefix = prefix @_handler def handle_save_restoreSet_FilePermissions ( self , permissions : int = 0 ): \"\"\" Specify the file permissions used to create new .sav files. This integer value will be supplied, exactly as given, to the system call, open(), and to the call fchmod(). Typically, file permissions are set with an octal number, such as 0640, and save_restoreSet_FilePermissions() will confirm any number given to it by echoing it to the console as an octal number. \"\"\" self . file_permissions = int ( permissions ) @_handler def handle_save_restoreSet_RetrySeconds ( self , seconds : int = 0 ): \"\"\" Specify the time delay between a failed .sav-file write and the retry of that write. The default delay is 60 seconds. If list-PV's change during the delay, the new values will be written. \"\"\" self . retry_seconds = int ( seconds ) @_handler def handle_save_restoreSet_UseStatusPVs ( self , ok : int = 0 ): \"\"\" Specifies whether save_restore should report its status to a preloaded set of EPICS PV's (contained in the database save_restoreStatus.db). If the argument is '0', then status PV's will not be used. \"\"\" self . use_status_pvs = bool ( ok ) @_handler def handle_save_restoreSet_CAReconnect ( self , ok : int = 0 ): \"\"\" Specify whether autosave should periodically retry connecting to PVs whose initial connection attempt failed. Currently, the connection-retry interval is hard-wired at 60 seconds. \"\"\" self . ca_reconnect = bool ( ok ) @_handler def handle_save_restoreSet_CallbackTimeout ( self , timeout : int = 0 ): \"\"\" Specify the time interval in seconds between forced save-file writes. (-1 means forever). This is intended to get save files written even if the normal trigger mechanism is broken. \"\"\" self . callback_timeout = int ( timeout ) @_handler def handle_asVerify ( self , filename : str = \"\" , verbose : int = 0 , restoreFileName : str = \"\" , * _ ): \"\"\" Compare PV values in the IOC with values written in filename (which should be an autosave restore file, or at least look like one). If restoreFileName is not empty, write a new restore file. \"\"\" ... @_handler def handle_save_restoreSet_periodicDatedBackups ( self , periodMinutes : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = True self . date_period_minutes = int ( periodMinutes ) # dbrestore.c @_handler def handle_set_pass0_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, before record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 0 , ) return { \"autosave\" : f \"Added pass 0 restore file { self . save_path } / { file } \" } @_handler def handle_set_pass1_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, after record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 1 , ) return { \"autosave\" : f \"Added pass 1 restore file { self . save_path } / { file } \" } @_handler def handle_dbrestoreShow ( self ): \"\"\" List all the save sets currently being managed by the save_restore task. If (verbose != 0), lists the PV's as well. \"\"\" ... @_handler def handle_makeAutosaveFileFromDbInfo ( self , filename : str = \"\" , info_name : str = \"\" , * _ ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for 'info' nodes named info_name; construct a list of PV names from the associated info_values found, and write the PV names to the file fileBaseName. If fileBaseName does not contain the string '.req', this string will be appended to it. See makeAutosaveFiles() for more information. \"\"\" @_handler def handle_makeAutosaveFiles ( self ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for info nodes named 'autosaveFields' and 'autosaveFields_pass0'; construct lists of PV names from the associated info values, and write the PV names to the files 'info_settings.req' and 'info_positions.req', respectively. \"\"\" @_handler def handle_eraseFile ( self , filename : str = \"\" ): \"\"\"Erase (empty) an autosave file.\"\"\" ... @_handler def handle_appendToFile ( self , filename : str = \"\" , line : str = \"\" ): \"\"\" Append line to a file. For example, to add a line to built_settings.req yourself: appendToFile(\"built_settings.req\", '$(P)userStringSeqEnable') \"\"\" ... @_handler def handle_autosaveBuild ( self , filename : str = \"\" , reqFileSuffix : str = \"\" , on : int = 0 , * _ ): \"\"\" It's tedious and error prone to have these entries separately maintained, so autosave can do the request-file part for you. To do this, you tell autosave to arrange to be called whenever dbLoadRecords() is called (note that dbLoadTemplate() calls dbLoadRecords()), you tell it how to make a request-file name from a database-file name, and you give it the name of the request file you want it to build. You can do this with the following command: autosaveBuild(\"built_settings.req\", \"_settings.req\", 1) This tells autosave to do the following: 1. Begin building the file built_settings.req. If this is the first call that mentions built_settings.req, erase the file. 2. Generate request-file names by stripping \".db\", or \".vdb\", or \".template\" from database-file names, and adding the suffix \"_settings.req\". 3. Enable (disable) automated building if the third argument is 1 (0). While automated building is enabled, autosave will generate request-file names and search for those files in its request-file path. If it finds a request file, it will add the appropriate line to built_settings.req. All this does is get the file built_settings.req built. If you want it to be used, you must add the following line to auto_settings.req: file built_settings.req P=$(P) \"\"\" def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: metadata = {} for restore_file in self . restore_files . values (): try : data = restore_file . update ( self . save_path ) except FileNotFoundError : fn = self . save_path / restore_file . save_filename metadata . setdefault ( \"error\" , []) . append ( f \"Restore file not found: { fn } \" ) continue record_data = data . values . get ( record . name , None ) if record_data is not None : metadata . setdefault ( \"restore\" , []) . append ( record_data ) for pvname in data . disconnected : if pvname . split ( \".\" )[ 0 ] == record . name : if \".\" in pvname : field = pvname . split ( \".\" , 1 )[ 1 ] else : field = \"VAL\" metadata . setdefault ( \"disconnected\" , []) . append ( field ) return metadata if metadata else None","title":"AutosaveState"},{"location":"parsers/#whatrecord.autosave.AutosaveState-attributes","text":"whatrecord . autosave . AutosaveState . save_name_pv : Optional [ str ] property readonly The save name PV, derived from the macro context. whatrecord . autosave . AutosaveState . save_path_pv : Optional [ str ] property readonly The save path PV, derived from the macro context.","title":"Attributes"},{"location":"parsers/#whatrecord.autosave.AutosaveState-methods","text":"whatrecord . autosave . AutosaveState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate the given record's metadata with state-related information. Source code in whatrecord/autosave.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: metadata = {} for restore_file in self . restore_files . values (): try : data = restore_file . update ( self . save_path ) except FileNotFoundError : fn = self . save_path / restore_file . save_filename metadata . setdefault ( \"error\" , []) . append ( f \"Restore file not found: { fn } \" ) continue record_data = data . values . get ( record . name , None ) if record_data is not None : metadata . setdefault ( \"restore\" , []) . append ( record_data ) for pvname in data . disconnected : if pvname . split ( \".\" )[ 0 ] == record . name : if \".\" in pvname : field = pvname . split ( \".\" , 1 )[ 1 ] else : field = \"VAL\" metadata . setdefault ( \"disconnected\" , []) . append ( field ) return metadata if metadata else None whatrecord . autosave . AutosaveState . handle_appendToFile ( self , filename : str = '' , line : str = '' ) Append line to a file. For example, to add a line to built_settings.req yourself: appendToFile(\"built_settings.req\", '$(P)userStringSeqEnable') Source code in whatrecord/autosave.py @_handler def handle_appendToFile ( self , filename : str = \"\" , line : str = \"\" ): \"\"\" Append line to a file. For example, to add a line to built_settings.req yourself: appendToFile(\"built_settings.req\", '$(P)userStringSeqEnable') \"\"\" ... whatrecord . autosave . AutosaveState . handle_asVerify ( self , filename : str = '' , verbose : int = 0 , restoreFileName : str = '' , * _ ) Compare PV values in the IOC with values written in filename (which should be an autosave restore file, or at least look like one). If restoreFileName is not empty, write a new restore file. Source code in whatrecord/autosave.py @_handler def handle_asVerify ( self , filename : str = \"\" , verbose : int = 0 , restoreFileName : str = \"\" , * _ ): \"\"\" Compare PV values in the IOC with values written in filename (which should be an autosave restore file, or at least look like one). If restoreFileName is not empty, write a new restore file. \"\"\" ... whatrecord . autosave . AutosaveState . handle_autosaveBuild ( self , filename : str = '' , reqFileSuffix : str = '' , on : int = 0 , * _ ) It's tedious and error prone to have these entries separately maintained, so autosave can do the request-file part for you. To do this, you tell autosave to arrange to be called whenever dbLoadRecords() is called (note that dbLoadTemplate() calls dbLoadRecords()), you tell it how to make a request-file name from a database-file name, and you give it the name of the request file you want it to build. You can do this with the following command: autosaveBuild(\"built_settings.req\", \"_settings.req\", 1) This tells autosave to do the following: 1. Begin building the file built_settings.req. If this is the first call that mentions built_settings.req, erase the file. 2. Generate request-file names by stripping \".db\", or \".vdb\", or \".template\" from database-file names, and adding the suffix \"_settings.req\". 3. Enable (disable) automated building if the third argument is 1 (0). While automated building is enabled, autosave will generate request-file names and search for those files in its request-file path. If it finds a request file, it will add the appropriate line to built_settings.req. All this does is get the file built_settings.req built. If you want it to be used, you must add the following line to auto_settings.req: file built_settings.req P=$(P) Source code in whatrecord/autosave.py @_handler def handle_autosaveBuild ( self , filename : str = \"\" , reqFileSuffix : str = \"\" , on : int = 0 , * _ ): \"\"\" It's tedious and error prone to have these entries separately maintained, so autosave can do the request-file part for you. To do this, you tell autosave to arrange to be called whenever dbLoadRecords() is called (note that dbLoadTemplate() calls dbLoadRecords()), you tell it how to make a request-file name from a database-file name, and you give it the name of the request file you want it to build. You can do this with the following command: autosaveBuild(\"built_settings.req\", \"_settings.req\", 1) This tells autosave to do the following: 1. Begin building the file built_settings.req. If this is the first call that mentions built_settings.req, erase the file. 2. Generate request-file names by stripping \".db\", or \".vdb\", or \".template\" from database-file names, and adding the suffix \"_settings.req\". 3. Enable (disable) automated building if the third argument is 1 (0). While automated building is enabled, autosave will generate request-file names and search for those files in its request-file path. If it finds a request file, it will add the appropriate line to built_settings.req. All this does is get the file built_settings.req built. If you want it to be used, you must add the following line to auto_settings.req: file built_settings.req P=$(P) \"\"\" whatrecord . autosave . AutosaveState . handle_create_manual_set ( self , filename : str = '' , macro_string : str = '' ) Create a save set for the request file. The save file will be written when the function manual_save() is called with the same request-file name. Source code in whatrecord/autosave.py @_handler def handle_create_manual_set ( self , filename : str = \"\" , macro_string : str = \"\" ): \"\"\" Create a save set for the request file. The save file will be written when the function manual_save() is called with the same request-file name. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"manual\" , ) whatrecord . autosave . AutosaveState . handle_create_monitor_set ( self , filename : Optional [ str ] = None , period : int = 0 , macro_string : str = '' , * _ ) Create a save set for the request file. The save file will be written every period seconds, if any PV in the save set was posted (changed value) since the last write. Source code in whatrecord/autosave.py @_handler def handle_create_monitor_set ( self , filename : Optional [ str ] = None , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds, if any PV in the save set was posted (changed value) since the last write. \"\"\" if filename is None : # An indicator to \"start the save task\" return self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = int ( period ), trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"monitor\" , ) whatrecord . autosave . AutosaveState . handle_create_periodic_set ( self , filename : str = '' , period : int = 0 , macro_string : str = '' , * _ ) Create a save set for the request file. The save file will be written every period seconds. Source code in whatrecord/autosave.py @_handler def handle_create_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written every period seconds. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = period , trigger_channel = None , macros = macros_from_string ( macro_string ), method = \"periodic\" , ) whatrecord . autosave . AutosaveState . handle_create_triggered_set ( self , filename : str = '' , trigger_channel : str = '' , macro_string : str = '' , * _ ) Create a save set for the request file. The save file will be written whenever the PV specified by trigger_channel is posted. Normally this occurs when the PV's value changes. Source code in whatrecord/autosave.py @_handler def handle_create_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" Create a save set for the request file. The save file will be written whenever the PV specified by trigger_channel is posted. Normally this occurs when the PV's value changes. \"\"\" self . sets [ filename ] = AutosaveSet ( context = self . get_load_context (), request_filename = filename , save_filename = \" {} .sav\" . format ( pathlib . Path ( filename ) . stem ), period = None , trigger_channel = trigger_channel , macros = macros_from_string ( macro_string ), method = \"triggered\" , ) whatrecord . autosave . AutosaveState . handle_dbrestoreShow ( self ) List all the save sets currently being managed by the save_restore task. If (verbose != 0), lists the PV's as well. Source code in whatrecord/autosave.py @_handler def handle_dbrestoreShow ( self ): \"\"\" List all the save sets currently being managed by the save_restore task. If (verbose != 0), lists the PV's as well. \"\"\" ... whatrecord . autosave . AutosaveState . handle_eraseFile ( self , filename : str = '' ) Erase (empty) an autosave file. Source code in whatrecord/autosave.py @_handler def handle_eraseFile ( self , filename : str = \"\" ): \"\"\"Erase (empty) an autosave file.\"\"\" ... whatrecord . autosave . AutosaveState . handle_fdbrestore ( self , filename : str = '' ) If save_file refers to a save set that exists in memory, then PV's in the save set will be restored from values in memory. Otherwise, this functions restores the PV's in / and creates a new backup file \" / .bu\". The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPutX() calls. Record processing will result from caput()'s to inherently process- passive fields. Source code in whatrecord/autosave.py @_handler def handle_fdbrestore ( self , filename : str = \"\" ): \"\"\" If save_file refers to a save set that exists in memory, then PV's in the save set will be restored from values in memory. Otherwise, this functions restores the PV's in <saveRestorePath>/<save_file> and creates a new backup file \"<saveRestorePath>/<save_file>.bu\". The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPutX() calls. Record processing will result from caput()'s to inherently process- passive fields. \"\"\" whatrecord . autosave . AutosaveState . handle_fdbrestoreX ( self , filename = '' , macrostring = '' ) This function restores from the file / , which can look just like a save file, but which needn't end with . No backup file will be written. The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPut*() calls. Record processing will result from caput()'s to inherently process-passive fields. Source code in whatrecord/autosave.py @_handler def handle_fdbrestoreX ( self , filename = \"\" , macrostring = \"\" ): \"\"\" This function restores from the file <saveRestorePath>/<save_file>, which can look just like a save file, but which needn't end with <END>. No backup file will be written. The effect probably will not be the same as a boot-time restore, because caput() calls are used instead of static database access dbPut*() calls. Record processing will result from caput()'s to inherently process-passive fields. \"\"\" whatrecord . autosave . AutosaveState . handle_makeAutosaveFileFromDbInfo ( self , filename : str = '' , info_name : str = '' , * _ ) Search through the EPICS database (that is, all EPICS records loaded into an IOC) for 'info' nodes named info_name; construct a list of PV names from the associated info_values found, and write the PV names to the file fileBaseName. If fileBaseName does not contain the string '.req', this string will be appended to it. See makeAutosaveFiles() for more information. Source code in whatrecord/autosave.py @_handler def handle_makeAutosaveFileFromDbInfo ( self , filename : str = \"\" , info_name : str = \"\" , * _ ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for 'info' nodes named info_name; construct a list of PV names from the associated info_values found, and write the PV names to the file fileBaseName. If fileBaseName does not contain the string '.req', this string will be appended to it. See makeAutosaveFiles() for more information. \"\"\" whatrecord . autosave . AutosaveState . handle_makeAutosaveFiles ( self ) Search through the EPICS database (that is, all EPICS records loaded into an IOC) for info nodes named 'autosaveFields' and 'autosaveFields_pass0'; construct lists of PV names from the associated info values, and write the PV names to the files 'info_settings.req' and 'info_positions.req', respectively. Source code in whatrecord/autosave.py @_handler def handle_makeAutosaveFiles ( self ): \"\"\" Search through the EPICS database (that is, all EPICS records loaded into an IOC) for info nodes named 'autosaveFields' and 'autosaveFields_pass0'; construct lists of PV names from the associated info values, and write the PV names to the files 'info_settings.req' and 'info_positions.req', respectively. \"\"\" whatrecord . autosave . AutosaveState . handle_manual_save ( self , request_file : str = '' ) Cause current PV values for the request file to be saved. Any request file named in a create_xxx_set() command can be saved manually. Source code in whatrecord/autosave.py @_handler def handle_manual_save ( self , request_file : str = \"\" ): \"\"\" Cause current PV values for the request file to be saved. Any request file named in a create_xxx_set() command can be saved manually. \"\"\" whatrecord . autosave . AutosaveState . handle_reload_manual_set ( self , filename : str = '' , macrostring : str = '' ) This function allows you to change the PV's associated with a save set created by create_manual_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_manual_set ( self , filename : str = \"\" , macrostring : str = \"\" ): \"\"\" This function allows you to change the PV's associated with a save set created by create_manual_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_reload_monitor_set ( self , filename : str = '' , period : int = 0 , macro_string : str = '' , * _ ) This function allows you to change the PV's and the period associated with a save set created by create_monitor_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_monitor_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_monitor_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_reload_periodic_set ( self , filename : str = '' , period : int = 0 , macro_string : str = '' , * _ ) This function allows you to change the PV's and the period associated with a save set created by create_periodic_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_periodic_set ( self , filename : str = \"\" , period : int = 0 , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the period associated with a save set created by create_periodic_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_reload_triggered_set ( self , filename : str = '' , trigger_channel : str = '' , macro_string : str = '' , * _ ) This function allows you to change the PV's and the trigger channel associated with a save set created by create_triggered_set(). Source code in whatrecord/autosave.py @_handler def handle_reload_triggered_set ( self , filename : str = \"\" , trigger_channel : str = \"\" , macro_string : str = \"\" , * _ ): \"\"\" This function allows you to change the PV's and the trigger channel associated with a save set created by create_triggered_set(). \"\"\" whatrecord . autosave . AutosaveState . handle_remove_data_set ( self , filename : str = '' ) If a save set has been created for request_file, this function will delete it. Source code in whatrecord/autosave.py @_handler def handle_remove_data_set ( self , filename : str = \"\" ): \"\"\"If a save set has been created for request_file, this function will delete it.\"\"\" ... whatrecord . autosave . AutosaveState . handle_save_restoreSet_CAReconnect ( self , ok : int = 0 ) Specify whether autosave should periodically retry connecting to PVs whose initial connection attempt failed. Currently, the connection-retry interval is hard-wired at 60 seconds. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_CAReconnect ( self , ok : int = 0 ): \"\"\" Specify whether autosave should periodically retry connecting to PVs whose initial connection attempt failed. Currently, the connection-retry interval is hard-wired at 60 seconds. \"\"\" self . ca_reconnect = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_CallbackTimeout ( self , timeout : int = 0 ) Specify the time interval in seconds between forced save-file writes. (-1 means forever). This is intended to get save files written even if the normal trigger mechanism is broken. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_CallbackTimeout ( self , timeout : int = 0 ): \"\"\" Specify the time interval in seconds between forced save-file writes. (-1 means forever). This is intended to get save files written even if the normal trigger mechanism is broken. \"\"\" self . callback_timeout = int ( timeout ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_DatedBackupFiles ( self , ok : int = 0 ) Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_DatedBackupFiles ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_Debug ( self , level : int = 0 ) Sets the value (int) save_restoreDebug (initially 0). Increase to get more informational messages printed to the console. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_Debug ( self , level : int = 0 ): \"\"\" Sets the value (int) save_restoreDebug (initially 0). Increase to get more informational messages printed to the console. \"\"\" self . debug = int ( level ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_FilePermissions ( self , permissions : int = 0 ) Specify the file permissions used to create new .sav files. This integer value will be supplied, exactly as given, to the system call, open(), and to the call fchmod(). Typically, file permissions are set with an octal number, such as 0640, and save_restoreSet_FilePermissions() will confirm any number given to it by echoing it to the console as an octal number. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_FilePermissions ( self , permissions : int = 0 ): \"\"\" Specify the file permissions used to create new .sav files. This integer value will be supplied, exactly as given, to the system call, open(), and to the call fchmod(). Typically, file permissions are set with an octal number, such as 0640, and save_restoreSet_FilePermissions() will confirm any number given to it by echoing it to the console as an octal number. \"\"\" self . file_permissions = int ( permissions ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_IncompleteSetsOk ( self , ok : int = 0 ) Sets the value of (int) save_restoreIncompleteSetsOk (initially 1). If set to zero, save files will not be restored at boot time unless they are perfect, and they will not be overwritten at save time unless a valid CA connection and value exists for every PV in the list. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_IncompleteSetsOk ( self , ok : int = 0 ): \"\"\" Sets the value of (int) save_restoreIncompleteSetsOk (initially 1). If set to zero, save files will not be restored at boot time unless they are perfect, and they will not be overwritten at save time unless a valid CA connection and value exists for every PV in the list. \"\"\" self . incomplete_sets_ok = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_NFSHost ( self , hostname : str = '' , address : str = '' , mntpoint : str = '' , * _ ) Specifies the name and IP address of the NFS host. If both have been specified, and set_savefile_path() has been called to specify the file path, save_restore will manage its own NFS mount. This allows save_restore to recover from a reboot of the NFS host (that is, a stale file handle) and from some kinds of tampering with the save_restore directory. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_NFSHost ( self , hostname : str = \"\" , address : str = \"\" , mntpoint : str = \"\" , * _ ): \"\"\" Specifies the name and IP address of the NFS host. If both have been specified, and set_savefile_path() has been called to specify the file path, save_restore will manage its own NFS mount. This allows save_restore to recover from a reboot of the NFS host (that is, a stale file handle) and from some kinds of tampering with the save_restore directory. \"\"\" self . nfs_host = f \"nfs:// { hostname } / { mntpoint } ( { address } )\" whatrecord . autosave . AutosaveState . handle_save_restoreSet_NumSeqFiles ( self , numSeqFiles : int = 0 ) Sets the value of (int) save_restoreNumSeqFiles (initially 3). This is the number of sequenced backup files to be maintained. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_NumSeqFiles ( self , numSeqFiles : int = 0 ): \"\"\" Sets the value of (int) save_restoreNumSeqFiles (initially 3). This is the number of sequenced backup files to be maintained. \"\"\" self . num_seq_files = int ( numSeqFiles ) if not ( 0 <= self . num_seq_files <= 10 ): raise ValueError ( \"numSeqFiles must be between 0 and 10 inclusive.\" ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_RetrySeconds ( self , seconds : int = 0 ) Specify the time delay between a failed .sav-file write and the retry of that write. The default delay is 60 seconds. If list-PV's change during the delay, the new values will be written. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_RetrySeconds ( self , seconds : int = 0 ): \"\"\" Specify the time delay between a failed .sav-file write and the retry of that write. The default delay is 60 seconds. If list-PV's change during the delay, the new values will be written. \"\"\" self . retry_seconds = int ( seconds ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_SeqPeriodInSeconds ( self , period : int = 0 ) Sets the value of (int) save_restoreSeqPeriodInSeconds (initially 60). Sequenced backup files will be written with this period. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_SeqPeriodInSeconds ( self , period : int = 0 ): \"\"\" Sets the value of (int) save_restoreSeqPeriodInSeconds (initially 60). Sequenced backup files will be written with this period. \"\"\" self . seq_period = int ( period ) if self . seq_period < 10 : raise ValueError ( \"period must be 10 or greater.\" ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_UseStatusPVs ( self , ok : int = 0 ) Specifies whether save_restore should report its status to a preloaded set of EPICS PV's (contained in the database save_restoreStatus.db). If the argument is '0', then status PV's will not be used. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_UseStatusPVs ( self , ok : int = 0 ): \"\"\" Specifies whether save_restore should report its status to a preloaded set of EPICS PV's (contained in the database save_restoreStatus.db). If the argument is '0', then status PV's will not be used. \"\"\" self . use_status_pvs = bool ( ok ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_periodicDatedBackups ( self , periodMinutes : int = 0 ) Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_periodicDatedBackups ( self , periodMinutes : int = 0 ): \"\"\" Sets the value of (int) save_restoreDatedBackupFiles (initially 1). If zero, the backup file written at reboot time (a copy of the file from which PV values are restored) will have the suffix '.bu', and will be overwritten every reboot. If nonzero, each reboot will leave behind its own backup file. \"\"\" self . dated_backups = True self . date_period_minutes = int ( periodMinutes ) whatrecord . autosave . AutosaveState . handle_save_restoreSet_status_prefix ( self , prefix : str = '' ) Specifies the prefix to be used to construct the names of PV's with which save_restore reports its status. If you want autosave to update status PVs as it operates, you must call this function and load the database save_restoreStatus.db, specifying the same prefix in both commands. Source code in whatrecord/autosave.py @_handler def handle_save_restoreSet_status_prefix ( self , prefix : str = \"\" ): \"\"\" Specifies the prefix to be used to construct the names of PV's with which save_restore reports its status. If you want autosave to update status PVs as it operates, you must call this function and load the database save_restoreStatus.db, specifying the same prefix in both commands. \"\"\" self . status_prefix = prefix whatrecord . autosave . AutosaveState . handle_save_restoreShow ( self , verbose : int = 0 ) Show the save restore status. Source code in whatrecord/autosave.py @_handler def handle_save_restoreShow ( self , verbose : int = 0 ): \"\"\"Show the save restore status.\"\"\" return self . sets whatrecord . autosave . AutosaveState . handle_set_pass0_restoreFile ( self , file : str = '' , macro_string : str = '' ) This function specifies a save file to be restored during iocInit, before record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. Source code in whatrecord/autosave.py @_handler def handle_set_pass0_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, before record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 0 , ) return { \"autosave\" : f \"Added pass 0 restore file { self . save_path } / { file } \" } whatrecord . autosave . AutosaveState . handle_set_pass1_restoreFile ( self , file : str = '' , macro_string : str = '' ) This function specifies a save file to be restored during iocInit, after record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. Source code in whatrecord/autosave.py @_handler def handle_set_pass1_restoreFile ( self , file : str = \"\" , macro_string : str = \"\" ): \"\"\" This function specifies a save file to be restored during iocInit, after record initialization. An unlimited number of files can be specified using calls to this function. If the file name begins with \"/\", autosave will use it as specified; otherwise, autosave will prepend the file path specified to set_savefile_path(). The second argument is optional. \"\"\" self . restore_files [ file ] = AutosaveRestorePassFile ( context = self . get_load_context (), save_filename = file , macros = macros_from_string ( macro_string ), pass_number = 1 , ) return { \"autosave\" : f \"Added pass 1 restore file { self . save_path } / { file } \" } whatrecord . autosave . AutosaveState . handle_set_saveTask_priority ( self , priority : int = 0 ) Set the priority of the save_restore task. Source code in whatrecord/autosave.py @_handler def handle_set_saveTask_priority ( self , priority : int = 0 ): \"\"\"Set the priority of the save_restore task.\"\"\" self . task_priority = int ( priority ) whatrecord . autosave . AutosaveState . handle_set_savefile_name ( self , request_file : str = '' , save_filename : str = '' ) If a save set has already been created for the request file, this function will change the save file name. Source code in whatrecord/autosave.py @_handler def handle_set_savefile_name ( self , request_file : str = \"\" , save_filename : str = \"\" ): \"\"\" If a save set has already been created for the request file, this function will change the save file name. \"\"\" try : set_ = self . sets [ request_file ] except KeyError : raise ValueError ( \"Request file not configured\" ) set_ . save_filename = save_filename whatrecord . autosave . AutosaveState . handle_set_savefile_path ( self , path : str = '' , subpath : str = '' ) Called before iocInit(), this function specifies the path to be prepended to save-file and restore-file names. pathsub, if present, will be appended to path, if present, with a separating '/', whether or not path ends or pathsub begins with '/'. If the result does not end in '/', one will be appended to it. If save_restore is managing its own NFS mount, this function specifies the mount point, and calling it will result in an NFS mount if all other requirements have already been met. If a valid NFS mount already exists, the file system will be dismounted and then mounted with the new path name. This function can be called at any time. Source code in whatrecord/autosave.py @_handler def handle_set_savefile_path ( self , path : str = \"\" , subpath : str = \"\" ): \"\"\" Called before iocInit(), this function specifies the path to be prepended to save-file and restore-file names. pathsub, if present, will be appended to path, if present, with a separating '/', whether or not path ends or pathsub begins with '/'. If the result does not end in '/', one will be appended to it. If save_restore is managing its own NFS mount, this function specifies the mount point, and calling it will result in an NFS mount if all other requirements have already been met. If a valid NFS mount already exists, the file system will be dismounted and then mounted with the new path name. This function can be called at any time. \"\"\" path = pathlib . Path ( path ) / subpath if self . primary_handler is not None : path = self . primary_handler . _fix_path ( path ) self . save_path = path . resolve ()","title":"Methods"},{"location":"parsers/#whatrecord.autosave.RestoreError","text":"RestoreError(context: 'FullLoadContext', number: 'int', description: 'str') Source code in whatrecord/autosave.py @dataclass class RestoreError : context : FullLoadContext number : int description : str","title":"RestoreError"},{"location":"parsers/#whatrecord.autosave.RestoreValue","text":"RestoreValue(context: 'FullLoadContext', pvname: 'str', record: 'str', field: 'str', value: 'Union[str, List[str]]') Source code in whatrecord/autosave.py @dataclass class RestoreValue : context : FullLoadContext pvname : str record : str field : str value : Union [ str , List [ str ]]","title":"RestoreValue"},{"location":"parsers/#whatrecord.db","text":"","title":"db"},{"location":"parsers/#whatrecord.db-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.db.Database","text":"Representation of an EPICS database, database definition, or both. Attributes: Name Type Description standalone_aliases Standalone aliases are those defined outside of the record body; this may only be useful for faithfully reconstructing the Database according to its original source code. Keyed on alias to actual record name. aliases Alias name to record name. paths The path command specifies the current search path for use when loading database and database definition files. The addpath appends directory names to the current path. The path is used to locate the initial database file and included files. An empty dir at the beginning, middle, or end of a non-empty path string means the current directory. addpaths See 'paths' above. breaktables Breakpoint table (look-up table) of raw-to-engineering values. comments Comments encountered while parsing the database. devices Device support declarations (dset). drivers Driver declarations (drvet). functions Exported C function names. includes Inline inclusion. Not supported just yet. links Links. menus Named value enumerations (enums). records Record name to RecordInstance. record_types Record type name to RecordType. registrars Exported registrar function name. variables IOC shell variables. Source code in whatrecord/db.py @dataclass class Database : \"\"\" Representation of an EPICS database, database definition, or both. Attributes ---------- standalone_aliases : Standalone aliases are those defined outside of the record body; this may only be useful for faithfully reconstructing the Database according to its original source code. Keyed on alias to actual record name. aliases : Alias name to record name. paths : The path command specifies the current search path for use when loading database and database definition files. The addpath appends directory names to the current path. The path is used to locate the initial database file and included files. An empty dir at the beginning, middle, or end of a non-empty path string means the current directory. addpaths : See 'paths' above. breaktables : Breakpoint table (look-up table) of raw-to-engineering values. comments : Comments encountered while parsing the database. devices : Device support declarations (dset). drivers : Driver declarations (drvet). functions : Exported C function names. includes : Inline inclusion. Not supported just yet. links : Links. menus : Named value enumerations (enums). records : Record name to RecordInstance. record_types : Record type name to RecordType. registrars : Exported registrar function name. variables : IOC shell variables. \"\"\" standalone_aliases : Dict [ str , str ] = field ( default_factory = dict ) aliases : Dict [ str , str ] = field ( default_factory = dict ) paths : List [ str ] = field ( default_factory = list ) addpaths : List [ str ] = field ( default_factory = list ) breaktables : Dict [ str , List [ str ]] = field ( default_factory = dict ) comments : List [ str ] = field ( default_factory = list ) devices : List [ DatabaseDevice ] = field ( default_factory = list ) drivers : List [ str ] = field ( default_factory = list ) functions : List [ str ] = field ( default_factory = list ) includes : List [ str ] = field ( default_factory = list ) links : Dict [ str , str ] = field ( default_factory = dict ) menus : Dict [ str , DatabaseMenu ] = field ( default_factory = dict ) records : Dict [ str , RecordInstance ] = field ( default_factory = dict ) pva_groups : Dict [ str , RecordInstance ] = field ( default_factory = dict ) record_types : Dict [ str , RecordType ] = field ( default_factory = dict ) registrars : List [ str ] = field ( default_factory = list ) variables : Dict [ str , Optional [ str ]] = field ( default_factory = dict ) @classmethod def from_string ( cls , contents : str , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , include_aliases : bool = True , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a string.\"\"\" if dbd is not None and not isinstance ( dbd , Database ): dbd = Database . from_file ( dbd , version = version ) comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , f \"db.v { version } .lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : comments . append }, transformer = _DatabaseTransformer ( filename , dbd = dbd , lint = lint ), maybe_placeholders = False , # Per-user `gettempdir` caching of the LALR grammar analysis way of # passing ``True`` here: cache = True , ) if macro_context is not None : contents = macro_context . expand_by_line ( contents ) . rstrip () + \" \\n \" db , linter_results = grammar . parse ( contents ) db . comments = comments if include_aliases : for record_name , record in list ( db . records . items ()): for alias in record . aliases : db . records [ alias ] = record return db @classmethod def from_file_obj ( cls , fp , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a file object.\"\"\" return cls . from_string ( fp . read (), filename = filename or getattr ( fp , \"name\" , None ), dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ], dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) def field_names_by_type ( self , field_types : List [ str ] ) -> Dict [ str , FrozenSet [ str ]]: \"\"\" Generate dictionary of record type to frozenset of field names. This can be used in scenarios where database definition files are unavailable and link information is requested. Parameters ---------- field_types : list of str Field types to look for. \"\"\" by_rtype = {} for rtype , info in sorted ( self . record_types . items ()): by_rtype [ rtype ] = frozenset ( field . name for field in info . fields . values () if field . type in field_types ) return by_rtype def add_or_update_record ( self , record : RecordInstance ): \"\"\" Update (or add) records given a dictionary of records. \"\"\" if record . is_pva : existing_record = self . pva_groups . get ( record . name , None ) else : existing_record = self . records . get ( record . name , None ) if not existing_record : self . records [ record . name ] = record else : existing_record . update ( record ) def append ( self , other : Database ): \"\"\" Append the other database, best-effort updating existing entries. This is not likely to do everything correctly (TODO). \"\"\" for instance in other . records . values (): self . add_or_update_record ( instance ) for instance in other . pva_groups . values (): self . add_or_update_record ( instance ) def _update_list ( this , other ): this . extend ([ v for v in other if v not in this ]) _update_list ( self . addpaths , other . addpaths ) _update_list ( self . comments , other . comments ) _update_list ( self . devices , other . devices ) _update_list ( self . drivers , other . drivers ) _update_list ( self . functions , other . functions ) _update_list ( self . includes , other . includes ) _update_list ( self . paths , other . paths ) _update_list ( self . registrars , other . registrars ) self . aliases . update ( other . aliases ) self . breaktables . update ( other . breaktables ) self . links . update ( other . links ) self . menus . update ( other . menus ) self . record_types . update ( other . record_types or {}) self . standalone_aliases . update ( other . standalone_aliases ) self . variables . update ( other . variables ) @classmethod def from_multiple ( cls , * items : _DatabaseSource ) -> Database : \"\"\" Create a Database instance from multiple sources, including: * Other Database instances * LinterResults * LoadedIoc * ShellState \"\"\" from .shell import LoadedIoc , ShellState db = cls () for item in items : if isinstance ( item , Database ): db . append ( item ) elif isinstance ( item , LinterResults ): if item . db is not None : db . append ( item . db ) elif isinstance ( item , ( LoadedIoc , ShellState )): state = item . shell_state if isinstance ( item , LoadedIoc ) else item new_records = list ( state . database . values ()) + list ( state . pva_database . values ()) for record in new_records : db . add_or_update_record ( record ) db . aliases . update ( state . aliases ) else : raise ValueError ( f \"Expected { _DatabaseSource } , got { type ( item ) } \" ) return db","title":"Database"},{"location":"parsers/#whatrecord.db.Database-methods","text":"whatrecord . db . Database . add_or_update_record ( self , record : RecordInstance ) Update (or add) records given a dictionary of records. Source code in whatrecord/db.py def add_or_update_record ( self , record : RecordInstance ): \"\"\" Update (or add) records given a dictionary of records. \"\"\" if record . is_pva : existing_record = self . pva_groups . get ( record . name , None ) else : existing_record = self . records . get ( record . name , None ) if not existing_record : self . records [ record . name ] = record else : existing_record . update ( record ) whatrecord . db . Database . append ( self , other : Database ) Append the other database, best-effort updating existing entries. This is not likely to do everything correctly (TODO). Source code in whatrecord/db.py def append ( self , other : Database ): \"\"\" Append the other database, best-effort updating existing entries. This is not likely to do everything correctly (TODO). \"\"\" for instance in other . records . values (): self . add_or_update_record ( instance ) for instance in other . pva_groups . values (): self . add_or_update_record ( instance ) def _update_list ( this , other ): this . extend ([ v for v in other if v not in this ]) _update_list ( self . addpaths , other . addpaths ) _update_list ( self . comments , other . comments ) _update_list ( self . devices , other . devices ) _update_list ( self . drivers , other . drivers ) _update_list ( self . functions , other . functions ) _update_list ( self . includes , other . includes ) _update_list ( self . paths , other . paths ) _update_list ( self . registrars , other . registrars ) self . aliases . update ( other . aliases ) self . breaktables . update ( other . breaktables ) self . links . update ( other . links ) self . menus . update ( other . menus ) self . record_types . update ( other . record_types or {}) self . standalone_aliases . update ( other . standalone_aliases ) self . variables . update ( other . variables ) whatrecord . db . Database . field_names_by_type ( self , field_types : List [ str ]) -> Dict [ str , FrozenSet [ str ]] Generate dictionary of record type to frozenset of field names. This can be used in scenarios where database definition files are unavailable and link information is requested. Parameters: Name Type Description Default field_types List[str] Field types to look for. required Source code in whatrecord/db.py def field_names_by_type ( self , field_types : List [ str ] ) -> Dict [ str , FrozenSet [ str ]]: \"\"\" Generate dictionary of record type to frozenset of field names. This can be used in scenarios where database definition files are unavailable and link information is requested. Parameters ---------- field_types : list of str Field types to look for. \"\"\" by_rtype = {} for rtype , info in sorted ( self . record_types . items ()): by_rtype [ rtype ] = frozenset ( field . name for field in info . fields . values () if field . type in field_types ) return by_rtype whatrecord . db . Database . from_file ( fn : Union [ str , pathlib . Path ], dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None ) -> Database classmethod Load a database [definition] from a filename. Source code in whatrecord/db.py @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ], dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn , dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) whatrecord . db . Database . from_file_obj ( fp , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None ) -> Database classmethod Load a database [definition] from a file object. Source code in whatrecord/db.py @classmethod def from_file_obj ( cls , fp , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a file object.\"\"\" return cls . from_string ( fp . read (), filename = filename or getattr ( fp , \"name\" , None ), dbd = dbd , macro_context = macro_context , version = version , lint = lint , ) whatrecord . db . Database . from_multiple ( * items : _DatabaseSource ) -> Database classmethod Create a Database instance from multiple sources, including: Other Database instances LinterResults LoadedIoc ShellState Source code in whatrecord/db.py @classmethod def from_multiple ( cls , * items : _DatabaseSource ) -> Database : \"\"\" Create a Database instance from multiple sources, including: * Other Database instances * LinterResults * LoadedIoc * ShellState \"\"\" from .shell import LoadedIoc , ShellState db = cls () for item in items : if isinstance ( item , Database ): db . append ( item ) elif isinstance ( item , LinterResults ): if item . db is not None : db . append ( item . db ) elif isinstance ( item , ( LoadedIoc , ShellState )): state = item . shell_state if isinstance ( item , LoadedIoc ) else item new_records = list ( state . database . values ()) + list ( state . pva_database . values ()) for record in new_records : db . add_or_update_record ( record ) db . aliases . update ( state . aliases ) else : raise ValueError ( f \"Expected { _DatabaseSource } , got { type ( item ) } \" ) return db whatrecord . db . Database . from_string ( contents : str , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , include_aliases : bool = True , lint : Optional [ LinterResults ] = None ) -> Database classmethod Load a database [definition] from a string. Source code in whatrecord/db.py @classmethod def from_string ( cls , contents : str , dbd : Optional [ Union [ Database , str , pathlib . Path ]] = None , filename : Union [ str , pathlib . Path ] = None , macro_context : Optional [ MacroContext ] = None , version : int = 4 , include_aliases : bool = True , lint : Optional [ LinterResults ] = None , ) -> Database : \"\"\"Load a database [definition] from a string.\"\"\" if dbd is not None and not isinstance ( dbd , Database ): dbd = Database . from_file ( dbd , version = version ) comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , f \"db.v { version } .lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , lexer_callbacks = { \"COMMENT\" : comments . append }, transformer = _DatabaseTransformer ( filename , dbd = dbd , lint = lint ), maybe_placeholders = False , # Per-user `gettempdir` caching of the LALR grammar analysis way of # passing ``True`` here: cache = True , ) if macro_context is not None : contents = macro_context . expand_by_line ( contents ) . rstrip () + \" \\n \" db , linter_results = grammar . parse ( contents ) db . comments = comments if include_aliases : for record_name , record in list ( db . records . items ()): for alias in record . aliases : db . records [ alias ] = record return db","title":"Methods"},{"location":"parsers/#whatrecord.db.DatabaseLoadFailure","text":"Database load failure. Source code in whatrecord/db.py class DatabaseLoadFailure ( Exception ): \"\"\"Database load failure.\"\"\" ...","title":"DatabaseLoadFailure"},{"location":"parsers/#whatrecord.db.LinterResults","text":"Container for dbdlint results, with easier-to-access attributes. Reimplementation of pyPDB.dbdlint.Results . Each error or warning has dictionary keys:: {name, message, file, line, raw_message, format_args} Attributes: Name Type Description errors list List of errors found warnings list List of warnings found Source code in whatrecord/db.py @dataclass ( repr = False ) class LinterResults : \"\"\" Container for dbdlint results, with easier-to-access attributes. Reimplementation of ``pyPDB.dbdlint.Results``. Each error or warning has dictionary keys:: {name, message, file, line, raw_message, format_args} Attributes ---------- errors : list List of errors found warnings : list List of warnings found \"\"\" macros : Dict [ str , str ] = field ( default_factory = dict ) errors : List [ LinterError ] = field ( default_factory = list ) warnings : List [ LinterWarning ] = field ( default_factory = list ) db : Optional [ Database ] = field ( default = None , metadata = apischema . metadata . skip ) dbd : Optional [ Database ] = field ( default = None , metadata = apischema . metadata . skip ) @classmethod def from_database_string ( cls , db : str , dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , db_filename : Optional [ Union [ str , pathlib . Path ]] = None , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database source. dbd : Database The pre-loaded database definition. Returns ------- results : LinterResults \"\"\" lint = cls () if dbd and not isinstance ( dbd , Database ): raise ValueError ( \"dbd should be a Database instance\" ) # The following fills `lint`, for better or worse database = Database . from_string ( db , dbd = dbd , macro_context = macro_context , version = version , lint = lint , filename = db_filename ) lint . db = database lint . dbd = dbd lint . macros = dict ( macro_context or {}) return lint @classmethod def from_database_file ( cls , db_filename : Union [ str , pathlib . Path ], dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database filename. dbd : Database The database definition. version : int, optional Use the old V3 style or new V3 style database grammar by specifying 3 or 4, respectively. Defaults to 3. Returns ------- results : LinterResults db : Database \"\"\" with open ( db_filename , \"rt\" ) as fp : db = fp . read () return cls . from_database_string ( db = db , dbd = dbd , db_filename = db_filename , macro_context = macro_context , version = version , ) @property def record_types ( self ) -> Optional [ Dict [ str , RecordType ]]: \"\"\"Defined record types.\"\"\" if self . dbd is not None : return self . dbd . record_types return self . db . record_types if self . db is not None else {} @property def records ( self ) -> Optional [ Dict [ str , RecordInstance ]]: \"\"\"Defined V3 records.\"\"\" return self . db . records if self . db is not None else {} @property def pva_groups ( self ) -> Optional [ Dict [ str , RecordInstance ]]: \"\"\"Defined PVAccess groups.\"\"\" return self . db . pva_groups if self . db is not None else {} def __repr__ ( self ): return ( f \"< { self . __class__ . __name__ } \" f \"records= { len ( self . records ) } \" f \"pva_groups= { len ( self . pva_groups ) } \" f \"errors= { len ( self . errors ) } \" f \"warnings= { len ( self . warnings ) } \" f \">\" )","title":"LinterResults"},{"location":"parsers/#whatrecord.db.LinterResults-attributes","text":"whatrecord . db . LinterResults . pva_groups : Optional [ Dict [ str , RecordInstance ]] property readonly Defined PVAccess groups. whatrecord . db . LinterResults . record_types : Optional [ Dict [ str , RecordType ]] property readonly Defined record types. whatrecord . db . LinterResults . records : Optional [ Dict [ str , RecordInstance ]] property readonly Defined V3 records.","title":"Attributes"},{"location":"parsers/#whatrecord.db.LinterResults-methods","text":"whatrecord . db . LinterResults . from_database_file ( db_filename : Union [ str , pathlib . Path ], dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , version : int = 3 ) -> LinterResults classmethod Lint a db (database) file using its database definition file (dbd). Parameters: Name Type Description Default db str The database filename. required dbd Optional[Database] The database definition. None version int Use the old V3 style or new V3 style database grammar by specifying 3 or 4, respectively. Defaults to 3. 3 Source code in whatrecord/db.py @classmethod def from_database_file ( cls , db_filename : Union [ str , pathlib . Path ], dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database filename. dbd : Database The database definition. version : int, optional Use the old V3 style or new V3 style database grammar by specifying 3 or 4, respectively. Defaults to 3. Returns ------- results : LinterResults db : Database \"\"\" with open ( db_filename , \"rt\" ) as fp : db = fp . read () return cls . from_database_string ( db = db , dbd = dbd , db_filename = db_filename , macro_context = macro_context , version = version , ) whatrecord . db . LinterResults . from_database_string ( db : str , dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , db_filename : Optional [ Union [ str , pathlib . Path ]] = None , version : int = 3 ) -> LinterResults classmethod Lint a db (database) file using its database definition file (dbd). Parameters: Name Type Description Default db str The database source. required dbd Optional[Database] The pre-loaded database definition. None Source code in whatrecord/db.py @classmethod def from_database_string ( cls , db : str , dbd : Optional [ Database ] = None , macro_context : Optional [ MacroContext ] = None , * , db_filename : Optional [ Union [ str , pathlib . Path ]] = None , version : int = 3 , ) -> LinterResults : \"\"\" Lint a db (database) file using its database definition file (dbd). Parameters ---------- db : str The database source. dbd : Database The pre-loaded database definition. Returns ------- results : LinterResults \"\"\" lint = cls () if dbd and not isinstance ( dbd , Database ): raise ValueError ( \"dbd should be a Database instance\" ) # The following fills `lint`, for better or worse database = Database . from_string ( db , dbd = dbd , macro_context = macro_context , version = version , lint = lint , filename = db_filename ) lint . db = database lint . dbd = dbd lint . macros = dict ( macro_context or {}) return lint","title":"Methods"},{"location":"parsers/#whatrecord.db.UnquotedString","text":"An unquoted string token found when loading a database file. May be a linter warning. Source code in whatrecord/db.py class UnquotedString ( str ): \"\"\" An unquoted string token found when loading a database file. May be a linter warning. \"\"\" ...","title":"UnquotedString"},{"location":"parsers/#whatrecord.db-functions","text":"","title":"Functions"},{"location":"parsers/#whatrecord.db.split_record_and_field","text":"Split REC.FLD into REC and FLD. Source code in whatrecord/db.py def split_record_and_field ( pvname ) -> Tuple [ str , str ]: \"\"\"Split REC.FLD into REC and FLD.\"\"\" record , * field = pvname . split ( \".\" , 1 ) return record , field [ 0 ] if field else \"\"","title":"split_record_and_field()"},{"location":"parsers/#whatrecord.dbtemplate","text":"dbLoadTemplate and msi -S substitution grammar helpers.","title":"dbtemplate"},{"location":"parsers/#whatrecord.dbtemplate-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.dbtemplate.GlobalDefinitions","text":"Global variable definitions. Source code in whatrecord/dbtemplate.py @dataclass class GlobalDefinitions ( VariableDefinitions ): \"\"\"Global variable definitions.\"\"\"","title":"GlobalDefinitions"},{"location":"parsers/#whatrecord.dbtemplate.PatternHeader","text":"Pattern header. Source code in whatrecord/dbtemplate.py @dataclass class PatternHeader : \"\"\"Pattern header.\"\"\" context : FullLoadContext patterns : List [ str ]","title":"PatternHeader"},{"location":"parsers/#whatrecord.dbtemplate.PatternValues","text":"Pattern values. Source code in whatrecord/dbtemplate.py @dataclass class PatternValues : \"\"\"Pattern values.\"\"\" context : FullLoadContext values : List [ str ]","title":"PatternValues"},{"location":"parsers/#whatrecord.dbtemplate.Substitution","text":"Single database template file from a full template. Represents approximately one line of a .substitutions file. For example, in this substitution file, file template.txt { pattern {a, b, c} {A, B, C} } The resulting Substitution would be Substitution(macros={\"a\": \"A\", \"b\": \"B\", \"c\": \"C\"}, filename=\"template.txt\") . Global macro values will be aggregated into this dictionary. Inside of the template file - template.txt above: * \"include\" is a supported command for the template file. * \"substitute\" is optionally supported (set allow_substitute ) Source code in whatrecord/dbtemplate.py @dataclass class Substitution : \"\"\" Single database template file from a full template. Represents approximately one line of a .substitutions file. For example, in this substitution file, ``` file template.txt { pattern {a, b, c} {A, B, C} } ``` The resulting Substitution would be ``Substitution(macros={\"a\": \"A\", \"b\": \"B\", \"c\": \"C\"}, filename=\"template.txt\")``. Global macro values will be aggregated into this dictionary. Inside of the template file - ``template.txt`` above: * \"include\" is a supported command for the template file. * \"substitute\" is optionally supported (set ``allow_substitute``) \"\"\" context : FullLoadContext filename : Optional [ str ] = None macros : Dict [ str , str ] = field ( default_factory = dict ) use_environment : bool = False allow_substitute : bool = True _items : Optional [ List [ Any ]] = field ( default_factory = list , metadata = apischema . metadata . skip , ) def expand_file ( self , * , filename : Optional [ str ] = None , search_paths : Optional [ List [ AnyPath ]] = None ) -> str : \"\"\" Expand the given file, looking in ``search_paths`` for template files. Parameters ---------- filename : str, optional Expand this file or fall back to the instance-defined filename. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" filename = filename or self . filename if filename is None : raise ValueError ( \"This substitution does not have a file defined\" ) filename = pathlib . Path ( filename ) search_paths = search_paths or [ filename . resolve () . parent ] with open ( self . filename , \"rt\" ) as fp : return self . expand ( fp . read (), search_paths = search_paths ) @property def macro_context ( self ) -> MacroContext : \"\"\"The macro context to be used when expanding the template.\"\"\" ctx = MacroContext ( use_environment = self . use_environment ) ctx . define ( ** self . macros ) return ctx @staticmethod def handle_include ( filename : str , search_paths : List [ AnyPath ]) -> str : \"\"\"Expand include files from the given search path.\"\"\" for path in search_paths : option = pathlib . Path ( path ) / filename if option . exists (): with open ( option , \"rt\" ) as fp : return fp . read () friendly_paths = \" or \" . join ( f '\" { path } \"' for path in search_paths ) raise FileNotFoundError ( f \" { filename } not found in { friendly_paths } \" ) def expand ( self , source : str , search_paths : Optional [ List [ AnyPath ]] = None ): \"\"\" Expand the provided substitution template, using the macro environment. Parameters ---------- source : str The source substitution template. May contain \"include\" or \"substitute\" lines. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" ctx = self . macro_context search_paths = search_paths or [ pathlib . Path ( \".\" )] results = [] source_stack = collections . deque ( source . splitlines ()) while source_stack : line = source_stack . popleft () logger . debug ( \"line %r \" , line ) line = ctx . expand ( line ) command , * command_args = line . strip () . split ( \" \" , 1 ) if command == \"include\" : # case sensitive args = shlex . split ( command_args [ 0 ]) if len ( args ) != 1 : raise ValueError ( f \"Include command takes one argument; got: { args } \" f \"where line= { line !r} \" ) include_file = args [ 0 ] logger . debug ( \"Including file from %s \" , include_file ) include_source = self . handle_include ( include_file , search_paths ) source_stack . extendleft ( reversed ( include_source . splitlines ())) logger . debug ( \"stack %r \" , source_stack ) elif command == \"substitute\" and self . allow_substitute : # Note that dbLoadTemplate does not support substitute, but msi # does. macro_string = command_args [ 0 ] . strip () # Strip only single beginning and end quotes macro_string = _strip_double_quote ( macro_string ) . strip () logger . debug ( \"Substituting additional macros %s \" , macro_string ) ctx . define_from_string ( macro_string ) else : results . append ( line ) return \" \\n \" . join ( results )","title":"Substitution"},{"location":"parsers/#whatrecord.dbtemplate.Substitution-attributes","text":"whatrecord . dbtemplate . Substitution . macro_context : MacroContext property readonly The macro context to be used when expanding the template.","title":"Attributes"},{"location":"parsers/#whatrecord.dbtemplate.Substitution-methods","text":"whatrecord . dbtemplate . Substitution . expand ( self , source : str , search_paths : Optional [ List [ AnyPath ]] = None ) Expand the provided substitution template, using the macro environment. Parameters: Name Type Description Default source str The source substitution template. May contain \"include\" or \"substitute\" lines. required search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand ( self , source : str , search_paths : Optional [ List [ AnyPath ]] = None ): \"\"\" Expand the provided substitution template, using the macro environment. Parameters ---------- source : str The source substitution template. May contain \"include\" or \"substitute\" lines. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" ctx = self . macro_context search_paths = search_paths or [ pathlib . Path ( \".\" )] results = [] source_stack = collections . deque ( source . splitlines ()) while source_stack : line = source_stack . popleft () logger . debug ( \"line %r \" , line ) line = ctx . expand ( line ) command , * command_args = line . strip () . split ( \" \" , 1 ) if command == \"include\" : # case sensitive args = shlex . split ( command_args [ 0 ]) if len ( args ) != 1 : raise ValueError ( f \"Include command takes one argument; got: { args } \" f \"where line= { line !r} \" ) include_file = args [ 0 ] logger . debug ( \"Including file from %s \" , include_file ) include_source = self . handle_include ( include_file , search_paths ) source_stack . extendleft ( reversed ( include_source . splitlines ())) logger . debug ( \"stack %r \" , source_stack ) elif command == \"substitute\" and self . allow_substitute : # Note that dbLoadTemplate does not support substitute, but msi # does. macro_string = command_args [ 0 ] . strip () # Strip only single beginning and end quotes macro_string = _strip_double_quote ( macro_string ) . strip () logger . debug ( \"Substituting additional macros %s \" , macro_string ) ctx . define_from_string ( macro_string ) else : results . append ( line ) return \" \\n \" . join ( results ) whatrecord . dbtemplate . Substitution . expand_file ( self , * , filename : Optional [ str ] = None , search_paths : Optional [ List [ AnyPath ]] = None ) -> str Expand the given file, looking in search_paths for template files. Parameters: Name Type Description Default filename Optional[str] Expand this file or fall back to the instance-defined filename. None search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand_file ( self , * , filename : Optional [ str ] = None , search_paths : Optional [ List [ AnyPath ]] = None ) -> str : \"\"\" Expand the given file, looking in ``search_paths`` for template files. Parameters ---------- filename : str, optional Expand this file or fall back to the instance-defined filename. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" filename = filename or self . filename if filename is None : raise ValueError ( \"This substitution does not have a file defined\" ) filename = pathlib . Path ( filename ) search_paths = search_paths or [ filename . resolve () . parent ] with open ( self . filename , \"rt\" ) as fp : return self . expand ( fp . read (), search_paths = search_paths ) whatrecord . dbtemplate . Substitution . handle_include ( filename : str , search_paths : List [ AnyPath ]) -> str staticmethod Expand include files from the given search path. Source code in whatrecord/dbtemplate.py @staticmethod def handle_include ( filename : str , search_paths : List [ AnyPath ]) -> str : \"\"\"Expand include files from the given search path.\"\"\" for path in search_paths : option = pathlib . Path ( path ) / filename if option . exists (): with open ( option , \"rt\" ) as fp : return fp . read () friendly_paths = \" or \" . join ( f '\" { path } \"' for path in search_paths ) raise FileNotFoundError ( f \" { filename } not found in { friendly_paths } \" )","title":"Methods"},{"location":"parsers/#whatrecord.dbtemplate.TemplateSubstitution","text":"Database substitutions, containing zero or more template files. Source code in whatrecord/dbtemplate.py @dataclass class TemplateSubstitution : \"\"\"Database substitutions, containing zero or more template files.\"\"\" substitutions : List [ Substitution ] = field ( default_factory = list ) def expand_template ( self , template : str , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" , ) -> str : \"\"\" Expands all substitutions for the given string. Parameters ---------- template : str The template text. delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand ( template , search_paths = search_paths ) for sub in self . substitutions ) def expand_files ( self , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" ) -> str : \"\"\" Expands and combines all contained substitution files. Parameters ---------- delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand_file ( search_paths = search_paths ) for sub in self . substitutions ) @classmethod def from_string ( cls , contents , filename = None , msi_format = False , all_global_scope = False , ) -> TemplateSubstitution : \"\"\"Load a template substitutions file given its string contents.\"\"\" comments = [] grammar_filename = \"msi-sub.lark\" if msi_format else \"dbtemplate.lark\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , grammar_filename , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: This is unsupported in lark: # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = False , propagate_positions = True , ) if msi_format : tr = _TemplateMsiTransformer ( cls , filename , all_global_scope = all_global_scope ) else : tr = _TemplateTransformer ( cls , filename ) subs = tr . transform ( grammar . parse ( contents )) subs . comments = comments return subs @classmethod def from_file_obj ( cls , fp , filename = None ) -> TemplateSubstitution : \"\"\"Load a template file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) @classmethod def from_file ( cls , fn ) -> TemplateSubstitution : \"\"\" Load a template file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- template : TemplateSubstitution The template file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn )","title":"TemplateSubstitution"},{"location":"parsers/#whatrecord.dbtemplate.TemplateSubstitution-methods","text":"whatrecord . dbtemplate . TemplateSubstitution . expand_files ( self , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = ' \\n ' ) -> str Expands and combines all contained substitution files. Parameters: Name Type Description Default delimiter str Delimiter to join individual substitutions. '\\n' search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand_files ( self , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" ) -> str : \"\"\" Expands and combines all contained substitution files. Parameters ---------- delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand_file ( search_paths = search_paths ) for sub in self . substitutions ) whatrecord . dbtemplate . TemplateSubstitution . expand_template ( self , template : str , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = ' \\n ' ) -> str Expands all substitutions for the given string. Parameters: Name Type Description Default template str The template text. required delimiter str Delimiter to join individual substitutions. '\\n' search_paths Optional[List[AnyPath]] List of paths to search for template files. None Source code in whatrecord/dbtemplate.py def expand_template ( self , template : str , search_paths : Optional [ List [ AnyPath ]] = None , delimiter : str = \" \\n \" , ) -> str : \"\"\" Expands all substitutions for the given string. Parameters ---------- template : str The template text. delimiter : str, optional Delimiter to join individual substitutions. search_paths : list of str or pathlib.Path, optional List of paths to search for template files. \"\"\" return delimiter . join ( sub . expand ( template , search_paths = search_paths ) for sub in self . substitutions ) whatrecord . dbtemplate . TemplateSubstitution . from_file ( fn ) -> TemplateSubstitution classmethod Load a template file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description TemplateSubstitution The template file. Source code in whatrecord/dbtemplate.py @classmethod def from_file ( cls , fn ) -> TemplateSubstitution : \"\"\" Load a template file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- template : TemplateSubstitution The template file. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) whatrecord . dbtemplate . TemplateSubstitution . from_file_obj ( fp , filename = None ) -> TemplateSubstitution classmethod Load a template file given a file object. Source code in whatrecord/dbtemplate.py @classmethod def from_file_obj ( cls , fp , filename = None ) -> TemplateSubstitution : \"\"\"Load a template file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) whatrecord . dbtemplate . TemplateSubstitution . from_string ( contents , filename = None , msi_format = False , all_global_scope = False ) -> TemplateSubstitution classmethod Load a template substitutions file given its string contents. Source code in whatrecord/dbtemplate.py @classmethod def from_string ( cls , contents , filename = None , msi_format = False , all_global_scope = False , ) -> TemplateSubstitution : \"\"\"Load a template substitutions file given its string contents.\"\"\" comments = [] grammar_filename = \"msi-sub.lark\" if msi_format else \"dbtemplate.lark\" grammar = lark . Lark . open_from_package ( \"whatrecord\" , grammar_filename , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: This is unsupported in lark: # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = False , propagate_positions = True , ) if msi_format : tr = _TemplateMsiTransformer ( cls , filename , all_global_scope = all_global_scope ) else : tr = _TemplateTransformer ( cls , filename ) subs = tr . transform ( grammar . parse ( contents )) subs . comments = comments return subs","title":"Methods"},{"location":"parsers/#whatrecord.dbtemplate.VariableDefinitions","text":"Variable definitions. Source code in whatrecord/dbtemplate.py @dataclass class VariableDefinitions : \"\"\"Variable definitions.\"\"\" context : FullLoadContext definitions : Dict [ str , str ] = field ( default_factory = dict )","title":"VariableDefinitions"},{"location":"parsers/#whatrecord.gateway","text":"","title":"gateway"},{"location":"parsers/#whatrecord.gateway-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.gateway.AccessSecurity","text":"A PVList rule access security settings. Source code in whatrecord/gateway.py @dataclass class AccessSecurity : \"\"\"A PVList rule access security settings.\"\"\" group : Optional [ str ] = None level : Optional [ str ] = None","title":"AccessSecurity"},{"location":"parsers/#whatrecord.gateway.AliasRule","text":"Rule to alias the pattern to a PV (or PVs). Source code in whatrecord/gateway.py @dataclass class AliasRule ( Rule ): \"\"\"Rule to alias the pattern to a PV (or PVs).\"\"\" pvname : str = \"\" access : Optional [ AccessSecurity ] = None","title":"AliasRule"},{"location":"parsers/#whatrecord.gateway.AllowRule","text":"Rule to allow access to a PV pattern. Source code in whatrecord/gateway.py @dataclass class AllowRule ( Rule ): \"\"\"Rule to allow access to a PV pattern.\"\"\" access : Optional [ AccessSecurity ] = None","title":"AllowRule"},{"location":"parsers/#whatrecord.gateway.DenyRule","text":"Rule to deny access to a PV pattern. Source code in whatrecord/gateway.py @dataclass class DenyRule ( Rule ): \"\"\"Rule to deny access to a PV pattern.\"\"\" hosts : List [ str ] = field ( default_factory = list )","title":"DenyRule"},{"location":"parsers/#whatrecord.gateway.GatewayConfig","text":"Source code in whatrecord/gateway.py class GatewayConfig : pvlists : Dict [ pathlib . Path , PVList ] def __init__ ( self , path : Union [ str , pathlib . Path ], glob_str : str = \"*.pvlist\" ): path = pathlib . Path ( path ) . resolve () if path . is_file (): filenames = [ path ] else : filenames = [ p . resolve () for p in path . glob ( glob_str )] self . pvlists = { filename : PVList . from_file ( filename ) for filename in filenames } def _update ( self , filename ): \"\"\"Update a gateway configuration file.\"\"\" self . pvlists [ filename ] = PVList . from_file ( filename ) def update_changed ( self ): \"\"\"Update any changed files.\"\"\" for filename , pvlist in self . pvlists . items (): if get_file_sha256 ( filename ) != pvlist . hash : logger . info ( \"Updating changed gateway file: %s \" , filename ) self . _update ( filename ) def get_matches ( self , name : str , remove_any : bool = True ) -> PVListMatches : \"\"\"Get matches from any PVList given a PV name.\"\"\" matches = [ PVListMatch ( filename = str ( fn ), rule = rule , groups = groups , ) for fn , pvlist in self . pvlists . items () for rule , groups in pvlist . match ( name ) if rule . pattern != \".*\" or not remove_any ] return PVListMatches ( name = name , matches = matches , )","title":"GatewayConfig"},{"location":"parsers/#whatrecord.gateway.GatewayConfig-methods","text":"whatrecord . gateway . GatewayConfig . get_matches ( self , name : str , remove_any : bool = True ) -> PVListMatches Get matches from any PVList given a PV name. Source code in whatrecord/gateway.py def get_matches ( self , name : str , remove_any : bool = True ) -> PVListMatches : \"\"\"Get matches from any PVList given a PV name.\"\"\" matches = [ PVListMatch ( filename = str ( fn ), rule = rule , groups = groups , ) for fn , pvlist in self . pvlists . items () for rule , groups in pvlist . match ( name ) if rule . pattern != \".*\" or not remove_any ] return PVListMatches ( name = name , matches = matches , ) whatrecord . gateway . GatewayConfig . update_changed ( self ) Update any changed files. Source code in whatrecord/gateway.py def update_changed ( self ): \"\"\"Update any changed files.\"\"\" for filename , pvlist in self . pvlists . items (): if get_file_sha256 ( filename ) != pvlist . hash : logger . info ( \"Updating changed gateway file: %s \" , filename ) self . _update ( filename )","title":"Methods"},{"location":"parsers/#whatrecord.gateway.PVList","text":"A PVList container. Source code in whatrecord/gateway.py @dataclass class PVList : \"\"\"A PVList container.\"\"\" filename : Optional [ str ] = None evaluation_order : Optional [ str ] = None rules : List [ Rule ] = field ( default_factory = list ) hash : Optional [ str ] = None header : str = \"\" comments : List [ lark . Token ] = field ( default_factory = list , metadata = apischema . metadata . skip , ) def find ( self , cls : typing . Type ) -> Generator [ Rule , None , None ]: \"\"\"Yield matching rule types.\"\"\" for rule in self . rules : if isinstance ( rule , cls ): yield rule def match ( self , name : str ) -> Generator [ Tuple [ Rule , List [ str ]], None , None ]: \"\"\"Yield matching rules.\"\"\" for rule in self . rules : m = rule . match ( name ) if m : yield rule , list ( m . groups ()) @classmethod def from_string ( cls , contents : str , filename : Optional [ str ] = None ): contents_hash = get_bytes_sha256 ( contents . encode ( \"utf-8\" )) comments = [] def add_comment ( comment : lark . Token ): comments . append ( StringWithContext ( str ( comment ) . lstrip ( \"# \" ), context = context_from_lark_token ( filename , comment ), ) ) grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"gateway.lark\" , search_paths = ( \"grammar\" , ), parser = \"lalr\" , maybe_placeholders = False , lexer_callbacks = { \"COMMENT\" : add_comment }, transformer = _PVListTransformer ( filename , contents_hash , comments ), ) # Sorry, the grammar isn't perfect: require a newline for rules pvlist : PVList = grammar . parse ( f \" { contents . strip () } \\n \" ) pvlist . comments = comments return pvlist @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ): \"\"\"Load a PVList from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]): \"\"\"Load a PVList from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn ))","title":"PVList"},{"location":"parsers/#whatrecord.gateway.PVList-methods","text":"whatrecord . gateway . PVList . find ( self , cls : Type ) -> Generator [ whatrecord . gateway . Rule , NoneType , NoneType ] Yield matching rule types. Source code in whatrecord/gateway.py def find ( self , cls : typing . Type ) -> Generator [ Rule , None , None ]: \"\"\"Yield matching rule types.\"\"\" for rule in self . rules : if isinstance ( rule , cls ): yield rule whatrecord . gateway . PVList . from_file ( fn : Union [ str , pathlib . Path ]) classmethod Load a PVList from a filename. Source code in whatrecord/gateway.py @classmethod def from_file ( cls , fn : Union [ str , pathlib . Path ]): \"\"\"Load a PVList from a filename.\"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_file_obj ( fp , filename = str ( fn )) whatrecord . gateway . PVList . from_file_obj ( fp , filename : Optional [ str ] = None ) classmethod Load a PVList from a file object. Source code in whatrecord/gateway.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ str ] = None ): \"\"\"Load a PVList from a file object.\"\"\" filename = filename or getattr ( fp , \"name\" , str ( id ( fp ))) return cls . from_string ( fp . read (), filename = filename ) whatrecord . gateway . PVList . match ( self , name : str ) -> Generator [ Tuple [ whatrecord . gateway . Rule , List [ str ]], NoneType , NoneType ] Yield matching rules. Source code in whatrecord/gateway.py def match ( self , name : str ) -> Generator [ Tuple [ Rule , List [ str ]], None , None ]: \"\"\"Yield matching rules.\"\"\" for rule in self . rules : m = rule . match ( name ) if m : yield rule , list ( m . groups ())","title":"Methods"},{"location":"parsers/#whatrecord.gateway.PVListMatch","text":"PVListMatch(filename: str, rule: whatrecord.gateway.Rule, groups: List[str]) Source code in whatrecord/gateway.py @dataclass class PVListMatch : filename : str rule : Rule groups : List [ str ]","title":"PVListMatch"},{"location":"parsers/#whatrecord.gateway.PVListMatches","text":"PVListMatches(name: str, matches: List[whatrecord.gateway.PVListMatch]) Source code in whatrecord/gateway.py @dataclass class PVListMatches : name : str matches : List [ PVListMatch ]","title":"PVListMatches"},{"location":"parsers/#whatrecord.gateway.Rule","text":"A PVList rule (base class). Source code in whatrecord/gateway.py @dataclass class Rule : \"\"\"A PVList rule (base class).\"\"\" context : FullLoadContext pattern : str command : str regex : typing . Pattern = field ( default = None , metadata = apischema . metadata . skip ) header : str = \"\" metadata : Dict [ str , str ] = field ( default_factory = dict ) def __post_init__ ( self ): if self . regex is None : try : self . regex = re . compile ( self . pattern ) except Exception as ex : self . metadata [ \"error\" ] = ( f \"Invalid regex. { ex . __class__ . __name__ } : { ex } \" ) def match ( self , name ): \"\"\"Match a pv name against this rule.\"\"\" if self . regex is not None : return self . regex . fullmatch ( name )","title":"Rule"},{"location":"parsers/#whatrecord.gateway.Rule-methods","text":"whatrecord . gateway . Rule . match ( self , name ) Match a pv name against this rule. Source code in whatrecord/gateway.py def match ( self , name ): \"\"\"Match a pv name against this rule.\"\"\" if self . regex is not None : return self . regex . fullmatch ( name )","title":"Methods"},{"location":"parsers/#whatrecord.gateway-functions","text":"","title":"Functions"},{"location":"parsers/#whatrecord.gateway.create_arg_parser","text":"Create the argument parser. Source code in whatrecord/gateway.py def create_arg_parser (): \"\"\"Create the argument parser.\"\"\" parser = argparse . ArgumentParser ( description = \"pvlist name matching and linting tool\" , ) parser . add_argument ( \"--lint\" , action = \"store_true\" , help = \"Lint regular expressions\" ) parser . add_argument ( \"--pvlists\" , type = str , nargs = \"*\" , help = \"Specific pvlists to check (empty for all)\" , ) parser . add_argument ( \"--hide-context\" , action = \"store_true\" , help = \"Hide comment context\" ) parser . add_argument ( \"--remove-any\" , action = \"store_true\" , help = \"Remove '.*' from results\" ) parser . add_argument ( \"names\" , nargs = \"*\" , type = str , help = \"PV names to match\" ) return parser","title":"create_arg_parser()"},{"location":"parsers/#whatrecord.snl","text":"","title":"snl"},{"location":"parsers/#whatrecord.snl-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.snl.AbstractDeclarator","text":"AbstractDeclarator(context: 'FullLoadContext', params: 'Optional[Sequence[ParameterDeclarator]]' = None, subscript: 'Optional[str]' = None, inner_decl: 'Optional[AbstractDeclarator]' = None) Source code in whatrecord/snl.py @dataclass class AbstractDeclarator : context : FullLoadContext params : Optional [ Sequence [ ParameterDeclarator ]] = None subscript : Optional [ str ] = None inner_decl : Optional [ AbstractDeclarator ] = None def __str__ ( self ) -> str : prefix = f \" { str ( self . inner_decl ) . strip () } \" if self . inner_decl is not None else \"\" if self . subscript is not None : return f \" { prefix }{ self . subscript } \" if self . params is not None : params = \", \" . join ( str ( param ) for param in self . params ) return f \" { prefix } ( { params } )\" return prefix . strip ()","title":"AbstractDeclarator"},{"location":"parsers/#whatrecord.snl.AbstractDeclaratorModifier","text":"AbstractDeclaratorModifier(context: 'FullLoadContext', modifier: 'str', decl: 'Optional[AbstractDeclarator]' = None) Source code in whatrecord/snl.py @dataclass class AbstractDeclaratorModifier : context : FullLoadContext modifier : str decl : Optional [ AbstractDeclarator ] = None def __str__ ( self ) -> str : if self . modifier == \"(\" : # ) return f \"( { self . decl } )\" if self . modifier == \"*\" : return f \"* { self . decl or '' } \" return f \" { self . modifier } { self . decl or '' } \"","title":"AbstractDeclaratorModifier"},{"location":"parsers/#whatrecord.snl.Assignment","text":"Assignment(context: 'FullLoadContext', variable: 'str', value: 'Optional[Union[str, Sequence[str]]]' = None, subscript: 'Optional[str]' = None) Source code in whatrecord/snl.py @dataclass class Assignment ( Definition ): variable : str value : Optional [ Union [ str , Sequence [ str ]]] = None subscript : Optional [ str ] = None def __str__ ( self ) -> str : if isinstance ( self . value , tuple ): value = \"{ \" + \", \" . join ( str ( s ) for s in self . value ) + \"}\" else : value = str ( self . value ) return f \" { self . variable }{ self . subscript or '' } = { value } ;\"","title":"Assignment"},{"location":"parsers/#whatrecord.snl.BinaryOperatorExpression","text":"BinaryOperatorExpression(context: 'FullLoadContext', left: 'Expression', operator: 'str', right: 'Expression') Source code in whatrecord/snl.py @dataclass class BinaryOperatorExpression ( Expression ): left : Expression operator : str right : Expression def __str__ ( self ) -> str : return f \" { self . left } { self . operator } { self . right } \"","title":"BinaryOperatorExpression"},{"location":"parsers/#whatrecord.snl.Block","text":"Block(context: 'FullLoadContext', definitions: 'Sequence[Definition]' = , statements: 'Sequence[Statement]' = ) Source code in whatrecord/snl.py @dataclass class Block : context : FullLoadContext definitions : Sequence [ Definition ] = field ( default_factory = list ) statements : Sequence [ Statement ] = field ( default_factory = list ) def __str__ ( self ) -> str : definitions = textwrap . indent ( \" \\n \" . join ( str ( defn ) for defn in self . definitions ), prefix = \" \" , ) statements = textwrap . indent ( \" \\n \" . join ( str ( statement ) for statement in self . statements ), prefix = \" \" , ) return \" \\n \" . join ( ( \"{\" , definitions , statements , \"}\" , ) )","title":"Block"},{"location":"parsers/#whatrecord.snl.BracketedExpression","text":"BracketedExpression(context: 'FullLoadContext', outer: 'Expression', inner: 'Expression') Source code in whatrecord/snl.py @dataclass class BracketedExpression ( Expression ): outer : Expression inner : Expression def __str__ ( self ) -> str : return f \" { self . outer } [ { self . inner } ]\"","title":"BracketedExpression"},{"location":"parsers/#whatrecord.snl.BreakStatement","text":"BreakStatement(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class BreakStatement ( Statement ): def __str__ ( self ) -> str : return \"break;\"","title":"BreakStatement"},{"location":"parsers/#whatrecord.snl.CCode","text":"CCode(context: 'FullLoadContext', code: 'str') Source code in whatrecord/snl.py @dataclass class CCode ( Definition ): code : str def __str__ ( self ) -> str : return self . code","title":"CCode"},{"location":"parsers/#whatrecord.snl.CommaSeparatedExpressions","text":"CommaSeparatedExpressions(context: 'FullLoadContext', expressions: 'List[Expression]') Source code in whatrecord/snl.py @dataclass class CommaSeparatedExpressions ( Expression ): expressions : List [ Expression ] def __str__ ( self ) -> str : return \", \" . join ( str ( item ) for item in self . expressions )","title":"CommaSeparatedExpressions"},{"location":"parsers/#whatrecord.snl.ContinueStatement","text":"ContinueStatement(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class ContinueStatement ( Statement ): def __str__ ( self ) -> str : return \"continue;\"","title":"ContinueStatement"},{"location":"parsers/#whatrecord.snl.Declaration","text":"Declaration(context: 'FullLoadContext', type: 'Optional[Type]' = None, declarators: 'Optional[Sequence[Declarator]]' = ) Source code in whatrecord/snl.py @dataclass class Declaration ( Definition ): type : Optional [ Type ] = None declarators : Optional [ Sequence [ Declarator ]] = field ( default_factory = list ) def __str__ ( self ) -> str : declarators = \", \" . join ( str ( decl ) for decl in self . declarators or []) return f \" { self . type } { declarators } ;\"","title":"Declaration"},{"location":"parsers/#whatrecord.snl.Declarator","text":"Declarator(context: 'FullLoadContext', object: 'Union[Declarator, Variable]', params: 'Optional[List[ParameterDeclarator]]' = None, value: 'Optional[Expression]' = None, modifier: 'Optional[str]' = None, subscript: 'Optional[int]' = None) Source code in whatrecord/snl.py @dataclass class Declarator : context : FullLoadContext object : Union [ Declarator , Variable ] params : Optional [ List [ ParameterDeclarator ]] = None value : Optional [ Expression ] = None modifier : Optional [ str ] = None subscript : Optional [ int ] = None def __str__ ( self ) -> str : if self . modifier == \"()\" : decl = f \"( { self . object } )\" elif self . modifier : decl = f \" { self . modifier }{ self . object } \" elif self . subscript : decl = f \" { self . object }{ self . subscript } \" elif self . params : params = \", \" . join ( str ( param ) for param in self . params ) decl = f \" { self . object } ( { params } )\" else : decl = str ( self . object ) if self . value : return f \" { decl } = { self . value } \" return f \" { decl } \"","title":"Declarator"},{"location":"parsers/#whatrecord.snl.Definition","text":"Definition(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class Definition : context : FullLoadContext","title":"Definition"},{"location":"parsers/#whatrecord.snl.ExitExpression","text":"ExitExpression(context: 'FullLoadContext', args: 'OptionalExpression') Source code in whatrecord/snl.py @dataclass class ExitExpression ( Expression ): args : OptionalExpression def __str__ ( self ) -> str : return f \"exit( { self . args or '' } )\"","title":"ExitExpression"},{"location":"parsers/#whatrecord.snl.ExitTransition","text":"ExitTransition(context: 'FullLoadContext', block: 'Block', target_state: 'Optional[str]' = None, condition: 'OptionalExpression' = None) Source code in whatrecord/snl.py @dataclass class ExitTransition ( Transition ): ...","title":"ExitTransition"},{"location":"parsers/#whatrecord.snl.Expression","text":"Expression(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class Expression : context : FullLoadContext","title":"Expression"},{"location":"parsers/#whatrecord.snl.ExpressionStatement","text":"ExpressionStatement(context: 'FullLoadContext', expression: 'CommaSeparatedExpressions') Source code in whatrecord/snl.py @dataclass class ExpressionStatement ( Statement ): expression : CommaSeparatedExpressions def __str__ ( self ) -> str : return f \" { self . expression } ;\"","title":"ExpressionStatement"},{"location":"parsers/#whatrecord.snl.ExpressionWithArguments","text":"ExpressionWithArguments(context: 'FullLoadContext', expression: 'Expression', arguments: 'OptionalExpression' = None) Source code in whatrecord/snl.py @dataclass class ExpressionWithArguments ( Expression ): expression : Expression arguments : OptionalExpression = None def __str__ ( self ) -> str : return f \" { self . expression } ( { self . arguments or '' } )\"","title":"ExpressionWithArguments"},{"location":"parsers/#whatrecord.snl.ForStatement","text":"ForStatement(context: 'FullLoadContext', init: 'OptionalExpression', condition: 'OptionalExpression', increment: 'OptionalExpression', statement: 'Statement') Source code in whatrecord/snl.py @dataclass class ForStatement ( Statement ): init : OptionalExpression condition : OptionalExpression increment : OptionalExpression statement : Statement def __str__ ( self ) -> str : return ( f \"for ( { self . init or '' } ; { self . condition or '' } ; { self . increment or '' } ) \" + str ( self . statement ) . lstrip () )","title":"ForStatement"},{"location":"parsers/#whatrecord.snl.ForeignDeclaration","text":"ForeignDeclaration(context: 'FullLoadContext', type: 'Optional[Type]' = None, declarators: 'Optional[Sequence[Declarator]]' = , names: 'Sequence[str]' = ) Source code in whatrecord/snl.py @dataclass class ForeignDeclaration ( Declaration ): names : Sequence [ str ] = field ( default_factory = list ) def __str__ ( self ) -> str : names = \", \" . join ( self . names ) return f \"foreign { names } ;\"","title":"ForeignDeclaration"},{"location":"parsers/#whatrecord.snl.FuncDef","text":"FuncDef(context: 'FullLoadContext', type: 'Type', declarator: 'Declarator', block: 'Block') Source code in whatrecord/snl.py @dataclass class FuncDef ( Definition ): type : Type declarator : Declarator block : Block def __str__ ( self ) -> str : return f \" { self . type } { self . declarator } ;\"","title":"FuncDef"},{"location":"parsers/#whatrecord.snl.IfStatement","text":"IfStatement(context: 'FullLoadContext', condition: 'CommaSeparatedExpressions', body: 'Statement', else_body: 'Optional[Statement]' = None) Source code in whatrecord/snl.py @dataclass class IfStatement ( Statement ): condition : CommaSeparatedExpressions body : Statement else_body : Optional [ Statement ] = None def __str__ ( self ) -> str : else_clause = \" \\n \" . join ( ( \" \\n else {\" , textwrap . indent ( str ( self . else_body ), \" \" * 4 ), \"}\" , ) if self . else_body else \"\" ) return \" \\n \" . join ( ( f \"if ( { self . condition } ) \" + \" {\" , textwrap . indent ( str ( self . body ), \" \" * 4 ), else_clause , \"}\" , ) )","title":"IfStatement"},{"location":"parsers/#whatrecord.snl.InitExpression","text":"Of the form: ( type ) { init_exprs } { init_exprs } expr Source code in whatrecord/snl.py @dataclass class InitExpression ( Expression ): \"\"\" Of the form: ( type ) { init_exprs } { init_exprs } expr \"\"\" # TODO: may be improved? context : FullLoadContext expressions : Sequence [ Union [ InitExpression , Expression ]] = field ( default_factory = list ) type : Optional [ Type ] = None def __str__ ( self ) -> str : exprs = \", \" . join ( str ( expr or '' ) for expr in self . expressions ) type_prefix = f \"( { self . type } ) \" if self . type else \"\" return f \" { type_prefix } {{ { exprs } }} \"","title":"InitExpression"},{"location":"parsers/#whatrecord.snl.Literal","text":"Literal(context: 'FullLoadContext', type: 'str', value: 'str') Source code in whatrecord/snl.py @dataclass class Literal ( Expression ): type : str value : str def __str__ ( self ) -> str : return self . value","title":"Literal"},{"location":"parsers/#whatrecord.snl.MemberExpression","text":"MemberExpression(context: 'FullLoadContext', parent: 'Expression', member: 'str', dereference: 'bool') Source code in whatrecord/snl.py @dataclass class MemberExpression ( Expression ): parent : Expression member : str dereference : bool # True = ->, False = . def __str__ ( self ) -> str : if self . dereference : return f \" { self . parent } -> { self . member } \" return f \" { self . parent } . { self . member } \"","title":"MemberExpression"},{"location":"parsers/#whatrecord.snl.Monitor","text":"Monitor(context: 'FullLoadContext', variable: 'str', subscript: 'Optional[int]') Source code in whatrecord/snl.py @dataclass class Monitor ( Definition ): variable : str subscript : Optional [ int ] def __str__ ( self ) -> str : return f \"monitor { self . variable }{ self . subscript or '' } ;\"","title":"Monitor"},{"location":"parsers/#whatrecord.snl.Option","text":"Option(context: 'FullLoadContext', name: 'str', enable: 'bool') Source code in whatrecord/snl.py @dataclass class Option ( Definition ): name : str enable : bool def __str__ ( self ) -> str : plus = \"+\" if self . enable else \"-\" return f \"option { plus }{ self . name } ;\"","title":"Option"},{"location":"parsers/#whatrecord.snl.ParameterDeclarator","text":"ParameterDeclarator(context: 'FullLoadContext', type: 'Type', declarator: 'Optional[Declarator]' = None) Source code in whatrecord/snl.py @dataclass class ParameterDeclarator : context : FullLoadContext type : Type declarator : Optional [ Declarator ] = None def __str__ ( self ) -> str : if self . declarator : return f \" { self . type } { self . declarator } \" return str ( self . type )","title":"ParameterDeclarator"},{"location":"parsers/#whatrecord.snl.ParenthesisExpression","text":"ParenthesisExpression(context: 'FullLoadContext', expression: 'Expression') Source code in whatrecord/snl.py @dataclass class ParenthesisExpression ( Expression ): expression : Expression def __str__ ( self ) -> str : return f \"( { self . expression } )\"","title":"ParenthesisExpression"},{"location":"parsers/#whatrecord.snl.ReturnStatement","text":"ReturnStatement(context: 'FullLoadContext', value: 'Optional[Expression]' = None) Source code in whatrecord/snl.py @dataclass class ReturnStatement ( Statement ): value : Optional [ Expression ] = None def __str__ ( self ) -> str : if self . value is not None : return f \"return { self . value } ;\" return \"return;\"","title":"ReturnStatement"},{"location":"parsers/#whatrecord.snl.SequencerProgram","text":"Representation of a state notation language (snl seq) program. Source code in whatrecord/snl.py @dataclass class SequencerProgram : \"\"\"Representation of a state notation language (snl seq) program.\"\"\" context : FullLoadContext name : str params : Optional [ str ] initial_definitions : Sequence [ Definition ] = field ( default_factory = list ) entry : Optional [ Block ] = None state_sets : Sequence [ StateSet ] = field ( default_factory = list ) exit : Optional [ Block ] = None final_definitions : Sequence [ Definition ] = field ( default_factory = list ) def __str__ ( self ) -> str : initial_definitions = \" \\n \" . join ( str ( defn ) for defn in self . initial_definitions ) final_definitions = \" \\n \" . join ( str ( defn ) for defn in self . final_definitions ) state_sets = \" \\n\\n \" . join ( str ( state_set ) for state_set in self . state_sets ) param = f \"( { self . params } )\" if self . params else \"\" return \" \\n\\n \" . join ( line for line in ( f \"program { self . name }{ param } \" , initial_definitions , str ( self . entry or \"\" ), state_sets , str ( self . exit or \"\" ), final_definitions , ) if line ) @staticmethod def preprocess ( code : str , search_path : Optional [ AnyPath ] = None ) -> str : \"\"\"Preprocess the given sequencer code, expanding #include.\"\"\" # Line numbers will be off with this, sadly # The sequencer itself gets around this by using LINE_MARKER tokens # to indicate what file and line the code came from. This could # be something we support in the future, but it might not be easy # with lark... search_path = pathlib . Path ( \".\" if search_path is None else search_path ) result = [] stack = collections . deque ([( search_path , line ) for line in code . splitlines ()]) while stack : search_path , line = stack . popleft () if line . startswith ( \"#include\" ): _ , include_file , * _ = shlex . split ( line ) include_file = ( search_path / include_file ) . resolve () with open ( include_file , \"rt\" ) as fp : stack . extendleft ( [ ( include_file . parent , line ) for line in reversed ( fp . read () . splitlines ()) ] ) elif line . startswith ( \"#if\" ): ... # sorry; this may break things elif line . startswith ( \"#else\" ): ... # sorry; this may break things elif line . startswith ( \"#elif\" ): ... # sorry; this may break things elif line . startswith ( \"#endif\" ): ... # sorry; this may break things elif line . startswith ( \"#define\" ): while stack and line . endswith ( \" \\\\ \" ): search_path , line = stack . popleft () ... # sorry; I think we can do better else : result . append ( line ) return \" \\n \" . join ( result ) @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , ) -> SequencerProgram : \"\"\"Load a state notation language file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"snl.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: alternative comment finding method # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = True , propagate_positions = True , debug = debug , ) search_path = None if filename : search_path = pathlib . Path ( filename ) . resolve () . parent preprocessed = cls . preprocess ( contents , search_path = search_path ) proto = _ProgramTransformer ( cls , filename ) . transform ( grammar . parse ( preprocessed ) ) proto . comments = comments return proto @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None ) -> SequencerProgram : \"\"\"Load a state notation language program given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) @classmethod def from_file ( cls , fn : AnyPath ) -> SequencerProgram : \"\"\" Load a state notation language file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- program : SequencerProgram The parsed program. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) def as_graph ( self , ** kwargs ) -> SequencerProgramGraph : \"\"\" Create a graphviz digraph of the state notation diagram. Returns ------- graph : SequencerProgramGraph \"\"\" return SequencerProgramGraph ( self , ** kwargs )","title":"SequencerProgram"},{"location":"parsers/#whatrecord.snl.SequencerProgram-methods","text":"whatrecord . snl . SequencerProgram . as_graph ( self , ** kwargs ) -> SequencerProgramGraph Create a graphviz digraph of the state notation diagram. Source code in whatrecord/snl.py def as_graph ( self , ** kwargs ) -> SequencerProgramGraph : \"\"\" Create a graphviz digraph of the state notation diagram. Returns ------- graph : SequencerProgramGraph \"\"\" return SequencerProgramGraph ( self , ** kwargs ) whatrecord . snl . SequencerProgram . from_file ( fn : AnyPath ) -> SequencerProgram classmethod Load a state notation language file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description SequencerProgram The parsed program. Source code in whatrecord/snl.py @classmethod def from_file ( cls , fn : AnyPath ) -> SequencerProgram : \"\"\" Load a state notation language file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- program : SequencerProgram The parsed program. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) whatrecord . snl . SequencerProgram . from_file_obj ( fp , filename : Optional [ AnyPath ] = None ) -> SequencerProgram classmethod Load a state notation language program given a file object. Source code in whatrecord/snl.py @classmethod def from_file_obj ( cls , fp , filename : Optional [ AnyPath ] = None ) -> SequencerProgram : \"\"\"Load a state notation language program given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) whatrecord . snl . SequencerProgram . from_string ( contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False ) -> SequencerProgram classmethod Load a state notation language file given its string contents. Source code in whatrecord/snl.py @classmethod def from_string ( cls , contents : str , filename : Optional [ AnyPath ] = None , debug : bool = False , ) -> SequencerProgram : \"\"\"Load a state notation language file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"snl.lark\" , search_paths = ( \"grammar\" ,), parser = \"earley\" , # TODO: alternative comment finding method # lexer_callbacks={\"COMMENT\": comments.append}, maybe_placeholders = True , propagate_positions = True , debug = debug , ) search_path = None if filename : search_path = pathlib . Path ( filename ) . resolve () . parent preprocessed = cls . preprocess ( contents , search_path = search_path ) proto = _ProgramTransformer ( cls , filename ) . transform ( grammar . parse ( preprocessed ) ) proto . comments = comments return proto whatrecord . snl . SequencerProgram . preprocess ( code : str , search_path : Optional [ AnyPath ] = None ) -> str staticmethod Preprocess the given sequencer code, expanding #include. Source code in whatrecord/snl.py @staticmethod def preprocess ( code : str , search_path : Optional [ AnyPath ] = None ) -> str : \"\"\"Preprocess the given sequencer code, expanding #include.\"\"\" # Line numbers will be off with this, sadly # The sequencer itself gets around this by using LINE_MARKER tokens # to indicate what file and line the code came from. This could # be something we support in the future, but it might not be easy # with lark... search_path = pathlib . Path ( \".\" if search_path is None else search_path ) result = [] stack = collections . deque ([( search_path , line ) for line in code . splitlines ()]) while stack : search_path , line = stack . popleft () if line . startswith ( \"#include\" ): _ , include_file , * _ = shlex . split ( line ) include_file = ( search_path / include_file ) . resolve () with open ( include_file , \"rt\" ) as fp : stack . extendleft ( [ ( include_file . parent , line ) for line in reversed ( fp . read () . splitlines ()) ] ) elif line . startswith ( \"#if\" ): ... # sorry; this may break things elif line . startswith ( \"#else\" ): ... # sorry; this may break things elif line . startswith ( \"#elif\" ): ... # sorry; this may break things elif line . startswith ( \"#endif\" ): ... # sorry; this may break things elif line . startswith ( \"#define\" ): while stack and line . endswith ( \" \\\\ \" ): search_path , line = stack . popleft () ... # sorry; I think we can do better else : result . append ( line ) return \" \\n \" . join ( result )","title":"Methods"},{"location":"parsers/#whatrecord.snl.SequencerProgramGraph","text":"A graph for a SequencerProgram. Parameters: Name Type Description Default program Optional[SequencerProgram] A program to add. None highlight_states Optional[List[str]] List of state names to highlight. None include_code bool Include code, where relevant, in nodes. False Source code in whatrecord/snl.py class SequencerProgramGraph ( _GraphHelper ): \"\"\" A graph for a SequencerProgram. Parameters ---------- program : SequencerProgram, optional A program to add. highlight_states : list of str, optional List of state names to highlight. include_code : bool, optional Include code, where relevant, in nodes. \"\"\" _entry_label : str = \"_Entry_\" _exit_label : str = \"_Exit_\" def __init__ ( self , program : Optional [ SequencerProgram ] = None , highlight_states : Optional [ List [ str ]] = None , include_code : bool = False , ): super () . __init__ () self . include_code = include_code self . highlight_states = highlight_states or [] if program is not None : self . add_program ( program ) def add_program ( self , program : SequencerProgram ): \"\"\"Add a program to the graph.\"\"\" for state_set in program . state_sets : for state in state_set . states : self . _add_state ( program , state_set , state ) # Only add entry/exit labels if there's an edge if self . _entry_label in self . nodes : self . get_node ( self . _entry_label , self . get_code ( program . entry , \"(Startup)\" ) ) if self . _exit_label in self . nodes : self . get_node ( self . _exit_label , self . get_code ( program . exit , \"(Exit)\" ) ) def _add_state ( self , program : SequencerProgram , state_set : StateSet , state : State ): \"\"\"Add a state set's state to the graph.\"\"\" qualified_name = f \" { state_set . name } . { state . name } \" self . get_node ( qualified_name , text = \" \\n \" . join ( self . _get_state_node_text ( state_set , state )), ) if state_set . states [ 0 ] is state : self . add_edge ( self . _entry_label , qualified_name , ) for transition in state . transitions : self . _add_transition ( program , state_set , state , transition ) for transition in state . code_transitions : self . add_edge ( qualified_name , f \" { state_set . name } . { transition . name } \" , label = f \"(Line { transition . context [ - 1 ] . line } )\" , ) def _ready_for_digraph ( self , graph : gv . Digraph ): \"\"\"Hook when the user calls ``to_digraph``.\"\"\" for node in self . nodes . values (): node . highlighted = node . label in self . highlight_states def _add_transition ( self , program : SequencerProgram , state_set : StateSet , state : State , transition : Transition , ): \"\"\"Add a state set's state transition to the graph.\"\"\" state_qualified_name = f \" { state_set . name } . { state . name } \" label = str ( transition . condition or \"\" ) transition_text = self . get_code ( transition . block ) target_state = ( f \" { state_set . name } . { transition . target_state } \" if transition . target_state else self . _exit_label ) if not self . include_code or not transition_text : self . add_edge ( state_qualified_name , target_state , label = label ) return transition_idx = state . transitions . index ( transition ) transition_node = f \" { state_qualified_name } . { transition_idx } \" self . get_node ( transition_node , text = transition_text ) self . add_edge ( state_qualified_name , transition_node , label = label ) self . add_edge ( transition_node , target_state ) def get_code ( self , obj , default : str = \"\" ): \"\"\"Get code for a node/edge.\"\"\" if self . include_code and obj is not None : return self . clean_code ( str ( obj )) or default return default def _get_state_node_text ( self , state_set : StateSet , state : State ): yield f \"<b> { state_set . name } . { state . name } </b>\" if self . include_code : if state . entry is not None : yield \"<u>Entry</u>\" yield self . clean_code ( state . entry ) if state . exit is not None : yield \"<u>Exit</u>\" yield self . clean_code ( state . exit )","title":"SequencerProgramGraph"},{"location":"parsers/#whatrecord.snl.SequencerProgramGraph-methods","text":"whatrecord . snl . SequencerProgramGraph . add_program ( self , program : SequencerProgram ) Add a program to the graph. Source code in whatrecord/snl.py def add_program ( self , program : SequencerProgram ): \"\"\"Add a program to the graph.\"\"\" for state_set in program . state_sets : for state in state_set . states : self . _add_state ( program , state_set , state ) # Only add entry/exit labels if there's an edge if self . _entry_label in self . nodes : self . get_node ( self . _entry_label , self . get_code ( program . entry , \"(Startup)\" ) ) if self . _exit_label in self . nodes : self . get_node ( self . _exit_label , self . get_code ( program . exit , \"(Exit)\" ) ) whatrecord . snl . SequencerProgramGraph . get_code ( self , obj , default : str = '' ) Get code for a node/edge. Source code in whatrecord/snl.py def get_code ( self , obj , default : str = \"\" ): \"\"\"Get code for a node/edge.\"\"\" if self . include_code and obj is not None : return self . clean_code ( str ( obj )) or default return default","title":"Methods"},{"location":"parsers/#whatrecord.snl.SizeofExpression","text":"SizeofExpression(context: 'FullLoadContext', type: 'Type') Source code in whatrecord/snl.py @dataclass class SizeofExpression ( Expression ): type : Type def __str__ ( self ) -> str : return f \"sizeof( { self . type } )\"","title":"SizeofExpression"},{"location":"parsers/#whatrecord.snl.State","text":"State(context: 'FullLoadContext', name: 'str', definitions: 'Sequence[Definition]' = , transitions: 'Sequence[Transition]' = , entry: 'Optional[Block]' = None, exit: 'Optional[Block]' = None, code_transitions: 'List[StateStatement]' = ) Source code in whatrecord/snl.py @dataclass class State : context : FullLoadContext name : str definitions : Sequence [ Definition ] = field ( default_factory = list ) transitions : Sequence [ Transition ] = field ( default_factory = list ) entry : Optional [ Block ] = None exit : Optional [ Block ] = None code_transitions : List [ StateStatement ] = field ( default_factory = list ) def __str__ ( self ) -> str : definitions = \" \\n \" . join ( str ( defn ) for defn in self . definitions ) transitions = \" \\n \" . join ( str ( transition ) for transition in self . transitions ) return \" \\n \" . join ( line for line in ( f \"state { self . name } \" + \" {\" , str ( self . entry or \"\" ), textwrap . indent ( definitions , \" \" * 4 ), textwrap . indent ( transitions , \" \" * 4 ), str ( self . exit or \"\" ), \"}\" , ) if line )","title":"State"},{"location":"parsers/#whatrecord.snl.StateSet","text":"StateSet(context: 'FullLoadContext', name: 'str', definitions: 'Sequence[Definition]' = , states: 'Sequence[State]' = ) Source code in whatrecord/snl.py @dataclass class StateSet : context : FullLoadContext name : str definitions : Sequence [ Definition ] = field ( default_factory = list ) states : Sequence [ State ] = field ( default_factory = list ) def __str__ ( self ) -> str : definitions = \" \\n \" . join ( str ( defn ) for defn in self . definitions ) states = \" \\n \" . join ( str ( state ) for state in self . states ) return \" \\n \" . join ( ( f \"ss { self . name } \" + \" {\" , textwrap . indent ( definitions , \" \" * 4 ), textwrap . indent ( states , \" \" * 4 ), \"}\" , ) )","title":"StateSet"},{"location":"parsers/#whatrecord.snl.StateStatement","text":"StateStatement(context: 'FullLoadContext', name: 'str') Source code in whatrecord/snl.py @dataclass class StateStatement ( Statement ): name : str def __str__ ( self ) -> str : return f \"state { self . name } ;\"","title":"StateStatement"},{"location":"parsers/#whatrecord.snl.Statement","text":"Statement(context: 'FullLoadContext') Source code in whatrecord/snl.py @dataclass class Statement : context : FullLoadContext","title":"Statement"},{"location":"parsers/#whatrecord.snl.StructDef","text":"StructDef(context: 'FullLoadContext', name: 'str', members: 'Sequence[Union[StructMemberDecl, CCode]]' = ) Source code in whatrecord/snl.py @dataclass class StructDef ( Definition ): name : str members : Sequence [ Union [ StructMemberDecl , CCode ]] = field ( default_factory = list ) def __str__ ( self ) -> str : members = \" \\n \" . join ( str ( member ) for member in self . members ) return \" \\n \" . join ( ( f \"struct { self . name } \" + \" {\" , textwrap . indent ( members , \" \" * 4 ), \"}\" , ) )","title":"StructDef"},{"location":"parsers/#whatrecord.snl.StructMemberDecl","text":"StructMemberDecl(context: 'FullLoadContext', type: 'Type', declarator: 'Declarator') Source code in whatrecord/snl.py @dataclass class StructMemberDecl : context : FullLoadContext type : Type declarator : Declarator def __str__ ( self ) -> str : return f \" { self . type } { self . declarator } ;\"","title":"StructMemberDecl"},{"location":"parsers/#whatrecord.snl.Sync","text":"Sync(context: 'FullLoadContext', variable: 'str', subscript: 'Optional[int]', queued: 'bool', event_flag: 'Optional[str]' = None, queue_size: 'Optional[int]' = None) Source code in whatrecord/snl.py @dataclass class Sync ( Definition ): variable : str subscript : Optional [ int ] queued : bool event_flag : Optional [ str ] = None queue_size : Optional [ int ] = None def __str__ ( self ) -> str : subscript = str ( self . subscript or \"\" ) variable = f \" { self . variable }{ subscript } \" event_flag = f \" to { self . event_flag } \" if self . event_flag else \"\" if self . queued : return f \"syncq { variable }{ event_flag } { self . queue_size or '' } ;\" return f \"sync { variable }{ event_flag } ;\"","title":"Sync"},{"location":"parsers/#whatrecord.snl.TernaryExpression","text":"TernaryExpression(context: 'FullLoadContext', condition: 'Expression', if_true: 'Expression', if_false: 'Expression') Source code in whatrecord/snl.py @dataclass class TernaryExpression ( Expression ): condition : Expression if_true : Expression if_false : Expression def __str__ ( self ) -> str : return f \" { self . condition } ? { self . if_true } : { self . if_false } \"","title":"TernaryExpression"},{"location":"parsers/#whatrecord.snl.Transition","text":"Transition(context: 'FullLoadContext', block: 'Block', target_state: 'Optional[str]' = None, condition: 'OptionalExpression' = None) Source code in whatrecord/snl.py @dataclass class Transition : context : FullLoadContext block : Block target_state : Optional [ str ] = None condition : OptionalExpression = None def __str__ ( self ) -> str : state = ( f \"state { self . target_state } \" if self . target_state else \"exit\" ) return \" \\n \" . join ( line for line in ( f \"when ( { self . condition or '' } )\" + \" {\" , str ( self . block ), \"}\" + f \" { state } \" , ) if line )","title":"Transition"},{"location":"parsers/#whatrecord.snl.Type","text":"Type(context: 'FullLoadContext', name: 'str', abstract: 'Optional[AbstractDeclarator]' = None) Source code in whatrecord/snl.py @dataclass class Type : context : FullLoadContext name : str abstract : Optional [ AbstractDeclarator ] = None def __str__ ( self ) -> str : return f \" { self . abstract or '' }{ self . name } \"","title":"Type"},{"location":"parsers/#whatrecord.snl.TypeCastExpression","text":"TypeCastExpression(context: 'FullLoadContext', type: 'Type', expression: 'Expression') Source code in whatrecord/snl.py @dataclass class TypeCastExpression ( Expression ): type : Type expression : Expression def __str__ ( self ) -> str : return f \" { self . type } ( { self . expression } )\"","title":"TypeCastExpression"},{"location":"parsers/#whatrecord.snl.UnaryPostfixExpression","text":"UnaryPostfixExpression(context: 'FullLoadContext', expression: 'Expression', operator: 'str') Source code in whatrecord/snl.py @dataclass class UnaryPostfixExpression ( Expression ): expression : Expression operator : str def __str__ ( self ) -> str : return f \" { self . expression }{ self . operator } \"","title":"UnaryPostfixExpression"},{"location":"parsers/#whatrecord.snl.UnaryPrefixExpression","text":"UnaryPrefixExpression(context: 'FullLoadContext', operator: 'str', expression: 'Expression') Source code in whatrecord/snl.py @dataclass class UnaryPrefixExpression ( Expression ): operator : str expression : Expression def __str__ ( self ) -> str : return f \" { self . operator }{ self . expression } \"","title":"UnaryPrefixExpression"},{"location":"parsers/#whatrecord.snl.Variable","text":"Variable(context: 'FullLoadContext', name: 'str') Source code in whatrecord/snl.py @dataclass class Variable ( Expression ): name : str def __str__ ( self ) -> str : return self . name","title":"Variable"},{"location":"parsers/#whatrecord.snl.WhileStatement","text":"WhileStatement(context: 'FullLoadContext', condition: 'CommaSeparatedExpressions', body: 'Statement') Source code in whatrecord/snl.py @dataclass class WhileStatement ( Statement ): condition : CommaSeparatedExpressions body : Statement def __str__ ( self ) -> str : return f \"while ( { self . condition } ) \" + str ( self . body ) . lstrip ()","title":"WhileStatement"},{"location":"parsers/#whatrecord.streamdevice","text":"","title":"streamdevice"},{"location":"parsers/#whatrecord.streamdevice-classes","text":"","title":"Classes"},{"location":"parsers/#whatrecord.streamdevice.Command","text":"Command(name: 'str', arguments: 'List[str]') Source code in whatrecord/streamdevice.py @dataclass class Command : name : str arguments : List [ str ]","title":"Command"},{"location":"parsers/#whatrecord.streamdevice.ConfigurationSetting","text":"ConfigurationSetting(name: 'str', value: 'str') Source code in whatrecord/streamdevice.py @dataclass class ConfigurationSetting : name : str value : str","title":"ConfigurationSetting"},{"location":"parsers/#whatrecord.streamdevice.HandlerDefinition","text":"HandlerDefinition(name: 'str', commands: 'List[Command]' = ) Source code in whatrecord/streamdevice.py @dataclass class HandlerDefinition : name : str commands : List [ Command ] = field ( default_factory = list )","title":"HandlerDefinition"},{"location":"parsers/#whatrecord.streamdevice.ProtocolDefinition","text":"ProtocolDefinition(context: 'FullLoadContext', name: 'str', handlers: 'Dict[str, HandlerDefinition]' = , variables: 'Dict[str, str]' = , commands: 'List[Command]' = , config: 'Dict[str, str]' = ) Source code in whatrecord/streamdevice.py @dataclass class ProtocolDefinition : context : FullLoadContext name : str handlers : Dict [ str , HandlerDefinition ] = field ( default_factory = dict ) variables : Dict [ str , str ] = field ( default_factory = dict ) commands : List [ Command ] = field ( default_factory = list ) config : Dict [ str , str ] = field ( default_factory = dict )","title":"ProtocolDefinition"},{"location":"parsers/#whatrecord.streamdevice.StreamDeviceState","text":"StreamDevice IOC shell state handler / container. Contains hooks for StreamDevice-related commands and state information. Attributes: Name Type Description protocols Dict[str, StreamProtocol] Loaded StreamDevice protocols by name. Source code in whatrecord/streamdevice.py @dataclass class StreamDeviceState ( ShellStateHandler ): \"\"\" StreamDevice IOC shell state handler / container. Contains hooks for StreamDevice-related commands and state information. Attributes ---------- protocols : Dict[str, StreamProtocol] Loaded StreamDevice protocols by name. \"\"\" metadata_key : ClassVar [ str ] = \"streamdevice\" protocols : Dict [ str , StreamProtocol ] = field ( default_factory = dict ) def find_streamdevice_protocol ( self , filename : AnyPath ) -> pathlib . Path : shell_state = self . primary_handler return shell_state . _fix_path_with_search_list ( filename , shell_state . paths_from_env_var ( \"STREAM_PROTOCOL_PATH\" , default = \".\" ) ) def load_streamdevice_protocol ( self , filename : AnyPath , ) -> StreamProtocol : \"\"\"Load a StreamDevice protocol file.\"\"\" filename = self . find_streamdevice_protocol ( filename ) key = str ( filename ) if key not in self . protocols : shell_state = self . primary_handler fn , contents = shell_state . load_file ( filename ) self . protocols [ key ] = StreamProtocol . from_string ( contents , filename = fn ) return self . protocols [ key ] def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" dtype = record . fields . get ( \"DTYP\" , None ) if not dtype or getattr ( dtype , \"value\" , None ) != \"stream\" : return info_field = record . fields . get ( \"INP\" , record . fields . get ( \"OUT\" , None )) if not info_field or isinstance ( info_field , PVAFieldReference ): return { \"error\" : \"INP/OUT not defined correctly\" } if not isinstance ( info_field . value , str ): return { \"error\" : \"INP/OUT not defined correctly (JSON)\" } info_field = info_field . value . strip () results = {} try : proto_file , proto_name , * proto_args = split_words ( info_field ) . argv proto_file = proto_file . lstrip ( \"@ \" ) except Exception : results [ \"error\" ] = ( f \"Invalid StreamDevice input/output field: { info_field !r} \" ) proto_file = None proto_name = None proto_args = [] else : try : protocol = self . load_streamdevice_protocol ( proto_file ) except Exception as ex : results [ \"error\" ] = f \" { ex . __class__ . __name__ } : { ex } \" else : if proto_name in protocol . protocols : results [ \"protocol\" ] = protocol . protocols [ proto_name ] else : results [ \"error\" ] = ( f \"Unknown protocol { proto_name !r} in { proto_file } ; \" f \"options are: { list ( protocol . protocols ) } \" ) return { \"protocol_file\" : proto_file , \"protocol_name\" : proto_name , \"protocol_args\" : proto_args , ** results , }","title":"StreamDeviceState"},{"location":"parsers/#whatrecord.streamdevice.StreamDeviceState-methods","text":"whatrecord . streamdevice . StreamDeviceState . annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]] Hook to annotate a record after being loaded. Source code in whatrecord/streamdevice.py def annotate_record ( self , record : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Hook to annotate a record after being loaded.\"\"\" dtype = record . fields . get ( \"DTYP\" , None ) if not dtype or getattr ( dtype , \"value\" , None ) != \"stream\" : return info_field = record . fields . get ( \"INP\" , record . fields . get ( \"OUT\" , None )) if not info_field or isinstance ( info_field , PVAFieldReference ): return { \"error\" : \"INP/OUT not defined correctly\" } if not isinstance ( info_field . value , str ): return { \"error\" : \"INP/OUT not defined correctly (JSON)\" } info_field = info_field . value . strip () results = {} try : proto_file , proto_name , * proto_args = split_words ( info_field ) . argv proto_file = proto_file . lstrip ( \"@ \" ) except Exception : results [ \"error\" ] = ( f \"Invalid StreamDevice input/output field: { info_field !r} \" ) proto_file = None proto_name = None proto_args = [] else : try : protocol = self . load_streamdevice_protocol ( proto_file ) except Exception as ex : results [ \"error\" ] = f \" { ex . __class__ . __name__ } : { ex } \" else : if proto_name in protocol . protocols : results [ \"protocol\" ] = protocol . protocols [ proto_name ] else : results [ \"error\" ] = ( f \"Unknown protocol { proto_name !r} in { proto_file } ; \" f \"options are: { list ( protocol . protocols ) } \" ) return { \"protocol_file\" : proto_file , \"protocol_name\" : proto_name , \"protocol_args\" : proto_args , ** results , } whatrecord . streamdevice . StreamDeviceState . load_streamdevice_protocol ( self , filename : AnyPath ) -> StreamProtocol Load a StreamDevice protocol file. Source code in whatrecord/streamdevice.py def load_streamdevice_protocol ( self , filename : AnyPath , ) -> StreamProtocol : \"\"\"Load a StreamDevice protocol file.\"\"\" filename = self . find_streamdevice_protocol ( filename ) key = str ( filename ) if key not in self . protocols : shell_state = self . primary_handler fn , contents = shell_state . load_file ( filename ) self . protocols [ key ] = StreamProtocol . from_string ( contents , filename = fn ) return self . protocols [ key ]","title":"Methods"},{"location":"parsers/#whatrecord.streamdevice.StreamProtocol","text":"Representation of a StreamDevice protocol. Source code in whatrecord/streamdevice.py @dataclass class StreamProtocol : \"\"\"Representation of a StreamDevice protocol.\"\"\" variables : Dict [ str , str ] = field ( default_factory = dict ) protocols : Dict [ str , ProtocolDefinition ] = field ( default_factory = dict ) comments : List [ str ] = field ( default_factory = list ) config : Dict [ str , str ] = field ( default_factory = dict ) handlers : Dict [ str , HandlerDefinition ] = field ( default_factory = dict ) @classmethod def from_string ( cls , contents , filename = None , ) -> StreamProtocol : \"\"\"Load a protocol file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"streamdevice.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , # lexer_callbacks={\"COMMENT\": comments.append}, ) proto = _ProtocolTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) proto . comments = comments return proto @classmethod def from_file_obj ( cls , fp , filename = None ) -> StreamProtocol : \"\"\"Load a protocol file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) @classmethod def from_file ( cls , fn ) -> StreamProtocol : \"\"\" Load a StreamDevice protocol file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- protocol : StreamProtocol The StreamDevice protocol. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn )","title":"StreamProtocol"},{"location":"parsers/#whatrecord.streamdevice.StreamProtocol-methods","text":"whatrecord . streamdevice . StreamProtocol . from_file ( fn ) -> StreamProtocol classmethod Load a StreamDevice protocol file. Parameters: Name Type Description Default filename pathlib.Path or str The filename. required Returns: Type Description StreamProtocol The StreamDevice protocol. Source code in whatrecord/streamdevice.py @classmethod def from_file ( cls , fn ) -> StreamProtocol : \"\"\" Load a StreamDevice protocol file. Parameters ---------- filename : pathlib.Path or str The filename. Returns ------- protocol : StreamProtocol The StreamDevice protocol. \"\"\" with open ( fn , \"rt\" ) as fp : return cls . from_string ( fp . read (), filename = fn ) whatrecord . streamdevice . StreamProtocol . from_file_obj ( fp , filename = None ) -> StreamProtocol classmethod Load a protocol file given a file object. Source code in whatrecord/streamdevice.py @classmethod def from_file_obj ( cls , fp , filename = None ) -> StreamProtocol : \"\"\"Load a protocol file given a file object.\"\"\" return cls . from_string ( fp . read (), filename = getattr ( fp , \"name\" , filename ), ) whatrecord . streamdevice . StreamProtocol . from_string ( contents , filename = None ) -> StreamProtocol classmethod Load a protocol file given its string contents. Source code in whatrecord/streamdevice.py @classmethod def from_string ( cls , contents , filename = None , ) -> StreamProtocol : \"\"\"Load a protocol file given its string contents.\"\"\" comments = [] grammar = lark . Lark . open_from_package ( \"whatrecord\" , \"streamdevice.lark\" , search_paths = ( \"grammar\" , ), parser = \"earley\" , maybe_placeholders = False , # lexer_callbacks={\"COMMENT\": comments.append}, ) proto = _ProtocolTransformer ( cls , filename ) . transform ( grammar . parse ( contents ) ) proto . comments = comments return proto","title":"Methods"},{"location":"parsers/#whatrecord.streamdevice.VariableAssignment","text":"VariableAssignment(name: 'str', value: 'str') Source code in whatrecord/streamdevice.py @dataclass class VariableAssignment : name : str value : str","title":"VariableAssignment"},{"location":"parsers/#whatrecord.transformer","text":"Helpers for writing lark transformers.","title":"transformer"},{"location":"parsers/#whatrecord.transformer-functions","text":"","title":"Functions"},{"location":"parsers/#whatrecord.transformer.context_from_token","text":"Get a LoadContext from a lark Token. Source code in whatrecord/transformer.py def context_from_token ( fn : str , token : lark . Token ) -> FullLoadContext : \"\"\"Get a LoadContext from a lark Token.\"\"\" return ( LoadContext ( name = fn , line = token . line ), )","title":"context_from_token()"},{"location":"parsers/#whatrecord.transformer.context_from_tree","text":"Get a LoadContext from a lark Tree. Source code in whatrecord/transformer.py def context_from_tree ( fn : str , tree : lark . Tree ) -> FullLoadContext : \"\"\"Get a LoadContext from a lark Tree.\"\"\" return ( LoadContext ( name = fn , line = tree . meta . line ), )","title":"context_from_tree()"},{"location":"parsers/#whatrecord.transformer.dictify","text":"Transformer helper to stringify a single argument. Source code in whatrecord/transformer.py @staticmethod def dictify ( * tuples : Tuple [ Any , Any ]) -> dict : \"\"\"Transformer helper to stringify a single argument.\"\"\" return dict ( tuples )","title":"dictify()"},{"location":"parsers/#whatrecord.transformer.ignore","text":"Transformer helper to drop the subtree. Source code in whatrecord/transformer.py @staticmethod def ignore ( * args : Any ) -> None : \"\"\"Transformer helper to drop the subtree.\"\"\"","title":"ignore()"},{"location":"parsers/#whatrecord.transformer.listify","text":"Transformer helper to listify *args. Source code in whatrecord/transformer.py @staticmethod def listify ( * objects : Any ): \"\"\"Transformer helper to listify *args.\"\"\" return list ( objects )","title":"listify()"},{"location":"parsers/#whatrecord.transformer.listify_strings","text":"Transformer helper to listify *args and stringify each arg. Source code in whatrecord/transformer.py @staticmethod def listify_strings ( * objects : Union [ str , lark . Token ]): \"\"\"Transformer helper to listify *args and stringify each arg.\"\"\" return list ( str ( obj ) for obj in objects )","title":"listify_strings()"},{"location":"parsers/#whatrecord.transformer.pass_through","text":"Transformer helper to pass through an optional single argument. Source code in whatrecord/transformer.py @staticmethod def pass_through ( obj : Optional [ T ] = None ) -> Optional [ T ]: \"\"\"Transformer helper to pass through an optional single argument.\"\"\" return obj","title":"pass_through()"},{"location":"parsers/#whatrecord.transformer.stringify","text":"Transformer helper to stringify a single argument. Source code in whatrecord/transformer.py @staticmethod def stringify ( obj : lark . Token ) -> str : \"\"\"Transformer helper to stringify a single argument.\"\"\" return str ( obj )","title":"stringify()"},{"location":"parsers/#whatrecord.transformer.tuple_args","text":"Transformer helper to get back the *args tuple. Source code in whatrecord/transformer.py @staticmethod def tuple_args ( * objects : T ) -> Tuple [ T , ... ]: \"\"\"Transformer helper to get back the *args tuple.\"\"\" return objects","title":"tuple_args()"},{"location":"plugins/","text":"Plugins Usage API whatrecord.plugins.happi happi whatrecord plugin Match your happi devices to IOCs and records. Classes whatrecord.plugins.happi.HappiPluginResults ( PluginResults ) dataclass HappiPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/happi.py @dataclass class HappiPluginResults ( PluginResults ): # Could potentially further specify metadata_by_key or metadata ... whatrecord.plugins.happi.HappiRecordInfo dataclass HappiRecordInfo(name: 'str', kind: 'str', signal: 'str') Source code in whatrecord/plugins/happi.py @dataclass class HappiRecordInfo : name : str kind : str signal : str Functions whatrecord . plugins . happi . find_signal_metadata_pairs ( criteria : CriteriaDict ) -> Generator [ Tuple [ OphydObject , str , EpicsSignalBase ], None , None ] Find all signal metadata that match the given criteria. Returns: Type Description Generator[Tuple[OphydObject, str, EpicsSignalBase], None, None] The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the md attribute. Source code in whatrecord/plugins/happi.py def find_signal_metadata_pairs ( criteria : CriteriaDict , ) -> Generator [ Tuple [ OphydObject , str , EpicsSignalBase ], None , None ]: \"\"\" Find all signal metadata that match the given criteria. Yields ------ root : OphydObject The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the ``md`` attribute. pvname : str The PV name. signal : EpicsSignal, EpicsSignalRO, ... The signal instance, one of ``SIGNAL_CLASSES``. \"\"\" attributes = [ \"pvname\" , \"setpoint_pvname\" , ] for root , sig in find_signals ( criteria , signal_class = SIGNAL_CLASSES ): found_pvs = set () for attr in attributes : pvname = getattr ( sig , attr , None ) if pvname is not None and isinstance ( pvname , str ): found_pvs . add ( pvname ) if found_pvs : for pvname in sorted ( found_pvs ): yield root , pvname , sig else : # Then it's the prefix - possibly pvname = getattr ( sig , \"prefix\" , None ) if pvname is not None : yield root , pvname , sig whatrecord . plugins . happi . find_signals ( criteria : CriteriaDict , signal_class : Type [ T ]) -> Generator [ Tuple [ OphydObject , T ], None , None ] Find all signal metadata that match the given criteria. Returns: Type Description Generator[Tuple[OphydObject, T], None, None] The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the md attribute. Source code in whatrecord/plugins/happi.py def find_signals ( criteria : CriteriaDict , signal_class : Type [ T ], ) -> Generator [ Tuple [ OphydObject , T ], None , None ]: \"\"\" Find all signal metadata that match the given criteria. Yields ------ root : OphydObject The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the ``md`` attribute. sig : signal_class Signals of type `signal_class`. \"\"\" patch_and_use_dummy_shim () def is_of_class ( obj ): return isinstance ( obj , signal_class ) if not criteria : devices = get_all_devices () else : devices = get_devices_by_criteria ( criteria ) for dev in devices : if not hasattr ( dev , \"md\" ): # This should be a guarantee, but check just in case. continue for sig in get_components_matching ( dev , predicate = is_of_class ): yield dev , sig # Top-level devices are OK too if isinstance ( dev , signal_class ): yield dev , dev whatrecord . plugins . happi . get_all_devices ( client : happi . Client = None ) -> Generator [ ophyd . Device , None , None ] Get all devices from a given happi client. Parameters: Name Type Description Default client happi.Client The happi client to use. Defaults to using one from the environment configuration. None Source code in whatrecord/plugins/happi.py def get_all_devices ( client : happi . Client = None , ) -> Generator [ ophyd . Device , None , None ]: \"\"\" Get all devices from a given happi client. Parameters ---------- client : happi.Client, optional The happi client to use. Defaults to using one from the environment configuration. Yields ------ ophyd.Device \"\"\" if client is None : client = happi . Client . from_config () if hasattr ( client . backend , \"_load_or_initialize\" ): # HACK: TODO: avoid re-re-re-reading the JSON database; happi needs # some work. loaded_database = client . backend . _load_or_initialize () client . backend . _load_or_initialize = lambda : loaded_database for dev in client : try : obj = client [ dev ] . get () except Exception : logger . exception ( \"Failed to instantiate device: %s \" , dev ) else : yield obj whatrecord . plugins . happi . get_components_matching ( obj : ophyd . Device , predicate : callable ) -> Generator [ OphydObject , None , None ] Find signals of a specific type from a given ophyd Device. Parameters: Name Type Description Default obj ophyd.Device The ophyd Device. required predicate callable Callable that should return True on a match. required Source code in whatrecord/plugins/happi.py def get_components_matching ( obj : ophyd . Device , predicate : callable , ) -> Generator [ OphydObject , None , None ]: \"\"\" Find signals of a specific type from a given ophyd Device. Parameters ---------- obj : ophyd.Device The ophyd Device. predicate : callable Callable that should return True on a match. Yields ------ obj : OphydObject \"\"\" for name , dev in obj . walk_subdevices ( include_lazy = True ): try : included = predicate ( dev ) except Exception : logger . exception ( \"Failed to check predicate against %s %s \" , name , dev ) else : if included : yield dev for walk in obj . walk_signals ( include_lazy = True ): try : included = predicate ( walk . item ) except Exception : logger . exception ( \"Failed to check predicate against %s \" , walk ) else : if included : yield walk . item whatrecord . plugins . happi . get_devices_by_criteria ( search_criteria : CriteriaDict , * , client : happi . Client = None , regex : bool = True ) -> Generator [ ophyd . Device , None , None ] Get all devices from a given happi client. Parameters: Name Type Description Default search_criteria CriteriaDict Dictionary of {'happi_key': 'search_value'} . required client happi.Client The happi client to use. Defaults to using one from the environment configuration. None Source code in whatrecord/plugins/happi.py def get_devices_by_criteria ( search_criteria : CriteriaDict , * , client : happi . Client = None , regex : bool = True , ) -> Generator [ ophyd . Device , None , None ]: \"\"\" Get all devices from a given happi client. Parameters ---------- search_criteria : dict Dictionary of ``{'happi_key': 'search_value'}``. client : happi.Client, optional The happi client to use. Defaults to using one from the environment configuration. Yields ------ ophyd.Device \"\"\" if client is None : client = happi . Client . from_config () search_method = client . search_regex if regex else client . search for item in search_method ( ** search_criteria ): try : obj = item . get () except Exception : logger . exception ( \"Failed to instantiate device: %s \" , obj ) else : yield obj whatrecord . plugins . happi . patch_and_use_dummy_shim () Hack ophyd and its dummy shim. We don't want any control-layer connections being made while we're looking for signals. Source code in whatrecord/plugins/happi.py def patch_and_use_dummy_shim (): \"\"\" Hack ophyd and its dummy shim. We don't want _any_ control-layer connections being made while we're looking for signals. Warning ------- Under no circumstances should this be used in a production environment where you intend to actually _use_ ophyd for its intended purpose. \"\"\" ophyd . Device . lazy_wait_for_connection = False def _no_op ( * args , ** kwargs ): ... class _PVStandIn : _reference_count = 0 def __init__ ( self , pvname , * args , ** kwargs ): self . pvname = pvname self . connected = True add_callback = _no_op remove_callback = _no_op clear_callbacks = _no_op get = _no_op put = _no_op get_with_metadata = _no_op wait_for_connection = _no_op def get_pv ( pvname , * args , ** kwargs ): return _PVStandIn ( pvname ) from ophyd import _dummy_shim _dummy_shim . get_pv = get_pv _dummy_shim . release_pvs = _no_op ophyd . set_cl ( \"dummy\" ) whatrecord.plugins.netconfig LDAP Configuration summary plugin Classes whatrecord.plugins.netconfig.NetconfigPluginResults ( PluginResults ) dataclass NetconfigPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/netconfig.py @dataclass class NetconfigPluginResults ( PluginResults ): # Could potentially further specify metadata_by_key or metadata ... Functions whatrecord . plugins . netconfig . decode_ldap_attrs ( attrs : Dict [ str , List [ bytes ]], encoding = 'utf-8' ) -> Dict [ str , List [ str ]] Decode byte-filled LDAP attrs dictionary. Source code in whatrecord/plugins/netconfig.py def decode_ldap_attrs ( attrs : Dict [ str , List [ bytes ]], encoding = LDAP_ENCODING ) -> Dict [ str , List [ str ]]: \"\"\"Decode byte-filled LDAP attrs dictionary.\"\"\" def decode_value ( key : str , value : List [ bytes ]): return [ part . decode ( encoding , \"replace\" ) for part in value ] return { key : decode_value ( key , value ) for key , value in attrs . items ()} whatrecord.plugins.util whatrecord.plugins.gdb_binary_info A GDB script to get useful information out of IOC binaries.","title":"Plugins"},{"location":"plugins/#plugins","text":"","title":"Plugins"},{"location":"plugins/#usage","text":"","title":"Usage"},{"location":"plugins/#api","text":"","title":"API"},{"location":"plugins/#whatrecord.plugins.happi","text":"happi whatrecord plugin Match your happi devices to IOCs and records.","title":"happi"},{"location":"plugins/#whatrecord.plugins.happi-classes","text":"","title":"Classes"},{"location":"plugins/#whatrecord.plugins.happi.HappiPluginResults","text":"HappiPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/happi.py @dataclass class HappiPluginResults ( PluginResults ): # Could potentially further specify metadata_by_key or metadata ...","title":"HappiPluginResults"},{"location":"plugins/#whatrecord.plugins.happi.HappiRecordInfo","text":"HappiRecordInfo(name: 'str', kind: 'str', signal: 'str') Source code in whatrecord/plugins/happi.py @dataclass class HappiRecordInfo : name : str kind : str signal : str","title":"HappiRecordInfo"},{"location":"plugins/#whatrecord.plugins.happi-functions","text":"","title":"Functions"},{"location":"plugins/#whatrecord.plugins.happi.find_signal_metadata_pairs","text":"Find all signal metadata that match the given criteria. Returns: Type Description Generator[Tuple[OphydObject, str, EpicsSignalBase], None, None] The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the md attribute. Source code in whatrecord/plugins/happi.py def find_signal_metadata_pairs ( criteria : CriteriaDict , ) -> Generator [ Tuple [ OphydObject , str , EpicsSignalBase ], None , None ]: \"\"\" Find all signal metadata that match the given criteria. Yields ------ root : OphydObject The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the ``md`` attribute. pvname : str The PV name. signal : EpicsSignal, EpicsSignalRO, ... The signal instance, one of ``SIGNAL_CLASSES``. \"\"\" attributes = [ \"pvname\" , \"setpoint_pvname\" , ] for root , sig in find_signals ( criteria , signal_class = SIGNAL_CLASSES ): found_pvs = set () for attr in attributes : pvname = getattr ( sig , attr , None ) if pvname is not None and isinstance ( pvname , str ): found_pvs . add ( pvname ) if found_pvs : for pvname in sorted ( found_pvs ): yield root , pvname , sig else : # Then it's the prefix - possibly pvname = getattr ( sig , \"prefix\" , None ) if pvname is not None : yield root , pvname , sig","title":"find_signal_metadata_pairs()"},{"location":"plugins/#whatrecord.plugins.happi.find_signals","text":"Find all signal metadata that match the given criteria. Returns: Type Description Generator[Tuple[OphydObject, T], None, None] The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the md attribute. Source code in whatrecord/plugins/happi.py def find_signals ( criteria : CriteriaDict , signal_class : Type [ T ], ) -> Generator [ Tuple [ OphydObject , T ], None , None ]: \"\"\" Find all signal metadata that match the given criteria. Yields ------ root : OphydObject The root OphydObject - may be the same as signal. This is guaranteed to have happi metadata on it as the ``md`` attribute. sig : signal_class Signals of type `signal_class`. \"\"\" patch_and_use_dummy_shim () def is_of_class ( obj ): return isinstance ( obj , signal_class ) if not criteria : devices = get_all_devices () else : devices = get_devices_by_criteria ( criteria ) for dev in devices : if not hasattr ( dev , \"md\" ): # This should be a guarantee, but check just in case. continue for sig in get_components_matching ( dev , predicate = is_of_class ): yield dev , sig # Top-level devices are OK too if isinstance ( dev , signal_class ): yield dev , dev","title":"find_signals()"},{"location":"plugins/#whatrecord.plugins.happi.get_all_devices","text":"Get all devices from a given happi client. Parameters: Name Type Description Default client happi.Client The happi client to use. Defaults to using one from the environment configuration. None Source code in whatrecord/plugins/happi.py def get_all_devices ( client : happi . Client = None , ) -> Generator [ ophyd . Device , None , None ]: \"\"\" Get all devices from a given happi client. Parameters ---------- client : happi.Client, optional The happi client to use. Defaults to using one from the environment configuration. Yields ------ ophyd.Device \"\"\" if client is None : client = happi . Client . from_config () if hasattr ( client . backend , \"_load_or_initialize\" ): # HACK: TODO: avoid re-re-re-reading the JSON database; happi needs # some work. loaded_database = client . backend . _load_or_initialize () client . backend . _load_or_initialize = lambda : loaded_database for dev in client : try : obj = client [ dev ] . get () except Exception : logger . exception ( \"Failed to instantiate device: %s \" , dev ) else : yield obj","title":"get_all_devices()"},{"location":"plugins/#whatrecord.plugins.happi.get_components_matching","text":"Find signals of a specific type from a given ophyd Device. Parameters: Name Type Description Default obj ophyd.Device The ophyd Device. required predicate callable Callable that should return True on a match. required Source code in whatrecord/plugins/happi.py def get_components_matching ( obj : ophyd . Device , predicate : callable , ) -> Generator [ OphydObject , None , None ]: \"\"\" Find signals of a specific type from a given ophyd Device. Parameters ---------- obj : ophyd.Device The ophyd Device. predicate : callable Callable that should return True on a match. Yields ------ obj : OphydObject \"\"\" for name , dev in obj . walk_subdevices ( include_lazy = True ): try : included = predicate ( dev ) except Exception : logger . exception ( \"Failed to check predicate against %s %s \" , name , dev ) else : if included : yield dev for walk in obj . walk_signals ( include_lazy = True ): try : included = predicate ( walk . item ) except Exception : logger . exception ( \"Failed to check predicate against %s \" , walk ) else : if included : yield walk . item","title":"get_components_matching()"},{"location":"plugins/#whatrecord.plugins.happi.get_devices_by_criteria","text":"Get all devices from a given happi client. Parameters: Name Type Description Default search_criteria CriteriaDict Dictionary of {'happi_key': 'search_value'} . required client happi.Client The happi client to use. Defaults to using one from the environment configuration. None Source code in whatrecord/plugins/happi.py def get_devices_by_criteria ( search_criteria : CriteriaDict , * , client : happi . Client = None , regex : bool = True , ) -> Generator [ ophyd . Device , None , None ]: \"\"\" Get all devices from a given happi client. Parameters ---------- search_criteria : dict Dictionary of ``{'happi_key': 'search_value'}``. client : happi.Client, optional The happi client to use. Defaults to using one from the environment configuration. Yields ------ ophyd.Device \"\"\" if client is None : client = happi . Client . from_config () search_method = client . search_regex if regex else client . search for item in search_method ( ** search_criteria ): try : obj = item . get () except Exception : logger . exception ( \"Failed to instantiate device: %s \" , obj ) else : yield obj","title":"get_devices_by_criteria()"},{"location":"plugins/#whatrecord.plugins.happi.patch_and_use_dummy_shim","text":"Hack ophyd and its dummy shim. We don't want any control-layer connections being made while we're looking for signals. Source code in whatrecord/plugins/happi.py def patch_and_use_dummy_shim (): \"\"\" Hack ophyd and its dummy shim. We don't want _any_ control-layer connections being made while we're looking for signals. Warning ------- Under no circumstances should this be used in a production environment where you intend to actually _use_ ophyd for its intended purpose. \"\"\" ophyd . Device . lazy_wait_for_connection = False def _no_op ( * args , ** kwargs ): ... class _PVStandIn : _reference_count = 0 def __init__ ( self , pvname , * args , ** kwargs ): self . pvname = pvname self . connected = True add_callback = _no_op remove_callback = _no_op clear_callbacks = _no_op get = _no_op put = _no_op get_with_metadata = _no_op wait_for_connection = _no_op def get_pv ( pvname , * args , ** kwargs ): return _PVStandIn ( pvname ) from ophyd import _dummy_shim _dummy_shim . get_pv = get_pv _dummy_shim . release_pvs = _no_op ophyd . set_cl ( \"dummy\" )","title":"patch_and_use_dummy_shim()"},{"location":"plugins/#whatrecord.plugins.netconfig","text":"LDAP Configuration summary plugin","title":"netconfig"},{"location":"plugins/#whatrecord.plugins.netconfig-classes","text":"","title":"Classes"},{"location":"plugins/#whatrecord.plugins.netconfig.NetconfigPluginResults","text":"NetconfigPluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/plugins/netconfig.py @dataclass class NetconfigPluginResults ( PluginResults ): # Could potentially further specify metadata_by_key or metadata ...","title":"NetconfigPluginResults"},{"location":"plugins/#whatrecord.plugins.netconfig-functions","text":"","title":"Functions"},{"location":"plugins/#whatrecord.plugins.netconfig.decode_ldap_attrs","text":"Decode byte-filled LDAP attrs dictionary. Source code in whatrecord/plugins/netconfig.py def decode_ldap_attrs ( attrs : Dict [ str , List [ bytes ]], encoding = LDAP_ENCODING ) -> Dict [ str , List [ str ]]: \"\"\"Decode byte-filled LDAP attrs dictionary.\"\"\" def decode_value ( key : str , value : List [ bytes ]): return [ part . decode ( encoding , \"replace\" ) for part in value ] return { key : decode_value ( key , value ) for key , value in attrs . items ()}","title":"decode_ldap_attrs()"},{"location":"plugins/#whatrecord.plugins.util","text":"","title":"util"},{"location":"plugins/#whatrecordpluginsgdb_binary_info","text":"A GDB script to get useful information out of IOC binaries.","title":"whatrecord.plugins.gdb_binary_info"},{"location":"server_client/","text":"Server / client Starting the backend API server With the provided test-suite IOCs: $ whatrecord server --scripts whatrecord/tests/iocs/*/st.cmd Gateway configuration among others can be specified separately, if available. Starting the frontend Install dependencies: $ conda install -c conda-forge nodejs $ cd frontend $ yarn install Compile and reload automatically when frontend files change: $ yarn serve Or alternatively compile and minify for production: $ yarn build Tweaking frontend settings In frontend/.env.local : API_HOST=localhost API_PORT=8898 FRONTEND_PORT=8899 WHATRECORD_PLUGINS=happi twincat_pytmc # The following is accessible in the vue frontend: VUE_APP_WHATRECORD_PLUGINS=$WHATRECORD_PLUGINS General flow Using the core tools: * Load up all EPICS IOCs listed in IOC manager - Load the startup scripts - Load all the databases and supported files * Provide a backend service for querying the information * Based on the backend server, provide a frontend for easy access to that information - vue.js-based frontend single-page application - Search for records/IOCs/etc by name and dig into the details... API whatrecord.ioc_finder Classes whatrecord.ioc_finder.IocScriptExternalLoader ( _IocInfoFinder ) dataclass IocScriptExternalLoader(load_script: str, scripts: Dict[pathlib.Path, whatrecord.common.IocMetadata] = ) Source code in whatrecord/ioc_finder.py @dataclasses . dataclass class IocScriptExternalLoader ( _IocInfoFinder ): load_script : str scripts : Dict [ pathlib . Path , IocMetadata ] = field ( default_factory = dict ) async def update ( self ): result = await run_script_with_json_output ( self . load_script ) for info in ( result or {}): self . add_or_update_entry ( IocMetadata . from_dict ( info )) return await super () . update () whatrecord.ioc_finder.IocScriptStaticInfoList ( _IocInfoFinder ) dataclass IocScriptStaticInfoList(ioc_infos: dataclasses.InitVar[typing.List[typing.Dict[str, typing.Union[str, typing.Dict[str, str], typing.List[str]]]]], scripts: Dict[pathlib.Path, whatrecord.common.IocMetadata] = ) Source code in whatrecord/ioc_finder.py @dataclasses . dataclass class IocScriptStaticInfoList ( _IocInfoFinder ): ioc_infos : InitVar [ List [ IocInfoDict ]] scripts : Dict [ pathlib . Path , IocMetadata ] = field ( default_factory = dict ) def __post_init__ ( self , ioc_infos : List [ IocInfoDict ]): for info in ioc_infos : self . add_or_update_entry ( IocMetadata . from_dict ( info )) whatrecord.ioc_finder.IocScriptStaticList ( _IocInfoFinder ) dataclass IocScriptStaticList(script_list: dataclasses.InitVar[typing.List[typing.Union[str, pathlib.Path]]], scripts: Dict[pathlib.Path, whatrecord.common.IocMetadata] = ) Source code in whatrecord/ioc_finder.py @dataclasses . dataclass class IocScriptStaticList ( _IocInfoFinder ): script_list : InitVar [ List [ Union [ str , pathlib . Path ]]] scripts : Dict [ pathlib . Path , IocMetadata ] = field ( default_factory = dict ) def __post_init__ ( self , script_list : List [ IocInfoDict ]): for fn in script_list : self . add_or_update_entry ( IocMetadata . from_file ( fn )) whatrecord.client Functions whatrecord . client . get_iocs ( pattern : str = '*' , server : Optional [ str ] = None , regex : bool = False ) -> IocGetMatchesResponse async Get record information from the server. Source code in whatrecord/client.py async def get_iocs ( pattern : str = \"*\" , server : Optional [ str ] = None , regex : bool = False ) -> IocGetMatchesResponse : \"\"\"Get record information from the server.\"\"\" response = await make_query ( \"/api/ioc/matches\" , server = server , params = dict ( pattern = pattern , regex = str ( regex )) ) return apischema . deserialize ( IocGetMatchesResponse , response ) whatrecord . client . get_record_info ( * records , * , server : Optional [ str ] = None ) -> Dict [ str , whatrecord . server . common . PVGetInfo ] async Get record information from the server. Source code in whatrecord/client.py async def get_record_info ( * records , server : Optional [ str ] = None ) -> Dict [ str , PVGetInfo ]: \"\"\"Get record information from the server.\"\"\" response = await make_query ( \"/api/pv/info\" , server = server , params = dict ( pv = list ( records ))) return apischema . deserialize ( Dict [ str , PVGetInfo ], response ) whatrecord.server special Modules whatrecord.server.common Classes whatrecord.server.common.IocGetDuplicatesResponse dataclass IocGetDuplicatesResponse(patterns: 'List[str]', regex: 'bool', duplicates: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class IocGetDuplicatesResponse : patterns : List [ str ] regex : bool duplicates : Dict [ str , List [ str ]] whatrecord.server.common.IocGetMatchesResponse dataclass IocGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[IocMetadata]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ IocMetadata ] whatrecord.server.common.IocGetMatchingRecordsResponse dataclass IocGetMatchingRecordsResponse(ioc_patterns: 'List[str]', record_patterns: 'List[str]', regex: 'bool', matches: 'List[Tuple[IocMetadata, List[AnyRecordInstance]]]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchingRecordsResponse : ioc_patterns : List [ str ] record_patterns : List [ str ] regex : bool # TODO: ew, redo this matches : List [ Tuple [ IocMetadata , List [ AnyRecordInstance ]]] whatrecord.server.common.PVGetInfo dataclass PVGetInfo(pv_name: 'str', present: 'bool', info: 'List[WhatRecord]') Source code in whatrecord/server/common.py @dataclass class PVGetInfo : pv_name : str present : bool info : List [ WhatRecord ] _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ {{ pv_name }}: In database: {{ present }} { % f or _info in info %} { % s et item_info = render_object(_info, \"console\") %} {{ item_info | indent(4)}} { % e ndfor %} } \"\"\" , } whatrecord.server.common.PVGetMatchesResponse dataclass PVGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[str]') Source code in whatrecord/server/common.py @dataclass class PVGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ str ] whatrecord.server.common.PVRelationshipResponse dataclass PVRelationshipResponse(pv_relations: 'PVRelations', script_relations: 'ScriptPVRelations', ioc_to_pvs: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class PVRelationshipResponse : pv_relations : PVRelations script_relations : ScriptPVRelations ioc_to_pvs : Dict [ str , List [ str ]] whatrecord.server.common.PVShortRelationshipResponse dataclass PVShortRelationshipResponse(script_relations: 'ScriptPVRelations') Source code in whatrecord/server/common.py @dataclass class PVShortRelationshipResponse : # pv_relations: PVRelationsSummary script_relations : ScriptPVRelations # ioc_to_pvs: Dict[str, List[str]] @classmethod def from_pv_relations ( cls , pv_relations : PVRelations , script_relations : ScriptPVRelations , ioc_to_pvs : Dict [ str , List [ str ]], ) -> PVRelationshipResponse : # summary = { # pv1: list(pv2s) # for pv1, pv2s in pv_relations.items() # } return cls ( # pv_relations=summary, script_relations = script_relations , # ioc_to_pvs=ioc_to_pvs, ) whatrecord.server.common.PluginResults dataclass PluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/server/common.py @dataclass class PluginResults : files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) record_to_metadata_keys : Dict [ str , List [ str ]] = field ( default_factory = dict ) metadata_by_key : Dict [ str , Any ] = field ( default_factory = dict ) metadata : Any = None execution_info : Dict [ str , Any ] = field ( default_factory = dict ) nested : Optional [ Dict [ str , PluginResults ]] = None def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info Methods whatrecord . server . common . PluginResults . find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info whatrecord . server . common . PluginResults . find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) whatrecord . server . common . PluginResults . is_loaded_file ( self , fn : str ) -> bool Is the given file one that was loaded in the plugin? Source code in whatrecord/server/common.py def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) whatrecord.server.common.RecordFieldSummary dataclass RecordFieldSummary(dtype: 'str', name: 'str', value: 'Any') Source code in whatrecord/server/common.py @dataclass class RecordFieldSummary : dtype : str name : str value : Any _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\"field({{name}}, \"{{value}}\")\"\"\" , \"console-verbose\" : \"\"\" \\ field({{name}}, \"{{value}}\") \"\"\" , } whatrecord.server.common.ServerPluginSpec dataclass ServerPluginSpec(name: 'str', module: 'Optional[str]' = None, executable: 'Optional[List[str]]' = None, files_to_monitor: 'Dict[str, str]' = , results: 'Optional[PluginResults]' = None, results_json: 'Any' = None, after_iocs: 'bool' = False) Source code in whatrecord/server/common.py @dataclass class ServerPluginSpec : name : str #: Python module module : Optional [ str ] = None #: Or any executable executable : Optional [ List [ str ]] = None #: Can be a dataclass or a builtin type # result_class: type files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) results : Optional [ PluginResults ] = None results_json : Any = None # Require IOCs to be loaded first before running after_iocs : bool = False @property def script ( self ) -> str : \"\"\"The script and arguments to run for the plugin.\"\"\" if self . executable : return \" \" . join ( f '\" { param } \"' for param in self . executable ) elif self . module : return f '\" { sys . executable } \" -m { self . module } ' raise ValueError ( \"module and executable both unset\" ) async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results Attributes whatrecord . server . common . ServerPluginSpec . script : str property readonly The script and arguments to run for the plugin. Methods whatrecord . server . common . ServerPluginSpec . update ( self ) -> Optional [ PluginResults ] async Call the plugin and get new information, storing it in results. Source code in whatrecord/server/common.py async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results whatrecord.server.server Classes whatrecord.server.server.ServerHandler Source code in whatrecord/server/server.py class ServerHandler : routes = web . RouteTableDef () def __init__ ( self , state : ServerState ): self . state = state async def async_init ( self , app ): await self . state . async_init ( app ) @routes . get ( \"/api/pv/info\" ) async def api_pv_get_info ( self , request : web . Request ): pv_names = request . query . getall ( \"pv\" ) info = { pv_name : self . state . whatrec ( pv_name ) for pv_name in pv_names } return serialized_response ( { pv_name : PVGetInfo ( pv_name = pv_name , present = ( pv_name in self . state . database or pv_name in self . state . pva_database ), info = [ obj for obj in info [ pv_name ]], ) for pv_name in pv_names } ) @routes . get ( \"/api/pv/matches\" ) async def api_pv_get_matches ( self , request : web . Request ): max_matches = int ( request . query . get ( \"max\" , \"200\" )) use_regex , patterns = get_patterns ( request . query ) matches = self . state . get_matching_pvs ( patterns , use_regex = use_regex ) if max_matches > 0 : matches = matches [: max_matches ] return serialized_response ( PVGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = matches , ) ) @routes . get ( \"/api/ioc/matches\" ) async def api_ioc_get_matches ( self , request : web . Request ): # Ignore max for now. This is not much in the way of information. # max_matches = int(request.query.get(\"max\", \"1000\")) use_regex , patterns = get_patterns ( request . query ) match_metadata = [ loaded_ioc . metadata for loaded_ioc in self . state . get_matching_iocs ( patterns , use_regex = use_regex ) ] return serialized_response ( IocGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = match_metadata , ) ) @routes . get ( \"/api/ioc/pvs\" ) async def api_ioc_get_pvs ( self , request : web . Request ): use_regex , ioc_patterns = get_patterns ( request . query , key = \"ioc\" ) _ , record_patterns = get_patterns ( request . query , key = \"pv\" ) response = IocGetMatchingRecordsResponse ( ioc_patterns = ioc_patterns , record_patterns = record_patterns , regex = use_regex , matches = [], ) def get_all_records ( shell_state ): yield from shell_state . database . items () yield from shell_state . pva_database . items () try : pv_glob_re = compile_patterns ( record_patterns , use_regex = use_regex , ) except re . error : raise web . HTTPBadRequest () for loaded_ioc in self . state . get_matching_iocs ( ioc_patterns , use_regex = response . regex , ): record_matches = [ rec_info . to_summary () for rec , rec_info in sorted ( get_all_records ( loaded_ioc . shell_state )) if pv_glob_re . match ( rec ) ] if record_matches : response . matches . append (( loaded_ioc . metadata , record_matches )) return serialized_response ( response ) @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) # @routes.get(\"/api/graphql/query\") # async def api_graphql_query(self, request: web.Request): # TODO: ... @routes . get ( \"/api/plugin/info\" ) async def api_plugin_info ( self , request : web . Request ): plugins = request . query . get ( \"plugin\" , \"all\" ) allow_list = None if plugins == \"all\" else plugins . split ( \" \" ) return serialized_response ( self . state . get_plugin_info ( allow_list )) @routes . get ( \"/api/plugin/nested/keys\" ) async def api_plugin_nested_keys ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] keys = self . state . get_plugin_nested_keys ( plugin ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( keys ) @routes . get ( \"/api/plugin/nested/info\" ) async def api_plugin_nested_info ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] key = request . query [ \"key\" ] info = self . state . get_plugin_nested_info ( plugin , key ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( info ) @routes . get ( \"/api/gateway/info\" ) async def api_gateway_info ( self , request : web . Request ): return serialized_response ( self . state . gateway_config . pvlists or {}) @routes . get ( \"/api/file/info\" ) async def api_ioc_info ( self , request : web . Request ): # script_name = pathlib.Path(request.query[\"file\"]) filename = request . query [ \"file\" ] ioc_name = self . state . container . startup_script_to_ioc . get ( filename , None ) if ioc_name : loaded_ioc = self . state . container . scripts [ ioc_name ] script_info = loaded_ioc . script ioc_md = loaded_ioc . metadata else : # Making this dual-purpose: script, db, or any loaded file ioc_md = None if not self . state . is_loaded_file ( filename ): raise web . HTTPBadRequest () script_info = self . state . script_info_from_loaded_file ( filename ) return serialized_response ( { \"script\" : script_info , \"ioc\" : ioc_md , } ) async def get_graph ( self , pv_names : List [ str ], use_glob : bool = False , graph_type : str = \"record\" , format : str = \"pdf\" ): if use_glob : pv_names = self . state . get_matching_pvs ( pv_names ) if format == \"dot\" : try : digraph = self . state . get_graph ( tuple ( pv_names ), graph_type = graph_type ) except TooManyRecordsError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = \"text/vnd.graphviz\" , body = digraph . source , ) rendered = await self . state . get_graph_rendered ( tuple ( pv_names ), format = format , graph_type = graph_type ) try : content_type = { \"pdf\" : \"application/pdf\" , \"png\" : \"image/png\" , \"svg\" : \"image/svg+xml\" , }[ format ] except KeyError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = content_type , body = rendered , ) @routes . get ( \"/api/logs/get\" ) async def api_logs_get ( self , request : web . Request ): return web . json_response ( list ( _log_handler . messages if _log_handler is not None else [ \"Logger not initialized\" ] ) ) @routes . get ( \"/api/pv/relations\" ) async def api_pv_get_relations ( self , request : web . Request ): use_regex , pv_names = get_patterns ( request . query , key = \"pv\" ) pv_names = self . state . get_matching_pvs ( pv_names , use_regex = use_regex ) full = request . query . get ( \"full\" , \"false\" ) in TRUE_VALUES return serialized_response ( self . state . get_pv_relations ( pv_names = pv_names , full = full ) ) @routes . get ( \"/api/pv/graph\" ) async def api_pv_get_record_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"record\" , ) @routes . get ( \"/api/pv/script-graph\" ) async def api_pv_get_script_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"script\" , ) Methods whatrecord . server . server . ServerHandler . api_pv_get_duplicates ( self , request : Request ) async Get record names duplicated among two or more IOCs. Source code in whatrecord/server/server.py @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) whatrecord.server.server.ServerLogHandler ( Handler ) Source code in whatrecord/server/server.py class ServerLogHandler ( logging . Handler ): def __init__ ( self , message_count : int = 1000 , level = \"DEBUG\" ): super () . __init__ ( level = level ) self . formatter = logging . Formatter ( \" %(asctime)s - PID %(process)d %(filename)18s : %(lineno)-3s \" \" %(funcName)-18s %(levelname)-8s %(message)s \" ) self . message_count = message_count self . messages = collections . deque ( maxlen = message_count ) def emit ( self , record ): self . messages . append ( self . format ( record )) Methods whatrecord . server . server . ServerLogHandler . emit ( self , record ) Do whatever it takes to actually log the specified logging record. This version is intended to be implemented by subclasses and so raises a NotImplementedError. Source code in whatrecord/server/server.py def emit ( self , record ): self . messages . append ( self . format ( record )) whatrecord.server.server.ServerState Source code in whatrecord/server/server.py class ServerState : running : bool container : ScriptContainer gateway_config : gateway . GatewayConfig script_loaders : List [ ioc_finder . _IocInfoFinder ] ioc_metadata : List [ IocMetadata ] _update_count : int def __init__ ( self , startup_scripts : Optional [ List [ str ]] = None , script_loaders : Optional [ List [ str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , gateway_config : Optional [ str ] = None , plugins : Optional [ List [ ServerPluginSpec ]] = None , ): self . running = False self . container = ScriptContainer () self . gateway_config = None self . gateway_config_path = gateway_config self . ioc_metadata = [] self . plugins = plugins or [] self . plugins_by_name = { plugin . name : plugin for plugin in plugins or [] } self . script_relations = {} self . standin_directories = standin_directories or {} self . tasks = TaskHandler () self . script_loaders = [ ioc_finder . IocScriptStaticList ( startup_scripts or []) ] + [ ioc_finder . IocScriptExternalLoader ( loader ) for loader in script_loaders or [] ] self . _update_count = 0 @property def iocs_by_name ( self ) -> Dict [ str , IocMetadata ]: \"\"\"Dictionary of IOC name to IocMetadata.\"\"\" return { ioc . name : ioc for ioc in self . ioc_metadata } def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) @property def update_count ( self ) -> int : \"\"\"The number of times IOCs have been updated.\"\"\" return self . _update_count async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) async def async_init ( self , app ): self . running = True self . tasks . create ( self . _update_loop ()) logger . info ( \"Server plugins enabled: %s \" , \", \" . join ( plugin . name for plugin in self . plugins ) ) for plugin in self . plugins : self . tasks . create ( self . _update_plugin_loop ( plugin )) async def _update_plugin_loop ( self , plugin : ServerPluginSpec ): while self . running and self . update_count == 0 and plugin . after_iocs : # Wait until IOCs have been loaded before updating this one for the # first time. await asyncio . sleep ( 1 ) logger . info ( \"Server plugin %r updates started.\" , plugin . name ) while self . running : logger . info ( \"Updating plugin: %s \" , plugin . name ) with common . time_context () as ctx : try : await plugin . update () except Exception : logger . exception ( \"Failed to update plugin %r [ %.1f s]\" , plugin . name , ctx () ) else : logger . info ( \"Successfully updated plugin %r [ %.1f s]\" , plugin . name , ctx () ) # for record, md in info[\"record_to_metadata\"].items(): # ... await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server plugin %r updates finished.\" , plugin . name ) async def _update_loop ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" while self . running : logger . info ( \"Checking for new or updated IOCs...\" ) await self . update_script_loaders () logger . info ( \"Checking for changed scripts and database files...\" ) self . _load_gateway_config () updated = self . get_updated_iocs () if not updated : logger . info ( \"No changes found.\" ) await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) continue logger . info ( \" %d IOC %s changed.\" , len ( updated ), \" has\" if len ( updated ) == 1 else \"s have\" ) for idx , ioc in enumerate ( updated [: 10 ], 1 ): logger . info ( \"* %d : %s \" , idx , ioc . name ) if len ( updated ) > 10 : logger . info ( \"... and %d more\" , len ( updated ) - 10 ) with common . time_context () as ctx : await self . update_iocs ( updated ) logger . info ( \"Updated %d IOCs in %.1f seconds\" , len ( updated ), ctx () ) self . clear_cache () await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server script updates finished.\" ) async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated def _replace_metadata ( self , old_md : IocMetadata , new_md : IocMetadata ) -> int : \"\"\"Replace the provided metadata information with a new one.\"\"\" idx = self . ioc_metadata . index ( old_md ) self . ioc_metadata . remove ( old_md ) self . ioc_metadata . insert ( idx , new_md ) return idx async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} def _load_gateway_config ( self ): if not self . gateway_config_path : logger . warning ( \"Gateway path not set; gateway configuration will not be loaded\" ) return if self . gateway_config is None : logger . info ( \"Loading gateway configuration for the first time...\" ) self . gateway_config = gateway . GatewayConfig ( self . gateway_config_path ) else : logger . info ( \"Updating gateway configuration...\" ) self . gateway_config . update_changed () for filename , pvlist in self . gateway_config . pvlists . items (): if pvlist . hash is not None : logger . debug ( \"New gateway file: %s ( %s )\" , filename , pvlist . hash ) self . container . loaded_files [ str ( filename )] = pvlist . hash def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results @property def aliases ( self ) -> Dict [ str , str ]: \"\"\"The CA/V3 aliases.\"\"\" return self . container . aliases @property def database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The CA/V3 Database of records.\"\"\" return self . container . database @property def pva_database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The pvAccess Database of groups/records.\"\"\" return self . container . pva_database def get_graph ( self , pv_names : Tuple [ str , ... ], graph_type : str ) -> graphviz . Digraph : if graph_type == \"record\" : return self . get_link_graph ( tuple ( pv_names )) if graph_type == \"script\" : return self . get_script_graph ( tuple ( pv_names )) raise RuntimeError ( \"Invalid graph type\" ) def get_script_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_script_relations ( database = self . database , limit_to_records = pv_names , script_relations = self . script_relations , ) return gr . to_digraph ( font_name = \"Courier\" ) def get_ioc_to_pvs ( self , pv_names : Tuple [ str , ... ]) -> Dict [ str , List [ str ]]: ioc_to_pvs = {} for pv in pv_names : try : owner = self . container . database [ pv ] . owner or \"unknown\" except KeyError : owner = \"unknown\" if owner not in ioc_to_pvs : ioc_to_pvs [ owner ] = [] ioc_to_pvs [ owner ] . append ( pv ) return ioc_to_pvs def get_pv_relations ( self , pv_names : Tuple [ str , ... ], * , full : bool = False , ) -> Union [ PVRelationshipResponse , PVShortRelationshipResponse ]: # TODO: pv_names if full : return PVRelationshipResponse ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) return PVShortRelationshipResponse . from_pv_relations ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) def get_link_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_links ( database = self . database , starting_records = list ( pv_names ), sort_fields = True , relations = self . container . pv_relations , ) digraph = gr . to_digraph ( font_name = \"Courier\" ) return digraph def clear_cache ( self ): for method in [ # self.get_graph, # self.get_graph_rendered, self . get_gateway_matches , self . get_matching_pvs , self . get_matching_iocs , self . script_info_from_loaded_file , self . get_duplicates , ]: method . cache_clear () def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) @functools . lru_cache ( maxsize = 2048 ) def script_info_from_loaded_file ( self , fn ) -> common . IocshScript : with open ( fn , \"rt\" ) as fp : lines = fp . read () . splitlines () result = [] for lineno , line in enumerate ( lines , 1 ): result . append ( common . IocshResult ( context = ( LoadContext ( fn , lineno ),), line = line , ) ) return common . IocshScript ( path = fn , lines = tuple ( result )) @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () Attributes whatrecord . server . server . ServerState . aliases : Dict [ str , str ] property readonly The CA/V3 aliases. whatrecord . server . server . ServerState . database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The CA/V3 Database of records. whatrecord . server . server . ServerState . iocs_by_name : Dict [ str , whatrecord . common . IocMetadata ] property readonly Dictionary of IOC name to IocMetadata. whatrecord . server . server . ServerState . pva_database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The pvAccess Database of groups/records. whatrecord . server . server . ServerState . update_count : int property readonly The number of times IOCs have been updated. Methods whatrecord . server . server . ServerState . add_or_update_ioc_metadata ( self , md : IocMetadata ) Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. Source code in whatrecord/server/server.py def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) whatrecord . server . server . ServerState . annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord Annotate WhatRecord instances with things ServerState knows about. Source code in whatrecord/server/server.py def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what whatrecord . server . server . ServerState . get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]] Get duplicate PVs from the matching IOC(s). Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } whatrecord . server . server . ServerState . get_gateway_matches ( self , pvname : str ) -> Optional [ whatrecord . gateway . PVListMatches ] Get gateway matches for the given pvname. Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) whatrecord . server . server . ServerState . get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes async Get a rendered PV relationship graph of the provided PVs. Parameters: Name Type Description Default pv_names Tuple[str, ...] PV names. required format str The format of the graph (e.g., pdf, png). required graph_type str The type of graph to generate. required Source code in whatrecord/server/server.py async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () whatrecord . server . server . ServerState . get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ whatrecord . shell . LoadedIoc ] Get matching IOCs given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] whatrecord . server . server . ServerState . get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ] Get matching PV names given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] whatrecord . server . server . ServerState . get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ] Get plugin information as a dictionary. Source code in whatrecord/server/server.py def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } whatrecord . server . server . ServerState . get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any Get plugin custom nested metadata info. Source code in whatrecord/server/server.py def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} whatrecord . server . server . ServerState . get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ] Get plugin custom nested metadata keys. Source code in whatrecord/server/server.py def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] whatrecord . server . server . ServerState . get_updated_iocs ( self ) -> List [ whatrecord . common . IocMetadata ] Check loaded IOCs for any changes. Source code in whatrecord/server/server.py def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated whatrecord . server . server . ServerState . is_loaded_file ( self , fn ) -> bool Is fn a file that was loaded? Source code in whatrecord/server/server.py def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) whatrecord . server . server . ServerState . stop ( self ) async Stop any background updates. Source code in whatrecord/server/server.py async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) whatrecord . server . server . ServerState . update_iocs ( self , iocs : List [ whatrecord . common . IocMetadata ]) async Reload the provided IOCs. Source code in whatrecord/server/server.py async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 whatrecord . server . server . ServerState . update_script_loaders ( self ) async Update scripts from the script loader and watch for updates. Source code in whatrecord/server/server.py async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) whatrecord . server . server . ServerState . whatrec ( self , pvname : str ) -> List [ whatrecord . common . WhatRecord ] Find WhatRecord matches. Source code in whatrecord/server/server.py def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results Functions whatrecord . server . server . compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ) Compile regular expression (or glob) patterns with re.compile . Source code in whatrecord/server/server.py def compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ): \"\"\"Compile regular expression (or glob) patterns with `re.compile`.\"\"\" if use_regex : return re . compile ( \"|\" . join ( patterns ), flags = flags ) return re . compile ( \"|\" . join ( fnmatch . translate ( pattern ) for pattern in patterns ), flags = flags , ) whatrecord . server . server . get_patterns ( query , key : str = 'pattern' , regex_key : str = 'regex' ) -> Tuple [ bool , Tuple [ str , ... ]] Get glob/regex patterns from a server query. Source code in whatrecord/server/server.py def get_patterns ( query , key : str = \"pattern\" , regex_key : str = \"regex\" ) -> Tuple [ bool , Tuple [ str , ... ]]: \"\"\"Get glob/regex patterns from a server query.\"\"\" use_regex = query . get ( regex_key , \"false\" ) . lower () in TRUE_VALUES default = ( \".*\" if use_regex else \"*\" ,) return use_regex , tuple ( query . getall ( key , default )) whatrecord . server . server . serialized_response ( obj : Any ) -> Response Return an apischema-serialized JSON response of a dataclass instance. Source code in whatrecord/server/server.py def serialized_response ( obj : Any ) -> web . Response : \"\"\"Return an apischema-serialized JSON response of a dataclass instance.\"\"\" return web . json_response ( apischema . serialize ( obj )) whatrecord.server.util Classes whatrecord.server.util.TaskHandler Helper to manage asyncio tasks in one spot. Source code in whatrecord/server/util.py class TaskHandler : \"\"\"Helper to manage asyncio tasks in one spot.\"\"\" def __init__ ( self ): self . tasks = [] self . _lock = threading . Lock () def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task def _remove_completed_task ( self , task ): try : with self . _lock : self . tasks . remove ( task ) except ValueError : # May have been cancelled or removed otherwise ... @staticmethod async def cancel ( task ): task . cancel () await task async def cancel_all ( self , wait = False ): with self . _lock : tasks = list ( self . tasks ) self . tasks . clear () for task in list ( tasks ): task . cancel () if wait and len ( tasks ): await asyncio . wait ( tasks ) Methods whatrecord . server . util . TaskHandler . create ( self , coro ) Schedule the execution of a coroutine object in a spawn task. Source code in whatrecord/server/util.py def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task whatrecord.server.common Classes whatrecord.server.common.IocGetDuplicatesResponse dataclass IocGetDuplicatesResponse(patterns: 'List[str]', regex: 'bool', duplicates: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class IocGetDuplicatesResponse : patterns : List [ str ] regex : bool duplicates : Dict [ str , List [ str ]] whatrecord.server.common.IocGetMatchesResponse dataclass IocGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[IocMetadata]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ IocMetadata ] whatrecord.server.common.IocGetMatchingRecordsResponse dataclass IocGetMatchingRecordsResponse(ioc_patterns: 'List[str]', record_patterns: 'List[str]', regex: 'bool', matches: 'List[Tuple[IocMetadata, List[AnyRecordInstance]]]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchingRecordsResponse : ioc_patterns : List [ str ] record_patterns : List [ str ] regex : bool # TODO: ew, redo this matches : List [ Tuple [ IocMetadata , List [ AnyRecordInstance ]]] whatrecord.server.common.PVGetInfo dataclass PVGetInfo(pv_name: 'str', present: 'bool', info: 'List[WhatRecord]') Source code in whatrecord/server/common.py @dataclass class PVGetInfo : pv_name : str present : bool info : List [ WhatRecord ] _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ {{ pv_name }}: In database: {{ present }} { % f or _info in info %} { % s et item_info = render_object(_info, \"console\") %} {{ item_info | indent(4)}} { % e ndfor %} } \"\"\" , } whatrecord.server.common.PVGetMatchesResponse dataclass PVGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[str]') Source code in whatrecord/server/common.py @dataclass class PVGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ str ] whatrecord.server.common.PVRelationshipResponse dataclass PVRelationshipResponse(pv_relations: 'PVRelations', script_relations: 'ScriptPVRelations', ioc_to_pvs: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class PVRelationshipResponse : pv_relations : PVRelations script_relations : ScriptPVRelations ioc_to_pvs : Dict [ str , List [ str ]] whatrecord.server.common.PVShortRelationshipResponse dataclass PVShortRelationshipResponse(script_relations: 'ScriptPVRelations') Source code in whatrecord/server/common.py @dataclass class PVShortRelationshipResponse : # pv_relations: PVRelationsSummary script_relations : ScriptPVRelations # ioc_to_pvs: Dict[str, List[str]] @classmethod def from_pv_relations ( cls , pv_relations : PVRelations , script_relations : ScriptPVRelations , ioc_to_pvs : Dict [ str , List [ str ]], ) -> PVRelationshipResponse : # summary = { # pv1: list(pv2s) # for pv1, pv2s in pv_relations.items() # } return cls ( # pv_relations=summary, script_relations = script_relations , # ioc_to_pvs=ioc_to_pvs, ) whatrecord.server.common.PluginResults dataclass PluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/server/common.py @dataclass class PluginResults : files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) record_to_metadata_keys : Dict [ str , List [ str ]] = field ( default_factory = dict ) metadata_by_key : Dict [ str , Any ] = field ( default_factory = dict ) metadata : Any = None execution_info : Dict [ str , Any ] = field ( default_factory = dict ) nested : Optional [ Dict [ str , PluginResults ]] = None def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info Methods whatrecord . server . common . PluginResults . find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info whatrecord . server . common . PluginResults . find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) whatrecord . server . common . PluginResults . is_loaded_file ( self , fn : str ) -> bool Is the given file one that was loaded in the plugin? Source code in whatrecord/server/common.py def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) whatrecord.server.common.RecordFieldSummary dataclass RecordFieldSummary(dtype: 'str', name: 'str', value: 'Any') Source code in whatrecord/server/common.py @dataclass class RecordFieldSummary : dtype : str name : str value : Any _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\"field({{name}}, \"{{value}}\")\"\"\" , \"console-verbose\" : \"\"\" \\ field({{name}}, \"{{value}}\") \"\"\" , } whatrecord.server.common.ServerPluginSpec dataclass ServerPluginSpec(name: 'str', module: 'Optional[str]' = None, executable: 'Optional[List[str]]' = None, files_to_monitor: 'Dict[str, str]' = , results: 'Optional[PluginResults]' = None, results_json: 'Any' = None, after_iocs: 'bool' = False) Source code in whatrecord/server/common.py @dataclass class ServerPluginSpec : name : str #: Python module module : Optional [ str ] = None #: Or any executable executable : Optional [ List [ str ]] = None #: Can be a dataclass or a builtin type # result_class: type files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) results : Optional [ PluginResults ] = None results_json : Any = None # Require IOCs to be loaded first before running after_iocs : bool = False @property def script ( self ) -> str : \"\"\"The script and arguments to run for the plugin.\"\"\" if self . executable : return \" \" . join ( f '\" { param } \"' for param in self . executable ) elif self . module : return f '\" { sys . executable } \" -m { self . module } ' raise ValueError ( \"module and executable both unset\" ) async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results Attributes whatrecord . server . common . ServerPluginSpec . script : str property readonly The script and arguments to run for the plugin. Methods whatrecord . server . common . ServerPluginSpec . update ( self ) -> Optional [ PluginResults ] async Call the plugin and get new information, storing it in results. Source code in whatrecord/server/common.py async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results whatrecord.server.server Classes whatrecord.server.server.ServerHandler Source code in whatrecord/server/server.py class ServerHandler : routes = web . RouteTableDef () def __init__ ( self , state : ServerState ): self . state = state async def async_init ( self , app ): await self . state . async_init ( app ) @routes . get ( \"/api/pv/info\" ) async def api_pv_get_info ( self , request : web . Request ): pv_names = request . query . getall ( \"pv\" ) info = { pv_name : self . state . whatrec ( pv_name ) for pv_name in pv_names } return serialized_response ( { pv_name : PVGetInfo ( pv_name = pv_name , present = ( pv_name in self . state . database or pv_name in self . state . pva_database ), info = [ obj for obj in info [ pv_name ]], ) for pv_name in pv_names } ) @routes . get ( \"/api/pv/matches\" ) async def api_pv_get_matches ( self , request : web . Request ): max_matches = int ( request . query . get ( \"max\" , \"200\" )) use_regex , patterns = get_patterns ( request . query ) matches = self . state . get_matching_pvs ( patterns , use_regex = use_regex ) if max_matches > 0 : matches = matches [: max_matches ] return serialized_response ( PVGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = matches , ) ) @routes . get ( \"/api/ioc/matches\" ) async def api_ioc_get_matches ( self , request : web . Request ): # Ignore max for now. This is not much in the way of information. # max_matches = int(request.query.get(\"max\", \"1000\")) use_regex , patterns = get_patterns ( request . query ) match_metadata = [ loaded_ioc . metadata for loaded_ioc in self . state . get_matching_iocs ( patterns , use_regex = use_regex ) ] return serialized_response ( IocGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = match_metadata , ) ) @routes . get ( \"/api/ioc/pvs\" ) async def api_ioc_get_pvs ( self , request : web . Request ): use_regex , ioc_patterns = get_patterns ( request . query , key = \"ioc\" ) _ , record_patterns = get_patterns ( request . query , key = \"pv\" ) response = IocGetMatchingRecordsResponse ( ioc_patterns = ioc_patterns , record_patterns = record_patterns , regex = use_regex , matches = [], ) def get_all_records ( shell_state ): yield from shell_state . database . items () yield from shell_state . pva_database . items () try : pv_glob_re = compile_patterns ( record_patterns , use_regex = use_regex , ) except re . error : raise web . HTTPBadRequest () for loaded_ioc in self . state . get_matching_iocs ( ioc_patterns , use_regex = response . regex , ): record_matches = [ rec_info . to_summary () for rec , rec_info in sorted ( get_all_records ( loaded_ioc . shell_state )) if pv_glob_re . match ( rec ) ] if record_matches : response . matches . append (( loaded_ioc . metadata , record_matches )) return serialized_response ( response ) @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) # @routes.get(\"/api/graphql/query\") # async def api_graphql_query(self, request: web.Request): # TODO: ... @routes . get ( \"/api/plugin/info\" ) async def api_plugin_info ( self , request : web . Request ): plugins = request . query . get ( \"plugin\" , \"all\" ) allow_list = None if plugins == \"all\" else plugins . split ( \" \" ) return serialized_response ( self . state . get_plugin_info ( allow_list )) @routes . get ( \"/api/plugin/nested/keys\" ) async def api_plugin_nested_keys ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] keys = self . state . get_plugin_nested_keys ( plugin ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( keys ) @routes . get ( \"/api/plugin/nested/info\" ) async def api_plugin_nested_info ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] key = request . query [ \"key\" ] info = self . state . get_plugin_nested_info ( plugin , key ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( info ) @routes . get ( \"/api/gateway/info\" ) async def api_gateway_info ( self , request : web . Request ): return serialized_response ( self . state . gateway_config . pvlists or {}) @routes . get ( \"/api/file/info\" ) async def api_ioc_info ( self , request : web . Request ): # script_name = pathlib.Path(request.query[\"file\"]) filename = request . query [ \"file\" ] ioc_name = self . state . container . startup_script_to_ioc . get ( filename , None ) if ioc_name : loaded_ioc = self . state . container . scripts [ ioc_name ] script_info = loaded_ioc . script ioc_md = loaded_ioc . metadata else : # Making this dual-purpose: script, db, or any loaded file ioc_md = None if not self . state . is_loaded_file ( filename ): raise web . HTTPBadRequest () script_info = self . state . script_info_from_loaded_file ( filename ) return serialized_response ( { \"script\" : script_info , \"ioc\" : ioc_md , } ) async def get_graph ( self , pv_names : List [ str ], use_glob : bool = False , graph_type : str = \"record\" , format : str = \"pdf\" ): if use_glob : pv_names = self . state . get_matching_pvs ( pv_names ) if format == \"dot\" : try : digraph = self . state . get_graph ( tuple ( pv_names ), graph_type = graph_type ) except TooManyRecordsError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = \"text/vnd.graphviz\" , body = digraph . source , ) rendered = await self . state . get_graph_rendered ( tuple ( pv_names ), format = format , graph_type = graph_type ) try : content_type = { \"pdf\" : \"application/pdf\" , \"png\" : \"image/png\" , \"svg\" : \"image/svg+xml\" , }[ format ] except KeyError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = content_type , body = rendered , ) @routes . get ( \"/api/logs/get\" ) async def api_logs_get ( self , request : web . Request ): return web . json_response ( list ( _log_handler . messages if _log_handler is not None else [ \"Logger not initialized\" ] ) ) @routes . get ( \"/api/pv/relations\" ) async def api_pv_get_relations ( self , request : web . Request ): use_regex , pv_names = get_patterns ( request . query , key = \"pv\" ) pv_names = self . state . get_matching_pvs ( pv_names , use_regex = use_regex ) full = request . query . get ( \"full\" , \"false\" ) in TRUE_VALUES return serialized_response ( self . state . get_pv_relations ( pv_names = pv_names , full = full ) ) @routes . get ( \"/api/pv/graph\" ) async def api_pv_get_record_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"record\" , ) @routes . get ( \"/api/pv/script-graph\" ) async def api_pv_get_script_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"script\" , ) Methods whatrecord . server . server . ServerHandler . api_pv_get_duplicates ( self , request : Request ) async Get record names duplicated among two or more IOCs. Source code in whatrecord/server/server.py @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) whatrecord.server.server.ServerLogHandler ( Handler ) Source code in whatrecord/server/server.py class ServerLogHandler ( logging . Handler ): def __init__ ( self , message_count : int = 1000 , level = \"DEBUG\" ): super () . __init__ ( level = level ) self . formatter = logging . Formatter ( \" %(asctime)s - PID %(process)d %(filename)18s : %(lineno)-3s \" \" %(funcName)-18s %(levelname)-8s %(message)s \" ) self . message_count = message_count self . messages = collections . deque ( maxlen = message_count ) def emit ( self , record ): self . messages . append ( self . format ( record )) Methods whatrecord . server . server . ServerLogHandler . emit ( self , record ) Do whatever it takes to actually log the specified logging record. This version is intended to be implemented by subclasses and so raises a NotImplementedError. Source code in whatrecord/server/server.py def emit ( self , record ): self . messages . append ( self . format ( record )) whatrecord.server.server.ServerState Source code in whatrecord/server/server.py class ServerState : running : bool container : ScriptContainer gateway_config : gateway . GatewayConfig script_loaders : List [ ioc_finder . _IocInfoFinder ] ioc_metadata : List [ IocMetadata ] _update_count : int def __init__ ( self , startup_scripts : Optional [ List [ str ]] = None , script_loaders : Optional [ List [ str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , gateway_config : Optional [ str ] = None , plugins : Optional [ List [ ServerPluginSpec ]] = None , ): self . running = False self . container = ScriptContainer () self . gateway_config = None self . gateway_config_path = gateway_config self . ioc_metadata = [] self . plugins = plugins or [] self . plugins_by_name = { plugin . name : plugin for plugin in plugins or [] } self . script_relations = {} self . standin_directories = standin_directories or {} self . tasks = TaskHandler () self . script_loaders = [ ioc_finder . IocScriptStaticList ( startup_scripts or []) ] + [ ioc_finder . IocScriptExternalLoader ( loader ) for loader in script_loaders or [] ] self . _update_count = 0 @property def iocs_by_name ( self ) -> Dict [ str , IocMetadata ]: \"\"\"Dictionary of IOC name to IocMetadata.\"\"\" return { ioc . name : ioc for ioc in self . ioc_metadata } def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) @property def update_count ( self ) -> int : \"\"\"The number of times IOCs have been updated.\"\"\" return self . _update_count async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) async def async_init ( self , app ): self . running = True self . tasks . create ( self . _update_loop ()) logger . info ( \"Server plugins enabled: %s \" , \", \" . join ( plugin . name for plugin in self . plugins ) ) for plugin in self . plugins : self . tasks . create ( self . _update_plugin_loop ( plugin )) async def _update_plugin_loop ( self , plugin : ServerPluginSpec ): while self . running and self . update_count == 0 and plugin . after_iocs : # Wait until IOCs have been loaded before updating this one for the # first time. await asyncio . sleep ( 1 ) logger . info ( \"Server plugin %r updates started.\" , plugin . name ) while self . running : logger . info ( \"Updating plugin: %s \" , plugin . name ) with common . time_context () as ctx : try : await plugin . update () except Exception : logger . exception ( \"Failed to update plugin %r [ %.1f s]\" , plugin . name , ctx () ) else : logger . info ( \"Successfully updated plugin %r [ %.1f s]\" , plugin . name , ctx () ) # for record, md in info[\"record_to_metadata\"].items(): # ... await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server plugin %r updates finished.\" , plugin . name ) async def _update_loop ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" while self . running : logger . info ( \"Checking for new or updated IOCs...\" ) await self . update_script_loaders () logger . info ( \"Checking for changed scripts and database files...\" ) self . _load_gateway_config () updated = self . get_updated_iocs () if not updated : logger . info ( \"No changes found.\" ) await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) continue logger . info ( \" %d IOC %s changed.\" , len ( updated ), \" has\" if len ( updated ) == 1 else \"s have\" ) for idx , ioc in enumerate ( updated [: 10 ], 1 ): logger . info ( \"* %d : %s \" , idx , ioc . name ) if len ( updated ) > 10 : logger . info ( \"... and %d more\" , len ( updated ) - 10 ) with common . time_context () as ctx : await self . update_iocs ( updated ) logger . info ( \"Updated %d IOCs in %.1f seconds\" , len ( updated ), ctx () ) self . clear_cache () await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server script updates finished.\" ) async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated def _replace_metadata ( self , old_md : IocMetadata , new_md : IocMetadata ) -> int : \"\"\"Replace the provided metadata information with a new one.\"\"\" idx = self . ioc_metadata . index ( old_md ) self . ioc_metadata . remove ( old_md ) self . ioc_metadata . insert ( idx , new_md ) return idx async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} def _load_gateway_config ( self ): if not self . gateway_config_path : logger . warning ( \"Gateway path not set; gateway configuration will not be loaded\" ) return if self . gateway_config is None : logger . info ( \"Loading gateway configuration for the first time...\" ) self . gateway_config = gateway . GatewayConfig ( self . gateway_config_path ) else : logger . info ( \"Updating gateway configuration...\" ) self . gateway_config . update_changed () for filename , pvlist in self . gateway_config . pvlists . items (): if pvlist . hash is not None : logger . debug ( \"New gateway file: %s ( %s )\" , filename , pvlist . hash ) self . container . loaded_files [ str ( filename )] = pvlist . hash def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results @property def aliases ( self ) -> Dict [ str , str ]: \"\"\"The CA/V3 aliases.\"\"\" return self . container . aliases @property def database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The CA/V3 Database of records.\"\"\" return self . container . database @property def pva_database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The pvAccess Database of groups/records.\"\"\" return self . container . pva_database def get_graph ( self , pv_names : Tuple [ str , ... ], graph_type : str ) -> graphviz . Digraph : if graph_type == \"record\" : return self . get_link_graph ( tuple ( pv_names )) if graph_type == \"script\" : return self . get_script_graph ( tuple ( pv_names )) raise RuntimeError ( \"Invalid graph type\" ) def get_script_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_script_relations ( database = self . database , limit_to_records = pv_names , script_relations = self . script_relations , ) return gr . to_digraph ( font_name = \"Courier\" ) def get_ioc_to_pvs ( self , pv_names : Tuple [ str , ... ]) -> Dict [ str , List [ str ]]: ioc_to_pvs = {} for pv in pv_names : try : owner = self . container . database [ pv ] . owner or \"unknown\" except KeyError : owner = \"unknown\" if owner not in ioc_to_pvs : ioc_to_pvs [ owner ] = [] ioc_to_pvs [ owner ] . append ( pv ) return ioc_to_pvs def get_pv_relations ( self , pv_names : Tuple [ str , ... ], * , full : bool = False , ) -> Union [ PVRelationshipResponse , PVShortRelationshipResponse ]: # TODO: pv_names if full : return PVRelationshipResponse ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) return PVShortRelationshipResponse . from_pv_relations ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) def get_link_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_links ( database = self . database , starting_records = list ( pv_names ), sort_fields = True , relations = self . container . pv_relations , ) digraph = gr . to_digraph ( font_name = \"Courier\" ) return digraph def clear_cache ( self ): for method in [ # self.get_graph, # self.get_graph_rendered, self . get_gateway_matches , self . get_matching_pvs , self . get_matching_iocs , self . script_info_from_loaded_file , self . get_duplicates , ]: method . cache_clear () def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) @functools . lru_cache ( maxsize = 2048 ) def script_info_from_loaded_file ( self , fn ) -> common . IocshScript : with open ( fn , \"rt\" ) as fp : lines = fp . read () . splitlines () result = [] for lineno , line in enumerate ( lines , 1 ): result . append ( common . IocshResult ( context = ( LoadContext ( fn , lineno ),), line = line , ) ) return common . IocshScript ( path = fn , lines = tuple ( result )) @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () Attributes whatrecord . server . server . ServerState . aliases : Dict [ str , str ] property readonly The CA/V3 aliases. whatrecord . server . server . ServerState . database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The CA/V3 Database of records. whatrecord . server . server . ServerState . iocs_by_name : Dict [ str , whatrecord . common . IocMetadata ] property readonly Dictionary of IOC name to IocMetadata. whatrecord . server . server . ServerState . pva_database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The pvAccess Database of groups/records. whatrecord . server . server . ServerState . update_count : int property readonly The number of times IOCs have been updated. Methods whatrecord . server . server . ServerState . add_or_update_ioc_metadata ( self , md : IocMetadata ) Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. Source code in whatrecord/server/server.py def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) whatrecord . server . server . ServerState . annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord Annotate WhatRecord instances with things ServerState knows about. Source code in whatrecord/server/server.py def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what whatrecord . server . server . ServerState . get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]] Get duplicate PVs from the matching IOC(s). Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } whatrecord . server . server . ServerState . get_gateway_matches ( self , pvname : str ) -> Optional [ whatrecord . gateway . PVListMatches ] Get gateway matches for the given pvname. Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) whatrecord . server . server . ServerState . get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes async Get a rendered PV relationship graph of the provided PVs. Parameters: Name Type Description Default pv_names Tuple[str, ...] PV names. required format str The format of the graph (e.g., pdf, png). required graph_type str The type of graph to generate. required Source code in whatrecord/server/server.py async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () whatrecord . server . server . ServerState . get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ whatrecord . shell . LoadedIoc ] Get matching IOCs given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] whatrecord . server . server . ServerState . get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ] Get matching PV names given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] whatrecord . server . server . ServerState . get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ] Get plugin information as a dictionary. Source code in whatrecord/server/server.py def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } whatrecord . server . server . ServerState . get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any Get plugin custom nested metadata info. Source code in whatrecord/server/server.py def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} whatrecord . server . server . ServerState . get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ] Get plugin custom nested metadata keys. Source code in whatrecord/server/server.py def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] whatrecord . server . server . ServerState . get_updated_iocs ( self ) -> List [ whatrecord . common . IocMetadata ] Check loaded IOCs for any changes. Source code in whatrecord/server/server.py def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated whatrecord . server . server . ServerState . is_loaded_file ( self , fn ) -> bool Is fn a file that was loaded? Source code in whatrecord/server/server.py def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) whatrecord . server . server . ServerState . stop ( self ) async Stop any background updates. Source code in whatrecord/server/server.py async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) whatrecord . server . server . ServerState . update_iocs ( self , iocs : List [ whatrecord . common . IocMetadata ]) async Reload the provided IOCs. Source code in whatrecord/server/server.py async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 whatrecord . server . server . ServerState . update_script_loaders ( self ) async Update scripts from the script loader and watch for updates. Source code in whatrecord/server/server.py async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) whatrecord . server . server . ServerState . whatrec ( self , pvname : str ) -> List [ whatrecord . common . WhatRecord ] Find WhatRecord matches. Source code in whatrecord/server/server.py def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results Functions whatrecord . server . server . compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ) Compile regular expression (or glob) patterns with re.compile . Source code in whatrecord/server/server.py def compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ): \"\"\"Compile regular expression (or glob) patterns with `re.compile`.\"\"\" if use_regex : return re . compile ( \"|\" . join ( patterns ), flags = flags ) return re . compile ( \"|\" . join ( fnmatch . translate ( pattern ) for pattern in patterns ), flags = flags , ) whatrecord . server . server . get_patterns ( query , key : str = 'pattern' , regex_key : str = 'regex' ) -> Tuple [ bool , Tuple [ str , ... ]] Get glob/regex patterns from a server query. Source code in whatrecord/server/server.py def get_patterns ( query , key : str = \"pattern\" , regex_key : str = \"regex\" ) -> Tuple [ bool , Tuple [ str , ... ]]: \"\"\"Get glob/regex patterns from a server query.\"\"\" use_regex = query . get ( regex_key , \"false\" ) . lower () in TRUE_VALUES default = ( \".*\" if use_regex else \"*\" ,) return use_regex , tuple ( query . getall ( key , default )) whatrecord . server . server . serialized_response ( obj : Any ) -> Response Return an apischema-serialized JSON response of a dataclass instance. Source code in whatrecord/server/server.py def serialized_response ( obj : Any ) -> web . Response : \"\"\"Return an apischema-serialized JSON response of a dataclass instance.\"\"\" return web . json_response ( apischema . serialize ( obj )) whatrecord.server.util Classes whatrecord.server.util.TaskHandler Helper to manage asyncio tasks in one spot. Source code in whatrecord/server/util.py class TaskHandler : \"\"\"Helper to manage asyncio tasks in one spot.\"\"\" def __init__ ( self ): self . tasks = [] self . _lock = threading . Lock () def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task def _remove_completed_task ( self , task ): try : with self . _lock : self . tasks . remove ( task ) except ValueError : # May have been cancelled or removed otherwise ... @staticmethod async def cancel ( task ): task . cancel () await task async def cancel_all ( self , wait = False ): with self . _lock : tasks = list ( self . tasks ) self . tasks . clear () for task in list ( tasks ): task . cancel () if wait and len ( tasks ): await asyncio . wait ( tasks ) Methods whatrecord . server . util . TaskHandler . create ( self , coro ) Schedule the execution of a coroutine object in a spawn task. Source code in whatrecord/server/util.py def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task","title":"Server / client"},{"location":"server_client/#server-client","text":"","title":"Server / client"},{"location":"server_client/#starting-the-backend-api-server","text":"With the provided test-suite IOCs: $ whatrecord server --scripts whatrecord/tests/iocs/*/st.cmd Gateway configuration among others can be specified separately, if available.","title":"Starting the backend API server"},{"location":"server_client/#starting-the-frontend","text":"Install dependencies: $ conda install -c conda-forge nodejs $ cd frontend $ yarn install Compile and reload automatically when frontend files change: $ yarn serve Or alternatively compile and minify for production: $ yarn build","title":"Starting the frontend"},{"location":"server_client/#tweaking-frontend-settings","text":"In frontend/.env.local : API_HOST=localhost API_PORT=8898 FRONTEND_PORT=8899 WHATRECORD_PLUGINS=happi twincat_pytmc # The following is accessible in the vue frontend: VUE_APP_WHATRECORD_PLUGINS=$WHATRECORD_PLUGINS","title":"Tweaking frontend settings"},{"location":"server_client/#general-flow","text":"Using the core tools: * Load up all EPICS IOCs listed in IOC manager - Load the startup scripts - Load all the databases and supported files * Provide a backend service for querying the information * Based on the backend server, provide a frontend for easy access to that information - vue.js-based frontend single-page application - Search for records/IOCs/etc by name and dig into the details...","title":"General flow"},{"location":"server_client/#api","text":"","title":"API"},{"location":"server_client/#whatrecord.ioc_finder","text":"","title":"ioc_finder"},{"location":"server_client/#whatrecord.ioc_finder-classes","text":"","title":"Classes"},{"location":"server_client/#whatrecord.ioc_finder.IocScriptExternalLoader","text":"IocScriptExternalLoader(load_script: str, scripts: Dict[pathlib.Path, whatrecord.common.IocMetadata] = ) Source code in whatrecord/ioc_finder.py @dataclasses . dataclass class IocScriptExternalLoader ( _IocInfoFinder ): load_script : str scripts : Dict [ pathlib . Path , IocMetadata ] = field ( default_factory = dict ) async def update ( self ): result = await run_script_with_json_output ( self . load_script ) for info in ( result or {}): self . add_or_update_entry ( IocMetadata . from_dict ( info )) return await super () . update ()","title":"IocScriptExternalLoader"},{"location":"server_client/#whatrecord.ioc_finder.IocScriptStaticInfoList","text":"IocScriptStaticInfoList(ioc_infos: dataclasses.InitVar[typing.List[typing.Dict[str, typing.Union[str, typing.Dict[str, str], typing.List[str]]]]], scripts: Dict[pathlib.Path, whatrecord.common.IocMetadata] = ) Source code in whatrecord/ioc_finder.py @dataclasses . dataclass class IocScriptStaticInfoList ( _IocInfoFinder ): ioc_infos : InitVar [ List [ IocInfoDict ]] scripts : Dict [ pathlib . Path , IocMetadata ] = field ( default_factory = dict ) def __post_init__ ( self , ioc_infos : List [ IocInfoDict ]): for info in ioc_infos : self . add_or_update_entry ( IocMetadata . from_dict ( info ))","title":"IocScriptStaticInfoList"},{"location":"server_client/#whatrecord.ioc_finder.IocScriptStaticList","text":"IocScriptStaticList(script_list: dataclasses.InitVar[typing.List[typing.Union[str, pathlib.Path]]], scripts: Dict[pathlib.Path, whatrecord.common.IocMetadata] = ) Source code in whatrecord/ioc_finder.py @dataclasses . dataclass class IocScriptStaticList ( _IocInfoFinder ): script_list : InitVar [ List [ Union [ str , pathlib . Path ]]] scripts : Dict [ pathlib . Path , IocMetadata ] = field ( default_factory = dict ) def __post_init__ ( self , script_list : List [ IocInfoDict ]): for fn in script_list : self . add_or_update_entry ( IocMetadata . from_file ( fn ))","title":"IocScriptStaticList"},{"location":"server_client/#whatrecord.client","text":"","title":"client"},{"location":"server_client/#whatrecord.client-functions","text":"","title":"Functions"},{"location":"server_client/#whatrecord.client.get_iocs","text":"Get record information from the server. Source code in whatrecord/client.py async def get_iocs ( pattern : str = \"*\" , server : Optional [ str ] = None , regex : bool = False ) -> IocGetMatchesResponse : \"\"\"Get record information from the server.\"\"\" response = await make_query ( \"/api/ioc/matches\" , server = server , params = dict ( pattern = pattern , regex = str ( regex )) ) return apischema . deserialize ( IocGetMatchesResponse , response )","title":"get_iocs()"},{"location":"server_client/#whatrecord.client.get_record_info","text":"Get record information from the server. Source code in whatrecord/client.py async def get_record_info ( * records , server : Optional [ str ] = None ) -> Dict [ str , PVGetInfo ]: \"\"\"Get record information from the server.\"\"\" response = await make_query ( \"/api/pv/info\" , server = server , params = dict ( pv = list ( records ))) return apischema . deserialize ( Dict [ str , PVGetInfo ], response )","title":"get_record_info()"},{"location":"server_client/#whatrecord.server","text":"","title":"server"},{"location":"server_client/#whatrecord.server-modules","text":"","title":"Modules"},{"location":"server_client/#whatrecord.server.common","text":"","title":"common"},{"location":"server_client/#whatrecord.server.common-classes","text":"whatrecord.server.common.IocGetDuplicatesResponse dataclass IocGetDuplicatesResponse(patterns: 'List[str]', regex: 'bool', duplicates: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class IocGetDuplicatesResponse : patterns : List [ str ] regex : bool duplicates : Dict [ str , List [ str ]] whatrecord.server.common.IocGetMatchesResponse dataclass IocGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[IocMetadata]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ IocMetadata ] whatrecord.server.common.IocGetMatchingRecordsResponse dataclass IocGetMatchingRecordsResponse(ioc_patterns: 'List[str]', record_patterns: 'List[str]', regex: 'bool', matches: 'List[Tuple[IocMetadata, List[AnyRecordInstance]]]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchingRecordsResponse : ioc_patterns : List [ str ] record_patterns : List [ str ] regex : bool # TODO: ew, redo this matches : List [ Tuple [ IocMetadata , List [ AnyRecordInstance ]]] whatrecord.server.common.PVGetInfo dataclass PVGetInfo(pv_name: 'str', present: 'bool', info: 'List[WhatRecord]') Source code in whatrecord/server/common.py @dataclass class PVGetInfo : pv_name : str present : bool info : List [ WhatRecord ] _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ {{ pv_name }}: In database: {{ present }} { % f or _info in info %} { % s et item_info = render_object(_info, \"console\") %} {{ item_info | indent(4)}} { % e ndfor %} } \"\"\" , } whatrecord.server.common.PVGetMatchesResponse dataclass PVGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[str]') Source code in whatrecord/server/common.py @dataclass class PVGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ str ] whatrecord.server.common.PVRelationshipResponse dataclass PVRelationshipResponse(pv_relations: 'PVRelations', script_relations: 'ScriptPVRelations', ioc_to_pvs: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class PVRelationshipResponse : pv_relations : PVRelations script_relations : ScriptPVRelations ioc_to_pvs : Dict [ str , List [ str ]] whatrecord.server.common.PVShortRelationshipResponse dataclass PVShortRelationshipResponse(script_relations: 'ScriptPVRelations') Source code in whatrecord/server/common.py @dataclass class PVShortRelationshipResponse : # pv_relations: PVRelationsSummary script_relations : ScriptPVRelations # ioc_to_pvs: Dict[str, List[str]] @classmethod def from_pv_relations ( cls , pv_relations : PVRelations , script_relations : ScriptPVRelations , ioc_to_pvs : Dict [ str , List [ str ]], ) -> PVRelationshipResponse : # summary = { # pv1: list(pv2s) # for pv1, pv2s in pv_relations.items() # } return cls ( # pv_relations=summary, script_relations = script_relations , # ioc_to_pvs=ioc_to_pvs, ) whatrecord.server.common.PluginResults dataclass PluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/server/common.py @dataclass class PluginResults : files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) record_to_metadata_keys : Dict [ str , List [ str ]] = field ( default_factory = dict ) metadata_by_key : Dict [ str , Any ] = field ( default_factory = dict ) metadata : Any = None execution_info : Dict [ str , Any ] = field ( default_factory = dict ) nested : Optional [ Dict [ str , PluginResults ]] = None def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info Methods whatrecord . server . common . PluginResults . find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info whatrecord . server . common . PluginResults . find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) whatrecord . server . common . PluginResults . is_loaded_file ( self , fn : str ) -> bool Is the given file one that was loaded in the plugin? Source code in whatrecord/server/common.py def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) whatrecord.server.common.RecordFieldSummary dataclass RecordFieldSummary(dtype: 'str', name: 'str', value: 'Any') Source code in whatrecord/server/common.py @dataclass class RecordFieldSummary : dtype : str name : str value : Any _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\"field({{name}}, \"{{value}}\")\"\"\" , \"console-verbose\" : \"\"\" \\ field({{name}}, \"{{value}}\") \"\"\" , } whatrecord.server.common.ServerPluginSpec dataclass ServerPluginSpec(name: 'str', module: 'Optional[str]' = None, executable: 'Optional[List[str]]' = None, files_to_monitor: 'Dict[str, str]' = , results: 'Optional[PluginResults]' = None, results_json: 'Any' = None, after_iocs: 'bool' = False) Source code in whatrecord/server/common.py @dataclass class ServerPluginSpec : name : str #: Python module module : Optional [ str ] = None #: Or any executable executable : Optional [ List [ str ]] = None #: Can be a dataclass or a builtin type # result_class: type files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) results : Optional [ PluginResults ] = None results_json : Any = None # Require IOCs to be loaded first before running after_iocs : bool = False @property def script ( self ) -> str : \"\"\"The script and arguments to run for the plugin.\"\"\" if self . executable : return \" \" . join ( f '\" { param } \"' for param in self . executable ) elif self . module : return f '\" { sys . executable } \" -m { self . module } ' raise ValueError ( \"module and executable both unset\" ) async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results Attributes whatrecord . server . common . ServerPluginSpec . script : str property readonly The script and arguments to run for the plugin. Methods whatrecord . server . common . ServerPluginSpec . update ( self ) -> Optional [ PluginResults ] async Call the plugin and get new information, storing it in results. Source code in whatrecord/server/common.py async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results","title":"Classes"},{"location":"server_client/#whatrecord.server.server","text":"","title":"server"},{"location":"server_client/#whatrecord.server.server-classes","text":"whatrecord.server.server.ServerHandler Source code in whatrecord/server/server.py class ServerHandler : routes = web . RouteTableDef () def __init__ ( self , state : ServerState ): self . state = state async def async_init ( self , app ): await self . state . async_init ( app ) @routes . get ( \"/api/pv/info\" ) async def api_pv_get_info ( self , request : web . Request ): pv_names = request . query . getall ( \"pv\" ) info = { pv_name : self . state . whatrec ( pv_name ) for pv_name in pv_names } return serialized_response ( { pv_name : PVGetInfo ( pv_name = pv_name , present = ( pv_name in self . state . database or pv_name in self . state . pva_database ), info = [ obj for obj in info [ pv_name ]], ) for pv_name in pv_names } ) @routes . get ( \"/api/pv/matches\" ) async def api_pv_get_matches ( self , request : web . Request ): max_matches = int ( request . query . get ( \"max\" , \"200\" )) use_regex , patterns = get_patterns ( request . query ) matches = self . state . get_matching_pvs ( patterns , use_regex = use_regex ) if max_matches > 0 : matches = matches [: max_matches ] return serialized_response ( PVGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = matches , ) ) @routes . get ( \"/api/ioc/matches\" ) async def api_ioc_get_matches ( self , request : web . Request ): # Ignore max for now. This is not much in the way of information. # max_matches = int(request.query.get(\"max\", \"1000\")) use_regex , patterns = get_patterns ( request . query ) match_metadata = [ loaded_ioc . metadata for loaded_ioc in self . state . get_matching_iocs ( patterns , use_regex = use_regex ) ] return serialized_response ( IocGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = match_metadata , ) ) @routes . get ( \"/api/ioc/pvs\" ) async def api_ioc_get_pvs ( self , request : web . Request ): use_regex , ioc_patterns = get_patterns ( request . query , key = \"ioc\" ) _ , record_patterns = get_patterns ( request . query , key = \"pv\" ) response = IocGetMatchingRecordsResponse ( ioc_patterns = ioc_patterns , record_patterns = record_patterns , regex = use_regex , matches = [], ) def get_all_records ( shell_state ): yield from shell_state . database . items () yield from shell_state . pva_database . items () try : pv_glob_re = compile_patterns ( record_patterns , use_regex = use_regex , ) except re . error : raise web . HTTPBadRequest () for loaded_ioc in self . state . get_matching_iocs ( ioc_patterns , use_regex = response . regex , ): record_matches = [ rec_info . to_summary () for rec , rec_info in sorted ( get_all_records ( loaded_ioc . shell_state )) if pv_glob_re . match ( rec ) ] if record_matches : response . matches . append (( loaded_ioc . metadata , record_matches )) return serialized_response ( response ) @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) # @routes.get(\"/api/graphql/query\") # async def api_graphql_query(self, request: web.Request): # TODO: ... @routes . get ( \"/api/plugin/info\" ) async def api_plugin_info ( self , request : web . Request ): plugins = request . query . get ( \"plugin\" , \"all\" ) allow_list = None if plugins == \"all\" else plugins . split ( \" \" ) return serialized_response ( self . state . get_plugin_info ( allow_list )) @routes . get ( \"/api/plugin/nested/keys\" ) async def api_plugin_nested_keys ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] keys = self . state . get_plugin_nested_keys ( plugin ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( keys ) @routes . get ( \"/api/plugin/nested/info\" ) async def api_plugin_nested_info ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] key = request . query [ \"key\" ] info = self . state . get_plugin_nested_info ( plugin , key ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( info ) @routes . get ( \"/api/gateway/info\" ) async def api_gateway_info ( self , request : web . Request ): return serialized_response ( self . state . gateway_config . pvlists or {}) @routes . get ( \"/api/file/info\" ) async def api_ioc_info ( self , request : web . Request ): # script_name = pathlib.Path(request.query[\"file\"]) filename = request . query [ \"file\" ] ioc_name = self . state . container . startup_script_to_ioc . get ( filename , None ) if ioc_name : loaded_ioc = self . state . container . scripts [ ioc_name ] script_info = loaded_ioc . script ioc_md = loaded_ioc . metadata else : # Making this dual-purpose: script, db, or any loaded file ioc_md = None if not self . state . is_loaded_file ( filename ): raise web . HTTPBadRequest () script_info = self . state . script_info_from_loaded_file ( filename ) return serialized_response ( { \"script\" : script_info , \"ioc\" : ioc_md , } ) async def get_graph ( self , pv_names : List [ str ], use_glob : bool = False , graph_type : str = \"record\" , format : str = \"pdf\" ): if use_glob : pv_names = self . state . get_matching_pvs ( pv_names ) if format == \"dot\" : try : digraph = self . state . get_graph ( tuple ( pv_names ), graph_type = graph_type ) except TooManyRecordsError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = \"text/vnd.graphviz\" , body = digraph . source , ) rendered = await self . state . get_graph_rendered ( tuple ( pv_names ), format = format , graph_type = graph_type ) try : content_type = { \"pdf\" : \"application/pdf\" , \"png\" : \"image/png\" , \"svg\" : \"image/svg+xml\" , }[ format ] except KeyError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = content_type , body = rendered , ) @routes . get ( \"/api/logs/get\" ) async def api_logs_get ( self , request : web . Request ): return web . json_response ( list ( _log_handler . messages if _log_handler is not None else [ \"Logger not initialized\" ] ) ) @routes . get ( \"/api/pv/relations\" ) async def api_pv_get_relations ( self , request : web . Request ): use_regex , pv_names = get_patterns ( request . query , key = \"pv\" ) pv_names = self . state . get_matching_pvs ( pv_names , use_regex = use_regex ) full = request . query . get ( \"full\" , \"false\" ) in TRUE_VALUES return serialized_response ( self . state . get_pv_relations ( pv_names = pv_names , full = full ) ) @routes . get ( \"/api/pv/graph\" ) async def api_pv_get_record_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"record\" , ) @routes . get ( \"/api/pv/script-graph\" ) async def api_pv_get_script_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"script\" , ) Methods whatrecord . server . server . ServerHandler . api_pv_get_duplicates ( self , request : Request ) async Get record names duplicated among two or more IOCs. Source code in whatrecord/server/server.py @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) whatrecord.server.server.ServerLogHandler ( Handler ) Source code in whatrecord/server/server.py class ServerLogHandler ( logging . Handler ): def __init__ ( self , message_count : int = 1000 , level = \"DEBUG\" ): super () . __init__ ( level = level ) self . formatter = logging . Formatter ( \" %(asctime)s - PID %(process)d %(filename)18s : %(lineno)-3s \" \" %(funcName)-18s %(levelname)-8s %(message)s \" ) self . message_count = message_count self . messages = collections . deque ( maxlen = message_count ) def emit ( self , record ): self . messages . append ( self . format ( record )) Methods whatrecord . server . server . ServerLogHandler . emit ( self , record ) Do whatever it takes to actually log the specified logging record. This version is intended to be implemented by subclasses and so raises a NotImplementedError. Source code in whatrecord/server/server.py def emit ( self , record ): self . messages . append ( self . format ( record )) whatrecord.server.server.ServerState Source code in whatrecord/server/server.py class ServerState : running : bool container : ScriptContainer gateway_config : gateway . GatewayConfig script_loaders : List [ ioc_finder . _IocInfoFinder ] ioc_metadata : List [ IocMetadata ] _update_count : int def __init__ ( self , startup_scripts : Optional [ List [ str ]] = None , script_loaders : Optional [ List [ str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , gateway_config : Optional [ str ] = None , plugins : Optional [ List [ ServerPluginSpec ]] = None , ): self . running = False self . container = ScriptContainer () self . gateway_config = None self . gateway_config_path = gateway_config self . ioc_metadata = [] self . plugins = plugins or [] self . plugins_by_name = { plugin . name : plugin for plugin in plugins or [] } self . script_relations = {} self . standin_directories = standin_directories or {} self . tasks = TaskHandler () self . script_loaders = [ ioc_finder . IocScriptStaticList ( startup_scripts or []) ] + [ ioc_finder . IocScriptExternalLoader ( loader ) for loader in script_loaders or [] ] self . _update_count = 0 @property def iocs_by_name ( self ) -> Dict [ str , IocMetadata ]: \"\"\"Dictionary of IOC name to IocMetadata.\"\"\" return { ioc . name : ioc for ioc in self . ioc_metadata } def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) @property def update_count ( self ) -> int : \"\"\"The number of times IOCs have been updated.\"\"\" return self . _update_count async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) async def async_init ( self , app ): self . running = True self . tasks . create ( self . _update_loop ()) logger . info ( \"Server plugins enabled: %s \" , \", \" . join ( plugin . name for plugin in self . plugins ) ) for plugin in self . plugins : self . tasks . create ( self . _update_plugin_loop ( plugin )) async def _update_plugin_loop ( self , plugin : ServerPluginSpec ): while self . running and self . update_count == 0 and plugin . after_iocs : # Wait until IOCs have been loaded before updating this one for the # first time. await asyncio . sleep ( 1 ) logger . info ( \"Server plugin %r updates started.\" , plugin . name ) while self . running : logger . info ( \"Updating plugin: %s \" , plugin . name ) with common . time_context () as ctx : try : await plugin . update () except Exception : logger . exception ( \"Failed to update plugin %r [ %.1f s]\" , plugin . name , ctx () ) else : logger . info ( \"Successfully updated plugin %r [ %.1f s]\" , plugin . name , ctx () ) # for record, md in info[\"record_to_metadata\"].items(): # ... await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server plugin %r updates finished.\" , plugin . name ) async def _update_loop ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" while self . running : logger . info ( \"Checking for new or updated IOCs...\" ) await self . update_script_loaders () logger . info ( \"Checking for changed scripts and database files...\" ) self . _load_gateway_config () updated = self . get_updated_iocs () if not updated : logger . info ( \"No changes found.\" ) await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) continue logger . info ( \" %d IOC %s changed.\" , len ( updated ), \" has\" if len ( updated ) == 1 else \"s have\" ) for idx , ioc in enumerate ( updated [: 10 ], 1 ): logger . info ( \"* %d : %s \" , idx , ioc . name ) if len ( updated ) > 10 : logger . info ( \"... and %d more\" , len ( updated ) - 10 ) with common . time_context () as ctx : await self . update_iocs ( updated ) logger . info ( \"Updated %d IOCs in %.1f seconds\" , len ( updated ), ctx () ) self . clear_cache () await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server script updates finished.\" ) async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated def _replace_metadata ( self , old_md : IocMetadata , new_md : IocMetadata ) -> int : \"\"\"Replace the provided metadata information with a new one.\"\"\" idx = self . ioc_metadata . index ( old_md ) self . ioc_metadata . remove ( old_md ) self . ioc_metadata . insert ( idx , new_md ) return idx async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} def _load_gateway_config ( self ): if not self . gateway_config_path : logger . warning ( \"Gateway path not set; gateway configuration will not be loaded\" ) return if self . gateway_config is None : logger . info ( \"Loading gateway configuration for the first time...\" ) self . gateway_config = gateway . GatewayConfig ( self . gateway_config_path ) else : logger . info ( \"Updating gateway configuration...\" ) self . gateway_config . update_changed () for filename , pvlist in self . gateway_config . pvlists . items (): if pvlist . hash is not None : logger . debug ( \"New gateway file: %s ( %s )\" , filename , pvlist . hash ) self . container . loaded_files [ str ( filename )] = pvlist . hash def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results @property def aliases ( self ) -> Dict [ str , str ]: \"\"\"The CA/V3 aliases.\"\"\" return self . container . aliases @property def database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The CA/V3 Database of records.\"\"\" return self . container . database @property def pva_database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The pvAccess Database of groups/records.\"\"\" return self . container . pva_database def get_graph ( self , pv_names : Tuple [ str , ... ], graph_type : str ) -> graphviz . Digraph : if graph_type == \"record\" : return self . get_link_graph ( tuple ( pv_names )) if graph_type == \"script\" : return self . get_script_graph ( tuple ( pv_names )) raise RuntimeError ( \"Invalid graph type\" ) def get_script_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_script_relations ( database = self . database , limit_to_records = pv_names , script_relations = self . script_relations , ) return gr . to_digraph ( font_name = \"Courier\" ) def get_ioc_to_pvs ( self , pv_names : Tuple [ str , ... ]) -> Dict [ str , List [ str ]]: ioc_to_pvs = {} for pv in pv_names : try : owner = self . container . database [ pv ] . owner or \"unknown\" except KeyError : owner = \"unknown\" if owner not in ioc_to_pvs : ioc_to_pvs [ owner ] = [] ioc_to_pvs [ owner ] . append ( pv ) return ioc_to_pvs def get_pv_relations ( self , pv_names : Tuple [ str , ... ], * , full : bool = False , ) -> Union [ PVRelationshipResponse , PVShortRelationshipResponse ]: # TODO: pv_names if full : return PVRelationshipResponse ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) return PVShortRelationshipResponse . from_pv_relations ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) def get_link_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_links ( database = self . database , starting_records = list ( pv_names ), sort_fields = True , relations = self . container . pv_relations , ) digraph = gr . to_digraph ( font_name = \"Courier\" ) return digraph def clear_cache ( self ): for method in [ # self.get_graph, # self.get_graph_rendered, self . get_gateway_matches , self . get_matching_pvs , self . get_matching_iocs , self . script_info_from_loaded_file , self . get_duplicates , ]: method . cache_clear () def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) @functools . lru_cache ( maxsize = 2048 ) def script_info_from_loaded_file ( self , fn ) -> common . IocshScript : with open ( fn , \"rt\" ) as fp : lines = fp . read () . splitlines () result = [] for lineno , line in enumerate ( lines , 1 ): result . append ( common . IocshResult ( context = ( LoadContext ( fn , lineno ),), line = line , ) ) return common . IocshScript ( path = fn , lines = tuple ( result )) @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () Attributes whatrecord . server . server . ServerState . aliases : Dict [ str , str ] property readonly The CA/V3 aliases. whatrecord . server . server . ServerState . database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The CA/V3 Database of records. whatrecord . server . server . ServerState . iocs_by_name : Dict [ str , whatrecord . common . IocMetadata ] property readonly Dictionary of IOC name to IocMetadata. whatrecord . server . server . ServerState . pva_database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The pvAccess Database of groups/records. whatrecord . server . server . ServerState . update_count : int property readonly The number of times IOCs have been updated. Methods whatrecord . server . server . ServerState . add_or_update_ioc_metadata ( self , md : IocMetadata ) Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. Source code in whatrecord/server/server.py def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) whatrecord . server . server . ServerState . annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord Annotate WhatRecord instances with things ServerState knows about. Source code in whatrecord/server/server.py def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what whatrecord . server . server . ServerState . get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]] Get duplicate PVs from the matching IOC(s). Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } whatrecord . server . server . ServerState . get_gateway_matches ( self , pvname : str ) -> Optional [ whatrecord . gateway . PVListMatches ] Get gateway matches for the given pvname. Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) whatrecord . server . server . ServerState . get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes async Get a rendered PV relationship graph of the provided PVs. Parameters: Name Type Description Default pv_names Tuple[str, ...] PV names. required format str The format of the graph (e.g., pdf, png). required graph_type str The type of graph to generate. required Source code in whatrecord/server/server.py async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () whatrecord . server . server . ServerState . get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ whatrecord . shell . LoadedIoc ] Get matching IOCs given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] whatrecord . server . server . ServerState . get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ] Get matching PV names given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] whatrecord . server . server . ServerState . get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ] Get plugin information as a dictionary. Source code in whatrecord/server/server.py def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } whatrecord . server . server . ServerState . get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any Get plugin custom nested metadata info. Source code in whatrecord/server/server.py def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} whatrecord . server . server . ServerState . get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ] Get plugin custom nested metadata keys. Source code in whatrecord/server/server.py def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] whatrecord . server . server . ServerState . get_updated_iocs ( self ) -> List [ whatrecord . common . IocMetadata ] Check loaded IOCs for any changes. Source code in whatrecord/server/server.py def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated whatrecord . server . server . ServerState . is_loaded_file ( self , fn ) -> bool Is fn a file that was loaded? Source code in whatrecord/server/server.py def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) whatrecord . server . server . ServerState . stop ( self ) async Stop any background updates. Source code in whatrecord/server/server.py async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) whatrecord . server . server . ServerState . update_iocs ( self , iocs : List [ whatrecord . common . IocMetadata ]) async Reload the provided IOCs. Source code in whatrecord/server/server.py async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 whatrecord . server . server . ServerState . update_script_loaders ( self ) async Update scripts from the script loader and watch for updates. Source code in whatrecord/server/server.py async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) whatrecord . server . server . ServerState . whatrec ( self , pvname : str ) -> List [ whatrecord . common . WhatRecord ] Find WhatRecord matches. Source code in whatrecord/server/server.py def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results","title":"Classes"},{"location":"server_client/#whatrecord.server.server-functions","text":"whatrecord . server . server . compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ) Compile regular expression (or glob) patterns with re.compile . Source code in whatrecord/server/server.py def compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ): \"\"\"Compile regular expression (or glob) patterns with `re.compile`.\"\"\" if use_regex : return re . compile ( \"|\" . join ( patterns ), flags = flags ) return re . compile ( \"|\" . join ( fnmatch . translate ( pattern ) for pattern in patterns ), flags = flags , ) whatrecord . server . server . get_patterns ( query , key : str = 'pattern' , regex_key : str = 'regex' ) -> Tuple [ bool , Tuple [ str , ... ]] Get glob/regex patterns from a server query. Source code in whatrecord/server/server.py def get_patterns ( query , key : str = \"pattern\" , regex_key : str = \"regex\" ) -> Tuple [ bool , Tuple [ str , ... ]]: \"\"\"Get glob/regex patterns from a server query.\"\"\" use_regex = query . get ( regex_key , \"false\" ) . lower () in TRUE_VALUES default = ( \".*\" if use_regex else \"*\" ,) return use_regex , tuple ( query . getall ( key , default )) whatrecord . server . server . serialized_response ( obj : Any ) -> Response Return an apischema-serialized JSON response of a dataclass instance. Source code in whatrecord/server/server.py def serialized_response ( obj : Any ) -> web . Response : \"\"\"Return an apischema-serialized JSON response of a dataclass instance.\"\"\" return web . json_response ( apischema . serialize ( obj ))","title":"Functions"},{"location":"server_client/#whatrecord.server.util","text":"","title":"util"},{"location":"server_client/#whatrecord.server.util-classes","text":"whatrecord.server.util.TaskHandler Helper to manage asyncio tasks in one spot. Source code in whatrecord/server/util.py class TaskHandler : \"\"\"Helper to manage asyncio tasks in one spot.\"\"\" def __init__ ( self ): self . tasks = [] self . _lock = threading . Lock () def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task def _remove_completed_task ( self , task ): try : with self . _lock : self . tasks . remove ( task ) except ValueError : # May have been cancelled or removed otherwise ... @staticmethod async def cancel ( task ): task . cancel () await task async def cancel_all ( self , wait = False ): with self . _lock : tasks = list ( self . tasks ) self . tasks . clear () for task in list ( tasks ): task . cancel () if wait and len ( tasks ): await asyncio . wait ( tasks ) Methods whatrecord . server . util . TaskHandler . create ( self , coro ) Schedule the execution of a coroutine object in a spawn task. Source code in whatrecord/server/util.py def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task","title":"Classes"},{"location":"server_client/#whatrecord.server.common","text":"","title":"common"},{"location":"server_client/#whatrecord.server.common-classes","text":"","title":"Classes"},{"location":"server_client/#whatrecord.server.common.IocGetDuplicatesResponse","text":"IocGetDuplicatesResponse(patterns: 'List[str]', regex: 'bool', duplicates: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class IocGetDuplicatesResponse : patterns : List [ str ] regex : bool duplicates : Dict [ str , List [ str ]]","title":"IocGetDuplicatesResponse"},{"location":"server_client/#whatrecord.server.common.IocGetMatchesResponse","text":"IocGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[IocMetadata]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ IocMetadata ]","title":"IocGetMatchesResponse"},{"location":"server_client/#whatrecord.server.common.IocGetMatchingRecordsResponse","text":"IocGetMatchingRecordsResponse(ioc_patterns: 'List[str]', record_patterns: 'List[str]', regex: 'bool', matches: 'List[Tuple[IocMetadata, List[AnyRecordInstance]]]') Source code in whatrecord/server/common.py @dataclass class IocGetMatchingRecordsResponse : ioc_patterns : List [ str ] record_patterns : List [ str ] regex : bool # TODO: ew, redo this matches : List [ Tuple [ IocMetadata , List [ AnyRecordInstance ]]]","title":"IocGetMatchingRecordsResponse"},{"location":"server_client/#whatrecord.server.common.PVGetInfo","text":"PVGetInfo(pv_name: 'str', present: 'bool', info: 'List[WhatRecord]') Source code in whatrecord/server/common.py @dataclass class PVGetInfo : pv_name : str present : bool info : List [ WhatRecord ] _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ {{ pv_name }}: In database: {{ present }} { % f or _info in info %} { % s et item_info = render_object(_info, \"console\") %} {{ item_info | indent(4)}} { % e ndfor %} } \"\"\" , }","title":"PVGetInfo"},{"location":"server_client/#whatrecord.server.common.PVGetMatchesResponse","text":"PVGetMatchesResponse(patterns: 'List[str]', regex: 'bool', matches: 'List[str]') Source code in whatrecord/server/common.py @dataclass class PVGetMatchesResponse : patterns : List [ str ] regex : bool matches : List [ str ]","title":"PVGetMatchesResponse"},{"location":"server_client/#whatrecord.server.common.PVRelationshipResponse","text":"PVRelationshipResponse(pv_relations: 'PVRelations', script_relations: 'ScriptPVRelations', ioc_to_pvs: 'Dict[str, List[str]]') Source code in whatrecord/server/common.py @dataclass class PVRelationshipResponse : pv_relations : PVRelations script_relations : ScriptPVRelations ioc_to_pvs : Dict [ str , List [ str ]]","title":"PVRelationshipResponse"},{"location":"server_client/#whatrecord.server.common.PVShortRelationshipResponse","text":"PVShortRelationshipResponse(script_relations: 'ScriptPVRelations') Source code in whatrecord/server/common.py @dataclass class PVShortRelationshipResponse : # pv_relations: PVRelationsSummary script_relations : ScriptPVRelations # ioc_to_pvs: Dict[str, List[str]] @classmethod def from_pv_relations ( cls , pv_relations : PVRelations , script_relations : ScriptPVRelations , ioc_to_pvs : Dict [ str , List [ str ]], ) -> PVRelationshipResponse : # summary = { # pv1: list(pv2s) # for pv1, pv2s in pv_relations.items() # } return cls ( # pv_relations=summary, script_relations = script_relations , # ioc_to_pvs=ioc_to_pvs, )","title":"PVShortRelationshipResponse"},{"location":"server_client/#whatrecord.server.common.PluginResults","text":"PluginResults(files_to_monitor: 'Dict[str, str]' = , record_to_metadata_keys: 'Dict[str, List[str]]' = , metadata_by_key: 'Dict[str, Any]' = , metadata: 'Any' = None, execution_info: 'Dict[str, Any]' = , nested: 'Optional[Dict[str, PluginResults]]' = None) Source code in whatrecord/server/common.py @dataclass class PluginResults : files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) record_to_metadata_keys : Dict [ str , List [ str ]] = field ( default_factory = dict ) metadata_by_key : Dict [ str , Any ] = field ( default_factory = dict ) metadata : Any = None execution_info : Dict [ str , Any ] = field ( default_factory = dict ) nested : Optional [ Dict [ str , PluginResults ]] = None def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () ) def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info","title":"PluginResults"},{"location":"server_client/#whatrecord.server.common.PluginResults-methods","text":"whatrecord . server . common . PluginResults . find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_by_key ( self , key : str ) -> Generator [ Tuple [ str , Any ], None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" md = self . metadata_by_key . get ( key , None ) if md is not None : yield key , md for nest_key , nested in ( self . nested or {}) . items (): for sub_key , info in nested . find_by_key ( key ): yield f \" { nest_key } : { sub_key } \" , info whatrecord . server . common . PluginResults . find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ] Find all metadata for the given record name. Source code in whatrecord/server/common.py def find_record_metadata ( self , record : str ) -> Generator [ Any , None , None ]: \"\"\"Find all metadata for the given record name.\"\"\" for key in self . record_to_metadata_keys . get ( record ) or []: try : yield self . metadata_by_key [ key ] except KeyError : logger . debug ( \"Consistency error in plugin: missing metadata key(s) %r \" \"for record %s \" , key , record ) for nested in ( self . nested or {}) . values (): yield from nested . find_record_metadata ( record ) whatrecord . server . common . PluginResults . is_loaded_file ( self , fn : str ) -> bool Is the given file one that was loaded in the plugin? Source code in whatrecord/server/common.py def is_loaded_file ( self , fn : str ) -> bool : \"\"\"Is the given file one that was loaded in the plugin?\"\"\" if fn in self . files_to_monitor : return True return any ( nested . is_loaded_file ( fn ) for nested in ( self . nested or {}) . values () )","title":"Methods"},{"location":"server_client/#whatrecord.server.common.RecordFieldSummary","text":"RecordFieldSummary(dtype: 'str', name: 'str', value: 'Any') Source code in whatrecord/server/common.py @dataclass class RecordFieldSummary : dtype : str name : str value : Any _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\"field({{name}}, \"{{value}}\")\"\"\" , \"console-verbose\" : \"\"\" \\ field({{name}}, \"{{value}}\") \"\"\" , }","title":"RecordFieldSummary"},{"location":"server_client/#whatrecord.server.common.ServerPluginSpec","text":"ServerPluginSpec(name: 'str', module: 'Optional[str]' = None, executable: 'Optional[List[str]]' = None, files_to_monitor: 'Dict[str, str]' = , results: 'Optional[PluginResults]' = None, results_json: 'Any' = None, after_iocs: 'bool' = False) Source code in whatrecord/server/common.py @dataclass class ServerPluginSpec : name : str #: Python module module : Optional [ str ] = None #: Or any executable executable : Optional [ List [ str ]] = None #: Can be a dataclass or a builtin type # result_class: type files_to_monitor : Dict [ str , str ] = field ( default_factory = dict ) results : Optional [ PluginResults ] = None results_json : Any = None # Require IOCs to be loaded first before running after_iocs : bool = False @property def script ( self ) -> str : \"\"\"The script and arguments to run for the plugin.\"\"\" if self . executable : return \" \" . join ( f '\" { param } \"' for param in self . executable ) elif self . module : return f '\" { sys . executable } \" -m { self . module } ' raise ValueError ( \"module and executable both unset\" ) async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results","title":"ServerPluginSpec"},{"location":"server_client/#whatrecord.server.common.ServerPluginSpec-attributes","text":"whatrecord . server . common . ServerPluginSpec . script : str property readonly The script and arguments to run for the plugin.","title":"Attributes"},{"location":"server_client/#whatrecord.server.common.ServerPluginSpec-methods","text":"whatrecord . server . common . ServerPluginSpec . update ( self ) -> Optional [ PluginResults ] async Call the plugin and get new information, storing it in results. Source code in whatrecord/server/common.py async def update ( self ) -> Optional [ PluginResults ]: \"\"\"Call the plugin and get new information, storing it in results.\"\"\" self . results_json = ( await util . run_script_with_json_output ( self . script ) ) or {} self . files_to_monitor = self . results_json . get ( \"files_to_monitor\" , {}) self . results = apischema . deserialize ( PluginResults , self . results_json ) if self . results : self . files_to_monitor = self . results . files_to_monitor return self . results","title":"Methods"},{"location":"server_client/#whatrecord.server.server","text":"","title":"server"},{"location":"server_client/#whatrecord.server.server-classes","text":"","title":"Classes"},{"location":"server_client/#whatrecord.server.server.ServerHandler","text":"Source code in whatrecord/server/server.py class ServerHandler : routes = web . RouteTableDef () def __init__ ( self , state : ServerState ): self . state = state async def async_init ( self , app ): await self . state . async_init ( app ) @routes . get ( \"/api/pv/info\" ) async def api_pv_get_info ( self , request : web . Request ): pv_names = request . query . getall ( \"pv\" ) info = { pv_name : self . state . whatrec ( pv_name ) for pv_name in pv_names } return serialized_response ( { pv_name : PVGetInfo ( pv_name = pv_name , present = ( pv_name in self . state . database or pv_name in self . state . pva_database ), info = [ obj for obj in info [ pv_name ]], ) for pv_name in pv_names } ) @routes . get ( \"/api/pv/matches\" ) async def api_pv_get_matches ( self , request : web . Request ): max_matches = int ( request . query . get ( \"max\" , \"200\" )) use_regex , patterns = get_patterns ( request . query ) matches = self . state . get_matching_pvs ( patterns , use_regex = use_regex ) if max_matches > 0 : matches = matches [: max_matches ] return serialized_response ( PVGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = matches , ) ) @routes . get ( \"/api/ioc/matches\" ) async def api_ioc_get_matches ( self , request : web . Request ): # Ignore max for now. This is not much in the way of information. # max_matches = int(request.query.get(\"max\", \"1000\")) use_regex , patterns = get_patterns ( request . query ) match_metadata = [ loaded_ioc . metadata for loaded_ioc in self . state . get_matching_iocs ( patterns , use_regex = use_regex ) ] return serialized_response ( IocGetMatchesResponse ( patterns = patterns , regex = use_regex , matches = match_metadata , ) ) @routes . get ( \"/api/ioc/pvs\" ) async def api_ioc_get_pvs ( self , request : web . Request ): use_regex , ioc_patterns = get_patterns ( request . query , key = \"ioc\" ) _ , record_patterns = get_patterns ( request . query , key = \"pv\" ) response = IocGetMatchingRecordsResponse ( ioc_patterns = ioc_patterns , record_patterns = record_patterns , regex = use_regex , matches = [], ) def get_all_records ( shell_state ): yield from shell_state . database . items () yield from shell_state . pva_database . items () try : pv_glob_re = compile_patterns ( record_patterns , use_regex = use_regex , ) except re . error : raise web . HTTPBadRequest () for loaded_ioc in self . state . get_matching_iocs ( ioc_patterns , use_regex = response . regex , ): record_matches = [ rec_info . to_summary () for rec , rec_info in sorted ( get_all_records ( loaded_ioc . shell_state )) if pv_glob_re . match ( rec ) ] if record_matches : response . matches . append (( loaded_ioc . metadata , record_matches )) return serialized_response ( response ) @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) ) # @routes.get(\"/api/graphql/query\") # async def api_graphql_query(self, request: web.Request): # TODO: ... @routes . get ( \"/api/plugin/info\" ) async def api_plugin_info ( self , request : web . Request ): plugins = request . query . get ( \"plugin\" , \"all\" ) allow_list = None if plugins == \"all\" else plugins . split ( \" \" ) return serialized_response ( self . state . get_plugin_info ( allow_list )) @routes . get ( \"/api/plugin/nested/keys\" ) async def api_plugin_nested_keys ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] keys = self . state . get_plugin_nested_keys ( plugin ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( keys ) @routes . get ( \"/api/plugin/nested/info\" ) async def api_plugin_nested_info ( self , request : web . Request ): try : plugin = request . query [ \"plugin\" ] key = request . query [ \"key\" ] info = self . state . get_plugin_nested_info ( plugin , key ) except KeyError : raise web . HTTPBadRequest () return serialized_response ( info ) @routes . get ( \"/api/gateway/info\" ) async def api_gateway_info ( self , request : web . Request ): return serialized_response ( self . state . gateway_config . pvlists or {}) @routes . get ( \"/api/file/info\" ) async def api_ioc_info ( self , request : web . Request ): # script_name = pathlib.Path(request.query[\"file\"]) filename = request . query [ \"file\" ] ioc_name = self . state . container . startup_script_to_ioc . get ( filename , None ) if ioc_name : loaded_ioc = self . state . container . scripts [ ioc_name ] script_info = loaded_ioc . script ioc_md = loaded_ioc . metadata else : # Making this dual-purpose: script, db, or any loaded file ioc_md = None if not self . state . is_loaded_file ( filename ): raise web . HTTPBadRequest () script_info = self . state . script_info_from_loaded_file ( filename ) return serialized_response ( { \"script\" : script_info , \"ioc\" : ioc_md , } ) async def get_graph ( self , pv_names : List [ str ], use_glob : bool = False , graph_type : str = \"record\" , format : str = \"pdf\" ): if use_glob : pv_names = self . state . get_matching_pvs ( pv_names ) if format == \"dot\" : try : digraph = self . state . get_graph ( tuple ( pv_names ), graph_type = graph_type ) except TooManyRecordsError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = \"text/vnd.graphviz\" , body = digraph . source , ) rendered = await self . state . get_graph_rendered ( tuple ( pv_names ), format = format , graph_type = graph_type ) try : content_type = { \"pdf\" : \"application/pdf\" , \"png\" : \"image/png\" , \"svg\" : \"image/svg+xml\" , }[ format ] except KeyError as ex : raise web . HTTPBadRequest () from ex return web . Response ( content_type = content_type , body = rendered , ) @routes . get ( \"/api/logs/get\" ) async def api_logs_get ( self , request : web . Request ): return web . json_response ( list ( _log_handler . messages if _log_handler is not None else [ \"Logger not initialized\" ] ) ) @routes . get ( \"/api/pv/relations\" ) async def api_pv_get_relations ( self , request : web . Request ): use_regex , pv_names = get_patterns ( request . query , key = \"pv\" ) pv_names = self . state . get_matching_pvs ( pv_names , use_regex = use_regex ) full = request . query . get ( \"full\" , \"false\" ) in TRUE_VALUES return serialized_response ( self . state . get_pv_relations ( pv_names = pv_names , full = full ) ) @routes . get ( \"/api/pv/graph\" ) async def api_pv_get_record_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"record\" , ) @routes . get ( \"/api/pv/script-graph\" ) async def api_pv_get_script_graph ( self , request : web . Request ): return await self . get_graph ( pv_names = request . query . getall ( \"pv\" ), use_glob = request . query . get ( \"glob\" , \"false\" ) in TRUE_VALUES , format = request . query [ \"format\" ], graph_type = \"script\" , )","title":"ServerHandler"},{"location":"server_client/#whatrecord.server.server.ServerHandler-methods","text":"whatrecord . server . server . ServerHandler . api_pv_get_duplicates ( self , request : Request ) async Get record names duplicated among two or more IOCs. Source code in whatrecord/server/server.py @routes . get ( \"/api/pv/duplicates\" ) async def api_pv_get_duplicates ( self , request : web . Request ): \"\"\"Get record names duplicated among two or more IOCs.\"\"\" use_regex , patterns = get_patterns ( request . query ) return serialized_response ( IocGetDuplicatesResponse ( patterns = patterns , regex = use_regex , duplicates = self . state . get_duplicates ( patterns , use_regex = use_regex ), ) )","title":"Methods"},{"location":"server_client/#whatrecord.server.server.ServerLogHandler","text":"Source code in whatrecord/server/server.py class ServerLogHandler ( logging . Handler ): def __init__ ( self , message_count : int = 1000 , level = \"DEBUG\" ): super () . __init__ ( level = level ) self . formatter = logging . Formatter ( \" %(asctime)s - PID %(process)d %(filename)18s : %(lineno)-3s \" \" %(funcName)-18s %(levelname)-8s %(message)s \" ) self . message_count = message_count self . messages = collections . deque ( maxlen = message_count ) def emit ( self , record ): self . messages . append ( self . format ( record ))","title":"ServerLogHandler"},{"location":"server_client/#whatrecord.server.server.ServerLogHandler-methods","text":"whatrecord . server . server . ServerLogHandler . emit ( self , record ) Do whatever it takes to actually log the specified logging record. This version is intended to be implemented by subclasses and so raises a NotImplementedError. Source code in whatrecord/server/server.py def emit ( self , record ): self . messages . append ( self . format ( record ))","title":"Methods"},{"location":"server_client/#whatrecord.server.server.ServerState","text":"Source code in whatrecord/server/server.py class ServerState : running : bool container : ScriptContainer gateway_config : gateway . GatewayConfig script_loaders : List [ ioc_finder . _IocInfoFinder ] ioc_metadata : List [ IocMetadata ] _update_count : int def __init__ ( self , startup_scripts : Optional [ List [ str ]] = None , script_loaders : Optional [ List [ str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , gateway_config : Optional [ str ] = None , plugins : Optional [ List [ ServerPluginSpec ]] = None , ): self . running = False self . container = ScriptContainer () self . gateway_config = None self . gateway_config_path = gateway_config self . ioc_metadata = [] self . plugins = plugins or [] self . plugins_by_name = { plugin . name : plugin for plugin in plugins or [] } self . script_relations = {} self . standin_directories = standin_directories or {} self . tasks = TaskHandler () self . script_loaders = [ ioc_finder . IocScriptStaticList ( startup_scripts or []) ] + [ ioc_finder . IocScriptExternalLoader ( loader ) for loader in script_loaders or [] ] self . _update_count = 0 @property def iocs_by_name ( self ) -> Dict [ str , IocMetadata ]: \"\"\"Dictionary of IOC name to IocMetadata.\"\"\" return { ioc . name : ioc for ioc in self . ioc_metadata } def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) @property def update_count ( self ) -> int : \"\"\"The number of times IOCs have been updated.\"\"\" return self . _update_count async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) async def async_init ( self , app ): self . running = True self . tasks . create ( self . _update_loop ()) logger . info ( \"Server plugins enabled: %s \" , \", \" . join ( plugin . name for plugin in self . plugins ) ) for plugin in self . plugins : self . tasks . create ( self . _update_plugin_loop ( plugin )) async def _update_plugin_loop ( self , plugin : ServerPluginSpec ): while self . running and self . update_count == 0 and plugin . after_iocs : # Wait until IOCs have been loaded before updating this one for the # first time. await asyncio . sleep ( 1 ) logger . info ( \"Server plugin %r updates started.\" , plugin . name ) while self . running : logger . info ( \"Updating plugin: %s \" , plugin . name ) with common . time_context () as ctx : try : await plugin . update () except Exception : logger . exception ( \"Failed to update plugin %r [ %.1f s]\" , plugin . name , ctx () ) else : logger . info ( \"Successfully updated plugin %r [ %.1f s]\" , plugin . name , ctx () ) # for record, md in info[\"record_to_metadata\"].items(): # ... await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server plugin %r updates finished.\" , plugin . name ) async def _update_loop ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" while self . running : logger . info ( \"Checking for new or updated IOCs...\" ) await self . update_script_loaders () logger . info ( \"Checking for changed scripts and database files...\" ) self . _load_gateway_config () updated = self . get_updated_iocs () if not updated : logger . info ( \"No changes found.\" ) await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) continue logger . info ( \" %d IOC %s changed.\" , len ( updated ), \" has\" if len ( updated ) == 1 else \"s have\" ) for idx , ioc in enumerate ( updated [: 10 ], 1 ): logger . info ( \"* %d : %s \" , idx , ioc . name ) if len ( updated ) > 10 : logger . info ( \"... and %d more\" , len ( updated ) - 10 ) with common . time_context () as ctx : await self . update_iocs ( updated ) logger . info ( \"Updated %d IOCs in %.1f seconds\" , len ( updated ), ctx () ) self . clear_cache () await asyncio . sleep ( settings . SERVER_SCAN_PERIOD ) logger . info ( \"Server script updates finished.\" ) async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated def _replace_metadata ( self , old_md : IocMetadata , new_md : IocMetadata ) -> int : \"\"\"Replace the provided metadata information with a new one.\"\"\" idx = self . ioc_metadata . index ( old_md ) self . ioc_metadata . remove ( old_md ) self . ioc_metadata . insert ( idx , new_md ) return idx async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} def _load_gateway_config ( self ): if not self . gateway_config_path : logger . warning ( \"Gateway path not set; gateway configuration will not be loaded\" ) return if self . gateway_config is None : logger . info ( \"Loading gateway configuration for the first time...\" ) self . gateway_config = gateway . GatewayConfig ( self . gateway_config_path ) else : logger . info ( \"Updating gateway configuration...\" ) self . gateway_config . update_changed () for filename , pvlist in self . gateway_config . pvlists . items (): if pvlist . hash is not None : logger . debug ( \"New gateway file: %s ( %s )\" , filename , pvlist . hash ) self . container . loaded_files [ str ( filename )] = pvlist . hash def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results @property def aliases ( self ) -> Dict [ str , str ]: \"\"\"The CA/V3 aliases.\"\"\" return self . container . aliases @property def database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The CA/V3 Database of records.\"\"\" return self . container . database @property def pva_database ( self ) -> Dict [ str , RecordInstance ]: \"\"\"The pvAccess Database of groups/records.\"\"\" return self . container . pva_database def get_graph ( self , pv_names : Tuple [ str , ... ], graph_type : str ) -> graphviz . Digraph : if graph_type == \"record\" : return self . get_link_graph ( tuple ( pv_names )) if graph_type == \"script\" : return self . get_script_graph ( tuple ( pv_names )) raise RuntimeError ( \"Invalid graph type\" ) def get_script_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_script_relations ( database = self . database , limit_to_records = pv_names , script_relations = self . script_relations , ) return gr . to_digraph ( font_name = \"Courier\" ) def get_ioc_to_pvs ( self , pv_names : Tuple [ str , ... ]) -> Dict [ str , List [ str ]]: ioc_to_pvs = {} for pv in pv_names : try : owner = self . container . database [ pv ] . owner or \"unknown\" except KeyError : owner = \"unknown\" if owner not in ioc_to_pvs : ioc_to_pvs [ owner ] = [] ioc_to_pvs [ owner ] . append ( pv ) return ioc_to_pvs def get_pv_relations ( self , pv_names : Tuple [ str , ... ], * , full : bool = False , ) -> Union [ PVRelationshipResponse , PVShortRelationshipResponse ]: # TODO: pv_names if full : return PVRelationshipResponse ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) return PVShortRelationshipResponse . from_pv_relations ( pv_relations = self . container . pv_relations , script_relations = self . script_relations , ioc_to_pvs = self . get_ioc_to_pvs ( tuple ( self . container . pv_relations )) ) def get_link_graph ( self , pv_names : Tuple [ str , ... ]) -> graphviz . Digraph : if len ( pv_names ) > settings . MAX_RECORDS : raise TooManyRecordsError () if not pv_names : return graphviz . Digraph () gr = graph . graph_links ( database = self . database , starting_records = list ( pv_names ), sort_fields = True , relations = self . container . pv_relations , ) digraph = gr . to_digraph ( font_name = \"Courier\" ) return digraph def clear_cache ( self ): for method in [ # self.get_graph, # self.get_graph_rendered, self . get_gateway_matches , self . get_matching_pvs , self . get_matching_iocs , self . script_info_from_loaded_file , self . get_duplicates , ]: method . cache_clear () def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) @functools . lru_cache ( maxsize = 2048 ) def script_info_from_loaded_file ( self , fn ) -> common . IocshScript : with open ( fn , \"rt\" ) as fp : lines = fp . read () . splitlines () result = [] for lineno , line in enumerate ( lines , 1 ): result . append ( common . IocshResult ( context = ( LoadContext ( fn , lineno ),), line = line , ) ) return common . IocshScript ( path = fn , lines = tuple ( result )) @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read ()","title":"ServerState"},{"location":"server_client/#whatrecord.server.server.ServerState-attributes","text":"whatrecord . server . server . ServerState . aliases : Dict [ str , str ] property readonly The CA/V3 aliases. whatrecord . server . server . ServerState . database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The CA/V3 Database of records. whatrecord . server . server . ServerState . iocs_by_name : Dict [ str , whatrecord . common . IocMetadata ] property readonly Dictionary of IOC name to IocMetadata. whatrecord . server . server . ServerState . pva_database : Dict [ str , whatrecord . common . RecordInstance ] property readonly The pvAccess Database of groups/records. whatrecord . server . server . ServerState . update_count : int property readonly The number of times IOCs have been updated.","title":"Attributes"},{"location":"server_client/#whatrecord.server.server.ServerState-methods","text":"whatrecord . server . server . ServerState . add_or_update_ioc_metadata ( self , md : IocMetadata ) Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. Source code in whatrecord/server/server.py def add_or_update_ioc_metadata ( self , md : IocMetadata ): \"\"\" Add a new IOC to monitor by its metadata. Note: an assumption is made here that an IOC name is unique among all those loaded. \"\"\" try : existing = self . iocs_by_name [ md . name ] except KeyError : self . ioc_metadata . append ( md ) else : existing . update ( md ) whatrecord . server . server . ServerState . annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord Annotate WhatRecord instances with things ServerState knows about. Source code in whatrecord/server/server.py def annotate_whatrec ( self , ioc : LoadedIoc , what : WhatRecord ) -> WhatRecord : \"\"\" Annotate WhatRecord instances with things ServerState knows about. \"\"\" matches = [ ( what . record . instance if what . record else None ), what . pva_group ] for instance in matches : if instance is None : continue if not instance . is_pva : # For now, V3 only instance . metadata [ \"gateway\" ] = apischema . serialize ( self . get_gateway_matches ( instance . name ) ) ioc . shell_state . annotate_record ( instance ) for plugin in self . plugins : if not plugin . results : continue info = list ( plugin . results . find_record_metadata ( instance . name )) if info : plugin_key = StringWithContext ( plugin . name , context = ()) instance . metadata [ plugin_key ] = info return what whatrecord . server . server . ServerState . get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]] Get duplicate PVs from the matching IOC(s). Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 20 ) def get_duplicates ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> Dict [ str , List [ str ]]: \"\"\"Get duplicate PVs from the matching IOC(s).\"\"\" iocs = self . get_matching_iocs ( patterns , use_regex = use_regex ) seen = collections . defaultdict ( list ) for ioc in iocs : shell_state : ShellState = ioc . shell_state for record in set ( shell_state . database ) . union ( shell_state . pva_database ): seen [ record ] . append ( ioc . name ) return { record : iocs for record , iocs in seen . items () if len ( iocs ) > 1 } whatrecord . server . server . ServerState . get_gateway_matches ( self , pvname : str ) -> Optional [ whatrecord . gateway . PVListMatches ] Get gateway matches for the given pvname. Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_gateway_matches ( self , pvname : str ) -> Optional [ gateway . PVListMatches ]: \"\"\"Get gateway matches for the given pvname.\"\"\" if self . gateway_config is None : return None return self . gateway_config . get_matches ( pvname ) whatrecord . server . server . ServerState . get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes async Get a rendered PV relationship graph of the provided PVs. Parameters: Name Type Description Default pv_names Tuple[str, ...] PV names. required format str The format of the graph (e.g., pdf, png). required graph_type str The type of graph to generate. required Source code in whatrecord/server/server.py async def get_graph_rendered ( self , pv_names : Tuple [ str , ... ], format : str , graph_type : str ) -> bytes : \"\"\" Get a rendered PV relationship graph of the provided PVs. Parameters ---------- pv_names : tuple of str PV names. format : str The format of the graph (e.g., pdf, png). graph_type : { \"record\", \"script\" } The type of graph to generate. \"\"\" graph = self . get_graph ( pv_names , graph_type = graph_type ) with tempfile . NamedTemporaryFile ( suffix = f \". { format } \" ) as source_file : rendered_filename = await graph . async_render ( source_file . name , format = format ) with open ( rendered_filename , \"rb\" ) as fp : return fp . read () whatrecord . server . server . ServerState . get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ whatrecord . shell . LoadedIoc ] Get matching IOCs given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_iocs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ LoadedIoc ]: \"\"\" Get matching IOCs given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] def by_name ( ioc : LoadedIoc ): return ioc . name return [ loaded_ioc for loaded_ioc in sorted ( self . container . scripts . values (), key = by_name ) if regex . match ( loaded_ioc . script . path ) or regex . match ( loaded_ioc . metadata . name ) ] whatrecord . server . server . ServerState . get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ] Get matching PV names given pattern(s). Parameters: Name Type Description Default patterns Tuple[str, ...] List of patterns in glob or regex format. required use_regex bool Interpret patterns as glob (False) or regex (True). False Source code in whatrecord/server/server.py @functools . lru_cache ( maxsize = 2048 ) def get_matching_pvs ( self , patterns : Tuple [ str , ... ], use_regex : bool = False ) -> List [ str ]: \"\"\" Get matching PV names given pattern(s). Parameters ---------- patterns : list of str List of patterns in glob or regex format. use_regex : bool, optional Interpret patterns as glob (False) or regex (True). \"\"\" try : regex = compile_patterns ( patterns , use_regex = use_regex ) except re . error : return [] pv_names = set ( self . database ) | set ( self . pva_database ) | set ( self . aliases ) return [ pv_name for pv_name in sorted ( pv_names ) if regex . match ( pv_name )] whatrecord . server . server . ServerState . get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ] Get plugin information as a dictionary. Source code in whatrecord/server/server.py def get_plugin_info ( self , allow_list : Optional [ List [ str ]] = None ) -> Dict [ str , Any ]: \"\"\"Get plugin information as a dictionary.\"\"\" if allow_list is None : allow_list = [ plugin . name for plugin in self . plugins ] return { plugin . name : plugin . results_json for plugin in self . plugins if plugin . name in allow_list and plugin . results } whatrecord . server . server . ServerState . get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any Get plugin custom nested metadata info. Source code in whatrecord/server/server.py def get_plugin_nested_info ( self , plugin_name : str , key : str ) -> Any : \"\"\"Get plugin custom nested metadata info.\"\"\" results = self . plugins_by_name [ plugin_name ] . results return results . nested [ key ] if results else {} whatrecord . server . server . ServerState . get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ] Get plugin custom nested metadata keys. Source code in whatrecord/server/server.py def get_plugin_nested_keys ( self , plugin_name : str ) -> List [ str ]: \"\"\"Get plugin custom nested metadata keys.\"\"\" plugin = self . plugins_by_name [ plugin_name ] if plugin . results and plugin . results . nested : return list ( plugin . results . nested ) return [] whatrecord . server . server . ServerState . get_updated_iocs ( self ) -> List [ whatrecord . common . IocMetadata ] Check loaded IOCs for any changes. Source code in whatrecord/server/server.py def get_updated_iocs ( self ) -> List [ IocMetadata ]: \"\"\"Check loaded IOCs for any changes.\"\"\" updated = [ md for md in self . ioc_metadata if not md . is_up_to_date () ] for item in list ( updated ): if not item . script or not item . script . exists () or item . looks_like_sh : if self . update_count == 0 : # Don't attempt another load unless the file exists updated . remove ( item ) return updated whatrecord . server . server . ServerState . is_loaded_file ( self , fn ) -> bool Is fn a file that was loaded? Source code in whatrecord/server/server.py def is_loaded_file ( self , fn ) -> bool : \"\"\"Is ``fn`` a file that was loaded?\"\"\" fn = str ( fn ) if fn in self . container . loaded_files : return True return any ( plugin . results . is_loaded_file ( fn ) for plugin in self . plugins if plugin . results is not None ) whatrecord . server . server . ServerState . stop ( self ) async Stop any background updates. Source code in whatrecord/server/server.py async def stop ( self ): \"\"\"Stop any background updates.\"\"\" self . running = False await self . tasks . cancel_all ( wait = True ) whatrecord . server . server . ServerState . update_iocs ( self , iocs : List [ whatrecord . common . IocMetadata ]) async Reload the provided IOCs. Source code in whatrecord/server/server.py async def update_iocs ( self , iocs : List [ IocMetadata ]): \"\"\"Reload the provided IOCs.\"\"\" async for md , loaded in load_startup_scripts_with_metadata ( * iocs , standin_directories = self . standin_directories ): self . container . add_loaded_ioc ( loaded ) self . _replace_metadata ( md , loaded . metadata ) # Let plugins update, if possible await asyncio . sleep ( 0 ) with common . time_context () as ctx : self . script_relations = graph . build_script_relations ( self . container . database , self . container . pv_relations , ) logger . info ( \"Updated script relations in %.1f s\" , ctx ()) self . _update_count += 1 whatrecord . server . server . ServerState . update_script_loaders ( self ) async Update scripts from the script loader and watch for updates. Source code in whatrecord/server/server.py async def update_script_loaders ( self ): \"\"\"Update scripts from the script loader and watch for updates.\"\"\" for loader in self . script_loaders : await loader . update () for _ , md in loader . scripts . items (): self . add_or_update_ioc_metadata ( md ) whatrecord . server . server . ServerState . whatrec ( self , pvname : str ) -> List [ whatrecord . common . WhatRecord ] Find WhatRecord matches. Source code in whatrecord/server/server.py def whatrec ( self , pvname : str ) -> List [ WhatRecord ]: \"\"\"Find WhatRecord matches.\"\"\" results = [] for loaded_ioc in self . container . scripts . values (): what = loaded_ioc . whatrec ( pvname ) if what is not None : self . annotate_whatrec ( loaded_ioc , what ) results . append ( what ) return results","title":"Methods"},{"location":"server_client/#whatrecord.server.server-functions","text":"","title":"Functions"},{"location":"server_client/#whatrecord.server.server.compile_patterns","text":"Compile regular expression (or glob) patterns with re.compile . Source code in whatrecord/server/server.py def compile_patterns ( patterns : Tuple [ str , ... ], flags = re . IGNORECASE , use_regex = False ): \"\"\"Compile regular expression (or glob) patterns with `re.compile`.\"\"\" if use_regex : return re . compile ( \"|\" . join ( patterns ), flags = flags ) return re . compile ( \"|\" . join ( fnmatch . translate ( pattern ) for pattern in patterns ), flags = flags , )","title":"compile_patterns()"},{"location":"server_client/#whatrecord.server.server.get_patterns","text":"Get glob/regex patterns from a server query. Source code in whatrecord/server/server.py def get_patterns ( query , key : str = \"pattern\" , regex_key : str = \"regex\" ) -> Tuple [ bool , Tuple [ str , ... ]]: \"\"\"Get glob/regex patterns from a server query.\"\"\" use_regex = query . get ( regex_key , \"false\" ) . lower () in TRUE_VALUES default = ( \".*\" if use_regex else \"*\" ,) return use_regex , tuple ( query . getall ( key , default ))","title":"get_patterns()"},{"location":"server_client/#whatrecord.server.server.serialized_response","text":"Return an apischema-serialized JSON response of a dataclass instance. Source code in whatrecord/server/server.py def serialized_response ( obj : Any ) -> web . Response : \"\"\"Return an apischema-serialized JSON response of a dataclass instance.\"\"\" return web . json_response ( apischema . serialize ( obj ))","title":"serialized_response()"},{"location":"server_client/#whatrecord.server.util","text":"","title":"util"},{"location":"server_client/#whatrecord.server.util-classes","text":"","title":"Classes"},{"location":"server_client/#whatrecord.server.util.TaskHandler","text":"Helper to manage asyncio tasks in one spot. Source code in whatrecord/server/util.py class TaskHandler : \"\"\"Helper to manage asyncio tasks in one spot.\"\"\" def __init__ ( self ): self . tasks = [] self . _lock = threading . Lock () def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task def _remove_completed_task ( self , task ): try : with self . _lock : self . tasks . remove ( task ) except ValueError : # May have been cancelled or removed otherwise ... @staticmethod async def cancel ( task ): task . cancel () await task async def cancel_all ( self , wait = False ): with self . _lock : tasks = list ( self . tasks ) self . tasks . clear () for task in list ( tasks ): task . cancel () if wait and len ( tasks ): await asyncio . wait ( tasks )","title":"TaskHandler"},{"location":"server_client/#whatrecord.server.util.TaskHandler-methods","text":"whatrecord . server . util . TaskHandler . create ( self , coro ) Schedule the execution of a coroutine object in a spawn task. Source code in whatrecord/server/util.py def create ( self , coro ): \"\"\"Schedule the execution of a coroutine object in a spawn task.\"\"\" task = asyncio . create_task ( coro ) with self . _lock : self . tasks . append ( task ) task . add_done_callback ( self . _remove_completed_task ) return task","title":"Methods"},{"location":"tests/","text":"Tests API whatrecord.tests special Modules whatrecord.tests.test_bin_graph Smoke tests to see if the provided IOCs load without crashing. whatrecord.tests.test_bin_lint Tests for the 'whatrecord lint' subcommand. whatrecord.tests.test_bin_parse Smoke tests to see if the provided IOCs load without crashing. whatrecord.tests.test_makefile Functions whatrecord . tests . test_makefile . check_module_in_group ( group : DependencyGroup , variable_name : str , path : Path ) -> Dependency Check if a module is present in a DependencyGroup. Source code in whatrecord/tests/test_makefile.py def check_module_in_group ( group : makefile . DependencyGroup , variable_name : str , path : pathlib . Path ) -> makefile . Dependency : \"\"\"Check if a module is present in a DependencyGroup.\"\"\" if path not in group . all_modules : paths = \", \" . join ( str ( path ) for path in group . all_modules ) raise ValueError ( f \"Module { variable_name } not found in dependency list. \" f \"Paths: { paths } \" ) module = group . all_modules [ path ] assert module . variable_name == variable_name return module whatrecord . tests . test_makefile . get_dependency_group ( contents : str , * , set_filename : bool = True ) -> Tuple [ whatrecord . makefile . Makefile , whatrecord . makefile . DependencyGroup ] Get a DependencyGroup instance given a single Makefile's contents. Source code in whatrecord/tests/test_makefile.py def get_dependency_group ( contents : str , * , set_filename : bool = True ) -> Tuple [ makefile . Makefile , makefile . DependencyGroup ]: \"\"\"Get a DependencyGroup instance given a single Makefile's contents.\"\"\" root = get_makefile ( contents , set_filename = set_filename ) group = makefile . DependencyGroup . from_makefile ( root ) if set_filename : assert root . filename is not None assert group . root == root . filename . parent return root , group whatrecord . tests . test_makefile . get_makefile ( contents : str , * , set_filename : bool = True ) -> Makefile Get a Makefile instance given its contents. Source code in whatrecord/tests/test_makefile.py def get_makefile ( contents : str , * , set_filename : bool = True ) -> makefile . Makefile : \"\"\"Get a Makefile instance given its contents.\"\"\" contents = textwrap . dedent ( contents ) . replace ( \" \" , \" \\t \" ) print ( \"Creating Makefile from contents:\" ) print ( contents ) make = makefile . Makefile . from_string ( contents , filename = DEPS_MAKEFILE_ROOT / \"Makefile.made_up\" if set_filename else None , ) if set_filename : # Make the object more realistic make . name = \"ioc\" make . variable_name = \"ioc_var\" return make whatrecord . tests . test_makefile . prune_result ( result : Makefile , expected : Makefile , to_keep : Optional [ Set [ str ]] = None ) -> None Prune resulting Makefile for the purposes of testing. Remove extra environment variables that we don't want here Source code in whatrecord/tests/test_makefile.py def prune_result ( result : makefile . Makefile , expected : makefile . Makefile , to_keep : Optional [ Set [ str ]] = None , ) -> None : \"\"\" Prune resulting Makefile for the purposes of testing. * Remove extra environment variables that we don't want here \"\"\" for key in set ( result . env ) - set ( expected . env ): result . env . pop ( key ) ignore = { \"env\" , \"filename\" } for field in dataclasses . fields ( makefile . Makefile ): if field . name not in to_keep and field . name not in ignore : setattr ( result , field . name , getattr ( expected , field . name )) whatrecord.tests.test_pva_parsing Placeholder for PVA parsing tests, for the most part... whatrecord.tests.test_serialization Functions whatrecord . tests . test_serialization . find_all_dataclasses () -> List [ type ] Find all dataclasses in whatrecord and return them as a list. Source code in whatrecord/tests/test_serialization.py def find_all_dataclasses () -> List [ type ]: \"\"\"Find all dataclasses in whatrecord and return them as a list.\"\"\" def should_include ( obj ): return ( inspect . isclass ( obj ) and dataclasses . is_dataclass ( obj ) and obj not in SKIP_CLASSES ) def sort_key ( cls ): return ( cls . __module__ , cls . __name__ ) devices = [ obj for module in find_whatrecord_submodules () . values () for _ , obj in inspect . getmembers ( module , predicate = should_include ) ] return list ( sorted ( set ( devices ), key = sort_key )) whatrecord . tests . test_serialization . find_whatrecord_submodules () -> Dict [ str , module ] Find all whatrecord submodules, as a dictionary of name to module. Source code in whatrecord/tests/test_serialization.py def find_whatrecord_submodules () -> Dict [ str , ModuleType ]: \"\"\"Find all whatrecord submodules, as a dictionary of name to module.\"\"\" modules = {} package_root = str ( MODULE_PATH . parent ) for item in pkgutil . walk_packages ( path = [ package_root ], prefix = \"whatrecord.\" ): if item . name . endswith ( \"__main__\" ): continue try : modules [ item . name ] = sys . modules [ item . name ] except KeyError : # Submodules may not yet be imported; do that here. try : modules [ item . name ] = importlib . import_module ( item . name , package = \"whatrecord\" ) except Exception : logger . exception ( \"Failed to import %s \" , item . name ) return modules whatrecord.tests.test_server_handler Requires pytest-aiohttp whatrecord.tests.test_v3_parsing V3 database parsing tests.","title":"Tests"},{"location":"tests/#tests","text":"","title":"Tests"},{"location":"tests/#api","text":"","title":"API"},{"location":"tests/#whatrecord.tests","text":"","title":"tests"},{"location":"tests/#whatrecord.tests-modules","text":"","title":"Modules"},{"location":"tests/#whatrecord.tests.test_bin_graph","text":"Smoke tests to see if the provided IOCs load without crashing.","title":"test_bin_graph"},{"location":"tests/#whatrecord.tests.test_bin_lint","text":"Tests for the 'whatrecord lint' subcommand.","title":"test_bin_lint"},{"location":"tests/#whatrecord.tests.test_bin_parse","text":"Smoke tests to see if the provided IOCs load without crashing.","title":"test_bin_parse"},{"location":"tests/#whatrecord.tests.test_makefile","text":"","title":"test_makefile"},{"location":"tests/#whatrecord.tests.test_makefile-functions","text":"whatrecord . tests . test_makefile . check_module_in_group ( group : DependencyGroup , variable_name : str , path : Path ) -> Dependency Check if a module is present in a DependencyGroup. Source code in whatrecord/tests/test_makefile.py def check_module_in_group ( group : makefile . DependencyGroup , variable_name : str , path : pathlib . Path ) -> makefile . Dependency : \"\"\"Check if a module is present in a DependencyGroup.\"\"\" if path not in group . all_modules : paths = \", \" . join ( str ( path ) for path in group . all_modules ) raise ValueError ( f \"Module { variable_name } not found in dependency list. \" f \"Paths: { paths } \" ) module = group . all_modules [ path ] assert module . variable_name == variable_name return module whatrecord . tests . test_makefile . get_dependency_group ( contents : str , * , set_filename : bool = True ) -> Tuple [ whatrecord . makefile . Makefile , whatrecord . makefile . DependencyGroup ] Get a DependencyGroup instance given a single Makefile's contents. Source code in whatrecord/tests/test_makefile.py def get_dependency_group ( contents : str , * , set_filename : bool = True ) -> Tuple [ makefile . Makefile , makefile . DependencyGroup ]: \"\"\"Get a DependencyGroup instance given a single Makefile's contents.\"\"\" root = get_makefile ( contents , set_filename = set_filename ) group = makefile . DependencyGroup . from_makefile ( root ) if set_filename : assert root . filename is not None assert group . root == root . filename . parent return root , group whatrecord . tests . test_makefile . get_makefile ( contents : str , * , set_filename : bool = True ) -> Makefile Get a Makefile instance given its contents. Source code in whatrecord/tests/test_makefile.py def get_makefile ( contents : str , * , set_filename : bool = True ) -> makefile . Makefile : \"\"\"Get a Makefile instance given its contents.\"\"\" contents = textwrap . dedent ( contents ) . replace ( \" \" , \" \\t \" ) print ( \"Creating Makefile from contents:\" ) print ( contents ) make = makefile . Makefile . from_string ( contents , filename = DEPS_MAKEFILE_ROOT / \"Makefile.made_up\" if set_filename else None , ) if set_filename : # Make the object more realistic make . name = \"ioc\" make . variable_name = \"ioc_var\" return make whatrecord . tests . test_makefile . prune_result ( result : Makefile , expected : Makefile , to_keep : Optional [ Set [ str ]] = None ) -> None Prune resulting Makefile for the purposes of testing. Remove extra environment variables that we don't want here Source code in whatrecord/tests/test_makefile.py def prune_result ( result : makefile . Makefile , expected : makefile . Makefile , to_keep : Optional [ Set [ str ]] = None , ) -> None : \"\"\" Prune resulting Makefile for the purposes of testing. * Remove extra environment variables that we don't want here \"\"\" for key in set ( result . env ) - set ( expected . env ): result . env . pop ( key ) ignore = { \"env\" , \"filename\" } for field in dataclasses . fields ( makefile . Makefile ): if field . name not in to_keep and field . name not in ignore : setattr ( result , field . name , getattr ( expected , field . name ))","title":"Functions"},{"location":"tests/#whatrecord.tests.test_pva_parsing","text":"Placeholder for PVA parsing tests, for the most part...","title":"test_pva_parsing"},{"location":"tests/#whatrecord.tests.test_serialization","text":"","title":"test_serialization"},{"location":"tests/#whatrecord.tests.test_serialization-functions","text":"whatrecord . tests . test_serialization . find_all_dataclasses () -> List [ type ] Find all dataclasses in whatrecord and return them as a list. Source code in whatrecord/tests/test_serialization.py def find_all_dataclasses () -> List [ type ]: \"\"\"Find all dataclasses in whatrecord and return them as a list.\"\"\" def should_include ( obj ): return ( inspect . isclass ( obj ) and dataclasses . is_dataclass ( obj ) and obj not in SKIP_CLASSES ) def sort_key ( cls ): return ( cls . __module__ , cls . __name__ ) devices = [ obj for module in find_whatrecord_submodules () . values () for _ , obj in inspect . getmembers ( module , predicate = should_include ) ] return list ( sorted ( set ( devices ), key = sort_key )) whatrecord . tests . test_serialization . find_whatrecord_submodules () -> Dict [ str , module ] Find all whatrecord submodules, as a dictionary of name to module. Source code in whatrecord/tests/test_serialization.py def find_whatrecord_submodules () -> Dict [ str , ModuleType ]: \"\"\"Find all whatrecord submodules, as a dictionary of name to module.\"\"\" modules = {} package_root = str ( MODULE_PATH . parent ) for item in pkgutil . walk_packages ( path = [ package_root ], prefix = \"whatrecord.\" ): if item . name . endswith ( \"__main__\" ): continue try : modules [ item . name ] = sys . modules [ item . name ] except KeyError : # Submodules may not yet be imported; do that here. try : modules [ item . name ] = importlib . import_module ( item . name , package = \"whatrecord\" ) except Exception : logger . exception ( \"Failed to import %s \" , item . name ) return modules","title":"Functions"},{"location":"tests/#whatrecord.tests.test_server_handler","text":"Requires pytest-aiohttp","title":"test_server_handler"},{"location":"tests/#whatrecord.tests.test_v3_parsing","text":"V3 database parsing tests.","title":"test_v3_parsing"},{"location":"utilities/","text":"Shared / Utilities Macros EPICS-compliant macro parsing by way of a Cython wrapper of macLib. whatrecord.macro Functions whatrecord . macro . macros_from_string ( macro_string : str , use_environment : bool = False ) -> Dict [ str , str ] Get a macro dictionary from a macro string. Parameters: Name Type Description Default macro_string str The macro string, in the format A=B,C=D,... required use_environment bool Use environment variables as well. Defaults to False. False Returns: Type Description Dict[str, str] Macro key to value. Source code in whatrecord/macro.py def macros_from_string ( macro_string : str , use_environment : bool = False ) -> Dict [ str , str ]: \"\"\" Get a macro dictionary from a macro string. Parameters ---------- macro_string : str The macro string, in the format A=B,C=D,... use_environment : bool, optional Use environment variables as well. Defaults to False. Returns ------- macros : Dict[str, str] Macro key to value. \"\"\" if not macro_string . strip (): return {} macro_context = MacroContext ( use_environment = use_environment ) return macro_context . define_from_string ( macro_string ) PV Graphing whatrecord.graph Classes whatrecord.graph.GraphEdge dataclass GraphEdge(source: whatrecord.graph.GraphNode, destination: whatrecord.graph.GraphNode, options: dict = ) Source code in whatrecord/graph.py @dataclass class GraphEdge : #: The source node. source : GraphNode #: The destination node. destination : GraphNode #: Options to pass to graphviz. options : dict = dataclasses . field ( default_factory = dict ) whatrecord.graph.GraphNode dataclass GraphNode(id: str, label: str, text: str, options: dict = , highlighted: bool = False) Source code in whatrecord/graph.py @dataclass () class GraphNode : #: The integer ID of the node id : str #: The node label label : str #: The text to show in the node text : str #: Options to pass to graphviz. options : dict = dataclasses . field ( default_factory = dict ) #: Highlight the node in the graph? highlighted : bool = False def __hash__ ( self ): return hash ( self . id ) whatrecord.graph.LinkInfo dataclass LinkInfo(record1: whatrecord.common.RecordInstance, field1: whatrecord.common.RecordField, record2: whatrecord.common.RecordInstance, field2: whatrecord.common.RecordField, info: List[str]) Source code in whatrecord/graph.py @dataclass class LinkInfo : record1 : RecordInstance field1 : RecordField record2 : RecordInstance field2 : RecordField info : List [ str ] whatrecord.graph.RecordLinkGraph ( _GraphHelper ) Record link graph. Source code in whatrecord/graph.py class RecordLinkGraph ( _GraphHelper ): \"\"\"Record link graph.\"\"\" # TODO: create node and color when not in database? database : Database starting_records : List [ str ] header_format : str = 'record( {rtype} , \" {name} \")' field_format : str = ' {field:>4s} : \" {value} \"' text_format : str = ( f \"<b> {{ header }} </b>\" f \" { _GraphHelper . newline } \" f \" { _GraphHelper . newline } \" f \" {{ field_lines }} \" ) sort_fields : bool show_empty : bool relations : Optional [ PVRelations ] record_types : Dict [ str , RecordType ] default_edge_kwargs : Dict [ str , str ] = { \"style\" : \"solid\" , \"color\" : \"black\" , } edge_kwargs : ClassVar [ Dict [ str , Dict [ str , str ]]] = { \"style\" : { \"PP\" : \"\" , \"CPP\" : \"\" , \"CP\" : \"\" , }, \"color\" : { \"MS\" : \"red\" , \"MSS\" : \"red\" , \"MSI\" : \"red\" , } } def __init__ ( self , database : Optional [ Union [ Database , Dict [ str , RecordInstance ]]] = None , starting_records : Optional [ List [ str ]] = None , header_format : Optional [ str ] = None , field_format : Optional [ str ] = None , text_format : Optional [ str ] = None , sort_fields : bool = True , show_empty : bool = False , relations : Optional [ PVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ): super () . __init__ () self . database = Database ( record_types = dict ( record_types or {})) self . starting_records = starting_records or [] self . header_format = header_format or type ( self ) . header_format self . field_format = field_format or type ( self ) . field_format self . text_format = text_format or type ( self ) . text_format self . sort_fields = sort_fields self . show_empty = show_empty self . relations = relations if database is not None : self . add_database ( database ) def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) if not self . relations : self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types ) for li in find_record_links ( self . database . records , self . starting_records , relations = self . relations ): for ( rec , field ) in (( li . record1 , li . field1 ), ( li . record2 , li . field2 )): if rec . name not in self . nodes : self . get_node ( label = rec . name , text = field . name ) src = self . get_node ( li . record1 . name ) dest = self . get_node ( li . record2 . name ) for field , node in [( li . field1 , src ), ( li . field2 , dest )]: if field . value or self . show_empty : text_line = self . field_format . format ( field = field . name , value = field . value ) if node . text and text_line not in node . text : node . text = \" \\n \" . join (( node . text , text_line )) else : node . text = text_line if li . field1 . dtype == \"DBF_INLINK\" : src , dest = dest , src li . field1 , li . field2 = li . field2 , li . field1 logger . debug ( \"New edge %s -> %s \" , src , dest ) edge_kw = dict ( self . default_edge_kwargs ) for key , to_find in self . edge_kwargs . items (): for match , value in to_find . items (): if match in li . info : edge_kw [ key ] = value break if ( src , dest ) not in set ( self . edge_pairs ): edge_kw [ \"xlabel\" ] = f \" { li . field1 . name } / { li . field2 . name } \" if li . info : edge_kw [ \"xlabel\" ] += f \" \\n { ' ' . join ( li . info ) } \" self . add_edge ( src . label , dest . label , ** edge_kw ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . starting_records : if rec_name in self . database . records : self . get_node ( rec_name ) for node in self . nodes . values (): field_lines = node . text if self . sort_fields : node . text = \" \\n \" . join ( sorted ( node . text . splitlines ())) if field_lines : node . text += \" \\n \" rec = self . database . records [ node . label ] header = self . header_format . format ( rtype = rec . record_type , name = rec . name ) if rec . aliases : header += f \" \\n Alias: { ', ' . join ( rec . aliases ) } \" escaped_header = html . escape ( header , quote = False ) node . text = self . text_format . format ( header = escaped_header . replace ( \" \\n \" , self . newline ), field_lines = self . newline . join ( html . escape ( line , quote = False ) for line in node . text . splitlines () ), ) def _ready_for_digraph ( self , graph : gv . Digraph ): \"\"\"Hook when the user calls ``to_digraph``.\"\"\" for node in self . nodes . values (): node . highlighted = node . label in self . starting_records Methods whatrecord . graph . RecordLinkGraph . add_database ( self , database : Union [ Dict [ str , whatrecord . common . RecordInstance ], whatrecord . db . Database ]) Add records from the given database to the graph. Source code in whatrecord/graph.py def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) if not self . relations : self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types ) for li in find_record_links ( self . database . records , self . starting_records , relations = self . relations ): for ( rec , field ) in (( li . record1 , li . field1 ), ( li . record2 , li . field2 )): if rec . name not in self . nodes : self . get_node ( label = rec . name , text = field . name ) src = self . get_node ( li . record1 . name ) dest = self . get_node ( li . record2 . name ) for field , node in [( li . field1 , src ), ( li . field2 , dest )]: if field . value or self . show_empty : text_line = self . field_format . format ( field = field . name , value = field . value ) if node . text and text_line not in node . text : node . text = \" \\n \" . join (( node . text , text_line )) else : node . text = text_line if li . field1 . dtype == \"DBF_INLINK\" : src , dest = dest , src li . field1 , li . field2 = li . field2 , li . field1 logger . debug ( \"New edge %s -> %s \" , src , dest ) edge_kw = dict ( self . default_edge_kwargs ) for key , to_find in self . edge_kwargs . items (): for match , value in to_find . items (): if match in li . info : edge_kw [ key ] = value break if ( src , dest ) not in set ( self . edge_pairs ): edge_kw [ \"xlabel\" ] = f \" { li . field1 . name } / { li . field2 . name } \" if li . info : edge_kw [ \"xlabel\" ] += f \" \\n { ' ' . join ( li . info ) } \" self . add_edge ( src . label , dest . label , ** edge_kw ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . starting_records : if rec_name in self . database . records : self . get_node ( rec_name ) for node in self . nodes . values (): field_lines = node . text if self . sort_fields : node . text = \" \\n \" . join ( sorted ( node . text . splitlines ())) if field_lines : node . text += \" \\n \" rec = self . database . records [ node . label ] header = self . header_format . format ( rtype = rec . record_type , name = rec . name ) if rec . aliases : header += f \" \\n Alias: { ', ' . join ( rec . aliases ) } \" escaped_header = html . escape ( header , quote = False ) node . text = self . text_format . format ( header = escaped_header . replace ( \" \\n \" , self . newline ), field_lines = self . newline . join ( html . escape ( line , quote = False ) for line in node . text . splitlines () ), ) whatrecord.graph.ScriptLinkGraph ( _GraphHelper ) Script link graph (i.e., inter-IOC record links). Parameters: Name Type Description Default database Union[whatrecord.db.Database, Dict[str, whatrecord.common.RecordInstance]] Dictionary of record name to record instance. None starting_records list of str Record names required sort_fields bool Sort list of fields required show_empty bool Show empty fields required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None script_relations Optional[Dict[str, Dict[str, List[str]]]] Pre-built script relationship dictionary. Generated from database if not provided. None record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. None Source code in whatrecord/graph.py class ScriptLinkGraph ( _GraphHelper ): \"\"\" Script link graph (i.e., inter-IOC record links). Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names sort_fields : bool, optional Sort list of fields show_empty : bool, optional Show empty fields relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. script_relations : dict, optional Pre-built script relationship dictionary. Generated from database if not provided. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. \"\"\" # TODO: create node and color when not in database? newline : str = '<br align=\"center\"/>' def __init__ ( self , database : Optional [ Union [ Database , Dict [ str , RecordInstance ]]] = None , limit_to_records : Optional [ List [ str ]] = None , relations : Optional [ PVRelations ] = None , script_relations : Optional [ ScriptPVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ): super () . __init__ () self . database = Database ( record_types = dict ( record_types or {})) self . limit_to_records = limit_to_records or [] self . relations = relations self . script_relations = script_relations if database is not None : self . add_database ( database ) def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) # if not self.script_relations: self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types , ) self . script_relations = build_script_relations ( database = self . database . records , by_record = self . relations , limit_to_records = self . limit_to_records , ) for script_a , script_a_relations in self . script_relations . items (): self . get_node ( script_a , text = script_a ) for script_b in script_a_relations : if script_b in self . nodes : continue self . get_node ( script_b , text = script_b ) inter_lines = ( [ f \"<b> { script_a } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_a ][ script_b ])) + [ \"\" ] + [ f \"<b> { script_b } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_b ][ script_a ])) ) inter_node = f \" { script_a } <-> { script_b } \" self . get_node ( inter_node , text = \" \\n \" . join ( inter_lines )) self . add_edge ( script_a , inter_node ) self . add_edge ( inter_node , script_b ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . limit_to_records or []: if rec_name in self . database . records : self . get_node ( rec_name ) def _ready_for_digraph ( self , graph : gv . Digraph ): \"\"\"Hook when the user calls ``to_digraph``.\"\"\" for node in self . nodes . values (): node . highlighted = node . label in self . limit_to_records Methods whatrecord . graph . ScriptLinkGraph . add_database ( self , database : Union [ Dict [ str , whatrecord . common . RecordInstance ], whatrecord . db . Database ]) Add records from the given database to the graph. Source code in whatrecord/graph.py def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) # if not self.script_relations: self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types , ) self . script_relations = build_script_relations ( database = self . database . records , by_record = self . relations , limit_to_records = self . limit_to_records , ) for script_a , script_a_relations in self . script_relations . items (): self . get_node ( script_a , text = script_a ) for script_b in script_a_relations : if script_b in self . nodes : continue self . get_node ( script_b , text = script_b ) inter_lines = ( [ f \"<b> { script_a } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_a ][ script_b ])) + [ \"\" ] + [ f \"<b> { script_b } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_b ][ script_a ])) ) inter_node = f \" { script_a } <-> { script_b } \" self . get_node ( inter_node , text = \" \\n \" . join ( inter_lines )) self . add_edge ( script_a , inter_node ) self . add_edge ( inter_node , script_b ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . limit_to_records or []: if rec_name in self . database . records : self . get_node ( rec_name ) Functions whatrecord . graph . build_database_relations ( database : Dict [ str , whatrecord . common . RecordInstance ], record_types : Optional [ Dict [ str , whatrecord . common . RecordType ]] = None , aliases : Optional [ Dict [ str , str ]] = None ) -> Dict [ str , Dict [ str , List [ Tuple [ whatrecord . common . RecordField , whatrecord . common . RecordField , List [ str ]]]]] Build a dictionary of PV relationships. This should not be called often for large databases, as it makes no attempt to be computationally efficient. For repeated usage, cache the result of this function and reuse it in future calls to graph_links and such. Parameters: Name Type Description Default database Dict[str, whatrecord.common.RecordInstance] Dictionary of record name to record instance. required record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. None Returns: Type Description Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]] Such that: info[pv1][pv2] = (field1, field2, info) And in reverse: info[pv2][pv1] = (field2, field1, info) Source code in whatrecord/graph.py def build_database_relations ( database : Dict [ str , RecordInstance ], record_types : Optional [ Dict [ str , RecordType ]] = None , aliases : Optional [ Dict [ str , str ]] = None , ) -> PVRelations : \"\"\" Build a dictionary of PV relationships. This should not be called often for large databases, as it makes no attempt to be computationally efficient. For repeated usage, cache the result of this function and reuse it in future calls to ``graph_links`` and such. Parameters ---------- database : dict Dictionary of record name to record instance. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Returns ------- info : dict Such that: ``info[pv1][pv2] = (field1, field2, info)`` And in reverse: ``info[pv2][pv1] = (field2, field1, info)`` \"\"\" aliases = aliases or {} warned = set () unset_ctx : FullLoadContext = ( LoadContext ( \"unknown\" , 0 ), ) by_record = collections . defaultdict ( lambda : collections . defaultdict ( list )) # TODO: alias handling? for rec1 in database . values (): if record_types : # Use links as defined in the database definition rec1_links = rec1 . get_links () else : # Fall back to static list of link fields rec1_links = rec1 . get_common_links () for field1 , link , info in rec1_links : # TODO: copied without thinking about implications # due to the removal of st.cmd context as an attempt to reduce field1 = copy . deepcopy ( field1 ) # field1.context = rec1.context[:1] + field1.context if \".\" in link : link , field2 = link . split ( \".\" , 1 ) elif field1 . name == \"FLNK\" : field2 = \"PROC\" else : field2 = \"VAL\" rec2 = database . get ( aliases . get ( link , link ), None ) if rec2 is None : # TODO: switch to debug; this will be expensive later if not is_supported_link ( link ): continue if link not in warned : warned . add ( link ) logger . debug ( \"Linked record from %s . %s not in database: %s \" , rec1 . name , field1 . name , link ) field2 = RecordField ( dtype = \"unknown\" , name = field2 , value = \"(unknown-record)\" , context = unset_ctx , ) rec2_name = link elif field2 in rec2 . fields : rec2_name = rec2 . name # TODO: copied without thinking about implications field2 = copy . deepcopy ( rec2 . fields [ field2 ]) # field2.context = rec2.context[:1] + field2.context elif record_types : rec2_name = rec2 . name dbd_record_type = record_types . get ( rec2 . record_type , None ) if dbd_record_type is None : field2 = RecordField ( dtype = \"invalid\" , name = field2 , value = \"(invalid-record-type)\" , context = unset_ctx , ) elif field2 not in dbd_record_type . fields : field2 = RecordField ( dtype = \"invalid\" , name = field2 , value = \"(invalid-field)\" , context = unset_ctx , ) else : dbd_record_field = dbd_record_type . fields [ field2 ] field2 = RecordField ( dtype = dbd_record_field . type , name = field2 , value = \"\" , context = dbd_record_field . context , ) else : rec2_name = rec2 . name field2 = RecordField ( dtype = \"unknown\" , name = field2 , value = \"\" , # unset or invalid, can't tell yet context = unset_ctx , ) by_record [ rec1 . name ][ rec2_name ] . append (( field1 , field2 , info )) by_record [ rec2_name ][ rec1 . name ] . append (( field2 , field1 , info )) return dict ( ( key , dict ( inner_dict )) for key , inner_dict in by_record . items () ) whatrecord . graph . combine_relations ( dest_relations : Dict [ str , Dict [ str , List [ Tuple [ whatrecord . common . RecordField , whatrecord . common . RecordField , List [ str ]]]]], dest_db : Dict [ str , whatrecord . common . RecordInstance ], source_relations : Dict [ str , Dict [ str , List [ Tuple [ whatrecord . common . RecordField , whatrecord . common . RecordField , List [ str ]]]]], source_db : Dict [ str , whatrecord . common . RecordInstance ], record_types : Optional [ Dict [ str , whatrecord . common . RecordType ]] = None , aliases : Optional [ Dict [ str , str ]] = None ) Combine multiple script relations into one. Source code in whatrecord/graph.py def combine_relations ( dest_relations : PVRelations , dest_db : Dict [ str , RecordInstance ], source_relations : PVRelations , source_db : Dict [ str , RecordInstance ], record_types : Optional [ Dict [ str , RecordType ]] = None , aliases : Optional [ Dict [ str , str ]] = None , ): \"\"\"Combine multiple script relations into one.\"\"\" aliases = aliases or {} def get_relation_by_field () -> Tuple [ str , str , Dict [ Tuple [ str , str ], Tuple [ str , str , List [ str ]]] ]: for rec1_name , rec2_names in source_relations . items (): dest_rec1_dict = dest_relations . setdefault ( rec1_name , {}) for rec2_name in rec2_names : dest_rec2 = dest_rec1_dict . setdefault ( rec2_name , []) relation_by_field = { ( field1 . name , field2 . name ): ( field1 , field2 , link ) for field1 , field2 , link in dest_rec2 } yield rec1_name , rec2_name , relation_by_field # Part 1: # Rebuild with new aliases, if available # Either set of relations could have referred to aliased names, actual # names, or even *both*. def alias_to_actual ( d ): # This is kinda expensive, imperfect, and confusing; consider reworking for alias_from , alias_to in aliases . items (): # A -> B inner_dict = d . pop ( alias_from , None ) if not inner_dict : continue # Fix up B <- A first, since it's symmetric for inner_name , inner_items in inner_dict . items (): # d[inner_name][alias_to] += d[inner_name][alias_from] d [ inner_name ] . setdefault ( alias_to , []) . extend ( d [ inner_name ] . pop ( alias_from ) ) if alias_to not in d : d [ alias_to ] = inner_dict else : # The actual record name is already in the relation dict for inner_name , inner_items in inner_dict . items (): # d[alias_to][inner_name] += inner_items d [ alias_to ] . setdefault ( inner_name , []) . extend ( inner_items ) alias_to_actual ( dest_relations ) alias_to_actual ( source_relations ) # Part 1: # Merge in new or updated relations from the second set for rec1_name , rec2_name , relation_by_field in get_relation_by_field (): for field1 , field2 , link in source_relations [ rec1_name ][ rec2_name ]: key = ( field1 . name , field2 . name ) existing_link = relation_by_field . get ( key , None ) if not existing_link : relation_by_field [ key ] = ( field1 , field2 , link ) else : existing_field1 , existing_field2 , _ = existing_link existing_field1 . update_unknowns ( field1 ) existing_field2 . update_unknowns ( field2 ) dest_relations [ rec1_name ][ rec2_name ] = list ( relation_by_field . values ()) def get_record ( name ) -> RecordInstance : \"\"\"Get record from either database.\"\"\" name = aliases . get ( name , name ) try : return dest_db . get ( name , None ) or source_db [ name ] except KeyError : raise def get_field_info ( record , field ): \"\"\"Get record definition if available.\"\"\" if field in record . fields : return record . fields [ field ] if record_types : field_def = record_types [ field ] return RecordField ( dtype = field_def . type , name = field , value = \"\" , context = field_def . context , ) raise KeyError ( \"Field not in database or database definition\" ) # Part 2: # Update any existing relations in the destination relations with # information from the source database for rec1_name , rec1 in source_db . items (): if rec1_name in dest_relations : for rec2_name , rec2_items in dest_relations [ rec1_name ] . items (): # We know rec1 is in the source database, but we don't know # where rec2 might be, so use `get_record`. try : rec2 = get_record ( rec2_name ) except KeyError : # It's not in this IOC... continue def get_items_to_update (): for field1 , field2 , _ in rec2_items : yield ( rec1 , field1 ) yield ( rec2 , field2 ) for field1 , field2 , _ in dest_relations [ rec2_name ][ rec1_name ]: yield ( rec2 , field1 ) yield ( rec1 , field2 ) for rec , field in get_items_to_update (): try : field_info = get_field_info ( rec , field . name ) except KeyError : logger . debug ( \"Missing field? %s . %s \" , rec . name , field . name ) else : field . update_unknowns ( field_info ) whatrecord . graph . find_record_links ( database : Dict [ str , whatrecord . common . RecordInstance ], starting_records : List [ str ], relations : Optional [ Dict [ str , Dict [ str , List [ Tuple [ whatrecord . common . RecordField , whatrecord . common . RecordField , List [ str ]]]]]] = None ) -> Generator [ whatrecord . graph . LinkInfo , NoneType , NoneType ] Get all related record links from a set of starting records. All starting records will be included, along with any other records that are linked to from there. Parameters: Name Type Description Default database Dict[str, whatrecord.common.RecordInstance] Dictionary of record name to record instance. required starting_records List[str] Record names required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None Returns: Type Description Generator[whatrecord.graph.LinkInfo, NoneType, NoneType] Link info Source code in whatrecord/graph.py def find_record_links ( database : Dict [ str , RecordInstance ], starting_records : List [ str ], relations : Optional [ PVRelations ] = None ) -> Generator [ LinkInfo , None , None ]: \"\"\" Get all related record links from a set of starting records. All starting records will be included, along with any other records that are linked to from there. Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. Yields ------ link_info : LinkInfo Link info \"\"\" checked = [] if relations is None : relations = build_database_relations ( database ) records_to_check = list ( starting_records ) while records_to_check : rec1 = database . get ( records_to_check . pop (), None ) if rec1 is None : continue checked . append ( rec1 . name ) logger . debug ( \"--- record %s ---\" , rec1 . name ) for rec2_name , fields in relations . get ( rec1 . name , {}) . items (): if rec2_name in checked : continue rec2 = database . get ( rec2_name , None ) if rec2 is None : continue for field1 , field2 , info in fields : if rec2_name not in checked and rec2_name not in records_to_check : records_to_check . append ( rec2_name ) li = LinkInfo ( record1 = rec1 , field1 = field1 , record2 = rec2 , field2 = field2 , info = info , ) logger . debug ( \"Link %s \" , li ) yield li whatrecord . graph . graph_links ( database : Union [ whatrecord . db . Database , Dict [ str , whatrecord . common . RecordInstance ]], starting_records : List [ str ], header_format : Optional [ str ] = None , field_format : Optional [ str ] = None , text_format : Optional [ str ] = None , sort_fields : bool = True , show_empty : bool = False , relations : Optional [ Dict [ str , Dict [ str , List [ Tuple [ whatrecord . common . RecordField , whatrecord . common . RecordField , List [ str ]]]]]] = None , record_types : Optional [ Dict [ str , whatrecord . common . RecordType ]] = None ) -> RecordLinkGraph Create a graphviz digraph of record links. All starting records will be included, along with any other records that are linked to from there - if available in the database. Parameters: Name Type Description Default database Union[whatrecord.db.Database, Dict[str, whatrecord.common.RecordInstance]] Dictionary of record name to record instance. required starting_records List[str] Record names required graph graphviz.Graph Graph instance to use. New one created if not specified. required engine str Graphviz engine (dot, fdp, etc) required field_format Optional[str] Format string for fields (keys: field, value, attr) None sort_fields bool Sort list of fields True text_format Optional[str] Text format for full node (keys: header, field_lines) None show_empty bool Show empty fields False font_name str Font name to use for all nodes and edges required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. None Source code in whatrecord/graph.py def graph_links ( database : Union [ Database , Dict [ str , RecordInstance ]], starting_records : List [ str ], header_format : Optional [ str ] = None , field_format : Optional [ str ] = None , text_format : Optional [ str ] = None , sort_fields : bool = True , show_empty : bool = False , relations : Optional [ PVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ) -> RecordLinkGraph : \"\"\" Create a graphviz digraph of record links. All starting records will be included, along with any other records that are linked to from there - if available in the database. Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names graph : graphviz.Graph, optional Graph instance to use. New one created if not specified. engine : str, optional Graphviz engine (dot, fdp, etc) field_format : str, optional Format string for fields (keys: field, value, attr) sort_fields : bool, optional Sort list of fields text_format : str, optional Text format for full node (keys: header, field_lines) show_empty : bool, optional Show empty fields font_name : str, optional Font name to use for all nodes and edges relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. Returns ------- graph : RecordLinkGraph \"\"\" return RecordLinkGraph ( database = database , starting_records = starting_records , header_format = header_format , field_format = field_format , text_format = text_format , sort_fields = sort_fields , show_empty = show_empty , relations = relations , record_types = record_types , ) whatrecord . graph . graph_script_relations ( database : Dict [ str , whatrecord . common . RecordInstance ], limit_to_records : Optional [ List [ str ]] = None , relations : Optional [ Dict [ str , Dict [ str , List [ Tuple [ whatrecord . common . RecordField , whatrecord . common . RecordField , List [ str ]]]]]] = None , script_relations : Optional [ Dict [ str , Dict [ str , List [ str ]]]] = None , record_types : Optional [ Dict [ str , whatrecord . common . RecordType ]] = None ) -> ScriptLinkGraph Create a graphviz digraph of script links (i.e., inter-IOC record links). Parameters: Name Type Description Default database Dict[str, whatrecord.common.RecordInstance] Dictionary of record name to record instance. required starting_records list of str Record names required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None script_relations Optional[Dict[str, Dict[str, List[str]]]] Pre-built script relationship dictionary. Generated from database if not provided. None record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. None Source code in whatrecord/graph.py def graph_script_relations ( database : Dict [ str , RecordInstance ], limit_to_records : Optional [ List [ str ]] = None , relations : Optional [ PVRelations ] = None , script_relations : Optional [ ScriptPVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ) -> ScriptLinkGraph : \"\"\" Create a graphviz digraph of script links (i.e., inter-IOC record links). Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. script_relations : dict, optional Pre-built script relationship dictionary. Generated from database if not provided. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. Returns ------- graph : ScriptLinkGraph \"\"\" return ScriptLinkGraph ( database = database , limit_to_records = limit_to_records , relations = relations , script_relations = script_relations , record_types = record_types , ) Shared whatrecord.common Classes whatrecord.common.AsynPortBase Base class for general asyn ports. Used in :mod: whatrecord.asyn , but made available here such that apischema can find it more readily. Source code in whatrecord/common.py class AsynPortBase : \"\"\" Base class for general asyn ports. Used in :mod:`whatrecord.asyn`, but made available here such that apischema can find it more readily. \"\"\" _union : Any = None def __init_subclass__ ( cls , ** kwargs ): # Registers new subclasses automatically in the union cls._union. # Deserializers stack directly as a Union apischema . deserializer ( apischema . conversions . Conversion ( apischema . identity , source = cls , target = AsynPortBase ) ) # Only AsynPortBase serializer must be registered (and updated for each # subclass) as a Union, and not be inherited AsynPortBase . _union = ( cls if AsynPortBase . _union is None else Union [ AsynPortBase . _union , cls ] ) apischema . serializer ( apischema . conversions . Conversion ( apischema . identity , source = AsynPortBase , target = AsynPortBase . _union , inherited = False , ) ) Methods whatrecord . common . AsynPortBase . __init_subclass__ ( ** kwargs ) classmethod special This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. Source code in whatrecord/common.py def __init_subclass__ ( cls , ** kwargs ): # Registers new subclasses automatically in the union cls._union. # Deserializers stack directly as a Union apischema . deserializer ( apischema . conversions . Conversion ( apischema . identity , source = cls , target = AsynPortBase ) ) # Only AsynPortBase serializer must be registered (and updated for each # subclass) as a Union, and not be inherited AsynPortBase . _union = ( cls if AsynPortBase . _union is None else Union [ AsynPortBase . _union , cls ] ) apischema . serializer ( apischema . conversions . Conversion ( apischema . identity , source = AsynPortBase , target = AsynPortBase . _union , inherited = False , ) ) whatrecord.common.DatabaseDevice dataclass DatabaseDevice(record_type: 'str', link_type: 'str', dset_name: 'str', choice_string: 'str') Source code in whatrecord/common.py @dataclass class DatabaseDevice : record_type : str link_type : str dset_name : str choice_string : str whatrecord.common.DatabaseMenu dataclass DatabaseMenu(context: 'FullLoadContext', name: 'str', choices: 'Dict[str, str]') Source code in whatrecord/common.py @dataclass class DatabaseMenu : context : FullLoadContext name : str choices : Dict [ str , str ] whatrecord.common.FileFormat ( str , Enum ) An enumeration. Source code in whatrecord/common.py class FileFormat ( str , enum . Enum ): iocsh = 'iocsh' database = 'database' database_definition = 'database_definition' substitution = 'substitution' gateway_pvlist = 'gateway_pvlist' access_security = 'access_security' stream_protocol = 'stream_protocol' state_notation = 'state_notation' makefile = 'makefile' @classmethod def from_extension ( cls , extension : str ) -> FileFormat : \"\"\"Get a file format based on a file extension.\"\"\" return { \"cmd\" : FileFormat . iocsh , \"db\" : FileFormat . database , \"dbd\" : FileFormat . database_definition , \"template\" : FileFormat . database , \"substitutions\" : FileFormat . substitution , \"pvlist\" : FileFormat . gateway_pvlist , \"acf\" : FileFormat . access_security , \"proto\" : FileFormat . stream_protocol , \"st\" : FileFormat . state_notation , }[ extension . lower ()] @classmethod def from_filename ( cls , filename : AnyPath ) -> FileFormat : \"\"\"Get a file format based on a full filename.\"\"\" path = pathlib . Path ( filename ) extension = path . suffix . lstrip ( \".\" ) if not extension and path . name . startswith ( \"Makefile\" ): return FileFormat . makefile try : return FileFormat . from_extension ( extension ) except KeyError : raise ValueError ( f \"Could not determine file type from extension: { extension } \" ) from None whatrecord.common.GdbBinaryInfo dataclass GdbBinaryInfo(commands: 'Dict[str, IocshCommand]', base_version: 'Optional[str]', variables: 'Dict[str, IocshVariable]', error: 'Optional[str]') Source code in whatrecord/common.py @dataclass class GdbBinaryInfo : commands : Dict [ str , IocshCommand ] base_version : Optional [ str ] variables : Dict [ str , IocshVariable ] error : Optional [ str ] whatrecord.common.IocMetadata dataclass IocMetadata(name: 'str' = 'unset', script: 'pathlib.Path' = , startup_directory: 'pathlib.Path' = , host: 'Optional[str]' = None, port: 'Optional[int]' = None, binary: 'Optional[str]' = None, base_version: 'str' = '3.15', metadata: 'Dict[str, Any]' = , macros: 'Dict[str, str]' = , standin_directories: 'Dict[str, str]' = , commands: 'Dict[str, IocshCommand]' = , variables: 'Dict[str, IocshVariable]' = , loaded_files: 'Dict[str, str]' = , load_success: 'bool' = True) Source code in whatrecord/common.py @dataclass class IocMetadata : name : str = \"unset\" script : pathlib . Path = field ( default_factory = pathlib . Path ) startup_directory : pathlib . Path = field ( default_factory = pathlib . Path ) host : Optional [ str ] = None port : Optional [ int ] = None binary : Optional [ str ] = None base_version : str = settings . DEFAULT_BASE_VERSION metadata : Dict [ str , Any ] = field ( default_factory = dict ) macros : Dict [ str , str ] = field ( default_factory = dict ) standin_directories : Dict [ str , str ] = field ( default_factory = dict ) commands : Dict [ str , IocshCommand ] = field ( default_factory = dict ) variables : Dict [ str , IocshVariable ] = field ( default_factory = dict ) loaded_files : Dict [ str , str ] = field ( default_factory = dict ) load_success : bool = True def update ( self , other : IocMetadata , merge : bool = False ): \"\"\" Update the metadata with a new set from an IOC Loader. Parameters ---------- other : IocMetadata The other IOC metadata to update this instance with. merge : bool, optional Merge in dictionary information, or overwrite it. Defaults to 'overwrite' (merge=False). \"\"\" self . name = other . name self . script = other . script self . startup_directory = other . startup_directory self . host = other . host or self . host self . port = other . port or self . port self . binary = other . binary or self . binary self . base_version = ( other . base_version if other . base_version != settings . DEFAULT_BASE_VERSION else self . base_version ) if merge : self . metadata . update ( other . metadata ) self . macros . update ( other . macros ) self . standin_directories . update ( other . standin_directories ) self . commands . update ( other . commands ) self . variables . update ( other . variables ) else : self . metadata = dict ( other . metadata ) self . macros = dict ( other . macros ) self . standin_directories = dict ( other . standin_directories ) self . commands = dict ( other . commands ) self . variables = dict ( other . variables ) @property def looks_like_sh ( self ) -> bool : \"\"\"Is the script likely sh/bash/etc?\"\"\" return self . binary and ( \"bin/sh\" in self . binary or \"bin/bash\" in self . binary or \"env bash\" in self . binary or \"bin/tcsh\" in self . binary or \"/python\" in self . binary ) @property def _cache_key ( self ) -> str : \"\"\"Cache key for storing this IOC information in a file.\"\"\" key = \"\" . join ( str ( v ) for v in ( self . name , str ( self . script . resolve ()), str ( self . startup_directory . resolve ()), str ( self . host ), str ( self . port ), ) ) hash = util . get_bytes_sha256 ( bytes ( key , \"utf-8\" )) return f \" { self . name } . { hash } \" @property def cache_filename ( self ) -> pathlib . Path : metadata_fn = f \" { self . _cache_key } .IocMetadata.json\" return pathlib . Path ( settings . CACHE_PATH ) / metadata_fn @property def ioc_cache_filename ( self ) -> pathlib . Path : metadata_fn = f \" { self . _cache_key } .LoadedIoc.json\" return pathlib . Path ( settings . CACHE_PATH ) / metadata_fn def from_cache ( self ) -> Optional [ IocMetadata ]: if not settings . CACHE_PATH : return try : with open ( self . cache_filename , \"rb\" ) as fp : return apischema . deserialize ( type ( self ), json . load ( fp )) except FileNotFoundError : ... except json . decoder . JSONDecodeError : # Truncated output file, perhaps ... def save_to_cache ( self ) -> bool : if not settings . CACHE_PATH : return False with open ( self . cache_filename , \"wt\" ) as fp : json . dump ( apischema . serialize ( self ), fp = fp ) return True def is_up_to_date ( self ) -> bool : \"\"\"Is this IOC up-to-date with what is on disk?\"\"\" if not self . loaded_files : return False return util . check_files_up_to_date ( self . loaded_files ) def add_loaded_file ( self , filename : Union [ pathlib . Path , str ], update : bool = False , ) -> bool : \"\"\" Add filename to the loaded file dictionary, optionally updating an existing hash. \"\"\" filename = pathlib . Path ( self . startup_directory ) / filename if str ( filename ) not in self . loaded_files or update : self . loaded_files [ str ( filename )] = util . get_file_sha256 ( filename ) return True return False async def get_binary_information ( self ) -> Optional [ GdbBinaryInfo ]: if not self . binary or not pathlib . Path ( self . binary ) . exists (): return try : info = await util . run_gdb ( \"gdb_binary_info\" , self . binary , cls = GdbBinaryInfo , ) except apischema . ValidationError : logger . error ( \"Failed to get gdb information for %s ( %s )\" , self . name , self . binary , exc_info = True , ) return if info . error : logger . error ( \"Failed to get gdb information for %s ( %s ): %s \" , self . name , self . binary , info . error ) return self . base_version = info . base_version or self . base_version self . commands . update ( info . commands ) self . variables . update ( info . variables ) for command in self . commands . values (): for context in command . context or []: try : self . add_loaded_file ( context . name ) except FileNotFoundError : logger . debug ( \"GDB source file does not exist for command %s ( %s )\" , command . name , context ) return info @property def database_version_spec ( self ) -> int : \"\"\"Load databases with this specification.\"\"\" # TODO: better version parsing try : base_major_minor = tuple ( int ( v ) for v in self . base_version . split ( \".\" )[: 2 ] ) return 3 if base_major_minor < ( 3 , 16 ) else 4 except Exception : return 3 @classmethod def empty ( cls ): return cls ( name = \"unset\" , script = pathlib . Path (), startup_directory = pathlib . Path ()) @classmethod def from_file ( cls , filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = settings . DEFAULT_BASE_VERSION , ** metadata ): \"\"\"Given at minimum a filename, guess the rest.\"\"\" filename = pathlib . Path ( filename ) . expanduser () . resolve () name = name or filename . parts [ - 2 ] # iocBoot/((ioc-something))/st.cmd if \"/\" in name : name = name . replace ( \"/\" , \"\" ) if not name : # Sorry, we need something unique here (better ideas welcome) name = util . get_bytes_sha256 ( bytes ( str ( filename ), \"utf-8\" ))[: 10 ] return cls ( name = name , host = host , port = port , script = filename , startup_directory = startup_directory or filename . parent , metadata = metadata , macros = macros or {}, standin_directories = standin_directories or {}, binary = binary or util . find_binary_from_hashbang ( filename ), base_version = base_version , ) #: Back-compat: from_filename is deprecated from_filename = from_file @classmethod def from_dict ( cls , iocdict : IocInfoDict , macros : Optional [ Dict [ str , str ]] = None ): \"\"\" Pick apart a given dictionary, relegating extra info to ``.metadata``. Parameters ---------- iocdict : dict IOC information dictionary. \"\"\" ioc = dict ( iocdict ) name = ioc . pop ( \"name\" ) host = ioc . pop ( \"host\" , None ) port = ioc . pop ( \"port\" , None ) script = ioc . pop ( \"script\" ) script = pathlib . Path ( str ( script )) . expanduser () . resolve () binary = ioc . pop ( \"binary\" , None ) base_version = ioc . pop ( \"base_version\" , None ) return cls ( name = name , script = script , startup_directory = script . parent , host = host , port = port , metadata = ioc , macros = macros or {}, binary = binary or util . find_binary_from_hashbang ( script ), base_version = base_version or settings . DEFAULT_BASE_VERSION , ) Attributes whatrecord . common . IocMetadata . database_version_spec : int property readonly Load databases with this specification. whatrecord . common . IocMetadata . looks_like_sh : bool property readonly Is the script likely sh/bash/etc? Methods whatrecord . common . IocMetadata . add_loaded_file ( self , filename : Union [ pathlib . Path , str ], update : bool = False ) -> bool Add filename to the loaded file dictionary, optionally updating an existing hash. Source code in whatrecord/common.py def add_loaded_file ( self , filename : Union [ pathlib . Path , str ], update : bool = False , ) -> bool : \"\"\" Add filename to the loaded file dictionary, optionally updating an existing hash. \"\"\" filename = pathlib . Path ( self . startup_directory ) / filename if str ( filename ) not in self . loaded_files or update : self . loaded_files [ str ( filename )] = util . get_file_sha256 ( filename ) return True return False whatrecord . common . IocMetadata . from_dict ( iocdict : IocInfoDict , macros : Optional [ Dict [ str , str ]] = None ) classmethod Pick apart a given dictionary, relegating extra info to .metadata . Parameters: Name Type Description Default iocdict IocInfoDict IOC information dictionary. required Source code in whatrecord/common.py @classmethod def from_dict ( cls , iocdict : IocInfoDict , macros : Optional [ Dict [ str , str ]] = None ): \"\"\" Pick apart a given dictionary, relegating extra info to ``.metadata``. Parameters ---------- iocdict : dict IOC information dictionary. \"\"\" ioc = dict ( iocdict ) name = ioc . pop ( \"name\" ) host = ioc . pop ( \"host\" , None ) port = ioc . pop ( \"port\" , None ) script = ioc . pop ( \"script\" ) script = pathlib . Path ( str ( script )) . expanduser () . resolve () binary = ioc . pop ( \"binary\" , None ) base_version = ioc . pop ( \"base_version\" , None ) return cls ( name = name , script = script , startup_directory = script . parent , host = host , port = port , metadata = ioc , macros = macros or {}, binary = binary or util . find_binary_from_hashbang ( script ), base_version = base_version or settings . DEFAULT_BASE_VERSION , ) whatrecord . common . IocMetadata . from_file ( filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = '3.15' , ** metadata ) classmethod Given at minimum a filename, guess the rest. Source code in whatrecord/common.py @classmethod def from_file ( cls , filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = settings . DEFAULT_BASE_VERSION , ** metadata ): \"\"\"Given at minimum a filename, guess the rest.\"\"\" filename = pathlib . Path ( filename ) . expanduser () . resolve () name = name or filename . parts [ - 2 ] # iocBoot/((ioc-something))/st.cmd if \"/\" in name : name = name . replace ( \"/\" , \"\" ) if not name : # Sorry, we need something unique here (better ideas welcome) name = util . get_bytes_sha256 ( bytes ( str ( filename ), \"utf-8\" ))[: 10 ] return cls ( name = name , host = host , port = port , script = filename , startup_directory = startup_directory or filename . parent , metadata = metadata , macros = macros or {}, standin_directories = standin_directories or {}, binary = binary or util . find_binary_from_hashbang ( filename ), base_version = base_version , ) whatrecord . common . IocMetadata . from_filename ( filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = '3.15' , ** metadata ) classmethod Given at minimum a filename, guess the rest. Source code in whatrecord/common.py @classmethod def from_file ( cls , filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = settings . DEFAULT_BASE_VERSION , ** metadata ): \"\"\"Given at minimum a filename, guess the rest.\"\"\" filename = pathlib . Path ( filename ) . expanduser () . resolve () name = name or filename . parts [ - 2 ] # iocBoot/((ioc-something))/st.cmd if \"/\" in name : name = name . replace ( \"/\" , \"\" ) if not name : # Sorry, we need something unique here (better ideas welcome) name = util . get_bytes_sha256 ( bytes ( str ( filename ), \"utf-8\" ))[: 10 ] return cls ( name = name , host = host , port = port , script = filename , startup_directory = startup_directory or filename . parent , metadata = metadata , macros = macros or {}, standin_directories = standin_directories or {}, binary = binary or util . find_binary_from_hashbang ( filename ), base_version = base_version , ) whatrecord . common . IocMetadata . is_up_to_date ( self ) -> bool Is this IOC up-to-date with what is on disk? Source code in whatrecord/common.py def is_up_to_date ( self ) -> bool : \"\"\"Is this IOC up-to-date with what is on disk?\"\"\" if not self . loaded_files : return False return util . check_files_up_to_date ( self . loaded_files ) whatrecord . common . IocMetadata . update ( self , other : IocMetadata , merge : bool = False ) Update the metadata with a new set from an IOC Loader. Parameters: Name Type Description Default other IocMetadata The other IOC metadata to update this instance with. required merge bool Merge in dictionary information, or overwrite it. Defaults to 'overwrite' (merge=False). False Source code in whatrecord/common.py def update ( self , other : IocMetadata , merge : bool = False ): \"\"\" Update the metadata with a new set from an IOC Loader. Parameters ---------- other : IocMetadata The other IOC metadata to update this instance with. merge : bool, optional Merge in dictionary information, or overwrite it. Defaults to 'overwrite' (merge=False). \"\"\" self . name = other . name self . script = other . script self . startup_directory = other . startup_directory self . host = other . host or self . host self . port = other . port or self . port self . binary = other . binary or self . binary self . base_version = ( other . base_version if other . base_version != settings . DEFAULT_BASE_VERSION else self . base_version ) if merge : self . metadata . update ( other . metadata ) self . macros . update ( other . macros ) self . standin_directories . update ( other . standin_directories ) self . commands . update ( other . commands ) self . variables . update ( other . variables ) else : self . metadata = dict ( other . metadata ) self . macros = dict ( other . macros ) self . standin_directories = dict ( other . standin_directories ) self . commands = dict ( other . commands ) self . variables = dict ( other . variables ) whatrecord.common.IocshArgument dataclass IocshArgument(name: 'str', type: 'str') Source code in whatrecord/common.py @dataclass class IocshArgument : name : str type : str whatrecord.common.IocshCmdArgs dataclass iocshCmd(...) arguments. Source code in whatrecord/common.py @dataclass class IocshCmdArgs : \"\"\"iocshCmd(...) arguments.\"\"\" context : FullLoadContext command : str whatrecord.common.IocshCommand dataclass IocshCommand(name: 'str', args: 'List[IocshArgument]' = , usage: 'Optional[str]' = None, context: 'Optional[FullLoadContext]' = None) Source code in whatrecord/common.py @dataclass class IocshCommand : name : str args : List [ IocshArgument ] = field ( default_factory = list ) usage : Optional [ str ] = None context : Optional [ FullLoadContext ] = None whatrecord.common.IocshResult dataclass IocshResult(context: 'FullLoadContext', line: 'str', outputs: 'List[str]' = , argv: 'Optional[List[str]]' = None, error: 'Optional[str]' = None, redirects: 'List[IocshRedirect]' = , result: 'Any' = None) Source code in whatrecord/common.py @apischema . fields . with_fields_set @dataclass class IocshResult : context : FullLoadContext line : str outputs : List [ str ] = field ( default_factory = list ) argv : Optional [ List [ str ]] = None error : Optional [ str ] = None redirects : List [ IocshRedirect ] = field ( default_factory = list ) # TODO: normalize this # result: Optional[Union[str, Dict[str, str], IocshCmdArgs, ShortLinterResults]] result : Any = None _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" { %- f or ctx in context -%} {{ctx.line}}: { %- e ndfor %} {{ line }} { % i f error %} ** ERROR on line { % i f context %}{{ context[0].line }}{ % e ndif %} ** {{ error | indent(4) }} { % e ndif %} { % i f outputs != [line] %} { % f or output in outputs %} -SH> {{ output | indent(6) }} { % e ndfor %} { % e ndif %} { % f or redirect in redirects %} -> Redirect: {{ redirect }} { %- e ndfor %} \"\"\" . strip (), } whatrecord.common.IocshScript dataclass IocshScript(path: 'str', lines: 'List[IocshResult]') Source code in whatrecord/common.py @dataclass class IocshScript : path : str # lines: Tuple[IocshResult, ...] lines : List [ IocshResult ] _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : textwrap . dedent ( \"\"\"\\ {%- for line in lines %} {% set line = render_object(line, \"console\") %} {{ line }} {%- endfor %} \"\"\" . rstrip (), ), \"console-verbose\" : textwrap . dedent ( \"\"\"\\ {%- for line in lines -%} {% set line = render_object(line, \"console-verbose\") %} {{ line }} {%- endfor %} \"\"\" . rstrip (), ) } @classmethod def from_metadata ( cls , md : IocMetadata , sh : ShellState ) -> IocshScript : if md . looks_like_sh : if md . base_version == settings . DEFAULT_BASE_VERSION : md . base_version = \"unknown\" return cls . from_general_file ( md . script ) return cls ( path = str ( md . script ), lines = tuple ( sh . interpret_shell_script ( md . script ) ), ) @classmethod def from_interpreted_script ( cls , filename : Union [ pathlib . Path , str ], contents : str , sh : ShellState ) -> IocshScript : return cls ( path = str ( filename ), lines = tuple ( sh . interpret_shell_script_text ( contents . splitlines (), name = str ( filename ) ) ), ) @classmethod def from_general_file ( cls , filename : Union [ pathlib . Path , str ]): # For use when shoehorning in a file that's not _really_ an IOC script # TODO: instead rework the api with open ( filename , \"rt\" ) as fp : lines = fp . read () . splitlines () return cls ( path = str ( filename ), lines = tuple ( IocshResult ( line = line , context = ( LoadContext ( str ( filename ), lineno ), ) ) for lineno , line in enumerate ( lines , 1 ) ), ) whatrecord.common.IocshVariable dataclass IocshVariable(name: 'str', value: 'Optional[str]' = None, type: 'Optional[str]' = None) Source code in whatrecord/common.py @dataclass class IocshVariable : name : str value : Optional [ str ] = None type : Optional [ str ] = None whatrecord.common.LinterError ( LinterMessage ) dataclass LinterError(name: 'str', line: 'int', message: 'str') Source code in whatrecord/common.py @dataclass class LinterError ( LinterMessage ): ... whatrecord.common.LinterMessage dataclass LinterMessage(name: 'str', line: 'int', message: 'str') Source code in whatrecord/common.py @dataclass class LinterMessage : name : str line : int message : str whatrecord.common.LinterWarning ( LinterMessage ) dataclass LinterWarning(name: 'str', line: 'int', message: 'str') Source code in whatrecord/common.py @dataclass class LinterWarning ( LinterMessage ): ... whatrecord.common.LoadContext dataclass LoadContext(name: 'str', line: 'int') Source code in whatrecord/common.py @dataclass ( frozen = True ) class LoadContext : name : str line : int def __repr__ ( self ): return f \" { self . name } : { self . line } \" @apischema . serializer @property def as_tuple ( self ) -> Sequence [ Union [ str , int ]]: return [ self . name , self . line ] whatrecord.common.MutableLoadContext dataclass MutableLoadContext(name: 'str', line: 'int') Source code in whatrecord/common.py @dataclass ( repr = False ) class MutableLoadContext : name : str line : int def __repr__ ( self ): return f \" { self . name } : { self . line } \" def to_load_context ( self ) -> LoadContext : return LoadContext ( self . name , self . line ) whatrecord.common.PVAFieldReference dataclass PVAFieldReference(context: 'FullLoadContext', name: 'str' = '', record_name: 'str' = '', field_name: 'str' = '', metadata: 'Dict[str, str]' = ) Source code in whatrecord/common.py @dataclass class PVAFieldReference : context : FullLoadContext name : str = \"\" record_name : str = \"\" field_name : str = \"\" metadata : Dict [ str , str ] = field ( default_factory = dict ) _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ PVAFieldReference: {{ record_name }}.{{ field_name }} - {{ metadata }} \"\"\" , } whatrecord.common.RecordDefinitionAndInstance dataclass A pair of V3 record definition and instance. Source code in whatrecord/common.py @dataclass class RecordDefinitionAndInstance : \"\"\"A pair of V3 record definition and instance.\"\"\" definition : Optional [ RecordType ] instance : RecordInstance _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ { % s et instance_info = render_object(instance, \"console\") %} {{ instance_info }} \"\"\" , } whatrecord.common.RecordField dataclass RecordField(dtype: 'str', name: 'str', value: 'Any', context: 'FullLoadContext') Source code in whatrecord/common.py @dataclass class RecordField : dtype : str name : str value : Any context : FullLoadContext _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\"field({{name}}, \"{{value}}\")\"\"\" , \"console-verbose\" : \"\"\" \\ field({{name}}, \"{{value}}\") # {{dtype}}{ % i f context %}; {{context[-1]}}{ % e ndif %} \\ \"\"\" , } def update_unknowns ( self , other : RecordField , * , unknown_values = None , dbd = None ): \"\"\" If this RecordField has some missing information (\"unknown\"), fill it in with information from the other field. \"\"\" unknown_values = unknown_values or { \"unknown\" , \"\" , \"(unknown-record)\" } if other . dtype not in unknown_values and self . dtype in unknown_values : self . dtype = other . dtype if other . value not in unknown_values and self . value in unknown_values : self . value = other . value if len ( other . context ) and len ( self . context ) == 1 : ctx , = self . context if ctx . name in unknown_values : # Even if the other context is unknown, let's take it anyway: self . context = other . context # if dbd is not None: Methods whatrecord . common . RecordField . update_unknowns ( self , other : RecordField , * , unknown_values = None , dbd = None ) If this RecordField has some missing information (\"unknown\"), fill it in with information from the other field. Source code in whatrecord/common.py def update_unknowns ( self , other : RecordField , * , unknown_values = None , dbd = None ): \"\"\" If this RecordField has some missing information (\"unknown\"), fill it in with information from the other field. \"\"\" unknown_values = unknown_values or { \"unknown\" , \"\" , \"(unknown-record)\" } if other . dtype not in unknown_values and self . dtype in unknown_values : self . dtype = other . dtype if other . value not in unknown_values and self . value in unknown_values : self . value = other . value if len ( other . context ) and len ( self . context ) == 1 : ctx , = self . context if ctx . name in unknown_values : # Even if the other context is unknown, let's take it anyway: self . context = other . context # if dbd is not None: whatrecord.common.RecordInstance dataclass RecordInstance(context: 'FullLoadContext', name: 'str', record_type: 'str', fields: 'Dict[str, AnyField]' = , info: 'Dict[StringWithContext, Any]' = , metadata: 'Dict[StringWithContext, Any]' = , aliases: 'List[str]' = , is_grecord: 'bool' = False, is_pva: 'bool' = False, owner: 'str' = '') Source code in whatrecord/common.py @dataclass class RecordInstance : context : FullLoadContext name : str record_type : str fields : Dict [ str , AnyField ] = field ( default_factory = dict ) info : Dict [ StringWithContext , Any ] = field ( default_factory = dict ) metadata : Dict [ StringWithContext , Any ] = field ( default_factory = dict ) aliases : List [ str ] = field ( default_factory = list ) is_grecord : bool = False is_pva : bool = False # For the convenience of downstream clients, redundantly keep track of the # associated IOC: owner : str = \"\" _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ record(\"{{record_type}}\", \"{{name}}\") { { % i f owner %} # Part of {{ owner }} { % e ndif %} { % f or ctx in context %} # {{ctx}} { % e ndfor %} { % f or name, field_inst in fields.items() | sort %} { % s et field_text = render_object(field_inst, \"console\") %} {{ field_text | indent(4) }} { % e ndfor %} } \"\"\" , } @property def access_security_group ( self ) -> str : \"\"\"The access security group name for the record.\"\"\" if \"ASG\" in self . fields and not self . is_pva : return str ( self . fields [ \"ASG\" ] . value ) return \"DEFAULT\" def get_fields_of_type ( self , * types ) -> Generator [ RecordField , None , None ]: \"\"\"Get all fields of the matching type(s).\"\"\" if self . is_pva : return for fld in self . fields . values (): if fld . dtype in types : yield fld def get_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Get all links. Yields ------ field : RecordField link_text: str link_info: str \"\"\" for fld in self . get_fields_of_type ( * LINK_TYPES ): try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info def get_common_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Without using a database definition, try to find links. This differs from ``get_links`` in that the other method requires a dbd file to be loaded, whereas this will use a simple - but possibly inaccurate - map of of record type to link fields. Yields ------ field : RecordField link_text: str link_info: str \"\"\" if self . is_pva : return for name in LINK_FIELDS_BY_RECORD . get ( self . record_type , COMMON_LINK_FIELDS ): fld = self . fields . get ( name , None ) if fld is not None : try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info def to_summary ( self ) -> RecordInstanceSummary : \"\"\"Return a summarized version of the record instance.\"\"\" return RecordInstanceSummary . from_record_instance ( self ) def update ( self , other : RecordInstance ) -> List [ LinterMessage ]: \"\"\" Update this record instance with another. TODO: This may not do exactly what an IOC would do. TODO: Return type? \"\"\" if other . is_pva != self . is_pva : return [ LinterError ( name = \"combine_pva_and_v3\" , line = 0 , message = \"Cannot combine PVA group with V3 record\" ) ] self . context = remove_redundant_context ( tuple ( self . context ) + tuple ( other . context ) ) self . info . update ( other . info ) self . metadata . update ( other . metadata ) self . fields . update ( other . fields ) self . aliases . extend ( [ alias for alias in other . aliases if alias not in self . aliases ] ) if self . record_type != other . record_type : return [ LinterError ( name = \"record_type_mismatch\" , line = 0 , message = ( f \"Record type mismatch in provided database files: \" f \" { self . name } { self . record_type } { other . record_type } \" ), ) ] return [] Attributes whatrecord . common . RecordInstance . access_security_group : str property readonly The access security group name for the record. Methods whatrecord . common . RecordInstance . get_common_links ( self ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ] Without using a database definition, try to find links. This differs from get_links in that the other method requires a dbd file to be loaded, whereas this will use a simple - but possibly inaccurate - map of of record type to link fields. Source code in whatrecord/common.py def get_common_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Without using a database definition, try to find links. This differs from ``get_links`` in that the other method requires a dbd file to be loaded, whereas this will use a simple - but possibly inaccurate - map of of record type to link fields. Yields ------ field : RecordField link_text: str link_info: str \"\"\" if self . is_pva : return for name in LINK_FIELDS_BY_RECORD . get ( self . record_type , COMMON_LINK_FIELDS ): fld = self . fields . get ( name , None ) if fld is not None : try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info whatrecord . common . RecordInstance . get_fields_of_type ( self , * types ) -> Generator [ RecordField , None , None ] Get all fields of the matching type(s). Source code in whatrecord/common.py def get_fields_of_type ( self , * types ) -> Generator [ RecordField , None , None ]: \"\"\"Get all fields of the matching type(s).\"\"\" if self . is_pva : return for fld in self . fields . values (): if fld . dtype in types : yield fld whatrecord . common . RecordInstance . get_links ( self ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ] Get all links. Source code in whatrecord/common.py def get_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Get all links. Yields ------ field : RecordField link_text: str link_info: str \"\"\" for fld in self . get_fields_of_type ( * LINK_TYPES ): try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info whatrecord . common . RecordInstance . to_summary ( self ) -> RecordInstanceSummary Return a summarized version of the record instance. Source code in whatrecord/common.py def to_summary ( self ) -> RecordInstanceSummary : \"\"\"Return a summarized version of the record instance.\"\"\" return RecordInstanceSummary . from_record_instance ( self ) whatrecord . common . RecordInstance . update ( self , other : RecordInstance ) -> List [ LinterMessage ] Update this record instance with another. TODO: This may not do exactly what an IOC would do. TODO: Return type? Source code in whatrecord/common.py def update ( self , other : RecordInstance ) -> List [ LinterMessage ]: \"\"\" Update this record instance with another. TODO: This may not do exactly what an IOC would do. TODO: Return type? \"\"\" if other . is_pva != self . is_pva : return [ LinterError ( name = \"combine_pva_and_v3\" , line = 0 , message = \"Cannot combine PVA group with V3 record\" ) ] self . context = remove_redundant_context ( tuple ( self . context ) + tuple ( other . context ) ) self . info . update ( other . info ) self . metadata . update ( other . metadata ) self . fields . update ( other . fields ) self . aliases . extend ( [ alias for alias in other . aliases if alias not in self . aliases ] ) if self . record_type != other . record_type : return [ LinterError ( name = \"record_type_mismatch\" , line = 0 , message = ( f \"Record type mismatch in provided database files: \" f \" { self . name } { self . record_type } { other . record_type } \" ), ) ] return [] whatrecord.common.RecordInstanceSummary dataclass An abbreviated form of :class: RecordInstance . Source code in whatrecord/common.py @dataclass class RecordInstanceSummary : \"\"\"An abbreviated form of :class:`RecordInstance`.\"\"\" context : FullLoadContext name : str record_type : str # fields: Dict[str, RecordField] info : Dict [ StringWithContext , Any ] = field ( default_factory = dict ) # metadata: Dict[str, Any] = field(default_factory=dict) aliases : List [ str ] = field ( default_factory = list ) # is_grecord: bool = False is_pva : bool = False owner : str = \"\" @classmethod def from_record_instance ( self , instance : RecordInstance ) -> RecordInstanceSummary : return RecordInstanceSummary ( context = instance . context , name = instance . name , record_type = instance . record_type , info = instance . info , aliases = instance . aliases , is_pva = instance . is_pva , owner = instance . owner , ) whatrecord.common.RecordType dataclass RecordType(context: 'FullLoadContext', name: 'str', cdefs: 'List[str]' = , fields: 'Dict[str, RecordTypeField]' = , devices: 'Dict[str, DatabaseDevice]' = , aliases: 'List[str]' = , info: 'Dict[str, str]' = , is_grecord: 'bool' = False) Source code in whatrecord/common.py @dataclass class RecordType : context : FullLoadContext name : str cdefs : List [ str ] = field ( default_factory = list ) fields : Dict [ str , RecordTypeField ] = field ( default_factory = dict ) devices : Dict [ str , DatabaseDevice ] = field ( default_factory = dict ) aliases : List [ str ] = field ( default_factory = list ) info : Dict [ str , str ] = field ( default_factory = dict ) is_grecord : bool = False whatrecord.common.RecordTypeField dataclass RecordTypeField(context: 'FullLoadContext', name: 'str', type: 'str', asl: 'Optional[str]' = None, initial: 'Optional[str]' = None, promptgroup: 'Optional[str]' = None, prompt: 'Optional[str]' = None, special: 'Optional[str]' = None, pp: 'Optional[str]' = None, interest: 'Optional[str]' = None, base: 'Optional[str]' = None, size: 'Optional[str]' = None, extra: 'Optional[str]' = None, menu: 'Optional[str]' = None, prop: 'Optional[str]' = None, body: 'Dict[str, str]' = ) Source code in whatrecord/common.py @apischema . fields . with_fields_set @dataclass class RecordTypeField : context : FullLoadContext name : str type : str asl : Optional [ str ] = None initial : Optional [ str ] = None promptgroup : Optional [ str ] = None prompt : Optional [ str ] = None special : Optional [ str ] = None pp : Optional [ str ] = None interest : Optional [ str ] = None base : Optional [ str ] = None size : Optional [ str ] = None extra : Optional [ str ] = None menu : Optional [ str ] = None prop : Optional [ str ] = None # -> bundle the remainder in \"body\", even if unrecognized body : Dict [ str , str ] = field ( default_factory = dict ) whatrecord.common.ShellStateHandler dataclass ShellStateHandler(parent: 'Optional[ShellStateHandler]' = None, primary_handler: 'Optional[ShellState]' = None) Source code in whatrecord/common.py @dataclass class ShellStateHandler : metadata_key : ClassVar [ str ] parent : Optional [ ShellStateHandler ] = field ( default = None , metadata = apischema . metadata . skip , repr = False , hash = False , compare = False ) primary_handler : Optional [ ShellState ] = field ( default = None , metadata = apischema . metadata . skip , repr = False , hash = False , compare = False ) _handlers : Dict [ str , Callable ] = field ( default_factory = dict , metadata = apischema . metadata . skip , repr = False , hash = False , compare = False , init = False ) def __post_init__ ( self ): self . _handlers . update ( dict ( self . find_handlers ())) self . _init_sub_handlers_ () def _init_sub_handlers_ ( self ): \"\"\"Initialize sub-handlers with parent/primary_handler.\"\"\" for sub_handler in self . sub_handlers : sub_handler . parent = self sub_handler . primary_handler = getattr ( self . parent , \"primary_handler\" , self ) sub_handler . _init_sub_handlers_ () def annotate_record ( self , instance : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate the given record's metadata with state-related information.\"\"\" ... def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if self . primary_handler is None : return tuple () return self . primary_handler . get_load_context () @property def sub_handlers ( self ) -> List [ ShellStateHandler ]: \"\"\"Handlers which contain their own state.\"\"\" return [] @staticmethod def generic_handler_decorator ( func = None , stub = False ): \"\"\" Decorate a handler method to generically return parameter-to-value information. This can be in addition to or in place of GDB command information. Parameters ---------- func : callable The ``handler_`` method. stub : bool, optional Mark this as a stub method. Variable arguments will be filled in as necessary, even if defaults are not provided. \"\"\" def wrap ( func ): params = list ( inspect . signature ( func ) . parameters . items ())[ 1 :] defaults = list ( None if param . default is inspect . Parameter . empty else param . default for _ , param in params ) @functools . wraps ( func ) def wrapped ( self , * args ): result = {} if len ( args ) < len ( params ) and stub : # Pad unspecified arguments with defaults or \"None\" args = list ( args ) + defaults [ len ( args ):] if len ( args ) > len ( params ): result [ \"argument_lint\" ] = \"Too many arguments\" result [ \"arguments\" ] = [ { \"name\" : name , \"type\" : getattr ( param . annotation , \"__name__\" , param . annotation ), \"value\" : value , } for ( name , param ), value in zip ( params , args ) ] call_result = func ( self , * args [: len ( params )]) if call_result is not None : for key , value in call_result . items (): if key in result : result [ key ] . update ( value ) else : result [ key ] = value return result return wrapped if func is not None : return wrap ( func ) return wrap def find_handlers ( self ) -> Generator [ Tuple [ str , Callable ], None , None ]: \"\"\"Find all IOC shell command handlers by name.\"\"\" for handler_obj in [ self ] + self . sub_handlers : for attr in dir ( handler_obj ): if attr . startswith ( \"handle_\" ): obj = getattr ( handler_obj , attr , None ) if callable ( obj ): name = attr . split ( \"_\" , 1 )[ 1 ] yield name , obj if handler_obj is not self : yield from handler_obj . find_handlers () def pre_ioc_init ( self ): \"\"\"Pre-iocInit hook.\"\"\" ... def post_ioc_init ( self ): \"\"\"Post-iocInit hook.\"\"\" ... Attributes whatrecord . common . ShellStateHandler . sub_handlers : List [ ShellStateHandler ] property readonly Handlers which contain their own state. Methods whatrecord . common . ShellStateHandler . annotate_record ( self , instance : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate the given record's metadata with state-related information. Source code in whatrecord/common.py def annotate_record ( self , instance : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate the given record's metadata with state-related information.\"\"\" ... whatrecord . common . ShellStateHandler . find_handlers ( self ) -> Generator [ Tuple [ str , Callable ], None , None ] Find all IOC shell command handlers by name. Source code in whatrecord/common.py def find_handlers ( self ) -> Generator [ Tuple [ str , Callable ], None , None ]: \"\"\"Find all IOC shell command handlers by name.\"\"\" for handler_obj in [ self ] + self . sub_handlers : for attr in dir ( handler_obj ): if attr . startswith ( \"handle_\" ): obj = getattr ( handler_obj , attr , None ) if callable ( obj ): name = attr . split ( \"_\" , 1 )[ 1 ] yield name , obj if handler_obj is not self : yield from handler_obj . find_handlers () whatrecord . common . ShellStateHandler . generic_handler_decorator ( func = None , stub = False ) staticmethod Decorate a handler method to generically return parameter-to-value information. This can be in addition to or in place of GDB command information. Parameters: Name Type Description Default func callable The handler_ method. None stub bool Mark this as a stub method. Variable arguments will be filled in as necessary, even if defaults are not provided. False Source code in whatrecord/common.py @staticmethod def generic_handler_decorator ( func = None , stub = False ): \"\"\" Decorate a handler method to generically return parameter-to-value information. This can be in addition to or in place of GDB command information. Parameters ---------- func : callable The ``handler_`` method. stub : bool, optional Mark this as a stub method. Variable arguments will be filled in as necessary, even if defaults are not provided. \"\"\" def wrap ( func ): params = list ( inspect . signature ( func ) . parameters . items ())[ 1 :] defaults = list ( None if param . default is inspect . Parameter . empty else param . default for _ , param in params ) @functools . wraps ( func ) def wrapped ( self , * args ): result = {} if len ( args ) < len ( params ) and stub : # Pad unspecified arguments with defaults or \"None\" args = list ( args ) + defaults [ len ( args ):] if len ( args ) > len ( params ): result [ \"argument_lint\" ] = \"Too many arguments\" result [ \"arguments\" ] = [ { \"name\" : name , \"type\" : getattr ( param . annotation , \"__name__\" , param . annotation ), \"value\" : value , } for ( name , param ), value in zip ( params , args ) ] call_result = func ( self , * args [: len ( params )]) if call_result is not None : for key , value in call_result . items (): if key in result : result [ key ] . update ( value ) else : result [ key ] = value return result return wrapped if func is not None : return wrap ( func ) return wrap whatrecord . common . ShellStateHandler . get_load_context ( self ) -> FullLoadContext Get a FullLoadContext tuple representing where we are now. Source code in whatrecord/common.py def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if self . primary_handler is None : return tuple () return self . primary_handler . get_load_context () whatrecord . common . ShellStateHandler . post_ioc_init ( self ) Post-iocInit hook. Source code in whatrecord/common.py def post_ioc_init ( self ): \"\"\"Post-iocInit hook.\"\"\" ... whatrecord . common . ShellStateHandler . pre_ioc_init ( self ) Pre-iocInit hook. Source code in whatrecord/common.py def pre_ioc_init ( self ): \"\"\"Pre-iocInit hook.\"\"\" ... whatrecord.common.StringWithContext ( str ) A string with LoadContext. Source code in whatrecord/common.py class StringWithContext ( str ): \"\"\"A string with LoadContext.\"\"\" __slots__ = ( \"context\" , ) context : Optional [ FullLoadContext ] def __new__ ( cls , value , context : Optional [ FullLoadContext ] = None ): self = super () . __new__ ( cls , value ) self . context = context return self Methods whatrecord . common . StringWithContext . __new__ ( cls , value , context : Optional [ FullLoadContext ] = None ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in whatrecord/common.py def __new__ ( cls , value , context : Optional [ FullLoadContext ] = None ): self = super () . __new__ ( cls , value ) self . context = context return self whatrecord.common.WhatRecord dataclass WhatRecord - full set of information regarding a specific record. This response is on a per-IOC basis, so at most it can return one V3 record and one V4 record, as these exist in separate namespaces. Attributes: Name Type Description name str The record name. record RecordDefinitionAndInstance The V3 record definition (if available) and record instance. pva_group RecordInstance The PVAccess group, if available. ioc IocMetadata The associated IOC metadata, if available. Source code in whatrecord/common.py @dataclass class WhatRecord : \"\"\" WhatRecord - full set of information regarding a specific record. This response is on a per-IOC basis, so at most it can return one V3 record and one V4 record, as these exist in separate namespaces. Attributes ---------- name : str The record name. record : RecordDefinitionAndInstance, optional The V3 record definition (if available) and record instance. pva_group : RecordInstance, optional The PVAccess group, if available. ioc : IocMetadata, optional The associated IOC metadata, if available. \"\"\" name : str record : Optional [ RecordDefinitionAndInstance ] = None menus : Optional [ Dict [ str , DatabaseMenu ]] = None pva_group : Optional [ RecordInstance ] = None ioc : Optional [ IocMetadata ] = None _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ {{ name }}: Owner: {{ present }} { % s et ioc_info = render_object(ioc, \"console\") %} IOC: {{ ioc_info }} { % i f record %} { % s et instance_info = render_object(record, \"console\") %} {{ instance_info | indent(4)}} { % e ndif %} { % i f pva_group %} { % s et instance_info = render_object(pva_group, \"console\") %} {{ instance_info | indent(4)}} { % e ndif %} } \"\"\" , } Functions whatrecord . common . context_from_lark_token ( fn : str , token : lark . Token ) -> FullLoadContext Get a full load context from a given lark Token. Source code in whatrecord/common.py def context_from_lark_token ( fn : str , token : lark . Token ) -> FullLoadContext : \"\"\"Get a full load context from a given lark Token.\"\"\" return ( LoadContext ( name = fn , line = token . line ), ) whatrecord . common . get_link_information ( link_str : str ) -> Tuple [ str , List [ str ]] Get link information from a DBF_{IN,OUT,FWD}LINK value. Source code in whatrecord/common.py def get_link_information ( link_str : str ) -> Tuple [ str , List [ str ]]: \"\"\"Get link information from a DBF_{IN,OUT,FWD}LINK value.\"\"\" if isinstance ( link_str , dict ): # Oh, PVA... raise ValueError ( \"PVA links are TODO, sorry\" ) if \" \" in link_str : # strip off PP/MS/etc (TODO might be useful later) link_str , additional_info = link_str . split ( \" \" , 1 ) else : additional_info = \"\" if link_str . startswith ( \"@\" ): # TODO asyn/device links raise ValueError ( \"asyn link\" ) if not link_str : raise ValueError ( \"empty link\" ) if link_str . isnumeric (): # 0 or 1 usually and not a string raise ValueError ( \"integral link\" ) try : float ( link_str ) except Exception : # Good, we don't want a float ... else : raise ValueError ( \"float link\" ) link_details = additional_info . split () return link_str , link_details whatrecord . common . remove_redundant_context ( full_context : FullLoadContext ) -> FullLoadContext Remove redundant context information if it does not add anything. Source code in whatrecord/common.py def remove_redundant_context ( full_context : FullLoadContext ) -> FullLoadContext : \"\"\"Remove redundant context information if it does not add anything.\"\"\" if not full_context : return full_context # Inefficient, but the data set is small here, so meh zero_line_files = set ( item . name for item in full_context if item . line == 0 ) for file in set ( zero_line_files ): for ctx in full_context : if ctx . name == file and ctx . line > 0 : break else : zero_line_files . remove ( file ) new_context = [] for ctx in full_context : is_specific = ctx . name not in zero_line_files or ctx . line > 0 if is_specific and ctx not in new_context : new_context . append ( ctx ) return tuple ( new_context ) whatrecord . common . time_context () Return a callable to measure the time since context manager init. Source code in whatrecord/common.py @contextmanager def time_context (): \"\"\"Return a callable to measure the time since context manager init.\"\"\" start_count = perf_counter () def inner (): return perf_counter () - start_count yield inner Miscellaneous whatrecord.cache Classes whatrecord.cache.CacheKey dataclass CacheKey() Source code in whatrecord/cache.py @dataclass class CacheKey : def _to_cache_key_part ( self , obj : Any ) -> str : \"\"\"Take an arbitrary value from the CacheKey and make a string out of it.\"\"\" if is_dataclass ( obj ): obj = asdict ( obj ) if isinstance ( obj , Mapping ): return \"_\" . join ( self . _to_cache_key_part ( part ) for part in sorted ( obj . items ())) if isinstance ( obj , Sequence ) and not isinstance ( obj , ( bytes , str )): return \"_\" . join ( self . _to_cache_key_part ( part ) for part in obj ) return repr ( obj ) def to_filename ( self , version : int = 1 , class_name : Optional [ str ] = None ) -> str : \"\"\"Get the cache filename.\"\"\" def by_name ( field ): return field . name values = \":\" . join ( field . name + \"=\" + self . _to_cache_key_part ( getattr ( self , field . name )) for field in sorted ( fields ( self ), key = by_name ) ) value_repr = repr ( values ) sha = get_bytes_sha256 ( value_repr . encode ( \"utf-8\" )) class_name = class_name or self . __class__ . __name__ return f \" { class_name } _v { version } _ { sha } .json\" Methods whatrecord . cache . CacheKey . to_filename ( self , version : int = 1 , class_name : Optional [ str ] = None ) -> str Get the cache filename. Source code in whatrecord/cache.py def to_filename ( self , version : int = 1 , class_name : Optional [ str ] = None ) -> str : \"\"\"Get the cache filename.\"\"\" def by_name ( field ): return field . name values = \":\" . join ( field . name + \"=\" + self . _to_cache_key_part ( getattr ( self , field . name )) for field in sorted ( fields ( self ), key = by_name ) ) value_repr = repr ( values ) sha = get_bytes_sha256 ( value_repr . encode ( \"utf-8\" )) class_name = class_name or self . __class__ . __name__ return f \" { class_name } _v { version } _ { sha } .json\" whatrecord.cache.Cached ( _Cached ) dataclass A generic dataclass that can be cached in WHATRECORD_CACHE_PATH . Expects to be subclassed and configured with a CacheKey subclass. Source code in whatrecord/cache.py @dataclass class Cached ( _Cached ): \"\"\" A generic dataclass that can be cached in ``WHATRECORD_CACHE_PATH``. Expects to be subclassed and configured with a CacheKey subclass. \"\"\" key : CacheKey = field ( metadata = apischema . metadata . skip ) def __init_subclass__ ( cls , key : Optional [ _CacheKeyType ] = None , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): if key is None or not inspect . isclass ( key ) or not is_dataclass ( key ): raise RuntimeError ( f \" { cls . __name__ } should be defined with a keyword argument 'key'; \" f \"such as `class { cls . __name__ } (Cached, key=CacheKeyClass):\" ) cls . _cache_version_ = version cls . __annotations__ [ \"key\" ] = key cls . CacheKey = key if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH ) Methods whatrecord . cache . Cached . __init_subclass__ ( key : Optional [ _CacheKeyType ] = None , version : int = 1 , cache_path : Optional [ AnyPath ] = None ) classmethod special This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. Source code in whatrecord/cache.py def __init_subclass__ ( cls , key : Optional [ _CacheKeyType ] = None , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): if key is None or not inspect . isclass ( key ) or not is_dataclass ( key ): raise RuntimeError ( f \" { cls . __name__ } should be defined with a keyword argument 'key'; \" f \"such as `class { cls . __name__ } (Cached, key=CacheKeyClass):\" ) cls . _cache_version_ = version cls . __annotations__ [ \"key\" ] = key cls . CacheKey = key if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH ) whatrecord.cache.InlineCached ( _Cached ) dataclass A generic dataclass that can be cached in WHATRECORD_CACHE_PATH . Expects to be subclassed and mixed in with a CacheKey subclass. Source code in whatrecord/cache.py @dataclass class InlineCached ( _Cached ): \"\"\" A generic dataclass that can be cached in ``WHATRECORD_CACHE_PATH``. Expects to be subclassed and mixed in with a CacheKey subclass. \"\"\" def __init_subclass__ ( cls , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): for supercls in cls . mro ()[ 1 :]: if issubclass ( supercls , CacheKey ) and supercls is not CacheKey : cls . CacheKey = supercls break else : raise RuntimeError ( f \" { cls . __name__ } should be defined as a subclass of a CacheKey\" ) cls . _cache_version_ = version if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH ) @property def key ( self ) -> CacheKey : \"\"\"An auto-generated CacheKey based on this dataclass's attributes.\"\"\" kwargs = { field . name : getattr ( self , field . name ) for field in fields ( self . CacheKey ) } return self . CacheKey ( ** kwargs ) Attributes whatrecord . cache . InlineCached . key : CacheKey property readonly An auto-generated CacheKey based on this dataclass's attributes. Methods whatrecord . cache . InlineCached . __init_subclass__ ( version : int = 1 , cache_path : Optional [ AnyPath ] = None ) classmethod special This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. Source code in whatrecord/cache.py def __init_subclass__ ( cls , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): for supercls in cls . mro ()[ 1 :]: if issubclass ( supercls , CacheKey ) and supercls is not CacheKey : cls . CacheKey = supercls break else : raise RuntimeError ( f \" { cls . __name__ } should be defined as a subclass of a CacheKey\" ) cls . _cache_version_ = version if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH ) whatrecord.format Classes whatrecord.format.FormatContext Source code in whatrecord/format.py class FormatContext : def __init__ ( self , helpers = None , * , trim_blocks = True , lstrip_blocks = False , default_options = \"console\" , ** env_kwargs ): self . helpers = helpers or [ self . render_object , type , locals ] self . default_options = default_options self . _template_dict = {} self . env = jinja2 . Environment ( loader = jinja2 . DictLoader ( self . _template_dict ), trim_blocks = trim_blocks , lstrip_blocks = lstrip_blocks , ** env_kwargs , ) self . env . filters . update ( self . get_filters ()) self . default_render_context = self . get_render_context () self . _fallback_formats = {} def get_filters ( self , ** user_config ): \"\"\"All jinja filters.\"\"\" @pass_eval_context def title_fill ( eval_ctx , text , fill_char ): return fill_char * len ( text ) @pass_eval_context def classname ( eval_ctx , obj ): if inspect . isclass ( obj ): return obj . __name__ return type ( obj ) . __name__ @pass_eval_context def render_object ( eval_ctx , obj , option ): return self . render_object ( obj , option ) return { key : value for key , value in locals () . items () if not key . startswith ( \"_\" ) and key not in { \"self\" } } def render_template ( self , _template : str , ** context ): # TODO: want this to be positional-only; fallback here for pypy template = _template for key , value in self . default_render_context . items (): context . setdefault ( key , value ) context [ \"render_ctx\" ] = context return self . env . from_string ( template ) . render ( context ) def _render_object_fallback ( self , _obj , _option , ** context ): # TODO: want this to be positional-only; fallback here for pypy obj , option = _obj , _option if isinstance ( obj , typing . Sequence ) and not isinstance ( obj , str ): if all ( isinstance ( obj_idx , LoadContext ) for obj_idx in obj ): # Special-case FullLoadContext return \" \" . join ( str ( ctx ) for ctx in obj ) return \" \\n \" . join ( f \"[ { idx } ]: \" + textwrap . indent ( self . render_object ( obj_idx , _option , ** context ), ' ' ) . lstrip () for idx , obj_idx in enumerate ( obj ) ) if isinstance ( obj , typing . Mapping ): return \" \\n \" . join ( f '\" { key } \": ' + self . render_object ( value , _option , ** context ) for key , value in sorted ( obj . items ()) ) if dataclasses . is_dataclass ( obj ): cls = type ( obj ) if cls not in self . _fallback_formats : # TODO: lazy method here with 'fields' serialized = apischema . serialize ( obj ) fields = [ field . name for field in dataclasses . fields ( obj ) if field . name in serialized ] self . _fallback_formats [ cls ] = template_from_dataclass ( cls , fields , option or self . default_options ) return self . render_template ( self . _fallback_formats [ cls ], ** context ) return str ( obj ) def render_object ( self , _obj , _option = None , ** context ): # TODO: want this to be positional-only; fallback here for pypy obj , option = _obj , _option if option is None : option = self . default_options if dataclasses . is_dataclass ( obj ): for field in dataclasses . fields ( obj ): context . setdefault ( field . name , getattr ( obj , field . name )) context . setdefault ( \"obj\" , obj ) try : template = obj . _jinja_format_ [ option ] except ( AttributeError , KeyError ): ... else : return self . render_template ( template , ** context ) return self . _render_object_fallback ( obj , option , ** context ) def get_render_context ( self ) -> dict : \"\"\"Jinja template context dictionary - helper functions.\"\"\" context = { func . __name__ : func for func in self . helpers } return context Methods whatrecord . format . FormatContext . get_filters ( self , ** user_config ) All jinja filters. Source code in whatrecord/format.py def get_filters ( self , ** user_config ): \"\"\"All jinja filters.\"\"\" @pass_eval_context def title_fill ( eval_ctx , text , fill_char ): return fill_char * len ( text ) @pass_eval_context def classname ( eval_ctx , obj ): if inspect . isclass ( obj ): return obj . __name__ return type ( obj ) . __name__ @pass_eval_context def render_object ( eval_ctx , obj , option ): return self . render_object ( obj , option ) return { key : value for key , value in locals () . items () if not key . startswith ( \"_\" ) and key not in { \"self\" } } whatrecord . format . FormatContext . get_render_context ( self ) -> dict Jinja template context dictionary - helper functions. Source code in whatrecord/format.py def get_render_context ( self ) -> dict : \"\"\"Jinja template context dictionary - helper functions.\"\"\" context = { func . __name__ : func for func in self . helpers } return context Functions whatrecord . format . template_from_dataclass ( cls , fields , render_option ) Generate a console-friendly render template from a dataclass. Source code in whatrecord/format.py def template_from_dataclass ( cls , fields , render_option ): \"\"\"Generate a console-friendly render template from a dataclass.\"\"\" if not fields : return f \" { cls . __name__ } \\n \" name_length = max ( len ( name ) + 1 for name in fields ) field_text = \" \\n \" . join ( \"{ % i f \" + field + \" | string | length > 0 %} \\n \" + field . rjust ( name_length ) + \": { % s et field_text = render_object(\" + field + \", render_option) %}\" \"{{ field_text | indent(name_length + 2) }}\" \"{ % e ndif %} \\n \" for field in fields ) return ( f \" { cls . __name__ } : \\n \" f \" {{ % set name_length = { name_length } % }}\\n \" f \" {{ % set render_option = { render_option } % }}\\n \" + field_text ) whatrecord.graphql whatrecord.settings whatrecord.util Functions whatrecord . util . check_files_up_to_date ( file_to_hash : Dict [ Union [ str , pathlib . Path ], str ]) -> bool Check if the provided files are up-to-date by way of recorded hash vs current hash. Parameters: Name Type Description Default file_to_hash Dict[Union[str, pathlib.Path], str] File path to hash. required Returns: Type Description bool If all files maintain their stored hashes, returns True. Source code in whatrecord/util.py def check_files_up_to_date ( file_to_hash : Dict [ AnyPath , str ] ) -> bool : \"\"\" Check if the provided files are up-to-date by way of recorded hash vs current hash. Parameters ---------- file_to_hash : Dict[Union[str, pathlib.Path], str] File path to hash. Returns ------- up_to_date : bool If all files maintain their stored hashes, returns True. \"\"\" for fn , file_hash in file_to_hash . items (): try : if get_file_sha256 ( fn ) != file_hash : return False except FileNotFoundError : return False return True whatrecord . util . find_binary_from_hashbang ( startup_script : Union [ str , pathlib . Path ], must_exist : bool = False ) -> Optional [ str ] Find the binary associated with a given startup script by looking at its shebang. Returns: Type Description Optional[str] The path to the binary, if available. Source code in whatrecord/util.py def find_binary_from_hashbang ( startup_script : Optional [ Union [ str , pathlib . Path ]], must_exist : bool = False , ) -> Optional [ str ]: \"\"\" Find the binary associated with a given startup script by looking at its shebang. Returns ------- binary_path : str or None The path to the binary, if available. \"\"\" if startup_script is None : return None try : with open ( startup_script , \"rt\" ) as fp : first_line = fp . read () . splitlines ()[ 0 ] except Exception : return None if first_line . startswith ( \"#!\" ): parent_dir = pathlib . Path ( startup_script ) . parent binary = parent_dir / first_line . lstrip ( \"#!\" ) . strip () if not must_exist or binary . exists (): return str ( binary . resolve ()) whatrecord . util . get_bytes_sha256 ( contents : bytes ) Hash a byte string with the SHA-256 algorithm. Source code in whatrecord/util.py def get_bytes_sha256 ( contents : bytes ): \"\"\"Hash a byte string with the SHA-256 algorithm.\"\"\" return hashlib . sha256 ( contents ) . hexdigest () whatrecord . util . get_file_sha256 ( binary : Union [ str , pathlib . Path ]) Hash a binary with the SHA-256 algorithm. Source code in whatrecord/util.py def get_file_sha256 ( binary : AnyPath ): \"\"\"Hash a binary with the SHA-256 algorithm.\"\"\" # This doesn't do any sort of buffering; but our binaries are pretty small # in comparison to what we're storing as metadata, anyway with open ( binary , \"rb\" ) as fp : return hashlib . sha256 ( fp . read ()) . hexdigest () whatrecord . util . lines_between ( text : str , start_marker : str , end_marker : str , * , include_blank : bool = False ) -> Generator [ str , NoneType , NoneType ] From a block of text, yield all lines between start_marker and end_marker Parameters: Name Type Description Default text str The block of text required start_marker str The block-starting marker to match required end_marker str The block-ending marker to match required include_blank bool Skip yielding blank lines False Returns: Type Description Generator[str, NoneType, NoneType] Line of text found between the markers. Source code in whatrecord/util.py def lines_between ( text : str , start_marker : str , end_marker : str , * , include_blank : bool = False ) -> Generator [ str , None , None ]: \"\"\" From a block of text, yield all lines between `start_marker` and `end_marker` Parameters ---------- text : str The block of text start_marker : str The block-starting marker to match end_marker : str The block-ending marker to match include_blank : bool, optional Skip yielding blank lines Yields ------ line : str Line of text found between the markers. \"\"\" found_start = False start_marker = start_marker . lower () end_marker = end_marker . lower () for line in text . splitlines (): line_lowercase = line . strip () . lower () if line_lowercase == start_marker : found_start = True elif found_start : if line_lowercase == end_marker : break elif line_lowercase or include_blank : yield line whatrecord . util . read_text_file_with_hash ( fn : Path , encoding = 'latin-1' ) -> Tuple [ str , str ] Hash a binary with the SHA-256 algorithm. Source code in whatrecord/util.py def read_text_file_with_hash ( fn : pathlib . Path , encoding = \"latin-1\" , ) -> Tuple [ str , str ]: \"\"\"Hash a binary with the SHA-256 algorithm.\"\"\" # This doesn't do any sort of buffering; but our binaries are pretty small # in comparison to what we're storing as metadata, anyway with open ( fn , \"rb\" ) as fp : contents = fp . read () sha256 = hashlib . sha256 ( contents ) . hexdigest () return sha256 , contents . decode ( encoding ) whatrecord . util . run_gdb ( script : str , binary : Union [ pathlib . Path , str ], cls : ~ T , args : Optional [ List [ str ]] = None , gdb_path : Optional [ str ] = None , use_cache : bool = True ) -> ~ T async Run a script and deserialize its output. Parameters: Name Type Description Default script str The script name to run (whatrecord. script , omitting .py) required binary Union[pathlib.Path, str] The binary file to load into GDB. required cls ~T The dataclass type to deserialize gdb's output to. required args Optional[List[str]] List of string arguments to pass to gdb. None gdb_path Optional[str] The path to the gdb binary. Defaults to WHATRECORD_GDB_PATH from the environment ( gdb ). None Source code in whatrecord/util.py async def run_gdb ( script : str , binary : Union [ pathlib . Path , str ], cls : T , args : Optional [ List [ str ]] = None , gdb_path : Optional [ str ] = None , use_cache : bool = True , ) -> T : \"\"\" Run a script and deserialize its output. Parameters ---------- script : str The script name to run (whatrecord.__script__, omitting .py) binary : str or pathlib.Path The binary file to load into GDB. cls : type The dataclass type to deserialize gdb's output to. args : list, optional List of string arguments to pass to gdb. gdb_path : str, optional The path to the gdb binary. Defaults to ``WHATRECORD_GDB_PATH`` from the environment (``gdb``). \"\"\" cache_path = pathlib . Path ( settings . CACHE_PATH ) binary_hash = get_file_sha256 ( binary ) hash_filename = cache_path / f \" { script } _ { cls . __name__ } _ { binary_hash } .json\" if use_cache : if not settings . CACHE_PATH or not cache_path . exists (): use_cache = False else : try : with open ( hash_filename , \"rt\" ) as fp : json_data = json . load ( fp ) return apischema . deserialize ( cls , json_data ) except FileNotFoundError : ... except Exception as ex : logger . warning ( \"Failed to load cached gdb information from disk; \" \"re-running gdb ( %s , filename= %s )\" , ex , hash_filename , exc_info = True ) args = \" \" . join ( f '\" { arg } \"' for arg in args or []) script_path = MODULE_PATH / \"plugins\" / f \" { script } .py\" gdb_path = gdb_path or settings . GDB_PATH to_execute = ( f '\" { gdb_path } \" ' f \"--batch-silent \" f '--command \" { script_path } \" ' f '--args \" { binary } \" { args } ' ) json_data = await run_script_with_json_output ( to_execute ) json_data = json_data or {} if use_cache : with open ( hash_filename , \"wt\" ) as fp : json . dump ( json_data , fp , indent = 4 ) try : return apischema . deserialize ( cls , json_data ) except Exception as ex : ex . json_data = json_data raise whatrecord . util . run_script_with_json_output ( script_line : str , encoding : str = 'utf-8' , log_errors : bool = True ) -> Optional [ dict ] async Run a script and get its JSON output. Source code in whatrecord/util.py async def run_script_with_json_output ( script_line : str , encoding : str = \"utf-8\" , log_errors : bool = True , ) -> Optional [ dict ]: \"\"\"Run a script and get its JSON output.\"\"\" proc = await asyncio . create_subprocess_shell ( script_line , stdout = asyncio . subprocess . PIPE , stderr = asyncio . subprocess . PIPE ) ( stdout , stderr ) = await proc . communicate () if stderr and log_errors : stderr_text = textwrap . indent ( stderr . decode ( \"utf-8\" , \"replace\" ), \" ! \" ) logger . warning ( \"Standard error output while running script ( %r ): \\n %s \" , script_line , stderr_text ) if stdout : return json . loads ( stdout . decode ( encoding )) if log_errors : logger . warning ( \"No standard output while running script ( %r )\" , script_line )","title":"Shared / Utilities"},{"location":"utilities/#shared-utilities","text":"","title":"Shared / Utilities"},{"location":"utilities/#macros","text":"EPICS-compliant macro parsing by way of a Cython wrapper of macLib.","title":"Macros"},{"location":"utilities/#whatrecord.macro","text":"","title":"macro"},{"location":"utilities/#whatrecord.macro-functions","text":"","title":"Functions"},{"location":"utilities/#whatrecord.macro.macros_from_string","text":"Get a macro dictionary from a macro string. Parameters: Name Type Description Default macro_string str The macro string, in the format A=B,C=D,... required use_environment bool Use environment variables as well. Defaults to False. False Returns: Type Description Dict[str, str] Macro key to value. Source code in whatrecord/macro.py def macros_from_string ( macro_string : str , use_environment : bool = False ) -> Dict [ str , str ]: \"\"\" Get a macro dictionary from a macro string. Parameters ---------- macro_string : str The macro string, in the format A=B,C=D,... use_environment : bool, optional Use environment variables as well. Defaults to False. Returns ------- macros : Dict[str, str] Macro key to value. \"\"\" if not macro_string . strip (): return {} macro_context = MacroContext ( use_environment = use_environment ) return macro_context . define_from_string ( macro_string )","title":"macros_from_string()"},{"location":"utilities/#pv-graphing","text":"","title":"PV Graphing"},{"location":"utilities/#whatrecord.graph","text":"","title":"graph"},{"location":"utilities/#whatrecord.graph-classes","text":"","title":"Classes"},{"location":"utilities/#whatrecord.graph.GraphEdge","text":"GraphEdge(source: whatrecord.graph.GraphNode, destination: whatrecord.graph.GraphNode, options: dict = ) Source code in whatrecord/graph.py @dataclass class GraphEdge : #: The source node. source : GraphNode #: The destination node. destination : GraphNode #: Options to pass to graphviz. options : dict = dataclasses . field ( default_factory = dict )","title":"GraphEdge"},{"location":"utilities/#whatrecord.graph.GraphNode","text":"GraphNode(id: str, label: str, text: str, options: dict = , highlighted: bool = False) Source code in whatrecord/graph.py @dataclass () class GraphNode : #: The integer ID of the node id : str #: The node label label : str #: The text to show in the node text : str #: Options to pass to graphviz. options : dict = dataclasses . field ( default_factory = dict ) #: Highlight the node in the graph? highlighted : bool = False def __hash__ ( self ): return hash ( self . id )","title":"GraphNode"},{"location":"utilities/#whatrecord.graph.LinkInfo","text":"LinkInfo(record1: whatrecord.common.RecordInstance, field1: whatrecord.common.RecordField, record2: whatrecord.common.RecordInstance, field2: whatrecord.common.RecordField, info: List[str]) Source code in whatrecord/graph.py @dataclass class LinkInfo : record1 : RecordInstance field1 : RecordField record2 : RecordInstance field2 : RecordField info : List [ str ]","title":"LinkInfo"},{"location":"utilities/#whatrecord.graph.RecordLinkGraph","text":"Record link graph. Source code in whatrecord/graph.py class RecordLinkGraph ( _GraphHelper ): \"\"\"Record link graph.\"\"\" # TODO: create node and color when not in database? database : Database starting_records : List [ str ] header_format : str = 'record( {rtype} , \" {name} \")' field_format : str = ' {field:>4s} : \" {value} \"' text_format : str = ( f \"<b> {{ header }} </b>\" f \" { _GraphHelper . newline } \" f \" { _GraphHelper . newline } \" f \" {{ field_lines }} \" ) sort_fields : bool show_empty : bool relations : Optional [ PVRelations ] record_types : Dict [ str , RecordType ] default_edge_kwargs : Dict [ str , str ] = { \"style\" : \"solid\" , \"color\" : \"black\" , } edge_kwargs : ClassVar [ Dict [ str , Dict [ str , str ]]] = { \"style\" : { \"PP\" : \"\" , \"CPP\" : \"\" , \"CP\" : \"\" , }, \"color\" : { \"MS\" : \"red\" , \"MSS\" : \"red\" , \"MSI\" : \"red\" , } } def __init__ ( self , database : Optional [ Union [ Database , Dict [ str , RecordInstance ]]] = None , starting_records : Optional [ List [ str ]] = None , header_format : Optional [ str ] = None , field_format : Optional [ str ] = None , text_format : Optional [ str ] = None , sort_fields : bool = True , show_empty : bool = False , relations : Optional [ PVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ): super () . __init__ () self . database = Database ( record_types = dict ( record_types or {})) self . starting_records = starting_records or [] self . header_format = header_format or type ( self ) . header_format self . field_format = field_format or type ( self ) . field_format self . text_format = text_format or type ( self ) . text_format self . sort_fields = sort_fields self . show_empty = show_empty self . relations = relations if database is not None : self . add_database ( database ) def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) if not self . relations : self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types ) for li in find_record_links ( self . database . records , self . starting_records , relations = self . relations ): for ( rec , field ) in (( li . record1 , li . field1 ), ( li . record2 , li . field2 )): if rec . name not in self . nodes : self . get_node ( label = rec . name , text = field . name ) src = self . get_node ( li . record1 . name ) dest = self . get_node ( li . record2 . name ) for field , node in [( li . field1 , src ), ( li . field2 , dest )]: if field . value or self . show_empty : text_line = self . field_format . format ( field = field . name , value = field . value ) if node . text and text_line not in node . text : node . text = \" \\n \" . join (( node . text , text_line )) else : node . text = text_line if li . field1 . dtype == \"DBF_INLINK\" : src , dest = dest , src li . field1 , li . field2 = li . field2 , li . field1 logger . debug ( \"New edge %s -> %s \" , src , dest ) edge_kw = dict ( self . default_edge_kwargs ) for key , to_find in self . edge_kwargs . items (): for match , value in to_find . items (): if match in li . info : edge_kw [ key ] = value break if ( src , dest ) not in set ( self . edge_pairs ): edge_kw [ \"xlabel\" ] = f \" { li . field1 . name } / { li . field2 . name } \" if li . info : edge_kw [ \"xlabel\" ] += f \" \\n { ' ' . join ( li . info ) } \" self . add_edge ( src . label , dest . label , ** edge_kw ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . starting_records : if rec_name in self . database . records : self . get_node ( rec_name ) for node in self . nodes . values (): field_lines = node . text if self . sort_fields : node . text = \" \\n \" . join ( sorted ( node . text . splitlines ())) if field_lines : node . text += \" \\n \" rec = self . database . records [ node . label ] header = self . header_format . format ( rtype = rec . record_type , name = rec . name ) if rec . aliases : header += f \" \\n Alias: { ', ' . join ( rec . aliases ) } \" escaped_header = html . escape ( header , quote = False ) node . text = self . text_format . format ( header = escaped_header . replace ( \" \\n \" , self . newline ), field_lines = self . newline . join ( html . escape ( line , quote = False ) for line in node . text . splitlines () ), ) def _ready_for_digraph ( self , graph : gv . Digraph ): \"\"\"Hook when the user calls ``to_digraph``.\"\"\" for node in self . nodes . values (): node . highlighted = node . label in self . starting_records","title":"RecordLinkGraph"},{"location":"utilities/#whatrecord.graph.RecordLinkGraph-methods","text":"whatrecord . graph . RecordLinkGraph . add_database ( self , database : Union [ Dict [ str , whatrecord . common . RecordInstance ], whatrecord . db . Database ]) Add records from the given database to the graph. Source code in whatrecord/graph.py def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) if not self . relations : self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types ) for li in find_record_links ( self . database . records , self . starting_records , relations = self . relations ): for ( rec , field ) in (( li . record1 , li . field1 ), ( li . record2 , li . field2 )): if rec . name not in self . nodes : self . get_node ( label = rec . name , text = field . name ) src = self . get_node ( li . record1 . name ) dest = self . get_node ( li . record2 . name ) for field , node in [( li . field1 , src ), ( li . field2 , dest )]: if field . value or self . show_empty : text_line = self . field_format . format ( field = field . name , value = field . value ) if node . text and text_line not in node . text : node . text = \" \\n \" . join (( node . text , text_line )) else : node . text = text_line if li . field1 . dtype == \"DBF_INLINK\" : src , dest = dest , src li . field1 , li . field2 = li . field2 , li . field1 logger . debug ( \"New edge %s -> %s \" , src , dest ) edge_kw = dict ( self . default_edge_kwargs ) for key , to_find in self . edge_kwargs . items (): for match , value in to_find . items (): if match in li . info : edge_kw [ key ] = value break if ( src , dest ) not in set ( self . edge_pairs ): edge_kw [ \"xlabel\" ] = f \" { li . field1 . name } / { li . field2 . name } \" if li . info : edge_kw [ \"xlabel\" ] += f \" \\n { ' ' . join ( li . info ) } \" self . add_edge ( src . label , dest . label , ** edge_kw ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . starting_records : if rec_name in self . database . records : self . get_node ( rec_name ) for node in self . nodes . values (): field_lines = node . text if self . sort_fields : node . text = \" \\n \" . join ( sorted ( node . text . splitlines ())) if field_lines : node . text += \" \\n \" rec = self . database . records [ node . label ] header = self . header_format . format ( rtype = rec . record_type , name = rec . name ) if rec . aliases : header += f \" \\n Alias: { ', ' . join ( rec . aliases ) } \" escaped_header = html . escape ( header , quote = False ) node . text = self . text_format . format ( header = escaped_header . replace ( \" \\n \" , self . newline ), field_lines = self . newline . join ( html . escape ( line , quote = False ) for line in node . text . splitlines () ), )","title":"Methods"},{"location":"utilities/#whatrecord.graph.ScriptLinkGraph","text":"Script link graph (i.e., inter-IOC record links). Parameters: Name Type Description Default database Union[whatrecord.db.Database, Dict[str, whatrecord.common.RecordInstance]] Dictionary of record name to record instance. None starting_records list of str Record names required sort_fields bool Sort list of fields required show_empty bool Show empty fields required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None script_relations Optional[Dict[str, Dict[str, List[str]]]] Pre-built script relationship dictionary. Generated from database if not provided. None record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. None Source code in whatrecord/graph.py class ScriptLinkGraph ( _GraphHelper ): \"\"\" Script link graph (i.e., inter-IOC record links). Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names sort_fields : bool, optional Sort list of fields show_empty : bool, optional Show empty fields relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. script_relations : dict, optional Pre-built script relationship dictionary. Generated from database if not provided. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. \"\"\" # TODO: create node and color when not in database? newline : str = '<br align=\"center\"/>' def __init__ ( self , database : Optional [ Union [ Database , Dict [ str , RecordInstance ]]] = None , limit_to_records : Optional [ List [ str ]] = None , relations : Optional [ PVRelations ] = None , script_relations : Optional [ ScriptPVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ): super () . __init__ () self . database = Database ( record_types = dict ( record_types or {})) self . limit_to_records = limit_to_records or [] self . relations = relations self . script_relations = script_relations if database is not None : self . add_database ( database ) def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) # if not self.script_relations: self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types , ) self . script_relations = build_script_relations ( database = self . database . records , by_record = self . relations , limit_to_records = self . limit_to_records , ) for script_a , script_a_relations in self . script_relations . items (): self . get_node ( script_a , text = script_a ) for script_b in script_a_relations : if script_b in self . nodes : continue self . get_node ( script_b , text = script_b ) inter_lines = ( [ f \"<b> { script_a } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_a ][ script_b ])) + [ \"\" ] + [ f \"<b> { script_b } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_b ][ script_a ])) ) inter_node = f \" { script_a } <-> { script_b } \" self . get_node ( inter_node , text = \" \\n \" . join ( inter_lines )) self . add_edge ( script_a , inter_node ) self . add_edge ( inter_node , script_b ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . limit_to_records or []: if rec_name in self . database . records : self . get_node ( rec_name ) def _ready_for_digraph ( self , graph : gv . Digraph ): \"\"\"Hook when the user calls ``to_digraph``.\"\"\" for node in self . nodes . values (): node . highlighted = node . label in self . limit_to_records","title":"ScriptLinkGraph"},{"location":"utilities/#whatrecord.graph.ScriptLinkGraph-methods","text":"whatrecord . graph . ScriptLinkGraph . add_database ( self , database : Union [ Dict [ str , whatrecord . common . RecordInstance ], whatrecord . db . Database ]) Add records from the given database to the graph. Source code in whatrecord/graph.py def add_database ( self , database : Union [ Dict [ str , RecordInstance ], Database ]): \"\"\"Add records from the given database to the graph.\"\"\" if isinstance ( database , Database ): self . database . append ( database ) else : for record in database . values (): self . database . add_or_update_record ( record ) # if not self.script_relations: self . relations = build_database_relations ( self . database . records , record_types = self . database . record_types , ) self . script_relations = build_script_relations ( database = self . database . records , by_record = self . relations , limit_to_records = self . limit_to_records , ) for script_a , script_a_relations in self . script_relations . items (): self . get_node ( script_a , text = script_a ) for script_b in script_a_relations : if script_b in self . nodes : continue self . get_node ( script_b , text = script_b ) inter_lines = ( [ f \"<b> { script_a } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_a ][ script_b ])) + [ \"\" ] + [ f \"<b> { script_b } </b>\" , \"\" ] + list ( sorted ( self . script_relations [ script_b ][ script_a ])) ) inter_node = f \" { script_a } <-> { script_b } \" self . get_node ( inter_node , text = \" \\n \" . join ( inter_lines )) self . add_edge ( script_a , inter_node ) self . add_edge ( inter_node , script_b ) if not self . nodes : # No relationship found; at least show the records for rec_name in self . limit_to_records or []: if rec_name in self . database . records : self . get_node ( rec_name )","title":"Methods"},{"location":"utilities/#whatrecord.graph-functions","text":"","title":"Functions"},{"location":"utilities/#whatrecord.graph.build_database_relations","text":"Build a dictionary of PV relationships. This should not be called often for large databases, as it makes no attempt to be computationally efficient. For repeated usage, cache the result of this function and reuse it in future calls to graph_links and such. Parameters: Name Type Description Default database Dict[str, whatrecord.common.RecordInstance] Dictionary of record name to record instance. required record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. None Returns: Type Description Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]] Such that: info[pv1][pv2] = (field1, field2, info) And in reverse: info[pv2][pv1] = (field2, field1, info) Source code in whatrecord/graph.py def build_database_relations ( database : Dict [ str , RecordInstance ], record_types : Optional [ Dict [ str , RecordType ]] = None , aliases : Optional [ Dict [ str , str ]] = None , ) -> PVRelations : \"\"\" Build a dictionary of PV relationships. This should not be called often for large databases, as it makes no attempt to be computationally efficient. For repeated usage, cache the result of this function and reuse it in future calls to ``graph_links`` and such. Parameters ---------- database : dict Dictionary of record name to record instance. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Returns ------- info : dict Such that: ``info[pv1][pv2] = (field1, field2, info)`` And in reverse: ``info[pv2][pv1] = (field2, field1, info)`` \"\"\" aliases = aliases or {} warned = set () unset_ctx : FullLoadContext = ( LoadContext ( \"unknown\" , 0 ), ) by_record = collections . defaultdict ( lambda : collections . defaultdict ( list )) # TODO: alias handling? for rec1 in database . values (): if record_types : # Use links as defined in the database definition rec1_links = rec1 . get_links () else : # Fall back to static list of link fields rec1_links = rec1 . get_common_links () for field1 , link , info in rec1_links : # TODO: copied without thinking about implications # due to the removal of st.cmd context as an attempt to reduce field1 = copy . deepcopy ( field1 ) # field1.context = rec1.context[:1] + field1.context if \".\" in link : link , field2 = link . split ( \".\" , 1 ) elif field1 . name == \"FLNK\" : field2 = \"PROC\" else : field2 = \"VAL\" rec2 = database . get ( aliases . get ( link , link ), None ) if rec2 is None : # TODO: switch to debug; this will be expensive later if not is_supported_link ( link ): continue if link not in warned : warned . add ( link ) logger . debug ( \"Linked record from %s . %s not in database: %s \" , rec1 . name , field1 . name , link ) field2 = RecordField ( dtype = \"unknown\" , name = field2 , value = \"(unknown-record)\" , context = unset_ctx , ) rec2_name = link elif field2 in rec2 . fields : rec2_name = rec2 . name # TODO: copied without thinking about implications field2 = copy . deepcopy ( rec2 . fields [ field2 ]) # field2.context = rec2.context[:1] + field2.context elif record_types : rec2_name = rec2 . name dbd_record_type = record_types . get ( rec2 . record_type , None ) if dbd_record_type is None : field2 = RecordField ( dtype = \"invalid\" , name = field2 , value = \"(invalid-record-type)\" , context = unset_ctx , ) elif field2 not in dbd_record_type . fields : field2 = RecordField ( dtype = \"invalid\" , name = field2 , value = \"(invalid-field)\" , context = unset_ctx , ) else : dbd_record_field = dbd_record_type . fields [ field2 ] field2 = RecordField ( dtype = dbd_record_field . type , name = field2 , value = \"\" , context = dbd_record_field . context , ) else : rec2_name = rec2 . name field2 = RecordField ( dtype = \"unknown\" , name = field2 , value = \"\" , # unset or invalid, can't tell yet context = unset_ctx , ) by_record [ rec1 . name ][ rec2_name ] . append (( field1 , field2 , info )) by_record [ rec2_name ][ rec1 . name ] . append (( field2 , field1 , info )) return dict ( ( key , dict ( inner_dict )) for key , inner_dict in by_record . items () )","title":"build_database_relations()"},{"location":"utilities/#whatrecord.graph.combine_relations","text":"Combine multiple script relations into one. Source code in whatrecord/graph.py def combine_relations ( dest_relations : PVRelations , dest_db : Dict [ str , RecordInstance ], source_relations : PVRelations , source_db : Dict [ str , RecordInstance ], record_types : Optional [ Dict [ str , RecordType ]] = None , aliases : Optional [ Dict [ str , str ]] = None , ): \"\"\"Combine multiple script relations into one.\"\"\" aliases = aliases or {} def get_relation_by_field () -> Tuple [ str , str , Dict [ Tuple [ str , str ], Tuple [ str , str , List [ str ]]] ]: for rec1_name , rec2_names in source_relations . items (): dest_rec1_dict = dest_relations . setdefault ( rec1_name , {}) for rec2_name in rec2_names : dest_rec2 = dest_rec1_dict . setdefault ( rec2_name , []) relation_by_field = { ( field1 . name , field2 . name ): ( field1 , field2 , link ) for field1 , field2 , link in dest_rec2 } yield rec1_name , rec2_name , relation_by_field # Part 1: # Rebuild with new aliases, if available # Either set of relations could have referred to aliased names, actual # names, or even *both*. def alias_to_actual ( d ): # This is kinda expensive, imperfect, and confusing; consider reworking for alias_from , alias_to in aliases . items (): # A -> B inner_dict = d . pop ( alias_from , None ) if not inner_dict : continue # Fix up B <- A first, since it's symmetric for inner_name , inner_items in inner_dict . items (): # d[inner_name][alias_to] += d[inner_name][alias_from] d [ inner_name ] . setdefault ( alias_to , []) . extend ( d [ inner_name ] . pop ( alias_from ) ) if alias_to not in d : d [ alias_to ] = inner_dict else : # The actual record name is already in the relation dict for inner_name , inner_items in inner_dict . items (): # d[alias_to][inner_name] += inner_items d [ alias_to ] . setdefault ( inner_name , []) . extend ( inner_items ) alias_to_actual ( dest_relations ) alias_to_actual ( source_relations ) # Part 1: # Merge in new or updated relations from the second set for rec1_name , rec2_name , relation_by_field in get_relation_by_field (): for field1 , field2 , link in source_relations [ rec1_name ][ rec2_name ]: key = ( field1 . name , field2 . name ) existing_link = relation_by_field . get ( key , None ) if not existing_link : relation_by_field [ key ] = ( field1 , field2 , link ) else : existing_field1 , existing_field2 , _ = existing_link existing_field1 . update_unknowns ( field1 ) existing_field2 . update_unknowns ( field2 ) dest_relations [ rec1_name ][ rec2_name ] = list ( relation_by_field . values ()) def get_record ( name ) -> RecordInstance : \"\"\"Get record from either database.\"\"\" name = aliases . get ( name , name ) try : return dest_db . get ( name , None ) or source_db [ name ] except KeyError : raise def get_field_info ( record , field ): \"\"\"Get record definition if available.\"\"\" if field in record . fields : return record . fields [ field ] if record_types : field_def = record_types [ field ] return RecordField ( dtype = field_def . type , name = field , value = \"\" , context = field_def . context , ) raise KeyError ( \"Field not in database or database definition\" ) # Part 2: # Update any existing relations in the destination relations with # information from the source database for rec1_name , rec1 in source_db . items (): if rec1_name in dest_relations : for rec2_name , rec2_items in dest_relations [ rec1_name ] . items (): # We know rec1 is in the source database, but we don't know # where rec2 might be, so use `get_record`. try : rec2 = get_record ( rec2_name ) except KeyError : # It's not in this IOC... continue def get_items_to_update (): for field1 , field2 , _ in rec2_items : yield ( rec1 , field1 ) yield ( rec2 , field2 ) for field1 , field2 , _ in dest_relations [ rec2_name ][ rec1_name ]: yield ( rec2 , field1 ) yield ( rec1 , field2 ) for rec , field in get_items_to_update (): try : field_info = get_field_info ( rec , field . name ) except KeyError : logger . debug ( \"Missing field? %s . %s \" , rec . name , field . name ) else : field . update_unknowns ( field_info )","title":"combine_relations()"},{"location":"utilities/#whatrecord.graph.find_record_links","text":"Get all related record links from a set of starting records. All starting records will be included, along with any other records that are linked to from there. Parameters: Name Type Description Default database Dict[str, whatrecord.common.RecordInstance] Dictionary of record name to record instance. required starting_records List[str] Record names required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None Returns: Type Description Generator[whatrecord.graph.LinkInfo, NoneType, NoneType] Link info Source code in whatrecord/graph.py def find_record_links ( database : Dict [ str , RecordInstance ], starting_records : List [ str ], relations : Optional [ PVRelations ] = None ) -> Generator [ LinkInfo , None , None ]: \"\"\" Get all related record links from a set of starting records. All starting records will be included, along with any other records that are linked to from there. Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. Yields ------ link_info : LinkInfo Link info \"\"\" checked = [] if relations is None : relations = build_database_relations ( database ) records_to_check = list ( starting_records ) while records_to_check : rec1 = database . get ( records_to_check . pop (), None ) if rec1 is None : continue checked . append ( rec1 . name ) logger . debug ( \"--- record %s ---\" , rec1 . name ) for rec2_name , fields in relations . get ( rec1 . name , {}) . items (): if rec2_name in checked : continue rec2 = database . get ( rec2_name , None ) if rec2 is None : continue for field1 , field2 , info in fields : if rec2_name not in checked and rec2_name not in records_to_check : records_to_check . append ( rec2_name ) li = LinkInfo ( record1 = rec1 , field1 = field1 , record2 = rec2 , field2 = field2 , info = info , ) logger . debug ( \"Link %s \" , li ) yield li","title":"find_record_links()"},{"location":"utilities/#whatrecord.graph.graph_links","text":"Create a graphviz digraph of record links. All starting records will be included, along with any other records that are linked to from there - if available in the database. Parameters: Name Type Description Default database Union[whatrecord.db.Database, Dict[str, whatrecord.common.RecordInstance]] Dictionary of record name to record instance. required starting_records List[str] Record names required graph graphviz.Graph Graph instance to use. New one created if not specified. required engine str Graphviz engine (dot, fdp, etc) required field_format Optional[str] Format string for fields (keys: field, value, attr) None sort_fields bool Sort list of fields True text_format Optional[str] Text format for full node (keys: header, field_lines) None show_empty bool Show empty fields False font_name str Font name to use for all nodes and edges required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. None Source code in whatrecord/graph.py def graph_links ( database : Union [ Database , Dict [ str , RecordInstance ]], starting_records : List [ str ], header_format : Optional [ str ] = None , field_format : Optional [ str ] = None , text_format : Optional [ str ] = None , sort_fields : bool = True , show_empty : bool = False , relations : Optional [ PVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ) -> RecordLinkGraph : \"\"\" Create a graphviz digraph of record links. All starting records will be included, along with any other records that are linked to from there - if available in the database. Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names graph : graphviz.Graph, optional Graph instance to use. New one created if not specified. engine : str, optional Graphviz engine (dot, fdp, etc) field_format : str, optional Format string for fields (keys: field, value, attr) sort_fields : bool, optional Sort list of fields text_format : str, optional Text format for full node (keys: header, field_lines) show_empty : bool, optional Show empty fields font_name : str, optional Font name to use for all nodes and edges relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. Returns ------- graph : RecordLinkGraph \"\"\" return RecordLinkGraph ( database = database , starting_records = starting_records , header_format = header_format , field_format = field_format , text_format = text_format , sort_fields = sort_fields , show_empty = show_empty , relations = relations , record_types = record_types , )","title":"graph_links()"},{"location":"utilities/#whatrecord.graph.graph_script_relations","text":"Create a graphviz digraph of script links (i.e., inter-IOC record links). Parameters: Name Type Description Default database Dict[str, whatrecord.common.RecordInstance] Dictionary of record name to record instance. required starting_records list of str Record names required relations Optional[Dict[str, Dict[str, List[Tuple[whatrecord.common.RecordField, whatrecord.common.RecordField, List[str]]]]]] Pre-built PV relationship dictionary. Generated from database if not provided. None script_relations Optional[Dict[str, Dict[str, List[str]]]] Pre-built script relationship dictionary. Generated from database if not provided. None record_types Optional[Dict[str, whatrecord.common.RecordType]] The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. None Source code in whatrecord/graph.py def graph_script_relations ( database : Dict [ str , RecordInstance ], limit_to_records : Optional [ List [ str ]] = None , relations : Optional [ PVRelations ] = None , script_relations : Optional [ ScriptPVRelations ] = None , record_types : Optional [ Dict [ str , RecordType ]] = None , ) -> ScriptLinkGraph : \"\"\" Create a graphviz digraph of script links (i.e., inter-IOC record links). Parameters ---------- database : dict Dictionary of record name to record instance. starting_records : list of str Record names relations : dict, optional Pre-built PV relationship dictionary. Generated from database if not provided. script_relations : dict, optional Pre-built script relationship dictionary. Generated from database if not provided. record_types : dict, optional The database definitions to use for fields that are not defined in the database file. Dictionary of record type name to RecordType. Only used for determining script relations if not specified. Returns ------- graph : ScriptLinkGraph \"\"\" return ScriptLinkGraph ( database = database , limit_to_records = limit_to_records , relations = relations , script_relations = script_relations , record_types = record_types , )","title":"graph_script_relations()"},{"location":"utilities/#shared","text":"","title":"Shared"},{"location":"utilities/#whatrecord.common","text":"","title":"common"},{"location":"utilities/#whatrecord.common-classes","text":"","title":"Classes"},{"location":"utilities/#whatrecord.common.AsynPortBase","text":"Base class for general asyn ports. Used in :mod: whatrecord.asyn , but made available here such that apischema can find it more readily. Source code in whatrecord/common.py class AsynPortBase : \"\"\" Base class for general asyn ports. Used in :mod:`whatrecord.asyn`, but made available here such that apischema can find it more readily. \"\"\" _union : Any = None def __init_subclass__ ( cls , ** kwargs ): # Registers new subclasses automatically in the union cls._union. # Deserializers stack directly as a Union apischema . deserializer ( apischema . conversions . Conversion ( apischema . identity , source = cls , target = AsynPortBase ) ) # Only AsynPortBase serializer must be registered (and updated for each # subclass) as a Union, and not be inherited AsynPortBase . _union = ( cls if AsynPortBase . _union is None else Union [ AsynPortBase . _union , cls ] ) apischema . serializer ( apischema . conversions . Conversion ( apischema . identity , source = AsynPortBase , target = AsynPortBase . _union , inherited = False , ) )","title":"AsynPortBase"},{"location":"utilities/#whatrecord.common.AsynPortBase-methods","text":"whatrecord . common . AsynPortBase . __init_subclass__ ( ** kwargs ) classmethod special This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. Source code in whatrecord/common.py def __init_subclass__ ( cls , ** kwargs ): # Registers new subclasses automatically in the union cls._union. # Deserializers stack directly as a Union apischema . deserializer ( apischema . conversions . Conversion ( apischema . identity , source = cls , target = AsynPortBase ) ) # Only AsynPortBase serializer must be registered (and updated for each # subclass) as a Union, and not be inherited AsynPortBase . _union = ( cls if AsynPortBase . _union is None else Union [ AsynPortBase . _union , cls ] ) apischema . serializer ( apischema . conversions . Conversion ( apischema . identity , source = AsynPortBase , target = AsynPortBase . _union , inherited = False , ) )","title":"Methods"},{"location":"utilities/#whatrecord.common.DatabaseDevice","text":"DatabaseDevice(record_type: 'str', link_type: 'str', dset_name: 'str', choice_string: 'str') Source code in whatrecord/common.py @dataclass class DatabaseDevice : record_type : str link_type : str dset_name : str choice_string : str","title":"DatabaseDevice"},{"location":"utilities/#whatrecord.common.DatabaseMenu","text":"DatabaseMenu(context: 'FullLoadContext', name: 'str', choices: 'Dict[str, str]') Source code in whatrecord/common.py @dataclass class DatabaseMenu : context : FullLoadContext name : str choices : Dict [ str , str ]","title":"DatabaseMenu"},{"location":"utilities/#whatrecord.common.FileFormat","text":"An enumeration. Source code in whatrecord/common.py class FileFormat ( str , enum . Enum ): iocsh = 'iocsh' database = 'database' database_definition = 'database_definition' substitution = 'substitution' gateway_pvlist = 'gateway_pvlist' access_security = 'access_security' stream_protocol = 'stream_protocol' state_notation = 'state_notation' makefile = 'makefile' @classmethod def from_extension ( cls , extension : str ) -> FileFormat : \"\"\"Get a file format based on a file extension.\"\"\" return { \"cmd\" : FileFormat . iocsh , \"db\" : FileFormat . database , \"dbd\" : FileFormat . database_definition , \"template\" : FileFormat . database , \"substitutions\" : FileFormat . substitution , \"pvlist\" : FileFormat . gateway_pvlist , \"acf\" : FileFormat . access_security , \"proto\" : FileFormat . stream_protocol , \"st\" : FileFormat . state_notation , }[ extension . lower ()] @classmethod def from_filename ( cls , filename : AnyPath ) -> FileFormat : \"\"\"Get a file format based on a full filename.\"\"\" path = pathlib . Path ( filename ) extension = path . suffix . lstrip ( \".\" ) if not extension and path . name . startswith ( \"Makefile\" ): return FileFormat . makefile try : return FileFormat . from_extension ( extension ) except KeyError : raise ValueError ( f \"Could not determine file type from extension: { extension } \" ) from None","title":"FileFormat"},{"location":"utilities/#whatrecord.common.GdbBinaryInfo","text":"GdbBinaryInfo(commands: 'Dict[str, IocshCommand]', base_version: 'Optional[str]', variables: 'Dict[str, IocshVariable]', error: 'Optional[str]') Source code in whatrecord/common.py @dataclass class GdbBinaryInfo : commands : Dict [ str , IocshCommand ] base_version : Optional [ str ] variables : Dict [ str , IocshVariable ] error : Optional [ str ]","title":"GdbBinaryInfo"},{"location":"utilities/#whatrecord.common.IocMetadata","text":"IocMetadata(name: 'str' = 'unset', script: 'pathlib.Path' = , startup_directory: 'pathlib.Path' = , host: 'Optional[str]' = None, port: 'Optional[int]' = None, binary: 'Optional[str]' = None, base_version: 'str' = '3.15', metadata: 'Dict[str, Any]' = , macros: 'Dict[str, str]' = , standin_directories: 'Dict[str, str]' = , commands: 'Dict[str, IocshCommand]' = , variables: 'Dict[str, IocshVariable]' = , loaded_files: 'Dict[str, str]' = , load_success: 'bool' = True) Source code in whatrecord/common.py @dataclass class IocMetadata : name : str = \"unset\" script : pathlib . Path = field ( default_factory = pathlib . Path ) startup_directory : pathlib . Path = field ( default_factory = pathlib . Path ) host : Optional [ str ] = None port : Optional [ int ] = None binary : Optional [ str ] = None base_version : str = settings . DEFAULT_BASE_VERSION metadata : Dict [ str , Any ] = field ( default_factory = dict ) macros : Dict [ str , str ] = field ( default_factory = dict ) standin_directories : Dict [ str , str ] = field ( default_factory = dict ) commands : Dict [ str , IocshCommand ] = field ( default_factory = dict ) variables : Dict [ str , IocshVariable ] = field ( default_factory = dict ) loaded_files : Dict [ str , str ] = field ( default_factory = dict ) load_success : bool = True def update ( self , other : IocMetadata , merge : bool = False ): \"\"\" Update the metadata with a new set from an IOC Loader. Parameters ---------- other : IocMetadata The other IOC metadata to update this instance with. merge : bool, optional Merge in dictionary information, or overwrite it. Defaults to 'overwrite' (merge=False). \"\"\" self . name = other . name self . script = other . script self . startup_directory = other . startup_directory self . host = other . host or self . host self . port = other . port or self . port self . binary = other . binary or self . binary self . base_version = ( other . base_version if other . base_version != settings . DEFAULT_BASE_VERSION else self . base_version ) if merge : self . metadata . update ( other . metadata ) self . macros . update ( other . macros ) self . standin_directories . update ( other . standin_directories ) self . commands . update ( other . commands ) self . variables . update ( other . variables ) else : self . metadata = dict ( other . metadata ) self . macros = dict ( other . macros ) self . standin_directories = dict ( other . standin_directories ) self . commands = dict ( other . commands ) self . variables = dict ( other . variables ) @property def looks_like_sh ( self ) -> bool : \"\"\"Is the script likely sh/bash/etc?\"\"\" return self . binary and ( \"bin/sh\" in self . binary or \"bin/bash\" in self . binary or \"env bash\" in self . binary or \"bin/tcsh\" in self . binary or \"/python\" in self . binary ) @property def _cache_key ( self ) -> str : \"\"\"Cache key for storing this IOC information in a file.\"\"\" key = \"\" . join ( str ( v ) for v in ( self . name , str ( self . script . resolve ()), str ( self . startup_directory . resolve ()), str ( self . host ), str ( self . port ), ) ) hash = util . get_bytes_sha256 ( bytes ( key , \"utf-8\" )) return f \" { self . name } . { hash } \" @property def cache_filename ( self ) -> pathlib . Path : metadata_fn = f \" { self . _cache_key } .IocMetadata.json\" return pathlib . Path ( settings . CACHE_PATH ) / metadata_fn @property def ioc_cache_filename ( self ) -> pathlib . Path : metadata_fn = f \" { self . _cache_key } .LoadedIoc.json\" return pathlib . Path ( settings . CACHE_PATH ) / metadata_fn def from_cache ( self ) -> Optional [ IocMetadata ]: if not settings . CACHE_PATH : return try : with open ( self . cache_filename , \"rb\" ) as fp : return apischema . deserialize ( type ( self ), json . load ( fp )) except FileNotFoundError : ... except json . decoder . JSONDecodeError : # Truncated output file, perhaps ... def save_to_cache ( self ) -> bool : if not settings . CACHE_PATH : return False with open ( self . cache_filename , \"wt\" ) as fp : json . dump ( apischema . serialize ( self ), fp = fp ) return True def is_up_to_date ( self ) -> bool : \"\"\"Is this IOC up-to-date with what is on disk?\"\"\" if not self . loaded_files : return False return util . check_files_up_to_date ( self . loaded_files ) def add_loaded_file ( self , filename : Union [ pathlib . Path , str ], update : bool = False , ) -> bool : \"\"\" Add filename to the loaded file dictionary, optionally updating an existing hash. \"\"\" filename = pathlib . Path ( self . startup_directory ) / filename if str ( filename ) not in self . loaded_files or update : self . loaded_files [ str ( filename )] = util . get_file_sha256 ( filename ) return True return False async def get_binary_information ( self ) -> Optional [ GdbBinaryInfo ]: if not self . binary or not pathlib . Path ( self . binary ) . exists (): return try : info = await util . run_gdb ( \"gdb_binary_info\" , self . binary , cls = GdbBinaryInfo , ) except apischema . ValidationError : logger . error ( \"Failed to get gdb information for %s ( %s )\" , self . name , self . binary , exc_info = True , ) return if info . error : logger . error ( \"Failed to get gdb information for %s ( %s ): %s \" , self . name , self . binary , info . error ) return self . base_version = info . base_version or self . base_version self . commands . update ( info . commands ) self . variables . update ( info . variables ) for command in self . commands . values (): for context in command . context or []: try : self . add_loaded_file ( context . name ) except FileNotFoundError : logger . debug ( \"GDB source file does not exist for command %s ( %s )\" , command . name , context ) return info @property def database_version_spec ( self ) -> int : \"\"\"Load databases with this specification.\"\"\" # TODO: better version parsing try : base_major_minor = tuple ( int ( v ) for v in self . base_version . split ( \".\" )[: 2 ] ) return 3 if base_major_minor < ( 3 , 16 ) else 4 except Exception : return 3 @classmethod def empty ( cls ): return cls ( name = \"unset\" , script = pathlib . Path (), startup_directory = pathlib . Path ()) @classmethod def from_file ( cls , filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = settings . DEFAULT_BASE_VERSION , ** metadata ): \"\"\"Given at minimum a filename, guess the rest.\"\"\" filename = pathlib . Path ( filename ) . expanduser () . resolve () name = name or filename . parts [ - 2 ] # iocBoot/((ioc-something))/st.cmd if \"/\" in name : name = name . replace ( \"/\" , \"\" ) if not name : # Sorry, we need something unique here (better ideas welcome) name = util . get_bytes_sha256 ( bytes ( str ( filename ), \"utf-8\" ))[: 10 ] return cls ( name = name , host = host , port = port , script = filename , startup_directory = startup_directory or filename . parent , metadata = metadata , macros = macros or {}, standin_directories = standin_directories or {}, binary = binary or util . find_binary_from_hashbang ( filename ), base_version = base_version , ) #: Back-compat: from_filename is deprecated from_filename = from_file @classmethod def from_dict ( cls , iocdict : IocInfoDict , macros : Optional [ Dict [ str , str ]] = None ): \"\"\" Pick apart a given dictionary, relegating extra info to ``.metadata``. Parameters ---------- iocdict : dict IOC information dictionary. \"\"\" ioc = dict ( iocdict ) name = ioc . pop ( \"name\" ) host = ioc . pop ( \"host\" , None ) port = ioc . pop ( \"port\" , None ) script = ioc . pop ( \"script\" ) script = pathlib . Path ( str ( script )) . expanduser () . resolve () binary = ioc . pop ( \"binary\" , None ) base_version = ioc . pop ( \"base_version\" , None ) return cls ( name = name , script = script , startup_directory = script . parent , host = host , port = port , metadata = ioc , macros = macros or {}, binary = binary or util . find_binary_from_hashbang ( script ), base_version = base_version or settings . DEFAULT_BASE_VERSION , )","title":"IocMetadata"},{"location":"utilities/#whatrecord.common.IocMetadata-attributes","text":"whatrecord . common . IocMetadata . database_version_spec : int property readonly Load databases with this specification. whatrecord . common . IocMetadata . looks_like_sh : bool property readonly Is the script likely sh/bash/etc?","title":"Attributes"},{"location":"utilities/#whatrecord.common.IocMetadata-methods","text":"whatrecord . common . IocMetadata . add_loaded_file ( self , filename : Union [ pathlib . Path , str ], update : bool = False ) -> bool Add filename to the loaded file dictionary, optionally updating an existing hash. Source code in whatrecord/common.py def add_loaded_file ( self , filename : Union [ pathlib . Path , str ], update : bool = False , ) -> bool : \"\"\" Add filename to the loaded file dictionary, optionally updating an existing hash. \"\"\" filename = pathlib . Path ( self . startup_directory ) / filename if str ( filename ) not in self . loaded_files or update : self . loaded_files [ str ( filename )] = util . get_file_sha256 ( filename ) return True return False whatrecord . common . IocMetadata . from_dict ( iocdict : IocInfoDict , macros : Optional [ Dict [ str , str ]] = None ) classmethod Pick apart a given dictionary, relegating extra info to .metadata . Parameters: Name Type Description Default iocdict IocInfoDict IOC information dictionary. required Source code in whatrecord/common.py @classmethod def from_dict ( cls , iocdict : IocInfoDict , macros : Optional [ Dict [ str , str ]] = None ): \"\"\" Pick apart a given dictionary, relegating extra info to ``.metadata``. Parameters ---------- iocdict : dict IOC information dictionary. \"\"\" ioc = dict ( iocdict ) name = ioc . pop ( \"name\" ) host = ioc . pop ( \"host\" , None ) port = ioc . pop ( \"port\" , None ) script = ioc . pop ( \"script\" ) script = pathlib . Path ( str ( script )) . expanduser () . resolve () binary = ioc . pop ( \"binary\" , None ) base_version = ioc . pop ( \"base_version\" , None ) return cls ( name = name , script = script , startup_directory = script . parent , host = host , port = port , metadata = ioc , macros = macros or {}, binary = binary or util . find_binary_from_hashbang ( script ), base_version = base_version or settings . DEFAULT_BASE_VERSION , ) whatrecord . common . IocMetadata . from_file ( filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = '3.15' , ** metadata ) classmethod Given at minimum a filename, guess the rest. Source code in whatrecord/common.py @classmethod def from_file ( cls , filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = settings . DEFAULT_BASE_VERSION , ** metadata ): \"\"\"Given at minimum a filename, guess the rest.\"\"\" filename = pathlib . Path ( filename ) . expanduser () . resolve () name = name or filename . parts [ - 2 ] # iocBoot/((ioc-something))/st.cmd if \"/\" in name : name = name . replace ( \"/\" , \"\" ) if not name : # Sorry, we need something unique here (better ideas welcome) name = util . get_bytes_sha256 ( bytes ( str ( filename ), \"utf-8\" ))[: 10 ] return cls ( name = name , host = host , port = port , script = filename , startup_directory = startup_directory or filename . parent , metadata = metadata , macros = macros or {}, standin_directories = standin_directories or {}, binary = binary or util . find_binary_from_hashbang ( filename ), base_version = base_version , ) whatrecord . common . IocMetadata . from_filename ( filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = '3.15' , ** metadata ) classmethod Given at minimum a filename, guess the rest. Source code in whatrecord/common.py @classmethod def from_file ( cls , filename : Union [ pathlib . Path , str ], * , name : Optional [ str ] = None , host : Optional [ str ] = None , port : Optional [ int ] = None , startup_directory : Optional [ pathlib . Path ] = None , macros : Optional [ Dict [ str , str ]] = None , standin_directories : Optional [ Dict [ str , str ]] = None , binary : Optional [ str ] = None , base_version : Optional [ str ] = settings . DEFAULT_BASE_VERSION , ** metadata ): \"\"\"Given at minimum a filename, guess the rest.\"\"\" filename = pathlib . Path ( filename ) . expanduser () . resolve () name = name or filename . parts [ - 2 ] # iocBoot/((ioc-something))/st.cmd if \"/\" in name : name = name . replace ( \"/\" , \"\" ) if not name : # Sorry, we need something unique here (better ideas welcome) name = util . get_bytes_sha256 ( bytes ( str ( filename ), \"utf-8\" ))[: 10 ] return cls ( name = name , host = host , port = port , script = filename , startup_directory = startup_directory or filename . parent , metadata = metadata , macros = macros or {}, standin_directories = standin_directories or {}, binary = binary or util . find_binary_from_hashbang ( filename ), base_version = base_version , ) whatrecord . common . IocMetadata . is_up_to_date ( self ) -> bool Is this IOC up-to-date with what is on disk? Source code in whatrecord/common.py def is_up_to_date ( self ) -> bool : \"\"\"Is this IOC up-to-date with what is on disk?\"\"\" if not self . loaded_files : return False return util . check_files_up_to_date ( self . loaded_files ) whatrecord . common . IocMetadata . update ( self , other : IocMetadata , merge : bool = False ) Update the metadata with a new set from an IOC Loader. Parameters: Name Type Description Default other IocMetadata The other IOC metadata to update this instance with. required merge bool Merge in dictionary information, or overwrite it. Defaults to 'overwrite' (merge=False). False Source code in whatrecord/common.py def update ( self , other : IocMetadata , merge : bool = False ): \"\"\" Update the metadata with a new set from an IOC Loader. Parameters ---------- other : IocMetadata The other IOC metadata to update this instance with. merge : bool, optional Merge in dictionary information, or overwrite it. Defaults to 'overwrite' (merge=False). \"\"\" self . name = other . name self . script = other . script self . startup_directory = other . startup_directory self . host = other . host or self . host self . port = other . port or self . port self . binary = other . binary or self . binary self . base_version = ( other . base_version if other . base_version != settings . DEFAULT_BASE_VERSION else self . base_version ) if merge : self . metadata . update ( other . metadata ) self . macros . update ( other . macros ) self . standin_directories . update ( other . standin_directories ) self . commands . update ( other . commands ) self . variables . update ( other . variables ) else : self . metadata = dict ( other . metadata ) self . macros = dict ( other . macros ) self . standin_directories = dict ( other . standin_directories ) self . commands = dict ( other . commands ) self . variables = dict ( other . variables )","title":"Methods"},{"location":"utilities/#whatrecord.common.IocshArgument","text":"IocshArgument(name: 'str', type: 'str') Source code in whatrecord/common.py @dataclass class IocshArgument : name : str type : str","title":"IocshArgument"},{"location":"utilities/#whatrecord.common.IocshCmdArgs","text":"iocshCmd(...) arguments. Source code in whatrecord/common.py @dataclass class IocshCmdArgs : \"\"\"iocshCmd(...) arguments.\"\"\" context : FullLoadContext command : str","title":"IocshCmdArgs"},{"location":"utilities/#whatrecord.common.IocshCommand","text":"IocshCommand(name: 'str', args: 'List[IocshArgument]' = , usage: 'Optional[str]' = None, context: 'Optional[FullLoadContext]' = None) Source code in whatrecord/common.py @dataclass class IocshCommand : name : str args : List [ IocshArgument ] = field ( default_factory = list ) usage : Optional [ str ] = None context : Optional [ FullLoadContext ] = None","title":"IocshCommand"},{"location":"utilities/#whatrecord.common.IocshResult","text":"IocshResult(context: 'FullLoadContext', line: 'str', outputs: 'List[str]' = , argv: 'Optional[List[str]]' = None, error: 'Optional[str]' = None, redirects: 'List[IocshRedirect]' = , result: 'Any' = None) Source code in whatrecord/common.py @apischema . fields . with_fields_set @dataclass class IocshResult : context : FullLoadContext line : str outputs : List [ str ] = field ( default_factory = list ) argv : Optional [ List [ str ]] = None error : Optional [ str ] = None redirects : List [ IocshRedirect ] = field ( default_factory = list ) # TODO: normalize this # result: Optional[Union[str, Dict[str, str], IocshCmdArgs, ShortLinterResults]] result : Any = None _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" { %- f or ctx in context -%} {{ctx.line}}: { %- e ndfor %} {{ line }} { % i f error %} ** ERROR on line { % i f context %}{{ context[0].line }}{ % e ndif %} ** {{ error | indent(4) }} { % e ndif %} { % i f outputs != [line] %} { % f or output in outputs %} -SH> {{ output | indent(6) }} { % e ndfor %} { % e ndif %} { % f or redirect in redirects %} -> Redirect: {{ redirect }} { %- e ndfor %} \"\"\" . strip (), }","title":"IocshResult"},{"location":"utilities/#whatrecord.common.IocshScript","text":"IocshScript(path: 'str', lines: 'List[IocshResult]') Source code in whatrecord/common.py @dataclass class IocshScript : path : str # lines: Tuple[IocshResult, ...] lines : List [ IocshResult ] _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : textwrap . dedent ( \"\"\"\\ {%- for line in lines %} {% set line = render_object(line, \"console\") %} {{ line }} {%- endfor %} \"\"\" . rstrip (), ), \"console-verbose\" : textwrap . dedent ( \"\"\"\\ {%- for line in lines -%} {% set line = render_object(line, \"console-verbose\") %} {{ line }} {%- endfor %} \"\"\" . rstrip (), ) } @classmethod def from_metadata ( cls , md : IocMetadata , sh : ShellState ) -> IocshScript : if md . looks_like_sh : if md . base_version == settings . DEFAULT_BASE_VERSION : md . base_version = \"unknown\" return cls . from_general_file ( md . script ) return cls ( path = str ( md . script ), lines = tuple ( sh . interpret_shell_script ( md . script ) ), ) @classmethod def from_interpreted_script ( cls , filename : Union [ pathlib . Path , str ], contents : str , sh : ShellState ) -> IocshScript : return cls ( path = str ( filename ), lines = tuple ( sh . interpret_shell_script_text ( contents . splitlines (), name = str ( filename ) ) ), ) @classmethod def from_general_file ( cls , filename : Union [ pathlib . Path , str ]): # For use when shoehorning in a file that's not _really_ an IOC script # TODO: instead rework the api with open ( filename , \"rt\" ) as fp : lines = fp . read () . splitlines () return cls ( path = str ( filename ), lines = tuple ( IocshResult ( line = line , context = ( LoadContext ( str ( filename ), lineno ), ) ) for lineno , line in enumerate ( lines , 1 ) ), )","title":"IocshScript"},{"location":"utilities/#whatrecord.common.IocshVariable","text":"IocshVariable(name: 'str', value: 'Optional[str]' = None, type: 'Optional[str]' = None) Source code in whatrecord/common.py @dataclass class IocshVariable : name : str value : Optional [ str ] = None type : Optional [ str ] = None","title":"IocshVariable"},{"location":"utilities/#whatrecord.common.LinterError","text":"LinterError(name: 'str', line: 'int', message: 'str') Source code in whatrecord/common.py @dataclass class LinterError ( LinterMessage ): ...","title":"LinterError"},{"location":"utilities/#whatrecord.common.LinterMessage","text":"LinterMessage(name: 'str', line: 'int', message: 'str') Source code in whatrecord/common.py @dataclass class LinterMessage : name : str line : int message : str","title":"LinterMessage"},{"location":"utilities/#whatrecord.common.LinterWarning","text":"LinterWarning(name: 'str', line: 'int', message: 'str') Source code in whatrecord/common.py @dataclass class LinterWarning ( LinterMessage ): ...","title":"LinterWarning"},{"location":"utilities/#whatrecord.common.LoadContext","text":"LoadContext(name: 'str', line: 'int') Source code in whatrecord/common.py @dataclass ( frozen = True ) class LoadContext : name : str line : int def __repr__ ( self ): return f \" { self . name } : { self . line } \" @apischema . serializer @property def as_tuple ( self ) -> Sequence [ Union [ str , int ]]: return [ self . name , self . line ]","title":"LoadContext"},{"location":"utilities/#whatrecord.common.MutableLoadContext","text":"MutableLoadContext(name: 'str', line: 'int') Source code in whatrecord/common.py @dataclass ( repr = False ) class MutableLoadContext : name : str line : int def __repr__ ( self ): return f \" { self . name } : { self . line } \" def to_load_context ( self ) -> LoadContext : return LoadContext ( self . name , self . line )","title":"MutableLoadContext"},{"location":"utilities/#whatrecord.common.PVAFieldReference","text":"PVAFieldReference(context: 'FullLoadContext', name: 'str' = '', record_name: 'str' = '', field_name: 'str' = '', metadata: 'Dict[str, str]' = ) Source code in whatrecord/common.py @dataclass class PVAFieldReference : context : FullLoadContext name : str = \"\" record_name : str = \"\" field_name : str = \"\" metadata : Dict [ str , str ] = field ( default_factory = dict ) _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ PVAFieldReference: {{ record_name }}.{{ field_name }} - {{ metadata }} \"\"\" , }","title":"PVAFieldReference"},{"location":"utilities/#whatrecord.common.RecordDefinitionAndInstance","text":"A pair of V3 record definition and instance. Source code in whatrecord/common.py @dataclass class RecordDefinitionAndInstance : \"\"\"A pair of V3 record definition and instance.\"\"\" definition : Optional [ RecordType ] instance : RecordInstance _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ { % s et instance_info = render_object(instance, \"console\") %} {{ instance_info }} \"\"\" , }","title":"RecordDefinitionAndInstance"},{"location":"utilities/#whatrecord.common.RecordField","text":"RecordField(dtype: 'str', name: 'str', value: 'Any', context: 'FullLoadContext') Source code in whatrecord/common.py @dataclass class RecordField : dtype : str name : str value : Any context : FullLoadContext _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\"field({{name}}, \"{{value}}\")\"\"\" , \"console-verbose\" : \"\"\" \\ field({{name}}, \"{{value}}\") # {{dtype}}{ % i f context %}; {{context[-1]}}{ % e ndif %} \\ \"\"\" , } def update_unknowns ( self , other : RecordField , * , unknown_values = None , dbd = None ): \"\"\" If this RecordField has some missing information (\"unknown\"), fill it in with information from the other field. \"\"\" unknown_values = unknown_values or { \"unknown\" , \"\" , \"(unknown-record)\" } if other . dtype not in unknown_values and self . dtype in unknown_values : self . dtype = other . dtype if other . value not in unknown_values and self . value in unknown_values : self . value = other . value if len ( other . context ) and len ( self . context ) == 1 : ctx , = self . context if ctx . name in unknown_values : # Even if the other context is unknown, let's take it anyway: self . context = other . context # if dbd is not None:","title":"RecordField"},{"location":"utilities/#whatrecord.common.RecordField-methods","text":"whatrecord . common . RecordField . update_unknowns ( self , other : RecordField , * , unknown_values = None , dbd = None ) If this RecordField has some missing information (\"unknown\"), fill it in with information from the other field. Source code in whatrecord/common.py def update_unknowns ( self , other : RecordField , * , unknown_values = None , dbd = None ): \"\"\" If this RecordField has some missing information (\"unknown\"), fill it in with information from the other field. \"\"\" unknown_values = unknown_values or { \"unknown\" , \"\" , \"(unknown-record)\" } if other . dtype not in unknown_values and self . dtype in unknown_values : self . dtype = other . dtype if other . value not in unknown_values and self . value in unknown_values : self . value = other . value if len ( other . context ) and len ( self . context ) == 1 : ctx , = self . context if ctx . name in unknown_values : # Even if the other context is unknown, let's take it anyway: self . context = other . context # if dbd is not None:","title":"Methods"},{"location":"utilities/#whatrecord.common.RecordInstance","text":"RecordInstance(context: 'FullLoadContext', name: 'str', record_type: 'str', fields: 'Dict[str, AnyField]' = , info: 'Dict[StringWithContext, Any]' = , metadata: 'Dict[StringWithContext, Any]' = , aliases: 'List[str]' = , is_grecord: 'bool' = False, is_pva: 'bool' = False, owner: 'str' = '') Source code in whatrecord/common.py @dataclass class RecordInstance : context : FullLoadContext name : str record_type : str fields : Dict [ str , AnyField ] = field ( default_factory = dict ) info : Dict [ StringWithContext , Any ] = field ( default_factory = dict ) metadata : Dict [ StringWithContext , Any ] = field ( default_factory = dict ) aliases : List [ str ] = field ( default_factory = list ) is_grecord : bool = False is_pva : bool = False # For the convenience of downstream clients, redundantly keep track of the # associated IOC: owner : str = \"\" _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ record(\"{{record_type}}\", \"{{name}}\") { { % i f owner %} # Part of {{ owner }} { % e ndif %} { % f or ctx in context %} # {{ctx}} { % e ndfor %} { % f or name, field_inst in fields.items() | sort %} { % s et field_text = render_object(field_inst, \"console\") %} {{ field_text | indent(4) }} { % e ndfor %} } \"\"\" , } @property def access_security_group ( self ) -> str : \"\"\"The access security group name for the record.\"\"\" if \"ASG\" in self . fields and not self . is_pva : return str ( self . fields [ \"ASG\" ] . value ) return \"DEFAULT\" def get_fields_of_type ( self , * types ) -> Generator [ RecordField , None , None ]: \"\"\"Get all fields of the matching type(s).\"\"\" if self . is_pva : return for fld in self . fields . values (): if fld . dtype in types : yield fld def get_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Get all links. Yields ------ field : RecordField link_text: str link_info: str \"\"\" for fld in self . get_fields_of_type ( * LINK_TYPES ): try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info def get_common_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Without using a database definition, try to find links. This differs from ``get_links`` in that the other method requires a dbd file to be loaded, whereas this will use a simple - but possibly inaccurate - map of of record type to link fields. Yields ------ field : RecordField link_text: str link_info: str \"\"\" if self . is_pva : return for name in LINK_FIELDS_BY_RECORD . get ( self . record_type , COMMON_LINK_FIELDS ): fld = self . fields . get ( name , None ) if fld is not None : try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info def to_summary ( self ) -> RecordInstanceSummary : \"\"\"Return a summarized version of the record instance.\"\"\" return RecordInstanceSummary . from_record_instance ( self ) def update ( self , other : RecordInstance ) -> List [ LinterMessage ]: \"\"\" Update this record instance with another. TODO: This may not do exactly what an IOC would do. TODO: Return type? \"\"\" if other . is_pva != self . is_pva : return [ LinterError ( name = \"combine_pva_and_v3\" , line = 0 , message = \"Cannot combine PVA group with V3 record\" ) ] self . context = remove_redundant_context ( tuple ( self . context ) + tuple ( other . context ) ) self . info . update ( other . info ) self . metadata . update ( other . metadata ) self . fields . update ( other . fields ) self . aliases . extend ( [ alias for alias in other . aliases if alias not in self . aliases ] ) if self . record_type != other . record_type : return [ LinterError ( name = \"record_type_mismatch\" , line = 0 , message = ( f \"Record type mismatch in provided database files: \" f \" { self . name } { self . record_type } { other . record_type } \" ), ) ] return []","title":"RecordInstance"},{"location":"utilities/#whatrecord.common.RecordInstance-attributes","text":"whatrecord . common . RecordInstance . access_security_group : str property readonly The access security group name for the record.","title":"Attributes"},{"location":"utilities/#whatrecord.common.RecordInstance-methods","text":"whatrecord . common . RecordInstance . get_common_links ( self ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ] Without using a database definition, try to find links. This differs from get_links in that the other method requires a dbd file to be loaded, whereas this will use a simple - but possibly inaccurate - map of of record type to link fields. Source code in whatrecord/common.py def get_common_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Without using a database definition, try to find links. This differs from ``get_links`` in that the other method requires a dbd file to be loaded, whereas this will use a simple - but possibly inaccurate - map of of record type to link fields. Yields ------ field : RecordField link_text: str link_info: str \"\"\" if self . is_pva : return for name in LINK_FIELDS_BY_RECORD . get ( self . record_type , COMMON_LINK_FIELDS ): fld = self . fields . get ( name , None ) if fld is not None : try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info whatrecord . common . RecordInstance . get_fields_of_type ( self , * types ) -> Generator [ RecordField , None , None ] Get all fields of the matching type(s). Source code in whatrecord/common.py def get_fields_of_type ( self , * types ) -> Generator [ RecordField , None , None ]: \"\"\"Get all fields of the matching type(s).\"\"\" if self . is_pva : return for fld in self . fields . values (): if fld . dtype in types : yield fld whatrecord . common . RecordInstance . get_links ( self ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ] Get all links. Source code in whatrecord/common.py def get_links ( self , ) -> Generator [ Tuple [ RecordField , str , Tuple [ str , ... ]], None , None ]: \"\"\" Get all links. Yields ------ field : RecordField link_text: str link_info: str \"\"\" for fld in self . get_fields_of_type ( * LINK_TYPES ): try : link , info = get_link_information ( fld . value ) except ValueError : continue yield fld , link , info whatrecord . common . RecordInstance . to_summary ( self ) -> RecordInstanceSummary Return a summarized version of the record instance. Source code in whatrecord/common.py def to_summary ( self ) -> RecordInstanceSummary : \"\"\"Return a summarized version of the record instance.\"\"\" return RecordInstanceSummary . from_record_instance ( self ) whatrecord . common . RecordInstance . update ( self , other : RecordInstance ) -> List [ LinterMessage ] Update this record instance with another. TODO: This may not do exactly what an IOC would do. TODO: Return type? Source code in whatrecord/common.py def update ( self , other : RecordInstance ) -> List [ LinterMessage ]: \"\"\" Update this record instance with another. TODO: This may not do exactly what an IOC would do. TODO: Return type? \"\"\" if other . is_pva != self . is_pva : return [ LinterError ( name = \"combine_pva_and_v3\" , line = 0 , message = \"Cannot combine PVA group with V3 record\" ) ] self . context = remove_redundant_context ( tuple ( self . context ) + tuple ( other . context ) ) self . info . update ( other . info ) self . metadata . update ( other . metadata ) self . fields . update ( other . fields ) self . aliases . extend ( [ alias for alias in other . aliases if alias not in self . aliases ] ) if self . record_type != other . record_type : return [ LinterError ( name = \"record_type_mismatch\" , line = 0 , message = ( f \"Record type mismatch in provided database files: \" f \" { self . name } { self . record_type } { other . record_type } \" ), ) ] return []","title":"Methods"},{"location":"utilities/#whatrecord.common.RecordInstanceSummary","text":"An abbreviated form of :class: RecordInstance . Source code in whatrecord/common.py @dataclass class RecordInstanceSummary : \"\"\"An abbreviated form of :class:`RecordInstance`.\"\"\" context : FullLoadContext name : str record_type : str # fields: Dict[str, RecordField] info : Dict [ StringWithContext , Any ] = field ( default_factory = dict ) # metadata: Dict[str, Any] = field(default_factory=dict) aliases : List [ str ] = field ( default_factory = list ) # is_grecord: bool = False is_pva : bool = False owner : str = \"\" @classmethod def from_record_instance ( self , instance : RecordInstance ) -> RecordInstanceSummary : return RecordInstanceSummary ( context = instance . context , name = instance . name , record_type = instance . record_type , info = instance . info , aliases = instance . aliases , is_pva = instance . is_pva , owner = instance . owner , )","title":"RecordInstanceSummary"},{"location":"utilities/#whatrecord.common.RecordType","text":"RecordType(context: 'FullLoadContext', name: 'str', cdefs: 'List[str]' = , fields: 'Dict[str, RecordTypeField]' = , devices: 'Dict[str, DatabaseDevice]' = , aliases: 'List[str]' = , info: 'Dict[str, str]' = , is_grecord: 'bool' = False) Source code in whatrecord/common.py @dataclass class RecordType : context : FullLoadContext name : str cdefs : List [ str ] = field ( default_factory = list ) fields : Dict [ str , RecordTypeField ] = field ( default_factory = dict ) devices : Dict [ str , DatabaseDevice ] = field ( default_factory = dict ) aliases : List [ str ] = field ( default_factory = list ) info : Dict [ str , str ] = field ( default_factory = dict ) is_grecord : bool = False","title":"RecordType"},{"location":"utilities/#whatrecord.common.RecordTypeField","text":"RecordTypeField(context: 'FullLoadContext', name: 'str', type: 'str', asl: 'Optional[str]' = None, initial: 'Optional[str]' = None, promptgroup: 'Optional[str]' = None, prompt: 'Optional[str]' = None, special: 'Optional[str]' = None, pp: 'Optional[str]' = None, interest: 'Optional[str]' = None, base: 'Optional[str]' = None, size: 'Optional[str]' = None, extra: 'Optional[str]' = None, menu: 'Optional[str]' = None, prop: 'Optional[str]' = None, body: 'Dict[str, str]' = ) Source code in whatrecord/common.py @apischema . fields . with_fields_set @dataclass class RecordTypeField : context : FullLoadContext name : str type : str asl : Optional [ str ] = None initial : Optional [ str ] = None promptgroup : Optional [ str ] = None prompt : Optional [ str ] = None special : Optional [ str ] = None pp : Optional [ str ] = None interest : Optional [ str ] = None base : Optional [ str ] = None size : Optional [ str ] = None extra : Optional [ str ] = None menu : Optional [ str ] = None prop : Optional [ str ] = None # -> bundle the remainder in \"body\", even if unrecognized body : Dict [ str , str ] = field ( default_factory = dict )","title":"RecordTypeField"},{"location":"utilities/#whatrecord.common.ShellStateHandler","text":"ShellStateHandler(parent: 'Optional[ShellStateHandler]' = None, primary_handler: 'Optional[ShellState]' = None) Source code in whatrecord/common.py @dataclass class ShellStateHandler : metadata_key : ClassVar [ str ] parent : Optional [ ShellStateHandler ] = field ( default = None , metadata = apischema . metadata . skip , repr = False , hash = False , compare = False ) primary_handler : Optional [ ShellState ] = field ( default = None , metadata = apischema . metadata . skip , repr = False , hash = False , compare = False ) _handlers : Dict [ str , Callable ] = field ( default_factory = dict , metadata = apischema . metadata . skip , repr = False , hash = False , compare = False , init = False ) def __post_init__ ( self ): self . _handlers . update ( dict ( self . find_handlers ())) self . _init_sub_handlers_ () def _init_sub_handlers_ ( self ): \"\"\"Initialize sub-handlers with parent/primary_handler.\"\"\" for sub_handler in self . sub_handlers : sub_handler . parent = self sub_handler . primary_handler = getattr ( self . parent , \"primary_handler\" , self ) sub_handler . _init_sub_handlers_ () def annotate_record ( self , instance : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate the given record's metadata with state-related information.\"\"\" ... def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if self . primary_handler is None : return tuple () return self . primary_handler . get_load_context () @property def sub_handlers ( self ) -> List [ ShellStateHandler ]: \"\"\"Handlers which contain their own state.\"\"\" return [] @staticmethod def generic_handler_decorator ( func = None , stub = False ): \"\"\" Decorate a handler method to generically return parameter-to-value information. This can be in addition to or in place of GDB command information. Parameters ---------- func : callable The ``handler_`` method. stub : bool, optional Mark this as a stub method. Variable arguments will be filled in as necessary, even if defaults are not provided. \"\"\" def wrap ( func ): params = list ( inspect . signature ( func ) . parameters . items ())[ 1 :] defaults = list ( None if param . default is inspect . Parameter . empty else param . default for _ , param in params ) @functools . wraps ( func ) def wrapped ( self , * args ): result = {} if len ( args ) < len ( params ) and stub : # Pad unspecified arguments with defaults or \"None\" args = list ( args ) + defaults [ len ( args ):] if len ( args ) > len ( params ): result [ \"argument_lint\" ] = \"Too many arguments\" result [ \"arguments\" ] = [ { \"name\" : name , \"type\" : getattr ( param . annotation , \"__name__\" , param . annotation ), \"value\" : value , } for ( name , param ), value in zip ( params , args ) ] call_result = func ( self , * args [: len ( params )]) if call_result is not None : for key , value in call_result . items (): if key in result : result [ key ] . update ( value ) else : result [ key ] = value return result return wrapped if func is not None : return wrap ( func ) return wrap def find_handlers ( self ) -> Generator [ Tuple [ str , Callable ], None , None ]: \"\"\"Find all IOC shell command handlers by name.\"\"\" for handler_obj in [ self ] + self . sub_handlers : for attr in dir ( handler_obj ): if attr . startswith ( \"handle_\" ): obj = getattr ( handler_obj , attr , None ) if callable ( obj ): name = attr . split ( \"_\" , 1 )[ 1 ] yield name , obj if handler_obj is not self : yield from handler_obj . find_handlers () def pre_ioc_init ( self ): \"\"\"Pre-iocInit hook.\"\"\" ... def post_ioc_init ( self ): \"\"\"Post-iocInit hook.\"\"\" ...","title":"ShellStateHandler"},{"location":"utilities/#whatrecord.common.ShellStateHandler-attributes","text":"whatrecord . common . ShellStateHandler . sub_handlers : List [ ShellStateHandler ] property readonly Handlers which contain their own state.","title":"Attributes"},{"location":"utilities/#whatrecord.common.ShellStateHandler-methods","text":"whatrecord . common . ShellStateHandler . annotate_record ( self , instance : RecordInstance ) -> Optional [ Dict [ str , Any ]] Annotate the given record's metadata with state-related information. Source code in whatrecord/common.py def annotate_record ( self , instance : RecordInstance ) -> Optional [ Dict [ str , Any ]]: \"\"\"Annotate the given record's metadata with state-related information.\"\"\" ... whatrecord . common . ShellStateHandler . find_handlers ( self ) -> Generator [ Tuple [ str , Callable ], None , None ] Find all IOC shell command handlers by name. Source code in whatrecord/common.py def find_handlers ( self ) -> Generator [ Tuple [ str , Callable ], None , None ]: \"\"\"Find all IOC shell command handlers by name.\"\"\" for handler_obj in [ self ] + self . sub_handlers : for attr in dir ( handler_obj ): if attr . startswith ( \"handle_\" ): obj = getattr ( handler_obj , attr , None ) if callable ( obj ): name = attr . split ( \"_\" , 1 )[ 1 ] yield name , obj if handler_obj is not self : yield from handler_obj . find_handlers () whatrecord . common . ShellStateHandler . generic_handler_decorator ( func = None , stub = False ) staticmethod Decorate a handler method to generically return parameter-to-value information. This can be in addition to or in place of GDB command information. Parameters: Name Type Description Default func callable The handler_ method. None stub bool Mark this as a stub method. Variable arguments will be filled in as necessary, even if defaults are not provided. False Source code in whatrecord/common.py @staticmethod def generic_handler_decorator ( func = None , stub = False ): \"\"\" Decorate a handler method to generically return parameter-to-value information. This can be in addition to or in place of GDB command information. Parameters ---------- func : callable The ``handler_`` method. stub : bool, optional Mark this as a stub method. Variable arguments will be filled in as necessary, even if defaults are not provided. \"\"\" def wrap ( func ): params = list ( inspect . signature ( func ) . parameters . items ())[ 1 :] defaults = list ( None if param . default is inspect . Parameter . empty else param . default for _ , param in params ) @functools . wraps ( func ) def wrapped ( self , * args ): result = {} if len ( args ) < len ( params ) and stub : # Pad unspecified arguments with defaults or \"None\" args = list ( args ) + defaults [ len ( args ):] if len ( args ) > len ( params ): result [ \"argument_lint\" ] = \"Too many arguments\" result [ \"arguments\" ] = [ { \"name\" : name , \"type\" : getattr ( param . annotation , \"__name__\" , param . annotation ), \"value\" : value , } for ( name , param ), value in zip ( params , args ) ] call_result = func ( self , * args [: len ( params )]) if call_result is not None : for key , value in call_result . items (): if key in result : result [ key ] . update ( value ) else : result [ key ] = value return result return wrapped if func is not None : return wrap ( func ) return wrap whatrecord . common . ShellStateHandler . get_load_context ( self ) -> FullLoadContext Get a FullLoadContext tuple representing where we are now. Source code in whatrecord/common.py def get_load_context ( self ) -> FullLoadContext : \"\"\"Get a FullLoadContext tuple representing where we are now.\"\"\" if self . primary_handler is None : return tuple () return self . primary_handler . get_load_context () whatrecord . common . ShellStateHandler . post_ioc_init ( self ) Post-iocInit hook. Source code in whatrecord/common.py def post_ioc_init ( self ): \"\"\"Post-iocInit hook.\"\"\" ... whatrecord . common . ShellStateHandler . pre_ioc_init ( self ) Pre-iocInit hook. Source code in whatrecord/common.py def pre_ioc_init ( self ): \"\"\"Pre-iocInit hook.\"\"\" ...","title":"Methods"},{"location":"utilities/#whatrecord.common.StringWithContext","text":"A string with LoadContext. Source code in whatrecord/common.py class StringWithContext ( str ): \"\"\"A string with LoadContext.\"\"\" __slots__ = ( \"context\" , ) context : Optional [ FullLoadContext ] def __new__ ( cls , value , context : Optional [ FullLoadContext ] = None ): self = super () . __new__ ( cls , value ) self . context = context return self","title":"StringWithContext"},{"location":"utilities/#whatrecord.common.StringWithContext-methods","text":"whatrecord . common . StringWithContext . __new__ ( cls , value , context : Optional [ FullLoadContext ] = None ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in whatrecord/common.py def __new__ ( cls , value , context : Optional [ FullLoadContext ] = None ): self = super () . __new__ ( cls , value ) self . context = context return self","title":"Methods"},{"location":"utilities/#whatrecord.common.WhatRecord","text":"WhatRecord - full set of information regarding a specific record. This response is on a per-IOC basis, so at most it can return one V3 record and one V4 record, as these exist in separate namespaces. Attributes: Name Type Description name str The record name. record RecordDefinitionAndInstance The V3 record definition (if available) and record instance. pva_group RecordInstance The PVAccess group, if available. ioc IocMetadata The associated IOC metadata, if available. Source code in whatrecord/common.py @dataclass class WhatRecord : \"\"\" WhatRecord - full set of information regarding a specific record. This response is on a per-IOC basis, so at most it can return one V3 record and one V4 record, as these exist in separate namespaces. Attributes ---------- name : str The record name. record : RecordDefinitionAndInstance, optional The V3 record definition (if available) and record instance. pva_group : RecordInstance, optional The PVAccess group, if available. ioc : IocMetadata, optional The associated IOC metadata, if available. \"\"\" name : str record : Optional [ RecordDefinitionAndInstance ] = None menus : Optional [ Dict [ str , DatabaseMenu ]] = None pva_group : Optional [ RecordInstance ] = None ioc : Optional [ IocMetadata ] = None _jinja_format_ : ClassVar [ Dict [ str , str ]] = { \"console\" : \"\"\" \\ {{ name }}: Owner: {{ present }} { % s et ioc_info = render_object(ioc, \"console\") %} IOC: {{ ioc_info }} { % i f record %} { % s et instance_info = render_object(record, \"console\") %} {{ instance_info | indent(4)}} { % e ndif %} { % i f pva_group %} { % s et instance_info = render_object(pva_group, \"console\") %} {{ instance_info | indent(4)}} { % e ndif %} } \"\"\" , }","title":"WhatRecord"},{"location":"utilities/#whatrecord.common-functions","text":"","title":"Functions"},{"location":"utilities/#whatrecord.common.context_from_lark_token","text":"Get a full load context from a given lark Token. Source code in whatrecord/common.py def context_from_lark_token ( fn : str , token : lark . Token ) -> FullLoadContext : \"\"\"Get a full load context from a given lark Token.\"\"\" return ( LoadContext ( name = fn , line = token . line ), )","title":"context_from_lark_token()"},{"location":"utilities/#whatrecord.common.get_link_information","text":"Get link information from a DBF_{IN,OUT,FWD}LINK value. Source code in whatrecord/common.py def get_link_information ( link_str : str ) -> Tuple [ str , List [ str ]]: \"\"\"Get link information from a DBF_{IN,OUT,FWD}LINK value.\"\"\" if isinstance ( link_str , dict ): # Oh, PVA... raise ValueError ( \"PVA links are TODO, sorry\" ) if \" \" in link_str : # strip off PP/MS/etc (TODO might be useful later) link_str , additional_info = link_str . split ( \" \" , 1 ) else : additional_info = \"\" if link_str . startswith ( \"@\" ): # TODO asyn/device links raise ValueError ( \"asyn link\" ) if not link_str : raise ValueError ( \"empty link\" ) if link_str . isnumeric (): # 0 or 1 usually and not a string raise ValueError ( \"integral link\" ) try : float ( link_str ) except Exception : # Good, we don't want a float ... else : raise ValueError ( \"float link\" ) link_details = additional_info . split () return link_str , link_details","title":"get_link_information()"},{"location":"utilities/#whatrecord.common.remove_redundant_context","text":"Remove redundant context information if it does not add anything. Source code in whatrecord/common.py def remove_redundant_context ( full_context : FullLoadContext ) -> FullLoadContext : \"\"\"Remove redundant context information if it does not add anything.\"\"\" if not full_context : return full_context # Inefficient, but the data set is small here, so meh zero_line_files = set ( item . name for item in full_context if item . line == 0 ) for file in set ( zero_line_files ): for ctx in full_context : if ctx . name == file and ctx . line > 0 : break else : zero_line_files . remove ( file ) new_context = [] for ctx in full_context : is_specific = ctx . name not in zero_line_files or ctx . line > 0 if is_specific and ctx not in new_context : new_context . append ( ctx ) return tuple ( new_context )","title":"remove_redundant_context()"},{"location":"utilities/#whatrecord.common.time_context","text":"Return a callable to measure the time since context manager init. Source code in whatrecord/common.py @contextmanager def time_context (): \"\"\"Return a callable to measure the time since context manager init.\"\"\" start_count = perf_counter () def inner (): return perf_counter () - start_count yield inner","title":"time_context()"},{"location":"utilities/#miscellaneous","text":"","title":"Miscellaneous"},{"location":"utilities/#whatrecord.cache","text":"","title":"cache"},{"location":"utilities/#whatrecord.cache-classes","text":"","title":"Classes"},{"location":"utilities/#whatrecord.cache.CacheKey","text":"CacheKey() Source code in whatrecord/cache.py @dataclass class CacheKey : def _to_cache_key_part ( self , obj : Any ) -> str : \"\"\"Take an arbitrary value from the CacheKey and make a string out of it.\"\"\" if is_dataclass ( obj ): obj = asdict ( obj ) if isinstance ( obj , Mapping ): return \"_\" . join ( self . _to_cache_key_part ( part ) for part in sorted ( obj . items ())) if isinstance ( obj , Sequence ) and not isinstance ( obj , ( bytes , str )): return \"_\" . join ( self . _to_cache_key_part ( part ) for part in obj ) return repr ( obj ) def to_filename ( self , version : int = 1 , class_name : Optional [ str ] = None ) -> str : \"\"\"Get the cache filename.\"\"\" def by_name ( field ): return field . name values = \":\" . join ( field . name + \"=\" + self . _to_cache_key_part ( getattr ( self , field . name )) for field in sorted ( fields ( self ), key = by_name ) ) value_repr = repr ( values ) sha = get_bytes_sha256 ( value_repr . encode ( \"utf-8\" )) class_name = class_name or self . __class__ . __name__ return f \" { class_name } _v { version } _ { sha } .json\"","title":"CacheKey"},{"location":"utilities/#whatrecord.cache.CacheKey-methods","text":"whatrecord . cache . CacheKey . to_filename ( self , version : int = 1 , class_name : Optional [ str ] = None ) -> str Get the cache filename. Source code in whatrecord/cache.py def to_filename ( self , version : int = 1 , class_name : Optional [ str ] = None ) -> str : \"\"\"Get the cache filename.\"\"\" def by_name ( field ): return field . name values = \":\" . join ( field . name + \"=\" + self . _to_cache_key_part ( getattr ( self , field . name )) for field in sorted ( fields ( self ), key = by_name ) ) value_repr = repr ( values ) sha = get_bytes_sha256 ( value_repr . encode ( \"utf-8\" )) class_name = class_name or self . __class__ . __name__ return f \" { class_name } _v { version } _ { sha } .json\"","title":"Methods"},{"location":"utilities/#whatrecord.cache.Cached","text":"A generic dataclass that can be cached in WHATRECORD_CACHE_PATH . Expects to be subclassed and configured with a CacheKey subclass. Source code in whatrecord/cache.py @dataclass class Cached ( _Cached ): \"\"\" A generic dataclass that can be cached in ``WHATRECORD_CACHE_PATH``. Expects to be subclassed and configured with a CacheKey subclass. \"\"\" key : CacheKey = field ( metadata = apischema . metadata . skip ) def __init_subclass__ ( cls , key : Optional [ _CacheKeyType ] = None , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): if key is None or not inspect . isclass ( key ) or not is_dataclass ( key ): raise RuntimeError ( f \" { cls . __name__ } should be defined with a keyword argument 'key'; \" f \"such as `class { cls . __name__ } (Cached, key=CacheKeyClass):\" ) cls . _cache_version_ = version cls . __annotations__ [ \"key\" ] = key cls . CacheKey = key if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH )","title":"Cached"},{"location":"utilities/#whatrecord.cache.Cached-methods","text":"whatrecord . cache . Cached . __init_subclass__ ( key : Optional [ _CacheKeyType ] = None , version : int = 1 , cache_path : Optional [ AnyPath ] = None ) classmethod special This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. Source code in whatrecord/cache.py def __init_subclass__ ( cls , key : Optional [ _CacheKeyType ] = None , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): if key is None or not inspect . isclass ( key ) or not is_dataclass ( key ): raise RuntimeError ( f \" { cls . __name__ } should be defined with a keyword argument 'key'; \" f \"such as `class { cls . __name__ } (Cached, key=CacheKeyClass):\" ) cls . _cache_version_ = version cls . __annotations__ [ \"key\" ] = key cls . CacheKey = key if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH )","title":"Methods"},{"location":"utilities/#whatrecord.cache.InlineCached","text":"A generic dataclass that can be cached in WHATRECORD_CACHE_PATH . Expects to be subclassed and mixed in with a CacheKey subclass. Source code in whatrecord/cache.py @dataclass class InlineCached ( _Cached ): \"\"\" A generic dataclass that can be cached in ``WHATRECORD_CACHE_PATH``. Expects to be subclassed and mixed in with a CacheKey subclass. \"\"\" def __init_subclass__ ( cls , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): for supercls in cls . mro ()[ 1 :]: if issubclass ( supercls , CacheKey ) and supercls is not CacheKey : cls . CacheKey = supercls break else : raise RuntimeError ( f \" { cls . __name__ } should be defined as a subclass of a CacheKey\" ) cls . _cache_version_ = version if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH ) @property def key ( self ) -> CacheKey : \"\"\"An auto-generated CacheKey based on this dataclass's attributes.\"\"\" kwargs = { field . name : getattr ( self , field . name ) for field in fields ( self . CacheKey ) } return self . CacheKey ( ** kwargs )","title":"InlineCached"},{"location":"utilities/#whatrecord.cache.InlineCached-attributes","text":"whatrecord . cache . InlineCached . key : CacheKey property readonly An auto-generated CacheKey based on this dataclass's attributes.","title":"Attributes"},{"location":"utilities/#whatrecord.cache.InlineCached-methods","text":"whatrecord . cache . InlineCached . __init_subclass__ ( version : int = 1 , cache_path : Optional [ AnyPath ] = None ) classmethod special This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. Source code in whatrecord/cache.py def __init_subclass__ ( cls , version : int = 1 , cache_path : Optional [ AnyPath ] = None , ): for supercls in cls . mro ()[ 1 :]: if issubclass ( supercls , CacheKey ) and supercls is not CacheKey : cls . CacheKey = supercls break else : raise RuntimeError ( f \" { cls . __name__ } should be defined as a subclass of a CacheKey\" ) cls . _cache_version_ = version if cache_path is None and not CACHE_PATH : cls . _cache_path_ = None # cache disabled else : cls . _cache_path_ = pathlib . Path ( cache_path or CACHE_PATH )","title":"Methods"},{"location":"utilities/#whatrecord.format","text":"","title":"format"},{"location":"utilities/#whatrecord.format-classes","text":"","title":"Classes"},{"location":"utilities/#whatrecord.format.FormatContext","text":"Source code in whatrecord/format.py class FormatContext : def __init__ ( self , helpers = None , * , trim_blocks = True , lstrip_blocks = False , default_options = \"console\" , ** env_kwargs ): self . helpers = helpers or [ self . render_object , type , locals ] self . default_options = default_options self . _template_dict = {} self . env = jinja2 . Environment ( loader = jinja2 . DictLoader ( self . _template_dict ), trim_blocks = trim_blocks , lstrip_blocks = lstrip_blocks , ** env_kwargs , ) self . env . filters . update ( self . get_filters ()) self . default_render_context = self . get_render_context () self . _fallback_formats = {} def get_filters ( self , ** user_config ): \"\"\"All jinja filters.\"\"\" @pass_eval_context def title_fill ( eval_ctx , text , fill_char ): return fill_char * len ( text ) @pass_eval_context def classname ( eval_ctx , obj ): if inspect . isclass ( obj ): return obj . __name__ return type ( obj ) . __name__ @pass_eval_context def render_object ( eval_ctx , obj , option ): return self . render_object ( obj , option ) return { key : value for key , value in locals () . items () if not key . startswith ( \"_\" ) and key not in { \"self\" } } def render_template ( self , _template : str , ** context ): # TODO: want this to be positional-only; fallback here for pypy template = _template for key , value in self . default_render_context . items (): context . setdefault ( key , value ) context [ \"render_ctx\" ] = context return self . env . from_string ( template ) . render ( context ) def _render_object_fallback ( self , _obj , _option , ** context ): # TODO: want this to be positional-only; fallback here for pypy obj , option = _obj , _option if isinstance ( obj , typing . Sequence ) and not isinstance ( obj , str ): if all ( isinstance ( obj_idx , LoadContext ) for obj_idx in obj ): # Special-case FullLoadContext return \" \" . join ( str ( ctx ) for ctx in obj ) return \" \\n \" . join ( f \"[ { idx } ]: \" + textwrap . indent ( self . render_object ( obj_idx , _option , ** context ), ' ' ) . lstrip () for idx , obj_idx in enumerate ( obj ) ) if isinstance ( obj , typing . Mapping ): return \" \\n \" . join ( f '\" { key } \": ' + self . render_object ( value , _option , ** context ) for key , value in sorted ( obj . items ()) ) if dataclasses . is_dataclass ( obj ): cls = type ( obj ) if cls not in self . _fallback_formats : # TODO: lazy method here with 'fields' serialized = apischema . serialize ( obj ) fields = [ field . name for field in dataclasses . fields ( obj ) if field . name in serialized ] self . _fallback_formats [ cls ] = template_from_dataclass ( cls , fields , option or self . default_options ) return self . render_template ( self . _fallback_formats [ cls ], ** context ) return str ( obj ) def render_object ( self , _obj , _option = None , ** context ): # TODO: want this to be positional-only; fallback here for pypy obj , option = _obj , _option if option is None : option = self . default_options if dataclasses . is_dataclass ( obj ): for field in dataclasses . fields ( obj ): context . setdefault ( field . name , getattr ( obj , field . name )) context . setdefault ( \"obj\" , obj ) try : template = obj . _jinja_format_ [ option ] except ( AttributeError , KeyError ): ... else : return self . render_template ( template , ** context ) return self . _render_object_fallback ( obj , option , ** context ) def get_render_context ( self ) -> dict : \"\"\"Jinja template context dictionary - helper functions.\"\"\" context = { func . __name__ : func for func in self . helpers } return context","title":"FormatContext"},{"location":"utilities/#whatrecord.format.FormatContext-methods","text":"whatrecord . format . FormatContext . get_filters ( self , ** user_config ) All jinja filters. Source code in whatrecord/format.py def get_filters ( self , ** user_config ): \"\"\"All jinja filters.\"\"\" @pass_eval_context def title_fill ( eval_ctx , text , fill_char ): return fill_char * len ( text ) @pass_eval_context def classname ( eval_ctx , obj ): if inspect . isclass ( obj ): return obj . __name__ return type ( obj ) . __name__ @pass_eval_context def render_object ( eval_ctx , obj , option ): return self . render_object ( obj , option ) return { key : value for key , value in locals () . items () if not key . startswith ( \"_\" ) and key not in { \"self\" } } whatrecord . format . FormatContext . get_render_context ( self ) -> dict Jinja template context dictionary - helper functions. Source code in whatrecord/format.py def get_render_context ( self ) -> dict : \"\"\"Jinja template context dictionary - helper functions.\"\"\" context = { func . __name__ : func for func in self . helpers } return context","title":"Methods"},{"location":"utilities/#whatrecord.format-functions","text":"","title":"Functions"},{"location":"utilities/#whatrecord.format.template_from_dataclass","text":"Generate a console-friendly render template from a dataclass. Source code in whatrecord/format.py def template_from_dataclass ( cls , fields , render_option ): \"\"\"Generate a console-friendly render template from a dataclass.\"\"\" if not fields : return f \" { cls . __name__ } \\n \" name_length = max ( len ( name ) + 1 for name in fields ) field_text = \" \\n \" . join ( \"{ % i f \" + field + \" | string | length > 0 %} \\n \" + field . rjust ( name_length ) + \": { % s et field_text = render_object(\" + field + \", render_option) %}\" \"{{ field_text | indent(name_length + 2) }}\" \"{ % e ndif %} \\n \" for field in fields ) return ( f \" { cls . __name__ } : \\n \" f \" {{ % set name_length = { name_length } % }}\\n \" f \" {{ % set render_option = { render_option } % }}\\n \" + field_text )","title":"template_from_dataclass()"},{"location":"utilities/#whatrecord.graphql","text":"","title":"graphql"},{"location":"utilities/#whatrecord.settings","text":"","title":"settings"},{"location":"utilities/#whatrecord.util","text":"","title":"util"},{"location":"utilities/#whatrecord.util-functions","text":"","title":"Functions"},{"location":"utilities/#whatrecord.util.check_files_up_to_date","text":"Check if the provided files are up-to-date by way of recorded hash vs current hash. Parameters: Name Type Description Default file_to_hash Dict[Union[str, pathlib.Path], str] File path to hash. required Returns: Type Description bool If all files maintain their stored hashes, returns True. Source code in whatrecord/util.py def check_files_up_to_date ( file_to_hash : Dict [ AnyPath , str ] ) -> bool : \"\"\" Check if the provided files are up-to-date by way of recorded hash vs current hash. Parameters ---------- file_to_hash : Dict[Union[str, pathlib.Path], str] File path to hash. Returns ------- up_to_date : bool If all files maintain their stored hashes, returns True. \"\"\" for fn , file_hash in file_to_hash . items (): try : if get_file_sha256 ( fn ) != file_hash : return False except FileNotFoundError : return False return True","title":"check_files_up_to_date()"},{"location":"utilities/#whatrecord.util.find_binary_from_hashbang","text":"Find the binary associated with a given startup script by looking at its shebang. Returns: Type Description Optional[str] The path to the binary, if available. Source code in whatrecord/util.py def find_binary_from_hashbang ( startup_script : Optional [ Union [ str , pathlib . Path ]], must_exist : bool = False , ) -> Optional [ str ]: \"\"\" Find the binary associated with a given startup script by looking at its shebang. Returns ------- binary_path : str or None The path to the binary, if available. \"\"\" if startup_script is None : return None try : with open ( startup_script , \"rt\" ) as fp : first_line = fp . read () . splitlines ()[ 0 ] except Exception : return None if first_line . startswith ( \"#!\" ): parent_dir = pathlib . Path ( startup_script ) . parent binary = parent_dir / first_line . lstrip ( \"#!\" ) . strip () if not must_exist or binary . exists (): return str ( binary . resolve ())","title":"find_binary_from_hashbang()"},{"location":"utilities/#whatrecord.util.get_bytes_sha256","text":"Hash a byte string with the SHA-256 algorithm. Source code in whatrecord/util.py def get_bytes_sha256 ( contents : bytes ): \"\"\"Hash a byte string with the SHA-256 algorithm.\"\"\" return hashlib . sha256 ( contents ) . hexdigest ()","title":"get_bytes_sha256()"},{"location":"utilities/#whatrecord.util.get_file_sha256","text":"Hash a binary with the SHA-256 algorithm. Source code in whatrecord/util.py def get_file_sha256 ( binary : AnyPath ): \"\"\"Hash a binary with the SHA-256 algorithm.\"\"\" # This doesn't do any sort of buffering; but our binaries are pretty small # in comparison to what we're storing as metadata, anyway with open ( binary , \"rb\" ) as fp : return hashlib . sha256 ( fp . read ()) . hexdigest ()","title":"get_file_sha256()"},{"location":"utilities/#whatrecord.util.lines_between","text":"From a block of text, yield all lines between start_marker and end_marker Parameters: Name Type Description Default text str The block of text required start_marker str The block-starting marker to match required end_marker str The block-ending marker to match required include_blank bool Skip yielding blank lines False Returns: Type Description Generator[str, NoneType, NoneType] Line of text found between the markers. Source code in whatrecord/util.py def lines_between ( text : str , start_marker : str , end_marker : str , * , include_blank : bool = False ) -> Generator [ str , None , None ]: \"\"\" From a block of text, yield all lines between `start_marker` and `end_marker` Parameters ---------- text : str The block of text start_marker : str The block-starting marker to match end_marker : str The block-ending marker to match include_blank : bool, optional Skip yielding blank lines Yields ------ line : str Line of text found between the markers. \"\"\" found_start = False start_marker = start_marker . lower () end_marker = end_marker . lower () for line in text . splitlines (): line_lowercase = line . strip () . lower () if line_lowercase == start_marker : found_start = True elif found_start : if line_lowercase == end_marker : break elif line_lowercase or include_blank : yield line","title":"lines_between()"},{"location":"utilities/#whatrecord.util.read_text_file_with_hash","text":"Hash a binary with the SHA-256 algorithm. Source code in whatrecord/util.py def read_text_file_with_hash ( fn : pathlib . Path , encoding = \"latin-1\" , ) -> Tuple [ str , str ]: \"\"\"Hash a binary with the SHA-256 algorithm.\"\"\" # This doesn't do any sort of buffering; but our binaries are pretty small # in comparison to what we're storing as metadata, anyway with open ( fn , \"rb\" ) as fp : contents = fp . read () sha256 = hashlib . sha256 ( contents ) . hexdigest () return sha256 , contents . decode ( encoding )","title":"read_text_file_with_hash()"},{"location":"utilities/#whatrecord.util.run_gdb","text":"Run a script and deserialize its output. Parameters: Name Type Description Default script str The script name to run (whatrecord. script , omitting .py) required binary Union[pathlib.Path, str] The binary file to load into GDB. required cls ~T The dataclass type to deserialize gdb's output to. required args Optional[List[str]] List of string arguments to pass to gdb. None gdb_path Optional[str] The path to the gdb binary. Defaults to WHATRECORD_GDB_PATH from the environment ( gdb ). None Source code in whatrecord/util.py async def run_gdb ( script : str , binary : Union [ pathlib . Path , str ], cls : T , args : Optional [ List [ str ]] = None , gdb_path : Optional [ str ] = None , use_cache : bool = True , ) -> T : \"\"\" Run a script and deserialize its output. Parameters ---------- script : str The script name to run (whatrecord.__script__, omitting .py) binary : str or pathlib.Path The binary file to load into GDB. cls : type The dataclass type to deserialize gdb's output to. args : list, optional List of string arguments to pass to gdb. gdb_path : str, optional The path to the gdb binary. Defaults to ``WHATRECORD_GDB_PATH`` from the environment (``gdb``). \"\"\" cache_path = pathlib . Path ( settings . CACHE_PATH ) binary_hash = get_file_sha256 ( binary ) hash_filename = cache_path / f \" { script } _ { cls . __name__ } _ { binary_hash } .json\" if use_cache : if not settings . CACHE_PATH or not cache_path . exists (): use_cache = False else : try : with open ( hash_filename , \"rt\" ) as fp : json_data = json . load ( fp ) return apischema . deserialize ( cls , json_data ) except FileNotFoundError : ... except Exception as ex : logger . warning ( \"Failed to load cached gdb information from disk; \" \"re-running gdb ( %s , filename= %s )\" , ex , hash_filename , exc_info = True ) args = \" \" . join ( f '\" { arg } \"' for arg in args or []) script_path = MODULE_PATH / \"plugins\" / f \" { script } .py\" gdb_path = gdb_path or settings . GDB_PATH to_execute = ( f '\" { gdb_path } \" ' f \"--batch-silent \" f '--command \" { script_path } \" ' f '--args \" { binary } \" { args } ' ) json_data = await run_script_with_json_output ( to_execute ) json_data = json_data or {} if use_cache : with open ( hash_filename , \"wt\" ) as fp : json . dump ( json_data , fp , indent = 4 ) try : return apischema . deserialize ( cls , json_data ) except Exception as ex : ex . json_data = json_data raise","title":"run_gdb()"},{"location":"utilities/#whatrecord.util.run_script_with_json_output","text":"Run a script and get its JSON output. Source code in whatrecord/util.py async def run_script_with_json_output ( script_line : str , encoding : str = \"utf-8\" , log_errors : bool = True , ) -> Optional [ dict ]: \"\"\"Run a script and get its JSON output.\"\"\" proc = await asyncio . create_subprocess_shell ( script_line , stdout = asyncio . subprocess . PIPE , stderr = asyncio . subprocess . PIPE ) ( stdout , stderr ) = await proc . communicate () if stderr and log_errors : stderr_text = textwrap . indent ( stderr . decode ( \"utf-8\" , \"replace\" ), \" ! \" ) logger . warning ( \"Standard error output while running script ( %r ): \\n %s \" , script_line , stderr_text ) if stdout : return json . loads ( stdout . decode ( encoding )) if log_errors : logger . warning ( \"No standard output while running script ( %r )\" , script_line )","title":"run_script_with_json_output()"}]}